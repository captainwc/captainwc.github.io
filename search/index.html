
<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title> | SHUAIKAI&#39;s Blog</title>
    <link rel="icon" href= /images/favicon.png />
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">主页</a></li>
      
      <li><a href="/series/">专栏</a></li>
      
      <li><a href="/categories/">分类</a></li>
      
      <li><a href="/tags/">标签</a></li>
      
      <li><a href="/archives/">归档</a></li>
      
      <li><a href="/search/">搜索</a></li>
      
      <li><a href="/about/">关于</a></li>
      
    </ul>
    <hr/>
    </nav>

<p style="margin: 1.8rem 0 -1rem 0; color: #191919;">可以根据标题、分类、标签、系列等条目检索本站文章</p>

<div class="search-container">
  <input type="text" id="search-input" placeholder="输入关键词搜索..." aria-label="搜索框" autocomplete="off">
  <div id="search-debug" style="margin-bottom: 10px; color: #999;"></div>
  <div id="search-results"></div>
</div>


<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.6.2"></script>


<script>
  
  function debug(text) {
    document.getElementById('search-debug').textContent = text;
  }

  
  let searchIndex = [];

  
  
  
    
  

  debug("索引初始化中...");

  
    searchIndex.push({
      title: "\"面向模式的软件架构 卷1 模式系统 读书笔记\"",
      permalink: "\"/%E7%AC%94%E8%AE%B0/%E9%9D%A2%E5%90%91%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84%E5%8D%B71%E6%A8%A1%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/\"",
      content: "\"《面向模式的软件架构 卷1：模式系统》读书笔记 概览 本书不仅仅是模式的目录，更是一套模式系统。模式（Pattern）是记录专家经验、解决特定设计问题的规范化方法。学习这些模式，能让我跳过多年的试错过程，直接站在巨人的肩膀上，构建出具备高可修改性、可重用性和可靠性的软件系统。本书提供的架构模式、设计模式和成例，分别从宏观结构、局部设计和语言细节三个层面提供了指导。\\n第1章 模式（Patterns） 本章系统地介绍了模式的概念和描述模式的原则。\\n概念 总结与理解 模式是什么 模式是对在特定情境下，某个反复出现的问题的解决方案的描述，它详细说明了如何解决问题、为什么解决以及该方案的优缺点。模式不是最终的代码，而是抽象的设计智慧。 模式的分类 模式分为三个抽象层次：架构模式 (Architectural Patterns)（最高层，提供系统骨架），设计模式 (Design Patterns)（中层，解决常见设计问题），成例 (Idioms)（最低层，语言特定的模式）。 模式之间的关系 模式并非孤立，它们相互关联、协作。一个架构模式可以由多个设计模式实现，一个设计模式的实现可能依赖于特定的成例。理解这种关系是构建模式系统的关键。 第2章 架构模式（Architectural Patterns） 架构模式是最高层的模式，旨在提供系统架构的整体骨架，决定了整个系统的组织结构和高层特性。\\n2.2 从混乱到有序 2.2.1 Layers 模式（分层） 总结项 内容 模式总结/定义 一种将应用程序划分为多组子任务的结构化方式，其中每组子任务都位于特定抽象层。 解决问题 管理复杂的系统结构，实现关注点分离，提升系统的可修改性、可维护性和可重用性。 模式架构 系统被组织成一组抽象层级（Layer J），第J+1层只使用第J层的服务。这种单向依赖关系保证了层级的清晰性。 优缺点总结 优点: 职责分离清晰，易于替换和修改特定层的实现，支持增量开发。 缺点: 严格分层可能导致不必要的层间通信开销（性能损耗）；难以确定合适的抽象层级。 可能的应用方向 几乎所有大型软件系统，尤其是网络协议栈（如TCP/IP）、操作系统和企业级应用的三层/多层架构。 2.2.2 Pipes and Filters 模式（管道与过滤器） 总结项 内容 模式总结/定义 一种适用于处理数据流的系统结构，将任务分解为一系列独立、顺序处理数据的单元。 解决问题 应对数据处理流程中对灵活性、可重用性、可维护性和易于理解的要求。 模式架构 由过滤器（Filters） 和 管道（Pipes） 组成。过滤器是独立的、处理输入流并产生输出流的组件。管道负责连接过滤器，传输数据流。 优缺点总结 优点: 组件高度解耦，可重用性极强；易于通过添加、替换或重新排列过滤器来修改处理流程。 缺点: 仅限于数据流处理系统；数据格式约定是挑战；难以处理交互式或流式处理不适用的情况。 可能的应用方向 编译器前端（词法分析、语法分析），ETL（抽取、转换、加载）工具，UNIX Shell命令链。 2.2.3 Blackboard 模式（黑板） 总结项 内容 模式总结/定义 一种用于解决没有明确解决策略的复杂问题的模式，多个专业子系统通过集思广益，逐步逼近可能的部分解。 解决问题 解决问题领域知识分散、且缺乏确定性算法的复杂问题。 模式架构 包含三个主要组件：黑板 (Blackboard)（集中存储问题、部分解和推测），知识源 (Knowledge Sources)（专用子系统，对黑板状态变化做出反应），控制组件 (Control)（驱动推理过程，决定知识源的执行顺序）。 优缺点总结 优点: 适合启发式问题求解和实验性系统；高度模块化，易于添加新的知识源。 缺点: 黑板可能成为性能瓶颈；知识源之间的协作逻辑（控制组件）复杂难设计。 可能的应用方向 语音识别，模式识别，AI专家系统，机器人控制。 2.3 分布式系统 Broker 模式（中间人） 总结项 内容 模式总结/定义 用于设计包含通过远程服务调用交互的组件的分布式软件系统。 解决问题 应对分布式系统中客户端和服务端的解耦、位置透明性以及通信协议的隐藏。 模式架构 中间人 (Broker) 负责协调组件间的通信。主要组件包括客户端、服务器、中间人、客户端代理和服务器端代理。中间人利用名称服务实现位置透明。 优缺点总结 优点: 客户端无需知道服务的位置，实现了高度的位置透明性；解耦客户端和服务端，提高了系统的可扩展性。 缺点: 引入了额外的中间层，增加了通信延迟；中间人本身可能成为性能瓶颈或单点故障。 可能的应用方向 CORBA/COM等分布式对象系统，面向服务的架构 (SOA)，微服务架构中的服务注册与发现。 2.4 交互式系统 2.4.1 Model-View-Controller 模式（MVC） 总结项 内容 模式总结/定义 将交互式应用程序划分为三个组件：核心功能、表示和控制。 解决问题 将用户界面（表示和控制）与业务逻辑（核心功能）分离，提高系统的可修改性和可重用性。 模式架构 模型 (Model) (封装业务数据和逻辑)；视图 (View) (展示数据)；控制器 (Controller) (处理用户输入)。视图通过Publisher-Subscriber模式观察模型变化，确保同步。 优缺点总结 优点: 职责分离清晰，易于修改和扩展用户界面；支持同一模型拥有多个视图。 缺点: 增加了系统的复杂性（引入了许多类）；视图和控制器有时耦合较紧密。 可能的应用方向 桌面GUI应用，Web应用程序框架（许多Web MVC框架是变体）。 2.4.2 Presentation-Abstraction-Control 模式（PAC） 总结项 内容 模式总结/定义 定义了一种适用于交互式软件系统的结构，由相互协作的智能体（Agents） 组成的层次结构。 解决问题 解决MVC模式在大型、复杂、需要多层次控制和协调的交互式系统中的扩展性问题。 模式架构 每个智能体都包含：表示 (Presentation)、抽象 (Abstraction) (功能核心) 和 控制 (Control) (通信和协调)。控制组件是智能体通信的枢纽。 优缺点总结 优点: 层次化和模块化程度更高，更适合复杂的系统；更好的关注点分离。 缺点: 比MVC更复杂，理解和实现难度更高；智能体间的通信和协调逻辑复杂。 可能的应用方向 复杂的图形用户界面，具有多层交互和协调的系统。 2.5 可适应系统 2.5.1 Microkernel 模式（微核） 总结项 内容 模式总结/定义 适用于必须能够适应需求不断变化的系统，将最基本的功能核心与扩展功能分离。 解决问题 应对核心系统需要高适应性、可扩展性，并支持多种定制化需求的问题。 模式架构 微核 (Microkernel) 位于最底层，只提供最小的必要核心功能。扩展功能则作为外部服务器 (External Servers) 运行，通过微核提供的机制进行协作。微核充当插座。 优缺点总结 优点: 扩展性高，适应性强；系统故障隔离性好（服务器间的独立性）；易于移植。 缺点: 由于功能大部分在微核外，需要大量的进程间通信（IPC），可能造成性能损耗。 可能的应用方向 操作系统（如Linux、Windows NT的早期设计），产品线架构，插件式应用框架。 2.5.2 Reflection 模式（反射） 总结项 内容 模式总结/定义 提供了一种动态修改软件系统的结构和行为的机制。 解决问题 系统需要极高的运行时适应性和可配置性，允许系统在运行时检查并修改自身的结构和行为。 模式架构 由基层 (Base Level) 和 元层 (Meta Level) 组成。基层包含应用逻辑，元层包含关于基层的元信息（如类型、函数调用机制），元层提供了检查和修改基层的接口。 优缺点总结 优点: 极高的动态适应性；能够实现高级、复杂的运行时行为（如动态配置、AOP）。 缺点: 极大地增加了系统的复杂性；运行时修改可能引入难以预料的错误；性能开销大。 可能的应用方向 动态语言运行时，面向方面的编程（AOP），软件配置管理系统。 第3章 设计模式（Design Patterns） 设计模式在架构模式的框架下，解决了软件系统局部结构和协作方面的常见问题。\\n模式名称 解决了什么问题 模式架构总结 优缺点/应用方向 Whole-Part (3.2) 将组件聚合成一个语义整体。 定义了整体 (Whole) 组件如何管理一个或多个部分 (Part) 组件的生命周期和关系。 应用方向: 复合文档、UI控件组。 优点: 封装了复杂性，明确了聚合关系。 Master-Slave (3.3) 提高计算的并行性、准确度和容错性。 主组件 (Master) 分配工作给多个相同的从组件 (Slave)，并汇总从组件的结果。 应用方向: 并行计算、容错系统、分布式计算。 优点: 提高性能和系统可靠性。 Proxy (3.4) 控制对对象的访问，提供代表而非组件本身通信。 代理 (Proxy) 对象与实际主题 (Real Subject) 实现相同接口，客户端通过代理访问实际主题。 应用方向: 远程代理（RPC），虚拟代理（延迟加载），保护代理（访问控制）。 优点: 提高效率，简化访问，保护实际对象。 Command Processor (3.5.1) 将服务的请求和执行分离，支持额外的服务，如撤销/重做。 命令处理器 (Command Processor) 管理封装请求的命令对象 (Command Object) 列表。 应用方向: 编辑器中的操作历史，事务管理。 优点: 支持撤销/重做功能，请求发送者与执行者解耦。 View Handler (3.5.2) 管理软件系统提供的所有视图，协调视图间依赖关系和更新。 视图处理器 (View Handler) 集中管理视图 (Views) 的创建、销毁和协调更新。 应用方向: 多窗口/多面板GUI应用，IDE。 优点: 简化了视图管理和协调，保证一致性。 Forwarder-Receiver (3.6.1) 实现透明的进程间通信（IPC）。 通过引入转发者 (Forwarder) 和 接收者 (Receiver) 将对等体与底层通信机制解耦。 应用方向: 分布式系统中的对等通信。 优点: 实现了通信透明性，解耦了通信细节。 Client-Dispatcher-Server (3.6.2) 提供位置透明性，并隐藏建立通信连接的细节。 在客户端和服务器之间添加分派器 (Dispatcher)，利用名称服务定位服务器并转发请求。 应用方向: 分布式服务定位，RPC系统。 优点: 位置透明性，隐藏通信细节。 Publisher-Subscriber (3.6.3) 帮助相互协作的组件状态保持同步。 发布者维护并通知所有订阅者其状态变更。 应用方向: 事件驱动系统，MVC模式中模型与视图的同步。 优点: 对象间松耦合，支持广播通信。 第4章 成例（Idioms） 成例是最低抽象层次的模式，通常是语言特定的编程技巧。\\nCounted Pointer（引用计数指针，C++成例） 总结项 内容 模式总结/定义 一种C++编程成例，用于简化动态分配的共享对象的内存管理。 解决问题 避免在C++中使用裸指针进行动态分配的共享对象时，容易出现的内存泄漏和多重删除问题。 模式架构 句柄类 (Handle) 作为用户接口，内部包含指向实体类 (Body) 的指针。实体类中嵌入了一个引用计数。句柄的构造、赋值、复制和析构操作自动维护引用计数。 优缺点总结 优点: 实现了自动内存管理，简化了C++中共享对象的生命周期管理；避免了不必要的复制，提高了效率。 缺点: 引入了额外的引用计数开销；无法解决循环引用问题。 可能的应用方向 C++中任何需要共享和自动管理资源（如大型对象、句柄）的场景，类似于现代C++中的 std::shared_ptr 的思想。 总结与体会 这本书系统地介绍了从宏观架构到微观实现的模式，为我打开了软件架构的大门。特别是理解架构模式，让我明白了如何从一开始就规划系统的整体结构（如选择Layers来划分职责或选择Broker来处理分布式问题），这是初级工程师向高级进阶的必经之路。未来的工作中，我将努力在具体设计中识别和应用这些模式，并通过实践深入理解每个模式的优缺点和权衡取舍，避免“为了模式而模式”。\\n\"",
      categories: "[\"读书笔记\",\"软件工程\"]",
      tags: "[\"设计模式\"]",
      series: "[\"软件架构之道\"]",
      date: "\"2025-12-04\""
    });
  
    searchIndex.push({
      title: "\"链接符号与符号导入导出宏——记一次因clangd补全头文件产生的链接错误\"",
      permalink: "\"/cpp/%E9%93%BE%E6%8E%A5%E7%AC%A6%E5%8F%B7%E5%AF%BC%E5%87%BA%E4%B8%8E%E7%AC%A6%E5%8F%B7%E5%8F%AF%E8%A7%81%E5%AE%8F/\"",
      content: "\"问题描述 在写一个demo项目的过程中，重构了一个从yaml中读取配置项的类，将它的单例模式从直接实现改为从模板中继承、以及将yaml文件加载等异常处理抽象到一个基类上。但就是这么明确的改动，居然导致，原本可以跑起来的代码，出现了链接错误！\\nTldr undefined reference to 'YAML::Node::IsDefined() const'，符号未定义，是yaml-cpp库链接出现的问题\\nC:\\\\WINDOWS\\\\system32\\\\cmd.exe /C \\u0026quot;cd . \\u0026amp;\\u0026amp; D:\\\\env\\\\msys2\\\\mingw64\\\\bin\\\\g++.exe -w -g -lstdc++exp CMakeFiles/app.dir/src/main.cpp.obj -o bin\\\\app.exe -Wl,--out-implib,bin\\\\libapp.dll.a -Wl,--major-image-version,0,--minor-image-version,0 D:/env/msys2/opt/vcpkg/installed/x64-mingw-static/debug/lib/libyaml-cppd.a -lws2_32 -lmswsock -lkernel32 -luser32 -lgdi32 -lwinspool -lshell32 -lole32 -loleaut32 -luuid -lcomdlg32 -ladvapi32 \\u0026amp;\\u0026amp; C:\\\\WINDOWS\\\\system32\\\\cmd.exe /C \\u0026quot;cd /D D:\\\\test\\\\crowserver\\\\build \\u0026amp;\\u0026amp; C:\\\\Users\\\\wddjwk\\\\scoop\\\\apps\\\\cmake\\\\3.31.7\\\\bin\\\\cmake.exe -E copy D:/test/crowserver/src/config.yaml D:/test/crowserver/build/bin/config.yaml\\u0026quot;\\u0026quot; D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles/app.dir/src/main.cpp.obj: in function `YAML::Node::operator bool() const': D:/env/msys2/opt/vcpkg/installed/x64-mingw-static/include/yaml-cpp/node/node.h:61:(.text$_ZNK4YAML4NodecvbEv[_ZNK4YAML4NodecvbEv]+0x14): undefined reference to `YAML::Node::IsDefined() const' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles/app.dir/src/main.cpp.obj: in function `YamlParser::YamlParser(std::__cxx11::basic_string\\u0026lt;char, std::char_traits\\u0026lt;char\\u0026gt;, std::allocator\\u0026lt;char\\u0026gt; \\u0026gt; const\\u0026amp;)': D:/test/crowserver/src/config.h:18:(.text$_ZN10YamlParserC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE[_ZN10YamlParserC2ERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE]+0x6f): undefined reference to `YAML::Node::operator=(YAML::Node const\\u0026amp;)' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles/app.dir/src/main.cpp.obj: in function `int YamlParser::GetOrDefault\\u0026lt;int\\u0026gt;(char const*, int)': D:/test/crowserver/src/config.h:29:(.text$_ZN10YamlParser12GetOrDefaultIiEET_PKcS1_[_ZN10YamlParser12GetOrDefaultIiEET_PKcS1_]+0x44): undefined reference to `YAML::Node YAML::Node::operator[]\\u0026lt;char const*\\u0026gt;(char const* const\\u0026amp;)' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: D:/test/crowserver/src/config.h:30:(.text$_ZN10YamlParser12GetOrDefaultIiEET_PKcS1_[_ZN10YamlParser12GetOrDefaultIiEET_PKcS1_]+0x83): undefined reference to `YAML::Node YAML::Node::operator[]\\u0026lt;char const*\\u0026gt;(char const* const\\u0026amp;)' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: D:/test/crowserver/src/config.h:30:(.text$_ZN10YamlParser12GetOrDefaultIiEET_PKcS1_[_ZN10YamlParser12GetOrDefaultIiEET_PKcS1_]+0x8f): undefined reference to `int YAML::Node::as\\u0026lt;int\\u0026gt;() const' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: CMakeFiles/app.dir/src/main.cpp.obj: in function `std::__cxx11::basic_string\\u0026lt;char, std::char_traits\\u0026lt;char\\u0026gt;, std::allocator\\u0026lt;char\\u0026gt; \\u0026gt; YamlParser::GetOrDefault\\u0026lt;std::__cxx11::basic_string\\u0026lt;char, std::char_traits\\u0026lt;char\\u0026gt;, std::allocator\\u0026lt;char\\u0026gt; \\u0026gt; \\u0026gt;(char const*, std::__cxx11::basic_string\\u0026lt;char, std::char_traits\\u0026lt;char\\u0026gt;, std::allocator\\u0026lt;char\\u0026gt; \\u0026gt;)': D:/test/crowserver/src/config.h:29:(.text$_ZN10YamlParser12GetOrDefaultINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEET_PKcS7_[_ZN10YamlParser12GetOrDefaultINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEET_PKcS7_]+0x4b): undefined reference to `YAML::Node YAML::Node::operator[]\\u0026lt;char const*\\u0026gt;(char const* const\\u0026amp;)' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: D:/test/crowserver/src/config.h:30:(.text$_ZN10YamlParser12GetOrDefaultINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEET_PKcS7_[_ZN10YamlParser12GetOrDefaultINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEET_PKcS7_]+0x8a): undefined reference to `YAML::Node YAML::Node::operator[]\\u0026lt;char const*\\u0026gt;(char const* const\\u0026amp;)' D:/env/msys2/mingw64/bin/../lib/gcc/x86_64-w64-mingw32/15.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: D:/test/crowserver/src/config.h:30:(.text$_ZN10YamlParser12GetOrDefaultINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEET_PKcS7_[_ZN10YamlParser12GetOrDefaultINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEEET_PKcS7_]+0x9d): undefined reference to `std::__cxx11::basic_string\\u0026lt;char, std::char_traits\\u0026lt;char\\u0026gt;, std::allocator\\u0026lt;char\\u0026gt; \\u0026gt; YAML::Node::as\\u0026lt;std::__cxx11::basic_string\\u0026lt;char, std::char_traits\\u0026lt;char\\u0026gt;, std::allocator\\u0026lt;char\\u0026gt; \\u0026gt; \\u0026gt;() const' collect2.exe: error: ld returned 1 exit status ninja: build stopped: subcommand failed. mingw32-make: *** [makefile:2: compile] Error 1 原因分析 过程不再赘述了，是一个很曲折的过程。因为，很难想象我的改动会导致什么链接错误。或许单例模式会沾点边，但是我用的是一个久经验证的模板单例\\n// Don't forget add `friend class Singleton\\u0026lt;T\\u0026gt;;` to your class. template \\u0026lt;typename T\\u0026gt; class Singleton : public Noncopyable { public: static T\\u0026amp; Instance() { static T instance; return instance; } protected: Singleton() = default; virtual ~Singleton() = default; }; 问题出错的点在于\\nBug 在补全yaml-cpp库的代码时，clangd自动为我引入了头文件，比如#include \\u0026lt;yaml-cpp/node/parse.h\\u0026gt; 既然是重构，看到clangd提示未使用的头文件，yaml-cpp/yaml.h，一时兴起，给它删了 而yaml-cpp/yaml.h这个总入口文件的缺失，直接导致了yaml-cpp/dll.h这个定义了YAML_CPP_API符号导入导出宏的文件缺失了 于是更进一步，我在编译代码时YAML_CPP_API宏没有按照预期展开为__declspec(dllimport) 最终，导致链接阶段符号未定义错误 还有个细节，其实我是用的mingw编译，链接的静态库，但是仍然碰到了符号导入导出的问题。这个是mingw编译环境太复杂了的缘故，它的静态库也会设计这个概念！ 所以要想解决这个问题也很简单\\nNote 以后使用这种库时，注意要引用人家给你定义好的入口头文件！\\n下面是更详细的分析与记录，如果没明白这个场景的读者可以继续往下看\\n什么是符号导入导出宏？ 考虑一个动态库的编译和使用的整个过程与场景：\\n库编译阶段\\n编译代码为库文件时，你要告诉编译器，哪些符号是需要添加到导出符号表的。这个可以由MSVC的__declspec(dllexport)或者GCC的__attribute__((visibility(\\u0026quot;default\\u0026quot;)))来完成\\n库使用阶段\\n使用库时，你的源码只包含了你使用的库的头文件和你自己的源码，不包含库的实现。你需要告诉编译器，这些函数和类是我要导入 (Import) 的，它们不在这里，它们在某个外部的DLL里。请帮我生成特殊的‘存根代码，以便程序运行时能正确地找到它们。而这个是由MSVC的__declspec(dllimport)来完成\\n跨平台的场景\\n在Windows平台的DLL动态库上，默认所有符号都是不导出的，你必须要有导出的逻辑才能使用 在linux平台的SO动态库上，所有符号默认都是导出的，你可能需要显示隐藏一些符号，来保证源码的安全性，或者获得一些链接时优化 符号导入导出宏就是干这个的！下面是一个比较经典的导入导出宏定义，基本上所有的也都是这么个模式。比如yaml-cpp，再比如ePromisa的fastdds等等，跨平台的代码到处都会见到这种写法\\n#pragma once // MY_LIB_API - 用于公开的类和函数 // MY_LIB_PRIVATE - 用于隐藏的、仅内部实现的符号 (在Linux/macOS上很有用) // // 关键的 \\u0026quot;开关\\u0026quot; 宏: // 1. MY_LIB_BUILDING_DLL - 当我们*正在编译*这个库(DLL)时，由构建系统(CMake)定义。 // 2. MY_LIB_STATIC_DEFINE - 当我们*要静态链接*这个库时，由构建系统(CMake)定义。 #if defined(_WIN32) || defined(__CYGWIN__) // ------------------- Windows ------------------- #ifdef MY_LIB_STATIC_DEFINE // 场景1：静态链接。不需要导入/导出。 #define MY_LIB_API #define MY_LIB_PRIVATE #else // 场景2：动态链接 (DLL) #ifdef MY_LIB_BUILDING_DLL // 2a. 正在构建DLL：导出 (Export) #define MY_LIB_API __declspec(dllexport) #else // 2b. 正在使用DLL：导入 (Import) #define MY_LIB_API __declspec(dllimport) #endif #define MY_LIB_PRIVATE // 在Windows上，默认就是隐藏的 #endif #elif __GNUC__ \\u0026gt;= 4 // ------------------- Linux / macOS (GCC/Clang) ------------------- // GCC 4.0+ 支持 'visibility' 属性 #ifdef MY_LIB_STATIC_DEFINE // 场景1：静态链接。 #define MY_LIB_API #define MY_LIB_PRIVATE #else // 场景2：动态链接 (SO) // 注意：Linux的逻辑和Windows相反。默认所有符号都是导出的。 // 'default' (导出) 和 'hidden' (隐藏) 是为了优化。 #define MY_LIB_API __attribute__((visibility(\\u0026quot;default\\u0026quot;))) #define MY_LIB_PRIVATE __attribute__((visibility(\\u0026quot;hidden\\u0026quot;))) #endif #else // ------------------- 其他不支持的编译器 ------------------- #define MY_LIB_API #define MY_LIB_PRIVATE #endif 错误全过程分析 就以这个IsDefined函数为例：\\nParse 0 库编译阶段：\\n在编译代码时，yaml-cpp的CMake文件中，会定义一个yaml_cpp_EXPORTS宏，进而导致YAML_CPP_API这个宏展开为__declspec(dllexport)，IsDefined() 函数被标记为 __declspec(dllexport) (导出)。编译器会生成这个函数的机器码，并给它贴上一个“我是导出的，供外部链接使用”的特殊标签，然后放进库文件中\\nParse 1 我的代码编译阶段\\n预期的正确情况：\\n由于我不会定义yaml_cpp_EXPORTS这个宏，最终我的代码里面，YAML_CPP_API会被展开为，__declspec(dllimport)，然后编译器说OK，这个函数被标记为 dllimport，意味着它不在本地，它的实体远在天边（在某个库里）。所以编译器不会尝试自己实现它，而是会在 main.cpp.obj 文件的外部符号列表里记下一笔：我需要一个**‘导入版’**的 IsDefined 函数\\n实际的错误情况：\\n由于我压根没导入yaml-cpp/dll.h这个文件，也就没有定义那一堆符号导入导出宏，所以我的YAML_CPP_API是空的，它并没有把IsDefined函数定义为import，这个时候，编译器会说OK，这是一个普通函数。我先假定它的实现在别的某个 .obj 文件或库里，然后再它的外部符号表里记录了，这里需要一个普通的符号。结果等链接完了发现，没找到这个符号！！（因为实际上它在动态库里）所以就产生符号未定义错误了\\n本质上是 main.cpp.obj 在“索要”一个普通函数，而 libyaml-cppd.a 却在“提供”一个带特殊标记（导出/导入）的函数。链接器认为这两者不是同一个东西，于是报告“未定义的引用”。\\nQA Q1. 为什么链接静态库 (.a) 还要管这个宏？ 这是最关键的问题。你又说对了：纯粹的静态链接（把 .obj 打包成 .a，再解包合并到 .exe）确实不涉及导入/导出的概念。\\n那么，为什么你的 yaml-cpp（一个 .a 静态库）链接会失败？\\n答案是：你（和 vcpkg）构建的环境很复杂，这个 yaml-cpp 库很可能不是一个“纯粹”的静态库。\\n我们来分析两种最可能导致你出错的场景：\\n场景 A (最可能)：符号命名不匹配 (Import/Export Mismatch) 你用的是 MinGW (g++) on Windows。这个环境必须同时能处理 Windows 的 DLL 和 Linux 的 .a 库。\\nvcpkg 如何构建 libyaml-cppd.a？ vcpkg 的构建脚本非常智能。它在构建 yaml-cpp 时，为了让这个库既可以用于静态链接，也可能用于动态链接，它很可能在编译时定义了 YAML_CPP_BUILDING_DLL。 结果：yaml-cpp 的所有 .cpp 文件在编译时，YAML_CPP_API 展开为 __declspec(dllexport)。 关键点：当 MinGW g++ 看到 dllexport，它会给函数符号一个特殊的“修饰名”，我们姑且称之为 _export_IsDefined。 这个 _export_IsDefined 符号被编译并存储在 libyaml-cppd.a 中。 你的 main.cpp 如何编译？(错误方式) 你包含了 node/node.h (内部头文件)。 这个头文件没有 YAML_CPP_API 宏。 你的代码调用 IsDefined()，编译器生成了一个对**“普通”函数**的引用，其修饰名为 _normal_IsDefined。 链接器 ld.exe 工作： 你的需求 (main.cpp.obj): \\u0026ldquo;我需要一个叫 _normal_IsDefined 的函数。\\u0026rdquo; 库的供给 (libyaml-cppd.a): \\u0026ldquo;我只有一个叫 _export_IsDefined 的函数。\\u0026rdquo; 链接器: \\u0026ldquo;找不到匹配项！\\u0026rdquo; -\\u0026gt; undefined reference 如何修复？ (正确方式) 你包含了 yaml.h (公共头文件)。 这个头文件正确设置了宏。它发现你没有定义 YAML_CPP_BUILDING_DLL，于是它将 YAML_CPP_API 定义为 __declspec(dllimport)。 你的代码调用 IsDefined()，编译器看到 dllimport，它生成了一个对**“导入”函数**的引用，其修饰名为 _import_IsDefined。 链接器 ld.exe 再次工作： 你的需求: \\u0026ldquo;我需要 _import_IsDefined。\\u0026rdquo; 库的供给: \\u0026ldquo;我有 _export_IsDefined。\\u0026rdquo; 链接器 (MinGW 特有): \\u0026ldquo;啊哈！我知道 _import_ 和 _export_ 是一对儿！它们是匹配的！\\u0026rdquo; -\\u0026gt; 链接成功。 小结：即使是静态库 .a，如果它在编译时被 dllexport \\u0026ldquo;污染\\u0026quot;了（这在复杂的构建系统中很常见），它内部的符号名就和“普通”的符号名不再匹配了。你必须使用那个能生成 dllimport 的公共头文件来匹配这些符号。\\n场景 B (也有可能)：inline 不匹配 头文件的另一个“诡计”是 inline。\\nnode/node.h (内部) 可能这样声明：\\nbool IsDefined() const; // 这是一个外部函数，需要链接\\nyaml.h (公共) 可能这样声明：\\ninline bool IsDefined() const { /* \\u0026hellip; 实现 \\u0026hellip; */ } // 这是一个内联函数，不需要链接\\n如果发生这种情况：\\n你包含 node/node.h，编译器为你生成一个外部引用，要求链接器提供 IsDefined。 但 libyaml-cppd.a 是用 yaml.h 编译的，IsDefined 函数已经被内联到所有调用它的地方了，库里根本没有一个单独编译的 IsDefined 符号。 链接器: \\u0026ldquo;你要的 IsDefined，库里根本没有！\\u0026rdquo; -\\u0026gt; undefined reference Q2. 为什么有了 private 还要 MY_LIB_PRIVATE 符号导入导出宏那个文件，其实还定义了一个MY_LIB_PRIVATE宏，MY_LIB_API用来描述这是一个公共的api，而它则标识这是一个需要被隐藏的api。但是隐藏的话，我直接写成private的，外部不就访问不到了吗，为什么还需要整这个宏呢？\\nC++ 的 private: 关键字在编译时阻止了外部代码访问这个成员。my_app.exe 的代码如果试图调用一个 private 成员，根本无法通过编译。\\nMY_LIB_PRIVATE 解决的是一个完全不同层面的问题：链接时和运行时的二进制符号可见性。\\nC++ private：\\n谁在用：C++ 编译器。 目的：实现 C++ 语言的封装性。 作用：在编译期阻止你 编写 调用的代码。 MY_LIB_PRIVATE (即 __attribute__((visibility(\\u0026quot;hidden\\u0026quot;)))):\\n谁在用：链接器 (Linker) 和 动态加载器 (Dynamic Loader)。 目的：实现二进制优化和二进制封装。 作用：在链接期告诉链接器：“不要把这个函数/符号放到库的公共导出表里。” 为什么这个“隐藏”很重要？\\n这在 Linux/macOS (.so 文件) 上尤为重要，在 Windows (.dll) 上则相反。\\n在 Linux/macOS (GCC/Clang)： 默认行为：导出所有符号。是的，默认情况下，你编译的 .so 库会把你所有的（非static）函数，包括 private 成员函数，都作为公共符号导出。 风险：一个恶意的（或无知的）用户可以通过 dlsym 等底层函数在运行时“手动”查找到你那个 private 函数的地址并强行调用它，完全绕过了 C++ 的 private 限制。 MY_LIB_PRIVATE 的作用：visibility(\\u0026quot;hidden\\u0026quot;) 告诉链接器：“把这个符号从公共列表中拿掉”。这提供了真正的二进制封装。 最重要的：优化。当链接器知道一个函数是 hidden 的，它就确定了“这个函数绝对不会被这个 .so 之外的任何代码调用”。这解锁了海量的优化，比如： 更激进的内联 (Inlining)：编译器可以在库内部跨文件自由地内联这个函数。 更快的链接 (LTO)：链接时优化 (LTO) 更高效，因为它要处理的公共符号更少。 更快的加载：程序启动时，动态加载器需要解析的符号更少，加载 .so 文件的速度更快。 在 Windows (MSVC)： 默认行为：不导出任何符号。你必须用 __declspec(dllexport) 显式标记你要导出的东西。 MY_LIB_PRIVATE 的作用：在这种情况下，它通常展开为空，因为它什么也不用做（默认就是隐藏的）。 总结： private: 是给编译器看的 C++ 规则。MY_LIB_PRIVATE 是给链接器看的二进制指令，主要用于在 Linux/macOS 上实现性能优化和加强封装。\\n\"",
      categories: "[\"C++笔记\"]",
      tags: "[\"C++\"]",
      series: "[\"C++踩坑\"]",
      date: "\"2025-11-17\""
    });
  
    searchIndex.push({
      title: "\"Qt从零开始（0）——环境配置\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/qt%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B/\"",
      content: "\"Qt快速开始 安装 不管是windows还是linux，都是通过在线安装器安装了。不想去网站走注册流程（虽然最终难逃一注），可以使用installer的镜像：\\nqt | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror 上面的custom安装自己看着勾选吧。我喜欢all in cmake，什么creator studio之类的都不安装\\n（或许也可以用sudo apt intall libqt6xxx，但是我没成功，直接用installer了。虽然要注册，但是可以指定安装位置，更干净，还可以管理模块增减更新）\\n依赖安装 Warning 这里我的环境不干净，所以具体安装了什么也不可控。比如linux上我安装了x11和xcb这些，没有的话可能你也要装。windows上装了那什么只有天知道了\\n主要是ubuntu上会缺东西，比如opengl\\nopengl: sudo apt install libgl1-mesa-dev libglu1-mesa-dev mesa-common-dev\\nlibpulse: sudo apt install libpulse-dev\\nvulkan：（部分项目用）这个可以去手动下载SDK下来 LunarXchange ， 1.4.321.1 然后配置环境变量：\\n# VULKAN export VULKAN_SDK=/opt/vulkansdk/1.4.321.1/x86_64 export PATH=$VULKAN_SDK/bin:$PATH export LD_LIBRARY_PATH=$VULKAN_SDK/lib:$LD_LIBRARY_PATH export VK_LAYER_PATH=$VULKAN_SDK/etc/vulkan/explicit_layer.d 快速开始 使用CMake几个点：\\n设置CMAKE_PREFIX_PATH让它能找到你的qt安装位置。比如export QT_PATH=\\u0026quot;/opt/Qt/6.9.2/gcc_64\\u0026quot; set(CMAKE_AUTOMOC ON) # 自动处理 Q_OBJECT 宏，用于实现信号槽机制，推荐开启 set(CMAKE_AUTORCC ON) # 自动处理资源文件，处理资源文件.qrc，推荐开启 set(CMAKE_AUTOUIC ON) # 自动处理 UI 文件.ui，自己看着搞。不开可以手动 qt6_wrap_ui(UI_HEADERS ${UI_FILES}) windows上不生成控制台窗口set_target_properties(${TARGET} PROPERTIES WIN32_EXECUTABLE TRUE) windows上可以自定义命令调用windeployqt.exe自动拷贝动态库，也可以直接命令行 windeployqt.exe YOUR_APP.exe cmake_minimum_required(VERSION 3.16) project(qt_demo VERSION 1.0 LANGUAGES CXX) set(TARGET qt6_demo) set(SOURCES main.cpp) set(UI_FILE main.ui) set(QT_INSTALL_PATH $ENV{QT_PATH}) set(CMAKE_AUTOMOC ON) # 自动处理 Q_OBJECT 宏 set(CMAKE_AUTORCC ON) # 自动处理资源文件 set(CMAKE_AUTOUIC ON) # 自动处理 UI 文件 # C++ 标准 set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_EXPORT_COMPILE_COMMANDS ON) set(CMAKE_BINARY_DIR ${PROJECT_SOURCE_DIR}/build) set(EXECUTABLE_OUTPUT_PATH ${CMAKE_BINARY_DIR}/bin) # 查找 Qt 包 list(APPEND CMAKE_PREFIX_PATH ${QT_INSTALL_PATH}) find_package(Qt6 COMPONENTS Core Gui Widgets REQUIRED) # 添加可执行文件 add_executable(${TARGET} ${SOURCES}) # 链接 Qt 库 target_link_libraries(${TARGET} PRIVATE Qt6::Core Qt6::Gui Qt6::Widgets ) # 在 Windows 上创建 Windows 应用程序（不显示控制台窗口） if(WIN32) set_target_properties(${TARGET} PROPERTIES WIN32_EXECUTABLE TRUE) endif() # 自动化 if(WIN32) find_program(UIC NAMES uic.exe HINTS ${QT_PATH}/bin REQUIRED) find_program(DEPLOYQT NAMES windeployqt.exe HINTS ${QT_PATH}/bin REQUIRED) string(REPLACE \\u0026quot;.ui\\u0026quot; \\u0026quot;_ui.h\\u0026quot; UI_HEADER ${UI_FILE}) # 生成 xxx_ui.h add_custom_command( OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/${UI_HEADER} COMMAND ${UIC} ${CMAKE_CURRENT_SOURCE_DIR}/${UI_FILE} -o ${CMAKE_CURRENT_SOURCE_DIR}/${UI_HEADER} DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/${UI_FILE} COMMENT \\u0026quot;Generating ${UI_HEADER}\\u0026quot; ) add_custom_target(GenerateUiHeader ALL DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/${UI_HEADER}) add_dependencies(${TARGET} GenerateUiHeader) # 自动拷贝依赖 add_custom_command( TARGET ${TARGET} POST_BUILD COMMAND ${CMAKE_COMMAND} -E echo \\u0026quot;Copying DLLs...\\u0026quot; COMMAND ${DEPLOYQT} --release --dir ${EXECUTABLE_OUTPUT_PATH} ${EXECUTABLE_OUTPUT_PATH}/${TARGET}.exe COMMENT \\u0026quot;Deploying Qt dependencies\\u0026quot; ) endif() \"",
      categories: "[\"环境配置\"]",
      tags: [],
      series: "[\"Qt专栏\"]",
      date: "\"2025-08-30\""
    });
  
    searchIndex.push({
      title: "\"ubuntu配置coredump文件生成位置\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/ubuntu%E7%94%9F%E6%88%90coredump%E6%96%87%E4%BB%B6/\"",
      content: "\"ubuntu配置coredump文件生成位置 (1) 修改 ulimit # 查看当前ulimit值。如果是0说明需要修改 ulimit -c 修改方式是：\\necho \\u0026quot;ulimit -c unlimited 2\\u0026gt;/dev/null || true\\u0026quot; \\u0026gt;\\u0026gt; ~/.bashrc 或者修改 /etc/security/limits.conf 文件，在文件末尾追加\\n(注意：如果你是WSL2用户的话，尝试下面方法无果后，建议还是使用第一种)\\n* soft core unlimited * hard core unlimited *：对所有用户生效（可替换为具体用户名或用户组，如 @developers）。 soft：软限制（用户可自行修改，但不能超过硬限制）。 hard：硬限制（root 用户设置的上限）。 (2) 禁用 apport 如果使用的是ubuntu桌面版，很有可能coredump是被apport（就是会弹窗告诉你你的程序崩溃了那个）接管的。\\ncat /proc/sys/kernel/core_pattern # 如果是下面的结果，则说明当前是被approt接管状态 |/usr/share/apport/apport %p %s %c %d %P %E 如果想得到coredump文件，则需要禁用它\\nsudo systemctl disable apport.service (3) 修改core-pattern 修改/etc/sysctl.conf文件，比如将core文件统一生成到/tmp/coredumps目录，则添加如下内容\\n(WSL2用户不要放在/tmp目录下，它好像会自动删除这个目录。建议是要么就放在/tmp，要么就换个目录，不要在/tmp创建子目录）\\nkernel.core_pattern=/tmp/coredumps/core-%e-%t-%p-%E kernel.core_uses_pid=1 确保目录存在且可写入\\nsudo mkdir -p /tmp/coredumps \\u0026amp;\\u0026amp; sudo chmod 777 /tmp/coredumps 说明符​​\\t​​含义​​ %%\\t转义字符，表示一个 % 符号本身（如 %% → %）\\n%p\\t​​进程 ID（PID）​​（例如 1234）\\n%P\\t​​全局 PID​​（包括线程组 ID，通常与 %p 相同）\\n%i\\t​​线程 ID（TID）​​（多线程程序的子线程 ID）\\n%I\\t​​全局线程 ID​​（内核调度器分配的 ID）\\n%n\\t​​进程的友好名称（comm）​​（通常是程序名，最多 16 字符）\\n%e\\t​​可执行文件名​​（不含路径，例如 nginx）\\n%E\\t​​可执行文件的完整路径​​（例如 /usr/bin/nginx）\\n%t\\t​​时间戳​​（Unix 时间戳，秒级，例如 1625097600）\\n%h\\t​​主机名​​（uname -n 的输出）\\n%s\\t​​触发 coredump 的信号编号​​（例如 11 表示 SIGSEGV）\\n%c\\t​​coredump 文件的大小限制​​（受 RLIMIT_CORE 限制，单位：字节）\\n%u\\t​​进程的实际用户 ID（UID）​​（例如 1000）\\n%g\\t​​进程的实际组 ID（GID）​​（例如 1000）\\n%d\\t​​进程的退出码​​（通常为信号编号）\\n%f\\t​​进程的页错误地址​​（十六进制，仅对某些信号有效，如 SIGSEGV）\\n%H\\t​​容器/命名空间的 ID​​（如果进程在容器中运行）\\n(4) 测试 kill -11 $$ ll /tmp/coredumps \"",
      categories: "[\"环境配置\"]",
      tags: [],
      series: [],
      date: "\"2025-08-01\""
    });
  
    searchIndex.push({
      title: "\"ubuntu安装中文输入法（fcitx5-rime）\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/ubuntu%E5%AE%89%E8%A3%85rime%E8%BE%93%E5%85%A5%E6%B3%95/\"",
      content: "\"安装 sudo apt install fcitx5 fcitx5-chinese-addons fcitx5-rime librime-lua export GTK_IM_MODULE=fcitx5 export QT_IM_MODULE=fcitx5 export XMODIFIERS=@im=fcitx5 然后重启，完了打开fcitx5的configure，添加输入源rime即可\\n雾凇拼音安装 Reference https://dvel.me/posts/rime-ice/ https://sspai.com/post/89281 https://sspai.com/post/84373 git clone https://github.com/rime/plum ~/plum # 切换到东风破的目录 cd ~/plum # 如果你使用Fcitx5，你需要加入参数，让东风破把配置文件写到正确的位置 rime_frontend=fcitx5-rime bash rime-install iDvel/rime-ice:others/recipes/full # 如果你是用IBus，则不需加参数，因为东风破默认是为IBus版的RIME打造。 bash rime-install iDvel/rime-ice:others/recipes/full # 重启 fcitx5-remote -r 配置 Reference https://www.lvbibir.cn/posts/tech/windowns-rime-input-method/ 主题 git clone https://github.com/thep0y/fcitx5-themes-candlelight.git # 拷贝子文件夹到 ~/.local/share/fcitx5/themes # 然后在fcitx5配置文件中指定主题（子文件夹名称） fcitx5 配置文件 vim ~/.config/fcitx5/conf/classicui.conf\\n# 垂直候选列表 Vertical Candidate List=False # 按屏幕 DPI 使用 PerScreenDPI=True # Font (设置成你喜欢的字体) Font=\\u0026quot;Smartisan Compact CNS 13\\u0026quot; # 主题(这里要改成你想要使用的主题名，主题名就在下面) Theme=macOS-light rime 配置文件 vim ~/.local/share/fcitx5/rime/default.custom.yaml\\npatch: schema_list: - schema: rime_ice # - schema: luna_pinyin_simp menu: page_size: 6 ascii_punct: true ascii_composer/switch_key: Shift_L: commit_code Shift_R: commit_code \"",
      categories: "[\"环境配置\"]",
      tags: [],
      series: [],
      date: "\"2025-07-10\""
    });
  
    searchIndex.push({
      title: "\"SSH反向隧道中转机-远程连接本地服务器\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/ssh%E5%8F%8D%E5%90%91%E9%9A%A7%E9%81%93%E4%B8%AD%E8%BD%AC%E6%9C%BA%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5%E6%9C%AC%E5%9C%B0%E6%9C%8D%E5%8A%A1%E5%99%A8/\"",
      content: "\"SSH反向隧道中转机-远程连接本地服务器 Intro 考虑下面这个场景：你有一台性能强劲的本地主机，但是没有公网IP；一台云服务器，可以远程访问（不一定要求独立公网IP），但是性能不咋滴。本地主机和远程的你，都认识云服务器，但是你俩互相不认识，这实在是让人扼腕叹息。有没有解决方案呢？\\n有的，本文介绍的SSH反向隧道就是这么个中间人\\n快速开始 提前在本地服务器上执行 ssh -N -R 22222:localhost:22 [cloud-username]@[cloud-hostname] 需要时，要远程访问的主机上，ssh连接到云服务器（ssh [cloud-username]@[cloud-hostname]） 然后在云服务器上执行 ssh -p 22222 [local-server-username]@localhost 即可实现从任意机器访问到那台本地主机。中间并没有要求云服务器有独立的公网IP，只要能远程SSH上就行。\\n注意，2，3可以合并成一步，即通过 -J指定跳转路径：\\nssh [-p [port]] -J [cloud-username]@[cloud-hostname]:[port] [local-server-username]@localhost:[port]\\n解释 参数说明 -N 告诉 ssh 不执行命令，不启动shell，只用于端口转发 -R [bind_address:]远程端口:本地主机:本地端口 将远程服务器的端口转发到本地端口 -J [user1@]jump_host1[:port1][,[user2@]jump_host2[:port2],...] [user@]final_target_host 一步一步通过跳板机/堡垒机登录到最终的服务器 额外参数 持久连接 如果需要一直保持连接，ssh加上如下参数\\n-o ServerAliveInterval=60 -o ServerAliveCountMax=3 每六十秒发送一次保活包；允许连续三次保活失败才断开连接 本地转发 与远程转发对应的还有本地转发\\n-L [bind_address:]本地端口:远程主机:远程端口 将本地端口数据自动转发到远程端口 应用场景比如：\\n有一台云服务器，它的端口3306上跑着服务，但是云服务器本身没有独立IP，只能通过ssh+用户名认证这种方式连接访问（比如vlab就是这样），你的应用客户端连接不上。那就可以在本地建立一个本地转发ssh -L 3306:localhost:3306 sverver-name@sverver，将本地的3306端口数据自动转发到远程的3306端口 或者不是没法访问云服务器，但是云服务器上想要的端口被防火墙关了，只有22端口开着，那也可以通过此方式绕开限制，往本地的端口发数据，让ssh将数据转发到云服务器的对应端口 远程转发的应用则比如本文的，想在远程访问本地机器 不管是本地转发还是远程转发，bind_address一般都是localhost，默认省略，它表示服务器默认只监听本地地址。\\n不管是本地转发还是远程转发，destination_host一般都填localhost，它是从本地主机/云服务器角度能理解解析访问的地址\\n可能错误情形 （1）client_global_hostkeys_prove_confirm: server gave bad signature for ECDSA key 1: incorrect signature\\n试试跳过验证：ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\\n\"",
      categories: "[\"工具使用\"]",
      tags: "[\"ssh\"]",
      series: [],
      date: "\"2025-06-16\""
    });
  
    searchIndex.push({
      title: "\"C++ 高并发服务器模型实现 | [转载](https://github.com/linkxzhou/mylib/blob/master/c%2B%2B/concurrency_server/README.md)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/06/10/22%E7%A7%8Dc-%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%9E%8B/\"",
      content: "\"C++ 高并发服务器模型实现 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: C++ 高并发服务器模型实现 本项目实现了多种不同的后端服务器并发模型，展示了各种网络编程和并发处理技术。所有实现都使用 C++11 标准，不依赖第三方库。\\n项目结构 concurrency_server/ ├── base/ # 基础组件目录 │ └── server_base.h # 服务器基类，提供通用的socket操作 ├── benchmark/ # 性能测试工具目录 ├── main.cpp # 主程序入口，支持多种服务器模型切换 ├── Makefile # 编译配置文件 ├── README.md # 项目说明文档 │ ├── 基础并发模型 ├── single_process_server.h # 单进程模型 - 串行处理，适合学习 ├── multi_thread_server.h # 多线程模型 - 每连接一线程 ├── multi_process_server.h # 多进程模型 - 每连接一进程 ├── thread_pool_server.h # 线程池模型 - 固定数量工作线程 ├── process_pool1_server.h # 进程池模型1 - 预创建进程池 ├── process_pool2_server.h # 进程池模型2 - 改进的进程池实现 │ ├── I/O多路复用模型 ├── select_server.h # Select模型 - 跨平台I/O多路复用 ├── poll_server.h # Poll模型 - 改进的select实现 ├── epoll_server.h # Epoll模型 - Linux高性能I/O复用 ├── kqueue_server.h # Kqueue模型 - BSD/macOS高性能I/O复用 │ ├── 高级并发架构 ├── reactor_server.h # Reactor模式 - 事件驱动架构 ├── proactor_server.h # Proactor模式 - 异步I/O架构 ├── event_loop_server.h # 事件循环模型 - 单线程事件驱动 ├── half_sync_async_server.h # 半同步半异步模式 - 分层处理 ├── leader_follower_server.h # Leader-Follower模式 - 动态角色切换 ├── producer_consumer_server.h # 生产者消费者模式 - 解耦处理 ├── pipeline_server.h # 管道模式 - 流水线处理 ├── work_stealing_server.h # 工作窃取模式 - 负载均衡 ├── hybrid_server.h # 混合模式 - 多种技术结合 │ ├── 现代并发技术 ├── coroutine_server.h # 协程模型 - 用户态轻量级线程 ├── fiber_server.h # 纤程模型 - 协作式多任务 ├── actor_server.h # Actor模型 - 消息传递并发 支持的并发模型 1. SingleProcess (单进程模型) 文件: single_process_server.h 特点: 串行处理客户端请求，简单但性能有限 适用场景: 学习和调试，低并发场景 优点: 实现简单，资源消耗少 缺点: 无法利用多核，一个请求阻塞会影响所有后续请求 详细介绍： 单进程模型是最简单的服务器架构，采用传统的阻塞I/O方式处理客户端请求。\\n服务器在单个进程中运行，使用一个主循环来依次处理每个客户端连接。\\n当有新连接到达时，服务器调用accept()接受连接，然后同步读取客户端数据、处理请求并发送响应。整个过程是串行的，一次只能处理一个客户端。\\n实现架构：\\n核心实现基于传统的socket编程模式。 服务器创建监听socket并绑定到指定端口，然后进入无限循环等待连接。 每当accept()返回新的客户端socket时，服务器立即处理该连接的所有I/O操作，包括读取HTTP请求、解析协议、生成响应并发送数据。 由于采用阻塞I/O，每个操作都会等待完成后才继续下一步。 sequenceDiagram participant C1 as Client1 participant C2 as Client2 participant S as Server Process C1-\\u0026gt;\\u0026gt;S: Connect S-\\u0026gt;\\u0026gt;S: Accept \\u0026amp; Process Request S-\\u0026gt;\\u0026gt;C1: Response Note over S: 串行处理，一次只能处理一个请求 C2-\\u0026gt;\\u0026gt;S: Connect (等待) S-\\u0026gt;\\u0026gt;S: Accept \\u0026amp; Process Request S-\\u0026gt;\\u0026gt;C2: Response 2. MultiProcess (多进程模型) 文件: multi_process_server.h 特点: 为每个客户端连接创建独立进程 适用场景: 需要进程隔离的场景 优点: 进程隔离，一个进程崩溃不影响其他 缺点: 进程创建开销大，内存消耗高 详细介绍： 多进程模型通过为每个客户端连接创建独立的子进程来实现并发处理。\\n主进程负责监听新连接，当accept()接受到新客户端时，立即调用fork()创建子进程来处理该连接，而主进程继续监听下一个连接。\\n每个子进程拥有独立的内存空间和资源，可以并行处理不同的客户端请求。\\n这种模型提供了最强的隔离性，一个进程的崩溃不会影响其他进程或主服务器。\\n实现架构：\\n架构采用经典的fork-per-connection模式。 主进程创建监听socket后进入accept循环，每次接受新连接后立即fork()创建子进程。 子进程关闭监听socket，专门处理分配给它的客户端连接，完成所有I/O操作后退出。 主进程关闭客户端socket，继续监听新连接，并通过signal处理或waitpid()回收僵尸进程。 flowchart TD A[Main Process] --\\u0026gt; B[Listen Socket] B --\\u0026gt; C{New Connection?} C --\\u0026gt;|Yes| D[fork] D --\\u0026gt; E[Child Process 1] D --\\u0026gt; F[Child Process 2] D --\\u0026gt; G[Child Process N] E --\\u0026gt; H[Handle Client 1] F --\\u0026gt; I[Handle Client 2] G --\\u0026gt; J[Handle Client N] C --\\u0026gt;|No| C style E fill:#e1f5fe style F fill:#e1f5fe style G fill:#e1f5fe 3. MultiThread (多线程模型) 文件: multi_thread_server.h 特点: 为每个客户端连接创建一个新线程 适用场景: 中等并发量的场景 优点: 线程创建比进程快，共享内存空间 缺点: 大量连接时线程数过多，上下文切换开销大 详细介绍： 多线程模型通过为每个客户端连接创建独立线程来实现并发处理。\\n主线程负责监听和接受新连接，当有新客户端连接时，创建一个工作线程来处理该连接的所有I/O操作。\\n所有线程共享同一个进程的内存空间，可以方便地共享数据和资源。\\n相比多进程模型，线程的创建和切换开销更小，内存使用更高效。但需要特别注意线程安全问题，避免竞态条件和数据竞争。\\n实现架构：\\n架构基于thread-per-connection模式。 主线程创建监听socket并进入accept循环，每接受一个新连接就调用pthread_create()或std::thread创建工作线程。 工作线程接收客户端socket描述符作为参数，独立处理该连接的读写操作，完成后自动退出。 为了避免线程泄漏，通常采用detached线程或在主线程中join回收。 共享资源（如日志、统计信息）需要使用互斥锁保护。 flowchart TD A[Main Thread] --\\u0026gt; B[Listen Socket] B --\\u0026gt; C{New Connection?} C --\\u0026gt;|Yes| D[Create Thread] D --\\u0026gt; E[Worker Thread 1] D --\\u0026gt; F[Worker Thread 2] D --\\u0026gt; G[Worker Thread N] E --\\u0026gt; H[Handle Client 1] F --\\u0026gt; I[Handle Client 2] G --\\u0026gt; J[Handle Client N] C --\\u0026gt;|No| C K[Shared Memory Space] E -.-\\u0026gt; K F -.-\\u0026gt; K G -.-\\u0026gt; K style E fill:#fff3e0 style F fill:#fff3e0 style G fill:#fff3e0 4. ProcessPool1 (进程池模型1) 文件: process_pool1_server.h 特点: 预先创建固定数量的工作进程，共享监听socket 适用场景: 高并发场景，需要进程隔离 优点: 避免频繁创建进程，资源利用率高 缺点: 进程间竞争accept可能不均匀 flowchart TD A[Master Process] --\\u0026gt; B[Create Process Pool] B --\\u0026gt; C[Worker Process 1] B --\\u0026gt; D[Worker Process 2] B --\\u0026gt; E[Worker Process N] F[Shared Listen Socket] --\\u0026gt; G{accept} C --\\u0026gt; G D --\\u0026gt; G E --\\u0026gt; G G --\\u0026gt;|Process 1 wins| H[Handle Client 1] G --\\u0026gt;|Process 2 wins| I[Handle Client 2] G --\\u0026gt;|Process N wins| J[Handle Client N] style C fill:#e8f5e8 style D fill:#e8f5e8 style E fill:#e8f5e8 style F fill:#ffecb3 5. ProcessPool2 (进程池模型2 - SO_REUSEPORT) 文件: process_pool2_server.h 特点: 使用SO_REUSEPORT选项，每个进程独立监听同一端口 适用场景: Linux环境下的高并发场景 优点: 内核负载均衡，避免惊群效应 缺点: 依赖操作系统特性，可移植性有限 flowchart TD A[Master Process] --\\u0026gt; B[Create Process Pool] B --\\u0026gt; C[Worker Process 1] B --\\u0026gt; D[Worker Process 2] B --\\u0026gt; E[Worker Process N] F[Port 8080] --\\u0026gt; G[SO_REUSEPORT] C --\\u0026gt; H[Listen Socket 1] D --\\u0026gt; I[Listen Socket 2] E --\\u0026gt; J[Listen Socket N] G --\\u0026gt; H G --\\u0026gt; I G --\\u0026gt; J K[Kernel Load Balancer] --\\u0026gt; H K --\\u0026gt; I K --\\u0026gt; J style C fill:#e8f5e8 style D fill:#e8f5e8 style E fill:#e8f5e8 style K fill:#f3e5f5 6. ThreadPool (线程池模型) 文件: thread_pool_server.h 特点: 预先创建固定数量的工作线程 适用场景: 高并发Web服务器 优点: 避免频繁创建线程，资源利用率高 缺点: 线程数固定，可能无法适应负载变化 详细介绍： 线程池模型通过预先创建固定数量的工作线程来处理客户端请求，避免了为每个连接动态创建线程的开销。\\n主线程负责接受新连接并将连接放入任务队列，工作线程从队列中取出任务进行处理。\\n这种模型有效控制了系统资源使用，避免了线程数量无限增长导致的系统崩溃。\\n线程池的大小通常根据CPU核心数和预期负载来设定，实现了更好的资源管理和性能优化。\\n实现架构：\\n架构采用生产者-消费者模式。 系统启动时预创建指定数量的工作线程，这些线程在任务队列上等待。 主线程accept新连接后，将客户端socket封装成任务对象放入线程安全的任务队列中。 作线程通过条件变量等待任务，取到任务后处理完整的客户端交互流程。任务队列通常使用互斥锁和条件变量实现同步。 当工作线程处理完一个任务后，会将自己重新加入线程池，等待下一个任务。 flowchart TD A[Main Thread] --\\u0026gt; B[Create Thread Pool] B --\\u0026gt; C[Worker Thread 1] B --\\u0026gt; D[Worker Thread 2] B --\\u0026gt; E[Worker Thread N] A --\\u0026gt; F[Accept Connections] F --\\u0026gt; G[Task Queue] C --\\u0026gt; H{Get Task} D --\\u0026gt; I{Get Task} E --\\u0026gt; J{Get Task} G --\\u0026gt; H G --\\u0026gt; I G --\\u0026gt; J H --\\u0026gt; K[Process Client] I --\\u0026gt; L[Process Client] J --\\u0026gt; M[Process Client] style C fill:#fff3e0 style D fill:#fff3e0 style E fill:#fff3e0 style G fill:#e3f2fd 7. LeaderAndFollower (领导者/跟随者模型) 文件: leader_follower_server.h 特点: 线程池变种，一个线程作为leader监听连接 适用场景: 需要精确控制线程行为的场景 优点: 减少线程间竞争，提高缓存局部性 缺点: 实现复杂，调试困难 详细介绍： 领导者/跟随者模型是一种高性能的并发模式，通过动态角色切换来优化线程利用率。 在任何时刻，只有一个线程担任领导者角色，负责监听和接受新的连接或事件，其他线程处于跟随者状态等待被激活。 当领导者接收到事件后，它会将自己降级为跟随者去处理该事件，同时从跟随者中选举出新的领导者继续监听。 这种模型避免了传统模型中的线程池调度开销，减少了线程间的竞争，提高了CPU缓存的局部性。特别适合高并发、低延迟的网络服务场景。\\n实现架构：\\n架构基于线程池和角色管理机制构建。 系统维护一个线程池，其中一个线程担任领导者，其余线程为跟随者。 领导者线程负责在事件多路复用器（如epoll）上等待I/O事件。 当事件到达时，领导者首先从跟随者中选择一个线程提升为新领导者，然后自己降级为工作线程处理该事件，角色切换通过条件变量和互斥锁实现同步。 为了避免惊群效应，只有领导者线程在事件多路复用器上等待。 处理完事件的线程会重新加入跟随者队列等待下次被选为领导者。 stateDiagram-v2 [*] --\\u0026gt; Leader: Thread becomes leader Leader --\\u0026gt; Processing: Accept connection Processing --\\u0026gt; Follower: Promote next follower Follower --\\u0026gt; Leader: Wait for promotion Processing --\\u0026gt; [*]: Complete request state Leader { [*] --\\u0026gt; Listening Listening --\\u0026gt; AcceptConnection: New connection AcceptConnection --\\u0026gt; [*] } state Processing { [*] --\\u0026gt; HandleRequest HandleRequest --\\u0026gt; SendResponse SendResponse --\\u0026gt; [*] } 8. Select (Select I/O多路复用) 文件: select_server.h 特点: 使用select系统调用监控多个文件描述符 适用场景: 跨平台的中等并发场景 优点: 跨平台兼容性好 缺点: 文件描述符数量有限制，性能随连接数线性下降 详细介绍： Select模型是最经典的I/O多路复用技术，通过select()系统调用在单线程中同时监控多个socket的状态变化。\\n服务器维护读、写、异常三个文件描述符集合，select()会阻塞等待直到至少一个描述符就绪。\\n当select()返回时，服务器遍历描述符集合，处理所有就绪的I/O操作。\\n这种模型避免了多线程的复杂性，用单线程就能处理多个并发连接，是事件驱动编程的基础。\\n实现架构：\\n架构基于事件循环模式。 服务器初始化时将监听socket加入读描述符集合，然后进入主循环调用select()等待事件。 当有新连接时，accept()后将客户端socket加入监控集合；当客户端socket可读时，读取并处理请求；当可写时，发送响应数据。 每次循环都需要重新设置描述符集合，因为select()会修改传入的集合。 flowchart TD A[Main Loop] --\\u0026gt; B[fd_set readfds] B --\\u0026gt; C[Add listen_fd] B --\\u0026gt; D[Add client_fd1] B --\\u0026gt; E[Add client_fd2] B --\\u0026gt; F[Add client_fdN] G[select] --\\u0026gt; H{Ready FDs?} C --\\u0026gt; G D --\\u0026gt; G E --\\u0026gt; G F --\\u0026gt; G H --\\u0026gt;|listen_fd ready| I[Accept new connection] H --\\u0026gt;|client_fd ready| J[Read/Write data] H --\\u0026gt;|timeout| K[Continue loop] I --\\u0026gt; A J --\\u0026gt; A K --\\u0026gt; A style B fill:#e1f5fe style G fill:#fff3e0 9. Poll (Poll I/O多路复用) 文件: poll_server.h 特点: 使用poll系统调用，改进了select的限制 适用场景: 中等并发场景 优点: 没有文件描述符数量限制 缺点: 性能仍随连接数线性下降 详细介绍： Poll模型是select模型的改进版本，使用poll()系统调用来监控多个文件描述符的I/O事件。\\n与select不同，poll使用pollfd结构数组来描述要监控的文件描述符和事件类型，没有FD_SETSIZE的限制，可以监控任意数量的描述符。\\npoll()返回时，通过检查每个pollfd结构的revents字段来确定哪些描述符就绪。这种模型保持了select的单线程优势，同时解决了描述符数量限制问题。\\n实现架构：\\n架构同样基于事件循环，但使用更灵活的数据结构。 服务器维护一个动态的pollfd数组，每个元素包含文件描述符、关注的事件和返回的事件。 主循环调用poll()等待事件，返回后遍历数组检查revents字段。 当有新连接时，动态扩展pollfd数组；当连接关闭时，从数组中移除对应元素。 相比select，poll的接口更清晰，不需要重复设置描述符集合。 flowchart TD A[Main Loop] --\\u0026gt; B[pollfd array] B --\\u0026gt; C[\\u0026quot;pollfd[0]: listen_fd\\u0026quot;] B --\\u0026gt; D[\\u0026quot;pollfd[1]: client_fd1\\u0026quot;] B --\\u0026gt; E[\\u0026quot;pollfd[2]: client_fd2\\u0026quot;] B --\\u0026gt; F[\\u0026quot;pollfd[N]: client_fdN\\u0026quot;] G[poll] --\\u0026gt; H{Check revents} C --\\u0026gt; G D --\\u0026gt; G E --\\u0026gt; G F --\\u0026gt; G H --\\u0026gt;|POLLIN on listen_fd| I[Accept new connection] H --\\u0026gt;|POLLIN on client_fd| J[Read data] H --\\u0026gt;|POLLOUT on client_fd| K[Write data] H --\\u0026gt;|POLLHUP/POLLERR| L[Close connection] I --\\u0026gt; M[Add to pollfd array] J --\\u0026gt; A K --\\u0026gt; A L --\\u0026gt; N[Remove from array] M --\\u0026gt; A N --\\u0026gt; A style B fill:#e8f5e8 style G fill:#fff3e0 10. Epoll (Epoll I/O多路复用) 文件: epoll_server.h 特点: Linux特有的高效I/O多路复用机制 适用场景: Linux环境下的高并发场景 优点: 性能优秀，支持边缘触发 缺点: 仅限Linux系统 详细介绍： Epoll是Linux内核提供的高性能I/O多路复用机制，专门为解决C10K问题而设计。 与select/poll不同，epoll使用事件驱动的方式，只返回就绪的文件描述符，避免了线性扫描。 Epoll内部使用红黑树管理文件描述符，使用就绪列表存储活跃事件，实现了O(1)的事件通知效率。 支持水平触发(LT)和边缘触发(ET)两种模式，为高性能服务器提供了极大的灵活性。\\n实现架构：\\n架构基于epoll的三个核心系统调用：epoll_create创建epoll实例，epoll_ctl管理监控的文件描述符，epoll_wait等待事件。 服务器启动时创建epoll实例，将监听socket加入监控。主循环调用epoll_wait等待事件，只处理返回的就绪描述符，无需遍历所有连接。 新连接通过epoll_ctl添加到监控集合，关闭连接时移除。 支持EPOLLIN、EPOLLOUT、EPOLLET等多种事件类型。 flowchart TD A[epoll_create] --\\u0026gt; B[epoll_fd] B --\\u0026gt; C[epoll_ctl ADD listen_fd] D[Main Loop] --\\u0026gt; E[epoll_wait] E --\\u0026gt; F{Ready Events?} F --\\u0026gt;|listen_fd EPOLLIN| G[Accept connection] F --\\u0026gt;|client_fd EPOLLIN| H[Read data] F --\\u0026gt;|client_fd EPOLLOUT| I[Write data] F --\\u0026gt;|client_fd EPOLLHUP| J[Close connection] G --\\u0026gt; K[epoll_ctl ADD client_fd] H --\\u0026gt; L[Process request] I --\\u0026gt; M[Send response] J --\\u0026gt; N[epoll_ctl DEL client_fd] K --\\u0026gt; D L --\\u0026gt; D M --\\u0026gt; D N --\\u0026gt; D style B fill:#ffecb3 style E fill:#e8f5e8 style F fill:#f3e5f5 11. Kqueue (Kqueue I/O多路复用) 文件: kqueue_server.h 特点: BSD/macOS特有的高效I/O多路复用机制 适用场景: BSD/macOS环境下的高并发场景 优点: 性能优秀，功能丰富 缺点: 仅限BSD/macOS系统 详细介绍： Kqueue是FreeBSD和macOS系统提供的高性能事件通知机制，类似于Linux的epoll但功能更强大。\\nKqueue不仅支持网络I/O事件，还支持文件系统变化、信号、定时器等多种事件类型。通过kevent()系统调用统一管理所有事件，提供了一致的编程接口。\\nKqueue使用内核事件队列，只通知发生变化的事件，避免了轮询开销。\\n其设计哲学是提供统一的事件处理框架，让应用程序能够高效地响应各种系统事件。\\n实现架构：\\n架构围绕kqueue()和kevent()两个核心系统调用构建。 服务器启动时调用kqueue()创建事件队列，然后使用kevent()注册感兴趣的事件（如监听socket的读事件）。 主循环调用kevent()等待事件，该函数既用于注册事件也用于获取就绪事件。 当有事件发生时，kevent()返回事件数组，包含事件类型、文件描述符、数据等信息。支持EVFILT_READ、EVFILT_WRITE、EVFILT_TIMER等多种过滤器。 flowchart TD A[kqueue] --\\u0026gt; B[kqueue_fd] B --\\u0026gt; C[\\u0026quot;EV_SET(listen_fd, EVFILT_READ)\\u0026quot;] C --\\u0026gt; D[kevent register] E[Main Loop] --\\u0026gt; F[kevent wait] F --\\u0026gt; G{Ready Events?} G --\\u0026gt;|listen_fd READ| H[Accept connection] G --\\u0026gt;|client_fd read| I[Read data] G --\\u0026gt;|client_fd write| J[Write data] G --\\u0026gt;|EOF/Error| K[Close connection] H --\\u0026gt; L[\\u0026quot;EV_SET(client_fd, EVFILT_READ)\\u0026quot;] I --\\u0026gt; M[Process request] J --\\u0026gt; N[Send response] K --\\u0026gt; O[Remove from kqueue] L --\\u0026gt; P[kevent add] M --\\u0026gt; E N --\\u0026gt; E O --\\u0026gt; E P --\\u0026gt; E style B fill:#ffecb3 style F fill:#e8f5e8 style G fill:#f3e5f5 12. Reactor (Reactor模式) 文件: reactor_server.h 特点: 事件驱动的网络编程模式 适用场景: 需要精确控制事件处理的场景 优点: 结构清晰，易于扩展 缺点: 实现复杂度较高 详细介绍： Reactor模式是一种事件驱动的设计模式，将事件检测和事件处理分离，提供了高度可扩展的架构。 该模式定义了一个事件循环，负责监听各种I/O事件，当事件发生时分发给相应的事件处理器。 Reactor模式的核心思想是\\u0026quot;不要调用我们，我们会调用你\\u0026quot;，应用程序注册事件处理器，由Reactor负责在适当时机调用。 这种模式广泛应用于网络编程框架，如Java NIO、Node.js等，提供了优雅的异步编程模型。\\n实现架构：\\n架构包含几个核心组件：Reactor负责事件循环和分发，Demultiplexer负责I/O事件检测（如epoll/select），EventHandler定义事件处理接口，ConcreteHandler实现具体的业务逻辑。 服务器启动时，各种处理器注册到Reactor，指定关注的事件类型。 Reactor进入事件循环，调用Demultiplexer等待事件，当事件就绪时查找对应的处理器并调用其处理方法。 支持AcceptHandler处理新连接、ReadHandler处理读事件、WriteHandler处理写事件等。 flowchart TD A[Reactor] --\\u0026gt; B[Event Demultiplexer] B --\\u0026gt; C[select/poll/epoll] D[Event Handlers] --\\u0026gt; E[AcceptHandler] D --\\u0026gt; F[ReadHandler] D --\\u0026gt; G[WriteHandler] H[Main Loop] --\\u0026gt; I[Handle Events] I --\\u0026gt; J{Event Type?} J --\\u0026gt;|Accept Event| K[AcceptHandler.handle] J --\\u0026gt;|Read Event| L[ReadHandler.handle] J --\\u0026gt;|Write Event| M[WriteHandler.handle] K --\\u0026gt; N[Create new connection] L --\\u0026gt; O[Read and process data] M --\\u0026gt; P[Send response] N --\\u0026gt; Q[Register with Reactor] O --\\u0026gt; R[Update event interest] P --\\u0026gt; S[Update event interest] Q --\\u0026gt; H R --\\u0026gt; H S --\\u0026gt; H style A fill:#e3f2fd style D fill:#fff3e0 style I fill:#e8f5e8 13. Coroutine (协程模式) 文件: coroutine_server.h 特点: 使用状态机模拟协程行为（C++11兼容） 适用场景: 异步处理场景 优点: 内存消耗少，上下文切换快 缺点: 实现复杂，调试困难 详细介绍： 协程模式通过状态机模拟协程行为，在C++11环境下实现异步编程。与传统的回调方式不同，协程允许函数在执行过程中暂停并在稍后恢复，使异步代码看起来像同步代码。 本实现使用状态机来跟踪每个连接的处理状态，当遇到会阻塞的I/O操作时，协程会yield让出控制权，等待I/O就绪后再resume继续执行。 这种模型特别适合处理大量并发连接，因为协程的内存开销远小于线程，可以创建成千上万个协程而不会耗尽系统资源。\\n实现架构：\\n架构基于状态机和事件循环构建。 每个客户端连接对应一个协程对象，包含当前状态、上下文数据和状态转换逻辑。协程调度器维护所有活跃协程的列表，在事件循环中轮询I/O事件。 当socket就绪时，调度器恢复对应协程的执行。 协程内部使用状态机实现：INIT状态初始化连接，READING状态处理读取，PROCESSING状态处理业务逻辑，WRITING状态发送响应，DONE状态清理资源。 每个状态都可能因为I/O阻塞而yield，调度器会在下次循环中检查并恢复。 stateDiagram-v2 [*] --\\u0026gt; INIT: Create Coroutine INIT --\\u0026gt; READING: Start read operation READING --\\u0026gt; PROCESSING: Data available READING --\\u0026gt; READING: Would block (yield) PROCESSING --\\u0026gt; WRITING: Process complete WRITING --\\u0026gt; WRITING: Would block (yield) WRITING --\\u0026gt; DONE: Write complete DONE --\\u0026gt; [*]: Coroutine finished state READING { [*] --\\u0026gt; CheckSocket CheckSocket --\\u0026gt; ReadData: Socket ready CheckSocket --\\u0026gt; Yield: Would block ReadData --\\u0026gt; [*]: Data read Yield --\\u0026gt; [*]: Resume later } state WRITING { [*] --\\u0026gt; CheckSocket CheckSocket --\\u0026gt; WriteData: Socket ready CheckSocket --\\u0026gt; Yield: Would block WriteData --\\u0026gt; [*]: Data written Yield --\\u0026gt; [*]: Resume later } 14. Actor模型 文件: actor_server.h 特点: 每个Actor是独立的计算单元，通过消息传递通信 适用场景: 分布式系统、高并发消息处理 优点: 无共享状态，天然避免竞态条件 缺点: 实现复杂，消息传递开销 实现: 可以基于线程池 + 消息队列实现 详细介绍： Actor模型是一种基于消息传递的并发计算模型，每个Actor都是独立的计算单元，拥有自己的状态和行为。 Actor之间不共享内存，只能通过异步消息进行通信。 当Actor接收到消息时，可以执行三种操作：处理消息并更新内部状态、向其他Actor发送消息、创建新的Actor。 这种模型天然避免了传统并发编程中的锁和竞态条件问题，提供了更安全的并发处理方式。 Actor模型特别适合构建分布式系统，因为Actor可以分布在不同的机器上，通过网络进行消息传递。\\n实现架构：\\n架构围绕Actor、消息队列和调度器构建。 每个Actor包含邮箱（消息队列）、状态数据和消息处理逻辑。 系统启动时创建多个Worker Actor处理客户端请求，一个Acceptor Actor负责接受新连接。 当有新连接时，Acceptor发送消息给负载最轻的Worker。 Worker Actor接收到连接消息后，负责该连接的整个生命周期。 Actor调度器负责从各个Actor的邮箱中取出消息并执行相应的处理函数。 消息传递通过线程安全的队列实现，支持本地和远程消息。 flowchart TD A[Actor 1] --\\u0026gt;|Message| B[Actor 2] A --\\u0026gt;|Message| C[Actor 3] B --\\u0026gt;|Message| A C --\\u0026gt;|Message| A D[Actor System] --\\u0026gt; A D --\\u0026gt; B D --\\u0026gt; C E[Message Queue 1] --\\u0026gt; A F[Message Queue 2] --\\u0026gt; B G[Message Queue 3] --\\u0026gt; C style A fill:#e1f5fe style B fill:#e8f5e8 style C fill:#fff3e0 style D fill:#f3e5f5 15. 事件循环模型 (Event Loop) 文件: event_loop_server.h 特点: 单线程事件循环，类似Node.js的实现方式 适用场景: I/O密集型应用 优点: 避免线程切换开销，内存占用少 缺点: 单线程限制，CPU密集型任务会阻塞 实现: 基于epoll/kqueue + 回调函数 详细介绍： 事件循环模型是一种单线程异步编程模式，通过一个无限循环来处理所有的I/O事件和回调函数。 事件循环不断地检查事件队列，当有事件就绪时执行相应的回调函数。 这种模型的核心思想是将所有阻塞操作转换为非阻塞的异步操作，通过事件通知机制来处理I/O完成。 事件循环模型广泛应用于Node.js、Redis等高性能服务器中，特别适合I/O密集型应用。 由于采用单线程设计，避免了多线程编程中的锁和同步问题，大大简化了编程复杂度。\\n实现架构：\\n架构围绕事件循环、事件队列和回调函数构建。 事件循环是系统的核心，负责监听文件描述符、定时器和其他事件源。 当事件发生时，相应的回调函数被添加到事件队列中，事件循环在每次迭代中处理队列中的所有回调，然后等待新的事件。 对于网络I/O，使用epoll/kqueue等高效的I/O多路复用机制。 定时器通过最小堆实现，支持高精度的定时任务。 所有的I/O操作都是非阻塞的，如果操作无法立即完成，会注册回调函数等待事件通知。 flowchart TD A[Event Loop] --\\u0026gt; B[Event Queue] B --\\u0026gt; C[Event Handler] C --\\u0026gt; D[Callback] D --\\u0026gt; A E[I/O Events] --\\u0026gt; B F[Timer Events] --\\u0026gt; B G[Network Events] --\\u0026gt; B style A fill:#ffecb3 style B fill:#e3f2fd style C fill:#fff3e0 16. 纤程/用户态线程 (Fiber/Green Thread) 文件: fiber_server.h 特点: 用户态调度的轻量级线程 适用场景: 需要大量并发连接的场景 优点: 创建成本极低，可创建数万个 缺点: 需要实现复杂的调度器和栈管理 实现: 需要实现用户态调度器和栈切换 详细介绍： 纤程（Fiber）是一种用户态的轻量级线程，也称为绿色线程或协作式线程。 与操作系统线程不同，纤程的创建、销毁和调度都在用户空间完成，不需要内核参与。 纤程之间采用协作式调度，只有当纤程主动让出控制权时才会发生切换，这避免了抢占式调度的开销和复杂性。 每个纤程只需要很少的内存（通常几KB的栈空间），因此可以创建数十万个纤程而不会耗尽系统资源。 纤程特别适合I/O密集型应用，当遇到阻塞操作时可以快速切换到其他纤程继续执行。\\n实现架构：\\n架构基于用户态调度器和上下文切换机制构建。 每个纤程包含独立的栈空间、寄存器状态和执行上下文。 纤程调度器维护就绪队列和阻塞队列，负责纤程的创建、调度和销毁。 当纤程遇到I/O操作时，会将自己加入阻塞队列并yield给调度器，调度器选择下一个就绪的纤程继续执行。 I/O完成后，相应的纤程被移回就绪队列等待调度。 上下文切换通过汇编代码实现，保存和恢复CPU寄存器状态。 为了支持异步I/O，通常结合epoll等机制，在I/O就绪时唤醒对应的纤程。 flowchart TD A[User Thread 1] --\\u0026gt; B[Scheduler] C[User Thread 2] --\\u0026gt; B D[User Thread N] --\\u0026gt; B B --\\u0026gt; E[Kernel Thread] F[Stack 1] --\\u0026gt; A G[Stack 2] --\\u0026gt; C H[Stack N] --\\u0026gt; D style A fill:#e8f5e8 style C fill:#e8f5e8 style D fill:#e8f5e8 style B fill:#f3e5f5 17. 工作窃取模型 (Work Stealing) 文件: work_stealing_server.h 特点: 每个线程有自己的任务队列，空闲时从其他线程窃取任务 适用场景: CPU密集型任务的负载均衡 优点: 自动负载均衡，减少线程空闲 缺点: 实现复杂，可能存在缓存一致性问题 实现: 基于无锁队列和线程池 详细介绍： 工作窃取模型是一种动态负载均衡的并行计算模式，每个工作线程维护自己的任务队列，当线程完成自己队列中的任务后，会尝试从其他线程的队列中\\u0026quot;窃取\\u0026quot;任务来执行。\\n这种模型能够自动适应任务执行时间的不均匀性，避免某些线程空闲而其他线程过载的情况。\\n工作窃取算法最初由Cilk项目提出，后来被广泛应用于Java的ForkJoinPool、Intel TBB等并行计算框架中。\\n该模型特别适合处理递归分治算法和任务执行时间差异较大的场景。\\n实现架构：\\n架构基于多个工作线程和双端队列（deque）构建。 每个工作线程拥有一个双端队列，新任务从队列头部添加，线程从头部取出任务执行（LIFO顺序，利用缓存局部性）。 当线程的队列为空时，会随机选择其他线程的队列，从尾部窃取任务（FIFO顺序，减少冲突）。 为了减少锁竞争，通常使用无锁的双端队列实现。 任务可以在执行过程中产生新的子任务，这些子任务会被添加到当前线程的队列中。 系统还包含一个全局任务队列，用于接收外部提交的任务。 flowchart TD A[Thread 1] --\\u0026gt; B[Task Queue 1] C[Thread 2] --\\u0026gt; D[Task Queue 2] E[Thread N] --\\u0026gt; F[Task Queue N] A --\\u0026gt;|Steal| D C --\\u0026gt;|Steal| F E --\\u0026gt;|Steal| B G[Global Task Pool] --\\u0026gt; B G --\\u0026gt; D G --\\u0026gt; F style B fill:#e3f2fd style D fill:#e3f2fd style F fill:#e3f2fd style G fill:#ffecb3 18. 生产者-消费者模型 文件: producer_consumer_server.h 特点: 专门的生产者线程接收连接，消费者线程处理请求 适用场景: 明确区分接收和处理逻辑的场景 优点: 职责分离，易于优化 缺点: 队列可能成为瓶颈 实现: 基于线程池 + 阻塞队列 详细介绍： 生产者-消费者模型是一种经典的并发设计模式，通过缓冲区将数据的生产和消费过程解耦。 生产者负责生成数据并放入缓冲区，消费者从缓冲区取出数据进行处理。 这种模型特别适合处理生产和消费速度不匹配的场景，缓冲区起到了削峰填谷的作用。 在网络服务器中，可以将接收连接作为生产过程，处理请求作为消费过程，通过任务队列进行解耦。\\n这种模型提高了系统的吞吐量和响应性，同时简化了系统设计。\\n实现架构：\\n架构围绕生产者线程、消费者线程和共享缓冲区构建。缓冲区通常使用线程安全的队列实现，支持多个生产者和消费者并发访问。 生产者线程负责接收客户端连接，将连接信息封装成任务对象放入队列。 消费者线程从队列中取出任务，执行具体的业务逻辑。 为了避免缓冲区溢出或空转，通常使用条件变量进行同步：当缓冲区满时生产者等待，当缓冲区空时消费者等待。 可以配置多个生产者和消费者线程以提高并发性。缓冲区大小需要根据生产和消费速度进行调优。 flowchart TD A[Producer Thread] --\\u0026gt; B[Blocking Queue] C[Consumer Thread 1] --\\u0026gt; B D[Consumer Thread 2] --\\u0026gt; B E[Consumer Thread N] --\\u0026gt; B F[Client Connections] --\\u0026gt; A B --\\u0026gt; G[Request Processing] style A fill:#e8f5e8 style B fill:#ffecb3 style C fill:#fff3e0 style D fill:#fff3e0 style E fill:#fff3e0 19. 半同步/半异步模型 (Half-Sync/Half-Async) 文件: half_sync_async_server.h 特点: 同步层处理协议，异步层处理I/O 适用场景: 复杂协议处理 优点: 结合同步和异步的优势 缺点: 架构复杂，层间通信开销 实现: 分层架构，异步I/O + 同步业务逻辑 详细介绍： 半同步/半异步模型是一种混合架构模式，将系统分为同步处理层和异步处理层，结合两种模式的优势。 异步层负责高效的I/O处理，使用事件驱动的方式处理网络事件；同步层负责业务逻辑处理，使用传统的同步编程模型。 两层之间通过队列进行通信，异步层将接收到的请求放入队列，同步层的工作线程从队列中取出请求进行处理。 这种模型既保证了I/O处理的高效性，又保持了业务逻辑的简洁性，是实际项目中常用的架构模式。\\n实现架构：\\n架构分为三个主要组件：异步I/O层、同步处理层和队列层。 异步I/O层使用单线程事件循环，基于epoll/kqueue等机制处理所有的网络I/O事件，包括接受连接、读取数据、发送响应。 当完整的请求接收完成后，将请求数据封装成任务对象放入队列。 同步处理层包含多个工作线程，从队列中取出任务，使用传统的同步方式处理业务逻辑，如数据库访问、文件操作等。 处理完成后，将响应数据通过队列传回异步层进行发送。 队列层负责两层之间的通信，通常使用线程安全的队列实现。 flowchart TD A[Client] --\\u0026gt; B[Synchronous Layer] B --\\u0026gt; C[Queue] C --\\u0026gt; D[Asynchronous Layer] D --\\u0026gt; E[I/O Operations] E --\\u0026gt; D D --\\u0026gt; C C --\\u0026gt; B B --\\u0026gt; A style B fill:#e1f5fe style C fill:#ffecb3 style D fill:#e8f5e8 20. Proactor模式 文件: proactor_server.h 特点: 异步I/O完成后通知应用程序 适用场景: Windows IOCP，异步I/O场景 优点: 真正的异步I/O 缺点: 平台依赖性强，实现复杂 实现: 基于操作系统的异步I/O机制 详细介绍： Proactor模式是一种基于异步I/O的设计模式，与Reactor模式相对应。 在Reactor模式中，应用程序在I/O就绪时被通知并自己执行I/O操作，而在Proactor模式中，应用程序发起异步I/O操作，操作系统完成I/O后通知应用程序处理结果。\\n这种模式真正实现了I/O操作的异步化，应用程序无需阻塞等待I/O完成，可以继续处理其他任务。\\nProactor模式特别适合I/O密集型应用，能够充分利用系统资源，提供更高的并发性能。\\n实现架构：\\n架构围绕异步I/O操作和完成通知构建。 核心组件包括：Proactor负责管理异步操作和分发完成事件，AsynchronousOperationProcessor处理异步I/O操作，CompletionHandler处理I/O完成事件。 应用程序发起异步读写操作时，将操作提交给操作系统，同时注册完成处理器。操作系统在后台执行I/O操作，完成后将结果放入完成队列。 Proactor从完成队列中取出事件，调用相应的完成处理器。 在Windows上可以使用IOCP（I/O Completion Ports），在Linux上可以使用io_uring或模拟实现。 flowchart TD A[Initiator] --\\u0026gt; B[Asynchronous Operation] B --\\u0026gt; C[OS Kernel] C --\\u0026gt; D[Completion Handler] D --\\u0026gt; A E[Application] --\\u0026gt; A F[I/O Completion Port] --\\u0026gt; D style A fill:#fff3e0 style B fill:#e3f2fd style C fill:#f3e5f5 style D fill:#e8f5e8 21. 管道模型 (Pipeline) 文件: pipeline_server.h 特点: 请求处理分为多个阶段，每个阶段由不同线程处理 适用场景: 复杂的请求处理流程 优点: 流水线处理，提高吞吐量 缺点: 阶段间同步复杂，可能存在瓶颈阶段 实现: 多个线程池，每个处理一个阶段 详细介绍： 管道模型将请求处理过程分解为多个连续的阶段，每个阶段由专门的线程或线程池负责，形成流水线式的处理架构。 请求按顺序通过各个阶段，每个阶段专注于特定的处理任务，如解析、验证、业务逻辑、响应生成等。 这种模型类似于工厂的流水线生产，能够显著提高系统的吞吐量，因为多个请求可以同时在不同阶段并行处理。 管道模型特别适合处理步骤固定、可以分解的复杂业务流程，在数据处理、图像处理、编译器等领域应用广泛。\\n实现架构：\\n架构由多个处理阶段和阶段间的缓冲队列组成，每个阶段包含一个或多个工作线程，专门负责特定的处理任务。 阶段之间通过线程安全的队列连接，前一阶段的输出作为后一阶段的输入。 请求从第一个阶段开始，依次通过所有阶段，最终产生响应。 每个阶段可以独立调优，包括线程数量、队列大小等参数。 为了避免某个阶段成为瓶颈，需要根据各阶段的处理能力合理配置资源。 可以实现阶段的动态扩缩容，根据负载情况调整线程数量。 flowchart TD A[Request] --\\u0026gt; B[Stage 1 Thread Pool] B --\\u0026gt; C[Stage 2 Thread Pool] C --\\u0026gt; D[Stage 3 Thread Pool] D --\\u0026gt; E[Stage N Thread Pool] E --\\u0026gt; F[Response] G[Buffer 1] --\\u0026gt; B H[Buffer 2] --\\u0026gt; C I[Buffer 3] --\\u0026gt; D J[Buffer N] --\\u0026gt; E style B fill:#e1f5fe style C fill:#e8f5e8 style D fill:#fff3e0 style E fill:#f3e5f5 22. 混合模型 文件: hybrid_server.h 特点: 结合多种模型的优势 示例: Reactor + 线程池 Epoll + 协程 多进程 + 多线程 适用场景: 需要平衡各种性能指标 优点: 灵活性高，可针对性优化 缺点: 实现复杂，调试困难 详细介绍： 混合模型是一种综合性的并发架构，根据不同的业务需求和性能要求，在同一个系统中组合使用多种并发模型，可以在I/O处理层使用Reactor模型实现高效的事件处理，在业务逻辑层使用线程池模型保证处理能力，在数据访问层使用异步I/O模型提高数据库访问效率。 这种模型允许开发者针对系统的不同部分选择最适合的并发策略，从而在整体上达到最优的性能表现。\\n混合模型在大型企业级应用、微服务架构、分布式系统中应用广泛，是现代高性能服务器的主流架构选择。\\n实现架构：\\n架构采用分层设计，每层根据其特点选择最适合的并发模型。 网络接入层通常使用事件驱动模型（如Epoll/Reactor）处理大量并发连接，保证高效的I/O处理。 请求路由层可能使用Actor模型实现请求的分发和负载均衡。 业务处理层根据业务特点选择合适的模型，如CPU密集型任务使用线程池，I/O密集型任务使用异步模型。 数据访问层可能结合连接池和异步I/O来优化数据库访问。 各层之间通过消息队列、事件总线或直接调用进行通信。 系统需要统一的监控和管理机制来协调各个模型的运行。 flowchart TD A[Model A] --\\u0026gt; B[Hybrid Controller] C[Model B] --\\u0026gt; B D[Model C] --\\u0026gt; B B --\\u0026gt; E[Unified Interface] F[Load Balancer] --\\u0026gt; A F --\\u0026gt; C F --\\u0026gt; D style A fill:#e8f5e8 style C fill:#fff3e0 style D fill:#e1f5fe style B fill:#f3e5f5 编译和运行 编译 make 运行服务器 # 基本用法 ./concurrency_server \\u0026lt;model\\u0026gt; [port] # 示例 ./concurrency_server thread_pool 8080 ./concurrency_server epoll 9000 ./concurrency_server reactor 8888 测试特定模型 # 测试线程池模型 make test-thread-pool # 测试epoll模型 make test-epoll # 测试所有模型（需要手动停止） make test-single make test-multi-thread # ... 等等 性能测试 # 需要安装Apache Bench (ab) make bench 客户端测试 可以使用多种工具测试服务器：\\n使用curl curl http://localhost:8080/ 使用Apache Bench # 1000个请求，10个并发连接 ab -n 1000 -c 10 http://localhost:8080/ 使用telnet telnet localhost 8080 GET / HTTP/1.1 Host: localhost 性能对比 模型名称 QPS single_process 19075.400 multi_process 6904.800 multi_thread 18137.834 process_pool1 18337.299 process_pool2 18589.268 thread_pool 18483.166 leader_follower 20180.701 poll 18817.867 kqueue 19096.133 reactor 18945.467 event_loop 19442.801 work_stealing 8903.566 actor 18681.500 fiber 18994.268 producer_consumer 18208.633 proactor 18130.533 技术要点 1. 非阻塞I/O 大部分模型都使用了非阻塞I/O来提高性能：\\nbool set_nonblocking(int fd) { int flags = fcntl(fd, F_GETFL, 0); if (flags == -1) return false; return fcntl(fd, F_SETFL, flags | O_NONBLOCK) != -1; } 2. 信号处理 进程模型需要处理SIGCHLD信号避免僵尸进程：\\nsignal(SIGCHLD, SIG_IGN); 3. 套接字选项 使用SO_REUSEADDR避免地址重用问题：\\nint opt = 1; setsockopt(server_fd, SOL_SOCKET, SO_REUSEADDR, \\u0026amp;opt, sizeof(opt)); 4. 边缘触发 vs 水平触发 水平触发: 只要条件满足就会触发事件 边缘触发: 只在状态变化时触发事件 注意事项 平台兼容性: Epoll仅在Linux上可用，Kqueue仅在BSD/macOS上可用 资源限制: 注意系统的文件描述符限制和内存限制 信号处理: 多进程模型需要正确处理子进程信号 线程安全: 多线程模型需要注意共享资源的同步 错误处理: 网络编程中要充分考虑各种错误情况 扩展建议 SSL/TLS支持: 添加HTTPS支持 HTTP解析: 完整的HTTP协议解析 配置文件: 支持配置文件设置参数 日志系统: 添加完整的日志记录 监控指标: 添加性能监控和统计 负载均衡: 实现多服务器负载均衡 学习资源 《Unix网络编程》- W. Richard Stevens 《Linux高性能服务器编程》- 游双 《C++并发编程实战》- Anthony Williams 《高性能网络编程》相关资料 许可证 本项目仅供学习和研究使用。\\n\"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"网络编程\",\"C++\"]",
      series: [],
      date: "\"2025-06-10\""
    });
  
    searchIndex.push({
      title: "\"libclang-py使用介绍\"",
      permalink: "\"/cpp/libclang-py%E4%BD%BF%E7%94%A8/\"",
      content: "\"libclang python binding API介绍 Info libclang 是一Clang提供的C接口库，具体介绍参见 clang: libclang: C Interface to Clang 它同时还提供了 python bindings，对有关的C接口进行了封装，方便用python代码来快速操作C/C++源码\\n本文正是对 libclang 的这一 python bindings 的使用做出简要介绍\\n同时值得一提的是，python 的这个 clang 包，也可以作为一个python封装C接口库的例子作为参考学习用\\n安装 安装最重要的点是要注意跟你系统上的clang/llvm版本要一致。可以通过clang -v来查看你真正需要的版本，然后：\\n# 版本号替换为你的clang的版本 pip install clang==20.1.3 基本概念介绍 translation_unit：翻译单元，我个人理解为就是一个c++编译单元对应的一棵语法树。通过 tu 可以获取一些全局信息比如头文件、诊断、补全信息等等 Cursor：语法树上的节点，通过 cursor 可以对语法树进行操作。（个人感觉叫做 node 更直观） Token：Cursor 是有结构的树上节点，对应的是树，Token 则是一个个的“单词”，可以用流的概念去类比 CursorKind：NodeType，节点类型。就是描述了什么函数节点、变量声明节点、分支节点等等 使用步骤 #（1）导包 from clang.cindex import Config, Cursor, CursorKind, Index, Rewriter #（2）导入动态库（什么libclang.dll、libclang.so、libclang.so.1之类的，特别注意版本） Config.set_library_file(\\u0026quot;/path/to/your/libclang.dll\\u0026quot;) #（3）解析源文件获取语法树 source_file = \\u0026quot;example.cpp\\u0026quot; compile_args = [\\u0026quot;-std=c++20\\u0026quot;, \\u0026quot;-Wall\\u0026quot;] tu = Index.create().parse(source_file, args=compile_args) #（4）对语法树进行各种你想要的读写变换操作 ## tu 就是 translation_unit ## tu.cursor 获取到的是语法树的根节点 ## tu.cursor.get_children() 可以获取节点的孩子，开始你对语法树的遍历 API说明 这家伙库基本没啥手册（反正我没找到），但是库本身不复杂，所以最好的api手册其实就是代码本身。\\nTip 推荐直接找到[python install path]/Lib/site-packages/clang/cindex.py 这个文件（跳转过去就好了），然后查看该文件的代码大纲，什么类有什么API就一目了然了。过一遍做到心中有数，用的时候再说\\n这里介绍简单介绍一些常用的类具有的API，供参考\\nTranslationUnit 翻译单元 # tu 是一个 TranslationUnit类型的对象 tu.cursor # 获取语法树根节点 tu.diagnostic # 获取诊断信息 tu.get_includes() # 获取引用的头文件 tu.get_tokens() # 获取 token 流 Cursor 语法树节点 # node 是一个 Cursor 类型的对象，这个基本上就是最常用的了，接口也非常非常多 node.walk_preorder() # 深度优先遍历序列 node.get_children() # 获取子节点 ... node.location # 节点位置 node.extent # 节点的代码块范围（start loc -\\u0026gt; end loc） node.kind # 节点的类型（描述这是个什么节点） node.type # 节点对应的元素的类型（如果有类型的话） node.spelling # token的名字（不一定有） node.displayname # 完整的名字（比如函数会把参数也带上） node.mangled_name # mangle之后的名字 ... node.semantic_parent # 节点的 semantic parent（语义上的父节点，比如成员函数类外声明父节点还是类） node.lexical_parent # 节点的 lexical parent（词法父节点，类外声明了词法父就是全局，类内声明就是类） ... node.get_arugments() # 获取参数（如果是FUNCTION_DECL的话） node.result_type # 当前节点的结果的类型（如果有的话，比如函数返回值） node.get_definition() # 获取定义节点（如果是reference的话） ... node.is_const_method() # 顾名思义 ... CursorKind 节点类型 # 有一些enum值，比如 FUNCTION_DECL CXX_METHOD VAR_DECL PARM_DECL NAMESPACE IF_STMT ... # 自身也是有一些函数的，方便做判断 node.kind.is_declaration() node.kind.is_reference() node.kind.is_expression() node.kind.is_statement() ... Type 节点元素类型 # 首先你得是这些类型才行 node.type.get_align() # 获取结构体元素的对齐方式 node.type.get_fields() # 遍历成员 node.type.get_array_size() # 常数组的size node.type.get_pointee() # 获取指针指向对象的类型 node.type.get_result() # 函数的返回值类型 node.type.is_pod() # 是POD ... node.type.spelling # 名字 node.type.kind # 返回 TypeKind TypeKind 描述类型的类型 # 一堆枚举，比如 BOOL INT LONGLONG WCHAR FUNCTIONNOPROTO AUTO ATOMIC ... node.type.kind.spelling # 字符串 SourceLocation 描述源码位置 node.location.file # 文件名 node.location.line # 行 node.location.column # 列 SourceRange 描述源码范围 node.extent.start # 开始的location node.extent.end # 结束的location Rewriter 保存语法树修改 writer = Rewriter.create(tu) # 从编译单元创建一个rewriter对象 writer.insert_text_before(loc, code) # 在指定location插入内容 writer.remove_text(extent) # 删除一个范围内的代码 writer.replace_text(extent, replacement) # 替换一个范围内的代码 writer.overwrite_changed_files() # 保存所有修改 writer.write_main_file_to_stdout() # 输出当前状态的语法树对应的文件 \\u0026hellip;\\n等等吧，直接看代码就是了\\n使用示例 类型判断 class NodeTypeJudger: @staticmethod def is_function(node: clang.cindex.Cursor) -\\u0026gt; bool: return node.kind in { clang.cindex.CursorKind.FUNCTION_DECL, clang.cindex.CursorKind.CXX_METHOD, clang.cindex.CursorKind.FUNCTION_TEMPLATE, clang.cindex.CursorKind.CONVERSION_FUNCTION } 打印节点 class NodeFormater: @staticmethod def format_as_detail_info(node: clang.cindex.Cursor) -\\u0026gt; str: return f\\u0026quot;\\u0026quot;\\u0026quot;NAME: {node.displayname} KIND: {node.kind.name} TYPE: {node.type.spelling} LINKAGE: {node.linkage.name} LOCATION: {NodeFormater.format_location(node.location)} RANGE: {NodeFormater.format_extent_shortly(node.extent)}\\u0026quot;\\u0026quot;\\u0026quot; @staticmethod def format_as_ast(node: clang.cindex.Cursor) -\\u0026gt; str: ast_list: list[str] = [] def _helper(n: clang.cindex.Cursor, intend: int) -\\u0026gt; None: ast_list.append( f\\u0026quot;{' '*intend}[{n.kind.name}][{n.displayname}] [{NodeFormater.format_extent(n.extent)}]\\u0026quot; ) for child in n.get_children(): _helper(child, intend + 2) _helper(node, 0) return \\u0026quot;\\\\n\\u0026quot;.join(ast_list) @staticmethod def format_function(node: clang.cindex.Cursor) -\\u0026gt; str: if NodeTypeJudger.is_function(node): func_name = node.spelling return_type = node.result_type.spelling args = \\u0026quot;, \\u0026quot;.join( [f\\u0026quot;{n.type.spelling} {n.spelling}\\u0026quot; for n in node.get_arguments()] # type: ignore ) return f\\u0026quot;{return_type} {func_name}({args})\\u0026quot; return \\u0026quot;\\u0026quot; @staticmethod def format_var(node: clang.cindex.Cursor) -\\u0026gt; str: if node.kind == clang.cindex.CursorKind.VAR_DECL: type = node.type.spelling name = node.displayname return f\\u0026quot;{name} ({type})\\u0026quot; return \\u0026quot;\\u0026quot; @staticmethod def format_location(loc: clang.cindex.SourceLocation) -\\u0026gt; str: return f\\u0026quot;{loc.file}:{loc.line}:{loc.column}\\u0026quot; @staticmethod def format_extent(range: clang.cindex.SourceRange) -\\u0026gt; str: return f\\u0026quot;({NodeFormater.format_location(range.start)} =\\u0026gt; {NodeFormater.format_location(range.end)})\\u0026quot; @staticmethod def format_extent_shortly(range: clang.cindex.SourceRange) -\\u0026gt; str: return f\\u0026quot;({range.start.line},{range.start.column}) -\\u0026gt; ({range.end.line},{range.end.column})\\u0026quot; 树上游走 class TreeVisitor: @staticmethod def collect_nodes( root_cursor: Cursor, node_filter: Callable[[Cursor], bool] ) -\\u0026gt; list[Cursor]: ret = [] for node in root_cursor.get_children(): if node_filter(node): ret.append(node) ret.extend(TreeVisitor.collect_nodes(node, node_filter)) return ret @staticmethod def travel_tree(root_cursor: Cursor, node_oper: Callable[[Cursor]]): for node in root_cursor.get_children(): node_oper(node) TreeVisitor.travel_tree(node, node_oper) # 可能的filter def filter_branch_node(node) -\\u0026gt; bool: return node.kind in [ CursorKind.IF_STMT, CursorKind.SWITCH_STMT, ] and \\u0026quot;modern\\u0026quot; in str(node.location.file) def filter_var_decl_node(node) -\\u0026gt; bool: return node.kind in [ CursorKind.VAR_DECL, CursorKind.FUNCTION_DECL, ] and \\u0026quot;modern\\u0026quot; in str(node.location.file) 结构变换 在所有if-elif-else结构的分支第一行插入语句（TODO: 写这个的时候还没发现 Rewirter 这个接口，因此采用的是直接读写文件行的方式。当然可以使用Rewriter来重构此函数）\\nclass NodeComposer: @staticmethod def __insert_in_if_stmt_helper( file_contents: list[str], insert_pos: int, node: Cursor, if_branch: str, else_branch: str, ): children = list(node.get_children()) csz = len(children) if csz \\u0026lt; 2: print(\\u0026quot;Strange If Node with less than 2 children!!!\\u0026quot;) elif csz == 2: if_pos = children[1].location.line real_if_branch = f'{\\u0026quot; \\u0026quot;*insert_pos}{if_branch}\\\\n' file_contents.insert(if_pos, real_if_branch) elif csz == 3: if_pos: int = children[1].location.line real_if_branch = f'{\\u0026quot; \\u0026quot;*insert_pos}{if_branch}\\\\n' if children[2].kind == CursorKind.IF_STMT: NodeComposer.__insert_in_if_stmt_helper( file_contents, insert_pos, children[2], if_branch, else_branch ) else: else_pos = children[2].location.line real_else_branch = f'{\\u0026quot; \\u0026quot;*insert_pos}{else_branch}\\\\n' file_contents.insert(else_pos, real_else_branch) file_contents.insert(if_pos, real_if_branch) else: print(\\u0026quot;Strange If Node with more than 3 children!!!\\u0026quot;) @staticmethod def insert_in_if_stmt(node: Cursor, if_branch: str, else_branch: str): \\u0026quot;\\u0026quot;\\u0026quot;在if-else_if-else节点中，插入想要的语句\\u0026quot;\\u0026quot;\\u0026quot; if node.kind != CursorKind.IF_STMT: return file_contents = [] with open(str(node.location.file), encoding=\\u0026quot;utf-8\\u0026quot;, mode=\\u0026quot;r\\u0026quot;) as f: file_contents = f.readlines() insert_pos = node.location.column + 3 NodeComposer.__insert_in_if_stmt_helper( file_contents, insert_pos, node, if_branch, else_branch ) with open(str(node.location.file), encoding=\\u0026quot;utf-8\\u0026quot;, mode=\\u0026quot;w\\u0026quot;) as f: f.writelines(file_contents) @staticmethod def insert_in_all_if_stmt( if_stmt_list: list[Cursor], if_branch: str, else_branch: str ): \\u0026quot;\\u0026quot;\\u0026quot;在所有的if-else节点插入。关键在于，要注意倒序插入\\u0026quot;\\u0026quot;\\u0026quot; for node in sorted(if_stmt_list, key=lambda n: n.location.line, reverse=True): NodeComposer.insert_in_if_stmt(node, if_branch, else_branch) \"",
      categories: [],
      tags: "[\"C++\",\"编译原理\"]",
      series: "[\"快速上手\"]",
      date: "\"2025-06-10\""
    });
  
    searchIndex.push({
      title: "\"参数包与折叠表达式傻傻分不清\"",
      permalink: "\"/cpp/%E5%8F%82%E6%95%B0%E5%8C%85%E4%B8%8E%E6%8A%98%E5%8F%A0%E8%A1%A8%E8%BE%BE%E5%BC%8F/\"",
      content: "\"参数包与折叠表达式傻傻分不清 开始接触可变参数的时候，...的位置总是整得我晕头转向，特别是一下几个例子\\n以下都是错误写法 不知道可变参数类型怎么声明 template\\u0026lt;typename... Args\\u0026gt; void foo(Args args...){} 不知到参数包、类型包应该怎么传递 std::forward\\u0026lt;Args...\\u0026gt;(args...) 折叠表达式和参数包展开傻傻分不清 (std::cout \\u0026lt;\\u0026lt; \\u0026quot;[prefix]\\u0026quot; \\u0026lt;\\u0026lt; Val)... 希望看完本文，能够让你明白上面几处错在哪里，正确的写法应该是什么样子的\\n参数包 作用说明 ...在参数包中，大致上有两种作用：\\n声明一个包（出现在类型或者参数名的左边，表示这是一个包） template\\u0026lt;typename... Args\\u0026gt;，声明了 Args 是一个类型的包 template\\u0026lt;auto... Ns\\u0026gt; 声明了 Ns 是一个非类型参数包 void foo(Args... args) 声明了 args 是一个函数参数包 展开一个包（出现在参数包名的右边，表示展开这个包为一个逗号分割的元素列表） foo(args...) 表示把args这个参数包，展开成一个个逗号分隔的参数，也就是类似 foo(arg_0, arg_1, arg_2) foo(std::forward\\u0026lt;Arg\\u0026gt;(arg)...) 把args这个参数包，展开为一个个的forward包起来的样子进行传参，即foo(forward\\u0026lt;Arg_1\\u0026gt;(arg_1), forward\\u0026lt;Arg_2\\u0026gt;(arg2), forward\\u0026lt;Arg_3\\u0026gt;(arg_3)) 个人记忆方式 上面说了一堆，但是用的时候还是容易搞混。单独的声明和展开的场景很好区分，但是我本人就是在std::forward\\u0026lt;Args...\\u0026gt;(args...)这个错误写法上老是晕。\\n所以，我用自己的办法来对...做出精简的理解：（但是不一定是精准，如果你发现这么想有什么致命错误，还望不吝赐教🫰\\nNote 在处理参数包的场景中，...的作用就是展开它左边的东西。是的，只关心左边\\n\\u0026lt;typename... Args\\u0026gt;：左边是typename，说明是把 typename 展开成了多个，也就是说声明了多个 typename，那不就是类型包 void foo(Args\\u0026amp;\\u0026amp;... args){}：左边是类型Args，说明把Args展开了，那就是定义了多个arg参数，用一个args来表示它们 bar(args...);：左边是args，说明把args展开了，这是一个参数包，就是展成了一个一个的参数，用逗号分隔，传给了bar函数 std::forward\\u0026lt;Arg\\u0026gt;(args)...：左边是一个forward完美转发参数，说明把args展开了，而且是展开成完美转发的样子，用逗号分隔 核心就是只关心...左边的东西就好了，不管左边是啥，你就按照展开它的方式去理解。是typename展开了就是声明类型包，是类型你展开了那就是声明了该类型的参数包，是参数包你展开了那肯定是用去传参了\\n折叠表达式 其实折叠表达式我不晕，比较好理解，直接去 Fold expressions (since C++17) - cppreference.com 看看就好了，在此不赘述\\n之所以在本文中提到，实际上是为了下一节，和参数包进行区分\\n二者区分的场景 首先定义一个接收可变参数的函数，它没什么用\\ntemplate\\u0026lt;typename... Args\\u0026gt; void foo(Args\\u0026amp;\\u0026amp;... args){} 然后考虑下面两组代码：\\n正确的写法 template\\u0026lt;typename... Args\\u0026gt; void bar(Args\\u0026amp;\\u0026amp;... args){ foo(std::forward\\u0026lt;Arg\\u0026gt;(args)...); // ✅ 没问题，对每个参数都进行完美转发 ((std::cout \\u0026lt;\\u0026lt; \\u0026quot;[prefix]:\\u0026quot; \\u0026lt;\\u0026lt; args), ...); // ✅ 也没问题，加上前缀打印每个参数 } 错误的写法 template\\u0026lt;typename... Args\\u0026gt; void bar(Args\\u0026amp;\\u0026amp;... args){ // ❌ 错误！并不能像上面cout一样用折叠表达式，把forward用表达式展开成一堆逗号分隔的参数 foo((std::forward\\u0026lt;Arg\\u0026gt;(args), ...)); // ❌ 错误！这个也不会像上面forward一样用参数包展开，把cout展开成一堆cout分别输出参数 (std::cout \\u0026lt;\\u0026lt; \\u0026quot;[prefix]:\\u0026quot; \\u0026lt;\\u0026lt; args)...; } 奇了怪了，为什么cout就只能用折叠表达式，根据,操作符进行展开；而forward就只能用参数包展开，默认展开成逗号分割呢？难道forward不算表达式？\\n或许这里是我想的少了，也或许它确实是一个容易混淆的点，但答案肯定是背后另有原因。原因是：\\n参数包的展开必须发生在可以接收逗号分割列表的上下文中 上下文类型 示例 是否直接支持参数包 说明 函数调用参数列表 func(args...) ✅ 是 自然接受逗号分隔参数 初始化列表 {args...} ✅ 是 自然接受逗号分隔值 模板参数列表 Class\\u0026lt;Args...\\u0026gt; ✅ 是 自然接受逗号分隔类型 独立表达式 函数体内的表达式 ❌ 否 需要特殊处理 所以上面的cout和forward的区别，其实是因为它们所处的位置不同：\\nforward处在函数调用参数列表中，可以当成参数包直接展开；\\n而cout是一个函数内的独立表达式，所以不能当参数包展开。而折叠表达式的引入，不正是为了解决表达式处理参数包不方便的问题么？\\n造成迷惑的，好像为什么这个只能这样用，其实也是因为，forward大多都用于完美转发参数，它确实就是常出现在参数列表，而一般没人写一堆cout去传参吧。实际上cout当然可以按照forward那样写：\\nSuccess template\\u0026lt;typename... Args\\u0026gt; void bar(Args\\u0026amp;\\u0026amp;... args){ // ✅ 没问题，直接把cout用参数包形式展开传给foo；此时foo的参数列表类型是一堆的ostream类型 foo((std::cout \\u0026lt;\\u0026lt; \\u0026quot;[prefix]:\\u0026quot; \\u0026lt;\\u0026lt; args)...); foo(std::forward\\u0026lt;Arg\\u0026gt;(args)...); // 是不是跟forward一样了 } 深入代码进行验证 通过 C++ Insights 可以很方便地查看这些语法糖经过编译器处理后地真实地样子\\n考虑这份源码，它这些参数包展开、表达式折叠等处理后，实际上是什么样子呢？\\n#include\\u0026lt;iostream\\u0026gt; #include\\u0026lt;utility\\u0026gt; template\\u0026lt;typename ... Args\\u0026gt; void foo(Args\\u0026amp;\\u0026amp;... args){} template\\u0026lt;typename ... Args\\u0026gt; void log(Args\\u0026amp;\\u0026amp;... args){ ((std::cout \\u0026lt;\\u0026lt; \\u0026quot;[P]:\\u0026quot;\\u0026lt;\\u0026lt;std::forward\\u0026lt;Args\\u0026gt;(args)),...); } template\\u0026lt;typename ... Args\\u0026gt; void bar(Args\\u0026amp;\\u0026amp;... args){ log(std::forward\\u0026lt;Args\\u0026gt;(args)...); foo((std::cout\\u0026lt;\\u0026lt;args)...); } int main(){ int a = 10; int\\u0026amp; b = a; bar(a, b, 100); } 实际上这样：\\n// ... 省略头文件和模板原始函数，直接看模板实例化出来的东西 // foo果然特化出了一个全是ostream的版本 // 所以即使是cout，在参数上下文中，直接被参数包展开也是没问题的 template\\u0026lt;\\u0026gt; void foo\\u0026lt;std::basic_ostream\\u0026lt;char\\u0026gt; \\u0026amp;, std::basic_ostream\\u0026lt;char\\u0026gt; \\u0026amp;, std::basic_ostream\\u0026lt;char\\u0026gt; \\u0026amp;\\u0026gt; (std::basic_ostream\\u0026lt;char\\u0026gt; \\u0026amp; __args0, std::basic_ostream\\u0026lt;char\\u0026gt; \\u0026amp; __args1, std::basic_ostream\\u0026lt;char\\u0026gt; \\u0026amp; __args2) {} // 这是逗号这个单目操作符，被右折叠表达式展开后的样子 template\\u0026lt;\\u0026gt; void log\\u0026lt;int \\u0026amp;, int \\u0026amp;, int\\u0026gt;(int \\u0026amp; __args0, int \\u0026amp; __args1, int \\u0026amp;\\u0026amp; __args2) { (std::operator\\u0026lt;\\u0026lt;(std::cout, \\u0026quot;[P]:\\u0026quot;).operator\\u0026lt;\\u0026lt;(std::forward\\u0026lt;int \\u0026amp;\\u0026gt;(__args0))) , ( (std::operator\\u0026lt;\\u0026lt;(std::cout, \\u0026quot;[P]:\\u0026quot;).operator\\u0026lt;\\u0026lt;(std::forward\\u0026lt;int \\u0026amp;\\u0026gt;(__args1))) , (std::operator\\u0026lt;\\u0026lt;(std::cout, \\u0026quot;[P]:\\u0026quot;).operator\\u0026lt;\\u0026lt;(std::forward\\u0026lt;int\\u0026gt;(__args2))) ) ; } // 这里是参数包展开的样子 template\\u0026lt;\\u0026gt; void bar\\u0026lt;int \\u0026amp;, int \\u0026amp;, int\\u0026gt;(int \\u0026amp; __args0, int \\u0026amp; __args1, int \\u0026amp;\\u0026amp; __args2) { log( std::forward\\u0026lt;int \\u0026amp;\\u0026gt;(__args0), std::forward\\u0026lt;int \\u0026amp;\\u0026gt;(__args1), std::forward\\u0026lt;int\\u0026gt;(__args2) ); foo( (std::cout.operator\\u0026lt;\\u0026lt;(__args0)), (std::cout.operator\\u0026lt;\\u0026lt;(__args1)), (std::cout.operator\\u0026lt;\\u0026lt;(__args2)) ); } // ... 省略main函数 \"",
      categories: "[\"C++笔记\"]",
      tags: "[\"C++\"]",
      series: "[\"modern c++\"]",
      date: "\"2025-06-05\""
    });
  
    searchIndex.push({
      title: "\"协程快速入门\"",
      permalink: "\"/cpp/%E5%8D%8F%E7%A8%8B%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/\"",
      content: "\"协程快速上手 什么是协程？ 协程就是一个可以暂停和恢复执行的函数。别的函数是一镜到底，协程是走走停停。停下（被挂起）的时候，就是说当前线程可以去执行别的任务了，完了还能再回来\\n为什么要有协程 首先看看线程的历史。为什么会有线程呢，线程的作用是什么呢？\\n是为了尽可能多的吃满CPU，发挥性能。当然，这是我们说的多线程并发的常用场景。但是最开始引入线程其实是为了解决一个异步IO的问题。\\n一开始的电脑，程序员编辑完一个文件，按下保存，然后就可以去玩了。因为只有一个线程，在保存的时候，就不能干别的了。但是这显然是不合理的，磁盘在那吭哧吭哧写，但是cpu却是闲着的。闲着的cpu是否应该找点活干呢？\\n后来有了多任务的概念（应该不是当前场景首创，较真的话需要深入考究），也就是多个线程。有了多个线程，保存的线程阻塞了，不影响编辑的线程。这就是多线程带来的异步，让IO进行的时候，CPU能空出来。\\n\\u0026hellip;\\n随着计算机的发展，异步写磁盘的情况已经是小菜一碟了，但是又有了新的挑战，比如经典的C10K问题，也就是服务器单机1w并发请求处理。单个线程处理1w个请求必然会卡死。创建1w个线程，每个线程4M的栈，这就是40G的内存，那显然也不行。看来用线程实现的异步IO不中用了。\\n那是时候引入单线程异步IO的概念了。用一个线程，就可以发起很多个IO操作。这需要：\\n一个IO多路复用的通知机制。一个接口，通知所有的IO时间。如果不是多路复用的，那必然就需要新的线程 非阻塞IO（只需有IO发起操作，无需等IO完成）。阻塞了当前这个唯一的线程就被挂起了 todo: 简化一下\\n深入理解协程 理解协程，最好的办法就是和线程进行类比：\\n从调度、挂起切换角度比较 线程由OS调度、切换，调用阻塞IO等会被挂起，IO就绪OS会将其恢复 协程由用户调度、切换，由用户指定什么时候挂起，什么时候恢复。怎么指定呢？——通过Awaiter指定，await_suspend()描述协程挂起时执行什么动作（比如发起一次非阻塞IO然后等待，比如注册fd到epoll然后等待）；await_resume()描述协程恢复时执行什么动作（比如读取就绪数据/向就绪fd发送）。 从编码角度比较。我们更习惯的都是以同步的方式编码 线程调用阻塞IO，比如read，发起一次IO，然后当前线程被OS阻塞，IO就绪时恢复。 协程效用一个异步IO/非阻塞IO，发起一次任务。然后当前协程被阻塞，任务就绪时恢复。线程阻不阻塞OS知道，协程怎么知道哪个IO要阻塞呢？用co_await标记。所以加上co_await后，就相当于告诉协程，这是一个“阻塞”IO，要阻塞协程。 简单来说，阻塞IO阻塞整个线程，非阻塞IO阻塞协程（用co_await标记上：这对于协程来说是一个阻塞IO） 从结果传出的角度 线程需要使用一个std::promise，传递不是立马能获取到的结果 协程也需要这么一个promise，它就是协程的Task\\u0026lt;T\\u0026gt;，里面要求必须有一个promise_type，这就是协程的promise，用于获取不是立马得到的结果 从第2点也可以看出：协程必须要搭配真正的异步IO才叫协程。因为 调用同步IO，OS管你这那的，直接阻塞整个线程了，它眼里可没有协程这么回事。 创建线程实现异步IO，那不还是多线程等于？ 类比完再想想，什么叫做，协程时由用户负责调度切换的协程这句话，有没有更清晰？\\nC++20协程核心概念 promise_type template\\u0026lt;typename T\\u0026gt; struct Task\\u0026lt;T\\u0026gt;::promise_type { T promised_value; std::exception_ptr exptr; T Get() { if(exptr) std::rethrow_excetion(exptr); return promised_value; } // 强制要求的函数： void get_return_object(){ return Task{std::coroutine_handle\\u0026lt;promise_type\\u0026gt;::from_promise(*this)}; } auto initial_suspend() { return std::suspend_never{}; } auto final_suspend() noexcept { return std::suspend_always{}; } void unhandled_exception() { exptr = std::current_excetion(); } template\\u0026lt;typename U = T\\u0026gt; require(std::is_same_v\\u0026lt;U, void\\u0026gt;) void return_void() {} template\\u0026lt;typename U = T\\u0026gt; require(std::is_convertible_v\\u0026lt;U, T\\u0026gt;) void return_value(U v){ promised_value = std::move(v); } template\\u0026lt;std::convertible_to\\u0026lt;T\\u0026gt; From\\u0026gt; std::suspend_always yield_value(From v) { promised_value = std::move(v); return {}; } }; 那么一个完整的task应该长什么样呢？\\ntemplate\\u0026lt;typename T\\u0026gt; class Task{ public: struct promise_type; using HandleType = std::coroutine_handle\\u0026lt;promise_type\\u0026gt;; Task(HandleType handle): coro_handle_(handle){} Task(Task\\u0026amp;\\u0026amp;); Task\\u0026amp; operator=(Task\\u0026amp;\\u0026amp;); ~Task(){ if(coro_handle_){ coro_handle_.destory(); coro_handle = nullptr; } } Get() { return coro_handle_.promise().Get(); } private: HandleType coro_handle_; }; Awatiable \\u0026amp; Awaiter \"",
      categories: "[\"C++笔记\"]",
      tags: "[\"coroutine\",\"C++\"]",
      series: "[\"modern c++\"]",
      date: "\"2025-05-21\""
    });
  
    searchIndex.push({
      title: "\"初等数学回忆录\"",
      permalink: "\"/%E7%AC%94%E8%AE%B0/%E5%88%9D%E7%AD%89%E6%95%B0%E5%AD%A6%E5%9B%9E%E5%BF%86%E5%BD%95/\"",
      content: "\"初等数学回忆录 关于latex语法 常用数学符号的latex表示 | SHUAIKAI\\u0026rsquo;s Blog Latex速查手册.pdf 坐标系 极坐标 $$ \\\\begin{cases} x = \\\\rho\\\\cos\\\\theta \\\\\\\\ y = \\\\rho\\\\sin\\\\theta \\\\end{cases} \\\\qquad \\\\begin{cases} \\\\rho^2 = x^2+y^2 \\\\\\\\ \\\\tan\\\\theta = \\\\frac{y}{x}\\\\ (x\\\\neq 0) \\\\end{cases} $$由上式即可完成坐标系互换。（常用技巧比如两边同时乘 $\\\\rho$ 等在此不表）\\n三角函数 Reference 三角函数公式 - Easymath-wiki 三角恒等式 倒数关系：\\n$$\\\\tan\\\\alpha \\\\cdot \\\\cot\\\\alpha = 1$$$$\\\\sin\\\\alpha \\\\cdot \\\\csc\\\\alpha = 1$$$$\\\\cos\\\\alpha \\\\cdot \\\\sec\\\\alpha = 1$$商数关系：\\n$$\\\\tan\\\\alpha = \\\\frac{\\\\sin\\\\alpha}{\\\\cos\\\\alpha}$$$$\\\\cot\\\\alpha = \\\\frac{\\\\cos\\\\alpha}{\\\\sin\\\\alpha}$$平方关系：\\n$$\\\\sin^2\\\\alpha + \\\\cos^2\\\\alpha = 1$$$$1 + \\\\tan^2\\\\alpha = \\\\sec^2\\\\alpha$$$$1 + \\\\cot^2\\\\alpha = \\\\csc^2\\\\alpha$$诱导公式 符号看象限，各函数在不同象限的正负:\\n第一象限 (0 to $\\\\frac{\\\\pi}{2}$): All positive ($\\\\sin\\\\alpha, \\\\cos\\\\alpha, \\\\tan\\\\alpha \\u0026gt; 0$) 第二象限 ($\\\\frac{\\\\pi}{2}$ to $\\\\pi$): Sine positive ($\\\\sin\\\\alpha \\u0026gt; 0, \\\\cos\\\\alpha \\u0026lt; 0, \\\\tan\\\\alpha \\u0026lt; 0$) 第三象限 ($\\\\pi$ to $\\\\frac{3\\\\pi}{2}$): Tangent positive ($\\\\sin\\\\alpha \\u0026lt; 0, \\\\cos\\\\alpha \\u0026lt; 0, \\\\tan\\\\alpha \\u0026gt; 0$) 第四象限 ($\\\\frac{3\\\\pi}{2}$ to $2\\\\pi$): Cosine positive ($\\\\sin\\\\alpha \\u0026lt; 0, \\\\cos\\\\alpha \\u0026gt; 0, \\\\tan\\\\alpha \\u0026lt; 0$) “奇变偶不变，符号看象限” (对于 $k\\\\frac{\\\\pi}{2} \\\\pm \\\\alpha$ 的形式， $k$ 为整数)\\n$k$ 为偶数时，函数名不变。 $k$ 为奇数时，$\\\\sin \\\\leftrightarrow \\\\cos$, $\\\\tan \\\\leftrightarrow \\\\cot$, $\\\\sec \\\\leftrightarrow \\\\csc$。 符号由原函数在 $\\\\alpha$ 视为锐角时， $k\\\\frac{\\\\pi}{2} \\\\pm \\\\alpha$ 所在象限的原函数符号决定。 常用公式（自行练习）：\\n$\\\\sin(2k\\\\pi + \\\\alpha) = \\\\sin\\\\alpha$\\n$\\\\cos(2k\\\\pi + \\\\alpha) = \\\\cos\\\\alpha$\\n$\\\\tan(2k\\\\pi + \\\\alpha) = \\\\tan\\\\alpha$\\n$\\\\cot(2k\\\\pi + \\\\alpha) = \\\\cot\\\\alpha$\\n$\\\\sin(\\\\pi + \\\\alpha) = -\\\\sin\\\\alpha$\\n$\\\\cos(\\\\pi + \\\\alpha) = -\\\\cos\\\\alpha$\\n$\\\\tan(\\\\pi + \\\\alpha) = \\\\tan\\\\alpha$\\n$\\\\sin(-\\\\alpha) = -\\\\sin\\\\alpha$ (奇函数)\\n$\\\\cos(-\\\\alpha) = \\\\cos\\\\alpha$ (偶函数)\\n$\\\\tan(-\\\\alpha) = -\\\\tan\\\\alpha$ (奇函数)\\n$\\\\sin(\\\\pi - \\\\alpha) = \\\\sin\\\\alpha$\\n$\\\\cos(\\\\pi - \\\\alpha) = -\\\\cos\\\\alpha$\\n$\\\\tan(\\\\pi - \\\\alpha) = -\\\\tan\\\\alpha$\\n$\\\\sin\\\\left(\\\\frac{\\\\pi}{2} - \\\\alpha\\\\right) = \\\\cos\\\\alpha$\\n$\\\\cos\\\\left(\\\\frac{\\\\pi}{2} - \\\\alpha\\\\right) = \\\\sin\\\\alpha$\\n$\\\\tan\\\\left(\\\\frac{\\\\pi}{2} - \\\\alpha\\\\right) = \\\\cot\\\\alpha$\\n$\\\\sin\\\\left(\\\\frac{\\\\pi}{2} + \\\\alpha\\\\right) = \\\\cos\\\\alpha$\\n$\\\\cos\\\\left(\\\\frac{\\\\pi}{2} + \\\\alpha\\\\right) = -\\\\sin\\\\alpha$\\n$\\\\tan\\\\left(\\\\frac{\\\\pi}{2} + \\\\alpha\\\\right) = -\\\\cot\\\\alpha$\\n$\\\\sin\\\\left(\\\\frac{3\\\\pi}{2} - \\\\alpha\\\\right) = -\\\\cos\\\\alpha$\\n$\\\\cos\\\\left(\\\\frac{3\\\\pi}{2} - \\\\alpha\\\\right) = -\\\\sin\\\\alpha$\\n$\\\\tan\\\\left(\\\\frac{3\\\\pi}{2} - \\\\alpha\\\\right) = \\\\cot\\\\alpha$\\n$\\\\sin\\\\left(\\\\frac{3\\\\pi}{2} + \\\\alpha\\\\right) = -\\\\cos\\\\alpha$\\n$\\\\cos\\\\left(\\\\frac{3\\\\pi}{2} + \\\\alpha\\\\right) = \\\\sin\\\\alpha$\\n$\\\\tan\\\\left(\\\\frac{3\\\\pi}{2} + \\\\alpha\\\\right) = -\\\\cot\\\\alpha$\\n辅助角公式 将 $a\\\\sin x + b\\\\cos x$ 的形式化为 $A\\\\sin(x+\\\\phi)$ 或 $A\\\\cos(x-\\\\phi\\u0026rsquo;)$：\\n$$a\\\\sin x + b\\\\cos x = \\\\sqrt{a^2+b^2} \\\\left( \\\\frac{a}{\\\\sqrt{a^2+b^2}}\\\\sin x + \\\\frac{b}{\\\\sqrt{a^2+b^2}}\\\\cos x \\\\right)$$令 $\\\\cos\\\\phi = \\\\frac{a}{\\\\sqrt{a^2+b^2}}$, $\\\\sin\\\\phi = \\\\frac{b}{\\\\sqrt{a^2+b^2}}$，则 $\\\\tan\\\\phi = \\\\frac{b}{a}$。\\n$$ a\\\\sin x + b\\\\cos x = \\\\sqrt{a^2+b^2} (\\\\cos\\\\phi\\\\sin x + \\\\sin\\\\phi\\\\cos x) = \\\\sqrt{a^2+b^2} \\\\sin(x+\\\\phi) $$ 其中 $\\\\phi$ 的值由 $a, b$ 的符号决定其所在象限。\\n$$ a\\\\sin x + b\\\\cos x = \\\\sqrt{a^2+b^2} (\\\\sin\\\\phi'\\\\sin x + \\\\cos\\\\phi'\\\\cos x) = \\\\sqrt{a^2+b^2} \\\\cos(x-\\\\phi') $$倍角公式 $$\\\\sin(2\\\\alpha) = 2\\\\sin\\\\alpha\\\\cos\\\\alpha$$$$\\\\cos(2\\\\alpha) = \\\\cos^2\\\\alpha - \\\\sin^2\\\\alpha = 2\\\\cos^2\\\\alpha - 1 = 1 - 2\\\\sin^2\\\\alpha$$$$\\\\tan(2\\\\alpha) = \\\\frac{2\\\\tan\\\\alpha}{1-\\\\tan^2\\\\alpha}$$三倍角公式 $$\\\\sin(3\\\\alpha) = 3\\\\sin\\\\alpha - 4\\\\sin^3\\\\alpha$$$$\\\\cos(3\\\\alpha) = 4\\\\cos^3\\\\alpha - 3\\\\cos\\\\alpha$$$$\\\\tan(3\\\\alpha) = \\\\frac{3\\\\tan\\\\alpha - \\\\tan^3\\\\alpha}{1 - 3\\\\tan^2\\\\alpha}$$半角公式、降幂公式 半角公式：\\n$$\\\\sin\\\\left(\\\\frac{\\\\alpha}{2}\\\\right) = \\\\pm\\\\sqrt{\\\\frac{1-\\\\cos\\\\alpha}{2}}$$$$\\\\cos\\\\left(\\\\frac{\\\\alpha}{2}\\\\right) = \\\\pm\\\\sqrt{\\\\frac{1+\\\\cos\\\\alpha}{2}}$$$$\\\\tan\\\\left(\\\\frac{\\\\alpha}{2}\\\\right) = \\\\pm\\\\sqrt{\\\\frac{1-\\\\cos\\\\alpha}{1+\\\\cos\\\\alpha}} = \\\\frac{\\\\sin\\\\alpha}{1+\\\\cos\\\\alpha} = \\\\frac{1-\\\\cos\\\\alpha}{\\\\sin\\\\alpha}$$(正负号取决于 $\\\\frac{\\\\alpha}{2}$ 所在的象限)\\n降幂公式 (由倍角公式变形得到)：\\n$$\\\\sin^2\\\\alpha = \\\\frac{1-\\\\cos(2\\\\alpha)}{2}$$$$\\\\cos^2\\\\alpha = \\\\frac{1+\\\\cos(2\\\\alpha)}{2}$$$$\\\\tan^2\\\\alpha = \\\\frac{1-\\\\cos(2\\\\alpha)}{1+\\\\cos(2\\\\alpha)}$$万能公式 令 $t = \\\\tan\\\\left(\\\\frac{\\\\alpha}{2}\\\\right)$：\\n$$\\\\sin\\\\alpha = \\\\frac{2t}{1+t^2}$$$$\\\\cos\\\\alpha = \\\\frac{1-t^2}{1+t^2}$$$$\\\\tan\\\\alpha = \\\\frac{2t}{1-t^2}$$和差公式 和角公式：\\n$$\\\\sin(\\\\alpha + \\\\beta) = \\\\sin\\\\alpha\\\\cos\\\\beta + \\\\cos\\\\alpha\\\\sin\\\\beta$$$$\\\\cos(\\\\alpha + \\\\beta) = \\\\cos\\\\alpha\\\\cos\\\\beta - \\\\sin\\\\alpha\\\\sin\\\\beta$$$$\\\\tan(\\\\alpha + \\\\beta) = \\\\frac{\\\\tan\\\\alpha + \\\\tan\\\\beta}{1 - \\\\tan\\\\alpha\\\\tan\\\\beta}$$差角公式：\\n$$\\\\sin(\\\\alpha - \\\\beta) = \\\\sin\\\\alpha\\\\cos\\\\beta - \\\\cos\\\\alpha\\\\sin\\\\beta$$$$\\\\cos(\\\\alpha - \\\\beta) = \\\\cos\\\\alpha\\\\cos\\\\beta + \\\\sin\\\\alpha\\\\sin\\\\beta$$$$\\\\tan(\\\\alpha - \\\\beta) = \\\\frac{\\\\tan\\\\alpha - \\\\tan\\\\beta}{1 + \\\\tan\\\\alpha\\\\tan\\\\beta}$$和差化积，积化和差 和差化积：\\n$$\\\\sin\\\\alpha + \\\\sin\\\\beta = 2\\\\sin\\\\left(\\\\frac{\\\\alpha+\\\\beta}{2}\\\\right)\\\\cos\\\\left(\\\\frac{\\\\alpha-\\\\beta}{2}\\\\right)$$$$\\\\sin\\\\alpha - \\\\sin\\\\beta = 2\\\\cos\\\\left(\\\\frac{\\\\alpha+\\\\beta}{2}\\\\right)\\\\sin\\\\left(\\\\frac{\\\\alpha-\\\\beta}{2}\\\\right)$$$$\\\\cos\\\\alpha + \\\\cos\\\\beta = 2\\\\cos\\\\left(\\\\frac{\\\\alpha+\\\\beta}{2}\\\\right)\\\\cos\\\\left(\\\\frac{\\\\alpha-\\\\beta}{2}\\\\right)$$$$\\\\cos\\\\alpha - \\\\cos\\\\beta = -2\\\\sin\\\\left(\\\\frac{\\\\alpha+\\\\beta}{2}\\\\right)\\\\sin\\\\left(\\\\frac{\\\\alpha-\\\\beta}{2}\\\\right)$$积化和差：\\n$$\\\\sin\\\\alpha\\\\cos\\\\beta = \\\\frac{1}{2}[\\\\sin(\\\\alpha+\\\\beta) + \\\\sin(\\\\alpha-\\\\beta)]$$$$\\\\cos\\\\alpha\\\\sin\\\\beta = \\\\frac{1}{2}[\\\\sin(\\\\alpha+\\\\beta) - \\\\sin(\\\\alpha-\\\\beta)]$$$$\\\\cos\\\\alpha\\\\cos\\\\beta = \\\\frac{1}{2}[\\\\cos(\\\\alpha+\\\\beta) + \\\\cos(\\\\alpha-\\\\beta)]$$$$\\\\sin\\\\alpha\\\\sin\\\\beta = -\\\\frac{1}{2}[\\\\cos(\\\\alpha+\\\\beta) - \\\\cos(\\\\alpha-\\\\beta)] = \\\\frac{1}{2}[\\\\cos(\\\\alpha-\\\\beta) - \\\\cos(\\\\alpha+\\\\beta)]$$面积公式 对于三角形 $\\\\triangle ABC$，角 $A, B, C$ 所对的边分别为 $a, b, c$，其面积 $S$：\\n$$S = \\\\frac{1}{2}ab\\\\sin C = \\\\frac{1}{2}bc\\\\sin A = \\\\frac{1}{2}ac\\\\sin B$$$$S = \\\\sqrt{p(p-a)(p-b)(p-c)} \\\\quad (\\\\text{海伦公式, 其中 } p = \\\\frac{a+b+c}{2})$$$$S = \\\\frac{abc}{4R} \\\\quad (R \\\\text{ 是外接圆半径})$$$$S = rp \\\\quad (r \\\\text{ 是内切圆半径, } p = \\\\frac{a+b+c}{2})$$正弦定理、余弦定理 正弦定理： 在任意三角形 $\\\\triangle ABC$ 中，角 $A, B, C$ 所对的边分别为 $a, b, c$， $R$ 为三角形外接圆的半径。\\n$$\\\\frac{a}{\\\\sin A} = \\\\frac{b}{\\\\sin B} = \\\\frac{c}{\\\\sin C} = 2R$$余弦定理： 在任意三角形 $\\\\triangle ABC$ 中，角 $A, B, C$ 所对的边分别为 $a, b, c$。\\n$$a^2 = b^2 + c^2 - 2bc\\\\cos A$$$$b^2 = a^2 + c^2 - 2ac\\\\cos B$$$$c^2 = a^2 + b^2 - 2ab\\\\cos C$$也可以表示为：\\n$$\\\\cos A = \\\\frac{b^2+c^2-a^2}{2bc}$$$$\\\\cos B = \\\\frac{a^2+c^2-b^2}{2ac}$$$$\\\\cos C = \\\\frac{a^2+b^2-c^2}{2ab}$$线性代数 Reference 线性代数简介 - OI Wiki 定积分 Reference 求解定积分方法汇总 - 知乎 不定积分 \"",
      categories: "[\"数学\"]",
      tags: "[\"数学\",\"三角函数\",\"极坐标\",\"定积分\"]",
      series: [],
      date: "\"2025-05-16\""
    });
  
    searchIndex.push({
      title: "\"Epoll详细介绍 | [转载](https://mp.weixin.qq.com/s/pahk8ay5MvkvONeg1-M82w)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/05/04/epoll%E8%AF%A6%E8%A7%A3/\"",
      content: "\"腾讯二面追问epoll，它凭啥性能一骑绝尘？ 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 腾讯二面追问epoll，它凭啥性能一骑绝尘？ epoll 性能高，主要得益于其独特设计。在事件驱动方面，摒弃传统 select 和 poll 的轮询方式，仅在文件描述符有实际事件发生时，才由内核通知应用程序，极大减少无效检查，像在拥有大量并发连接的场景中，能精准定位到活跃连接，避免对众多无事件连接的遍历。在数据结构运用上，采用红黑树管理注册的文件描述符，其插入、删除和查找的时间复杂度为 O (log N)，远优于传统线性结构；同时利用就绪链表，当文件描述符就绪时，内核将其从红黑树移至链表，epoll_wait 只需遍历该链表，就能获取就绪事件，提升了事件获取效率。\\n在数据传输方面，借助 mmap 技术，在内核与用户空间建立共享内存，减少数据在内核缓冲区与用户空间应用程序缓冲区之间的拷贝次数，提高传输效率。此外，epoll 支持水平触发（LT）和边缘触发（ET）两种模式，边缘触发模式仅在文件描述符状态变化瞬间通知一次应用程序，促使应用程序一次性处理完相关数据，减少 epoll_wait 调用次数，提升效率。而且，epoll 由内核维护就绪列表，避免了传统 select 和 poll 在用户态与内核态频繁拷贝文件描述符集合的操作，降低了系统开销 。\\n一、epoll 技术简介 IO 多路复用的概念 在深入了解 epoll 之前，我们先来理解一下 IO 多路复用的概念。在网络编程中，我们常常会遇到这样的场景：一个服务器需要处理多个客户端的连接和数据传输 。如果采用传统的方式，为每个客户端连接创建一个单独的线程或进程来处理，那么当客户端数量增多时，系统资源会被大量消耗，性能也会急剧下降。\\nIO 多路复用就像是一个 “万能助手”，它可以让一个线程来处理多个 I/O 流。打个比方，你开了一家餐厅，来了很多桌客人 。如果每个客人都安排一个服务员专门服务，那成本可太高了。最好的办法是安排一个机灵的服务员，他可以同时照顾好几桌客人，哪个客人有需求（比如要点餐、加水），他就马上过去服务。在网络编程里，这个服务员就是 IO 多路复用机制，而客人就是一个个 I/O 流，这样就能大大提高效率，节省资源。\\n常见的 IO 多路复用技术有 select、poll 和 epoll，而 epoll 就是其中的 “佼佼者”，在性能上有着独特的优势。\\nepoll 技术概述 从技术原理的深度剖析来看，epoll 摒弃了传统 select 和 poll 采用的低效轮询机制。传统方式下，就如同在一个巨大的仓库里，不管货物有没有变化，都要逐个去查看，在连接数量众多时，大量的时间和资源就浪费在了这些无效的检查上。而 epoll 采用事件驱动机制，当文件描述符状态发生变化，比如有数据可读或可写时，内核会主动发出通知，应用程序只需关注这些有事件发生的文件描述符即可，这大大减少了无效操作，就好比仓库有了智能提示系统，货物一有变动就马上提醒，无需盲目查找。\\nepoll 的数据结构设计堪称精妙绝伦。它利用红黑树来管理大量的文件描述符，红黑树的特性使得插入、删除和查找操作的时间复杂度仅为 O (log N)，即便面对海量的文件描述符，也能快速定位和处理。同时，epoll 维护着一个就绪链表，一旦文件描述符就绪，内核会迅速将其放入链表中。这样，当应用程序调用 epoll_wait 获取就绪事件时，只需遍历这个就绪链表，无需像传统机制那样对所有文件描述符进行全量扫描，大大提高了事件获取的效率，如同从精心整理的货架上快速找到所需物品。\\nepoll 在数据传输方面也有着独特优势。它借助 mmap 技术，在内核空间与用户空间建立起共享内存。在传统数据传输过程中，数据从内核缓冲区到用户空间应用程序缓冲区，往往需要多次拷贝，这无疑增加了时间和资源开销。而 epoll 通过共享内存，让数据传输更直接高效，减少了拷贝次数，加快了数据传输速度，就像开辟了一条数据传输的 “高速公路”。\\n举个例子，一个热门的网站服务器，每天都有大量的用户访问。服务器需要同时处理这些用户的连接请求，接收他们发送的数据（比如用户的登录信息、搜索关键词等），并返回相应的响应（比如网页内容、搜索结果）。如果使用 epoll，服务器就可以通过 epoll 来监听这些大量的用户连接对应的文件描述符，一旦有某个用户发送了数据过来，epoll 就能迅速感知到，并通知服务器程序去读取和处理这些数据 ，这样就能高效地应对高并发的网络请求了。\\n二、Epoll 的数据结构 epoll 之所以性能卓越，离不开其精心设计的数据结构。epoll 主要依赖红黑树和双向链表这两种数据结构来实现高效的事件管理，再配合三个核心 API，让它在处理大量并发连接时游刃有余 。\\nepoll 工作在应用程序和内核协议栈之间。 epoll 是在内核协议栈和 vfs 都有的情况下才有的。 epoll 的核心数据结构是：1 个红黑树和 1 个双向链表。还有 3 个核心 API。\\n可以看到，链表和红黑树使用的是同一个结点。实际上是红黑树管理所有的 IO，当内部 IO 就绪的时候就会调用 epoll 的回调函数，将相应的 IO 添加到就绪链表上。数据结构有 epitm 和 eventpoll，分别代表红黑树和单个结点，在单个结点上分别使用 rbn 和 rblink 使得结点同时指向两个数据结构。\\n红黑树的巧妙运用 epoll 使用红黑树来管理所有注册的文件描述符。红黑树是一种自平衡的二叉搜索树，它有着非常优秀的性质：每个节点要么是红色，要么是黑色；根节点是黑色；所有叶子节点（通常是 NULL 节点）是黑色；如果一个节点是红色，那么它的两个子节点都是黑色；从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点 。这些性质保证了红黑树的高度近似平衡，使得查找、插入和删除操作的时间复杂度都稳定在 O (log n)，这里的 n 是红黑树中节点的数量。\\n因为链表在查询，删除的时候毫无疑问时间复杂度是 O(n)； 数组查询很快，但是删除和新增时间复杂度是 O(n)； 二叉搜索树虽然查询效率是 lgn，但是如果不是平衡的，那么就会退化为线性查找，复杂度直接来到 O(n)； B+ 树是平衡多路查找树，主要是通过降低树的高度来存储上亿级别的数据，但是它的应用场景是内存放不下的时候能够用最少的 IO 访问次数从磁盘获取数据。比如数据库聚簇索引，成百上千万的数据内存无法满足查找就需要到内存查找，而因为 B+ 树层高很低，只需要几次磁盘 IO 就能获取数据到内存，所以在这种磁盘到内存访问上 B+ 树更适合。 因为我们处理上万级的 fd，它们本身的存储空间并不会很大，所以倾向于在内存中去实现管理，而红黑树是一种非常优秀的平衡树，它完全是在内存中操作，而且查找，删除和新增时间复杂度都是 lgn，效率非常高，因此选择用红黑树实现 epoll 是最佳的选择。\\n当然不选择用 AVL 树是因为红黑树是不符合 AVL 树的平衡条件的，红黑树用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决；而 AVL 树是严格平衡树，在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高。\\n我们来具体分析一下。假如我们有一个服务器，需要监听 1000 个客户端的连接，每个连接对应一个文件描述符。如果使用普通的链表来管理这些文件描述符，当我们要查找某个特定的文件描述符时，最坏情况下需要遍历整个链表，时间复杂度是 O (n)，也就是需要 1000 次比较操作。但如果使用红黑树，由于其平衡特性，即使在最坏情况下，查找一个文件描述符也只需要 O (log n) 次比较操作，对于 1000 个节点的红黑树，log₂1000 约等于 10 次左右，相比链表效率大大提高。同样，在插入新的文件描述符（比如有新的客户端连接）和删除文件描述符（比如客户端断开连接）时，红黑树的 O (log n) 时间复杂度也比链表的 O (n) 高效得多。\\n再对比一下其他数据结构。数组虽然查询效率高，时间复杂度为 O (1)，但插入和删除操作比较麻烦，平均时间复杂度为 O (n) 。二叉搜索树在理想情况下查找、插入和删除的时间复杂度是 O (log n)，但如果树的平衡性被破坏，比如节点插入顺序不当，就可能退化为链表，时间复杂度变成 O (n)。B + 树主要用于磁盘存储，适合处理大量数据且需要频繁磁盘 I/O 的场景，在内存中管理文件描述符不如红黑树高效。所以，综合考虑，红黑树是 epoll 管理大量文件描述符的最佳选择，它能够快速地定位和操作文件描述符，大大提高了 epoll 的性能。\\n就绪 socket 列表-双向链表 除了红黑树，epoll 还使用双向链表来存储就绪的 socket。当某个文件描述符上有事件发生（比如有数据可读、可写），对应的 socket 就会被加入到这个双向链表中。双向链表的优势在于它可以快速地插入和删除节点，时间复杂度都是 O (1) 。这对于 epoll 来说非常重要，因为在高并发场景下，就绪的 socket 可能随时增加或减少。\\n就绪列表存储的是就绪的 socket，所以它应能够快速的插入数据；程序可能随时调用 epoll_ctl 添加监视 socket，也可能随时删除。当删除时，若该 socket 已经存放在就绪列表中，它也应该被移除。（事实上，每个 epoll_item 既是红黑树节点，也是链表节点，删除红黑树节点，自然删除了链表节点）所以就绪列表应是一种能够快速插入和删除的数据结构。双向链表就是这样一种数据结构，epoll 使用双向链表来实现就绪队列（rdllist）。\\n想象一下，在一个繁忙的在线游戏服务器中，同时有大量玩家在线。每个玩家的连接都由一个 socket 表示，当某个玩家发送了操作指令（比如移动、攻击等），对应的 socket 就有数据可读，需要被加入到就绪列表中等待服务器处理。如果使用单向链表，插入节点时虽然也能实现，但删除节点时，由于单向链表只能从前往后遍历，找到要删除节点的前驱节点比较麻烦，时间复杂度会达到 O (n) 。而双向链表每个节点都有指向前驱和后继节点的指针，无论是插入还是删除节点，都可以在 O (1) 时间内完成。当服务器处理完某个 socket 的事件后，如果该 socket 不再有就绪事件，就可以快速地从双向链表中删除，不会影响其他节点的操作。\\n双向链表和红黑树在 epoll 中协同工作。红黑树负责管理所有注册的文件描述符，保证文件描述符的增删查操作高效进行；而双向链表则专注于存储就绪的 socket，让应用程序能够快速获取到有事件发生的 socket 并进行处理。当一个 socket 的事件发生时，epoll 会先在红黑树中找到对应的节点，然后将其加入到双向链表中。这样，epoll_wait 函数只需要遍历双向链表，就能获取到所有就绪的 socket，避免了对大量未就绪 socket 的无效遍历，大大提高了事件处理的效率。\\n红黑树和就绪队列的关系\\n红黑树的结点和就绪队列的结点的同一个节点，所谓的加入就绪队列，就是将结点的前后指针联系到一起。所以就绪了不是将红黑树结点 delete 掉然后加入队列。他们是同一个结点，不需要 delete。\\nstruct epitem { RB_ ENTRY(epitem) rbn; LIST_ ENTRY(epitem) rdlink; int rdy; //exist in List int sockfd; struct epoll_ event event ; }; struct eventpoll { ep_ _rb_ tree rbr; int rbcnt ; LIST_ HEAD( ,epitem) rdlist; int rdnum; int waiting; pthread_ mutex_ t mtx; //rbtree update pthread_ spinlock_ t 1ock; //rdList update pthread_ cond_ _t cond; //bLock for event pthread_ mutex_ t cdmtx; //mutex for cond };| 三个核心 API 解析 epoll 提供了三个核心 API，分别是 epoll_create、epoll_ctl 和 epoll_wait，它们是使用 epoll 的关键。\\n(1)epoll_create 函数用于创建一个 epoll 实例，返回一个 epoll 专用的文件描述符。它的原型是：\\nint epoll_create(int size) 功能：内核会产生一个 epoll 实例数据结构并返回一个文件描述符 epfd，这个特殊的描述符就是 epoll 实例的句柄，后面的两个接口都以它为中心。同时也会创建红黑树和就绪列表，红黑树来管理注册 fd，就绪列表来收集所有就绪 fd。size 参数表示所要监视文件描述符的最大值，不过在后来的 Linux 版本中已经被弃用（同时，size 不要传 0，会报 invalid argument 错误）。\\n在较新的 Linux 版本中，size 参数已经被弃用，但仍然需要传入一个大于 0 的值。这个函数在内核中创建了一个 eventpoll 结构体，其中包含了红黑树和双向链表等数据结构，用于后续对文件描述符的管理。简单来说，它就像是创建了一个 “监控中心”，后续的操作都围绕这个 “监控中心” 展开。\\n(2)epoll_ctl 函数用于控制 epoll 实例，它可以向 epoll 实例中添加、修改或删除要监控的文件描述符及其对应的事件。函数原型如下：\\nint epoll_ctl(int epfd， int op， int fd， struct epoll_event *event) 功能：将被监听的 socket 文件描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改；同时向内核中断处理程序注册一个回调函数，内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数将文件描述符放在就绪链表中。\\n参数 epfd 是 epoll_create 返回的文件描述符；op 表示操作类型，有 EPOLL_CTL_ADD（添加）、EPOLL_CTL_MOD（修改）、EPOLL_CTL_DEL（删除）三种取值；fd 是要操作的文件描述符；event 是一个指向 epoll_event 结构体的指针，用于指定要监控的事件类型，比如 EPOLLIN（可读）、EPOLLOUT（可写）、EPOLLERR（错误）等。例如，我们要向 epoll 实例中添加一个监听 socket，代码可以这样写：\\nint epfd = epoll_create(1024); int listenfd = socket(AF_INET, SOCK_STREAM, 0); struct epoll_event ev; ev.data.fd = listenfd; ev.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, \\u0026amp;ev); 这段代码首先创建了一个 epoll 实例，然后创建了一个监听 socket，接着设置了要监控的事件为 EPOLLIN（即监听 socket 有数据可读时触发事件），最后通过 epoll_ctl 将监听 socket 添加到 epoll 实例中。\\n(3)epoll_wait 函数用于等待事件的发生，它会阻塞当前线程，直到有注册的事件发生或者超时。函数原型为：\\nint epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout); 功能：阻塞等待注册的事件发生，返回事件的数目，并将触发的事件写入 events 数组中。\\nepfd 是 epoll 实例的文件描述符；events 是一个 epoll_event 结构体数组，用于存储发生的事件；maxevents 表示最多能返回的事件数；timeout 是超时时间，单位是毫秒，-1 表示永久阻塞，0 表示立即返回不阻塞。当有事件发生时，epoll_wait 会将发生事件的文件描述符和事件类型填充到 events 数组中，并返回事件的数量。例如：\\nstruct epoll_event events[10]; int nfds = epoll_wait(epfd, events, 10, -1); for (int i = 0; i \\u0026lt; nfds; i++) { int fd = events[i].data.fd; // 根据事件类型处理相应的逻辑 if (events[i].events \\u0026amp; EPOLLIN) { // 处理读事件 } else if (events[i].events \\u0026amp; EPOLLOUT) { // 处理写事件 } } 这段代码通过 epoll_wait 等待事件发生，最多返回 10 个事件。当有事件发生时，遍历 events 数组，根据不同的事件类型（这里只简单示例了读和写事件）进行相应的处理。\\nevents: 用来记录被触发的 events，其大小应该和 maxevents 一致 maxevents: 返回的 events 的最大个数处于 ready 状态的那些文件描述符会被复制进 ready list 中，epoll_wait 用于向用户进程返回 ready list(就绪列表) events 和 maxevents 两个参数描述一个由用户分配的 struct epoll event 数组，调用返回时，内核将就绪列表(双向链表)复制到这个数组中，并将实际复制的个数作为返回值。\\n注意，如果就绪列表比 maxevents 长，则只能复制前 maxevents 个成员；反之，则能够完全复制就绪列表。\\n另外，struct epoll event 结构中的 events 域在这里的解释是：在被监测的文件描述符上实际发生的事件。\\n调用 epoll_create 时，在内核 cache 里建了个红黑树用于存储以后 epoll_ctl 传来的 socket 外，还会再建立一个 list 链表，用于存储准备就绪的事件，内部使用回调机制，红黑树中的节点通过回调函数添加到双向链表。\\n当 epoll_wait 调用时，仅仅观察这个双向链表里有没有数据即可。有数据就返回，没有数据就 sleep，等到 timeout 时间到后即使链表没数据也返回。所以，epoll_wait 非常高效。而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait 仅需要从内核态 copy 少量的句柄到用户态而已。\\nepoll 和 poll/select 区别？\\n（1）使用接口：select/poll 需要把 fds 总集拷贝到内核协议栈中，epoll 不需要。 （2）实现原理：select/poll 在内核内循环 遍历是否有就绪 io，epoll 是单个加入红黑树。 解释：poll/select 每次都要把 fds 总集拷贝到内核协议栈内，内核采取轮询/遍历，返回就绪的 fds 集合。（大白话：poll/select 的 fds 是存放在用户态协议栈，调用时拷贝到内核协议栈中并轮询，轮询完成后再拷贝到用户态协议栈）。而 epoll 是通过 epoll_ctl 每次有新的 io 就加入到红黑树里，有触发的时候用 epoll_wait 带出即可，不需要拷贝总集。\\n最后总结一下，这三个核心 API 相互配合，epoll_create 创建监控实例，epoll_ctl 管理要监控的文件描述符和事件，epoll_wait 等待并获取发生的事件，共同构成了 epoll 高效的事件驱动模型，使得开发者能够轻松地实现高性能的网络编程。\\n三、Epoll 的工作原理剖析 协议栈与 Epoll 的通信机制 在网络通信中，协议栈扮演着关键角色，它负责处理网络数据包的接收、解析和发送等底层操作。而 epoll 则专注于高效地管理和通知应用程序关于网络事件的发生 。\\n那么，协议栈与 epoll 是如何通信的呢？\\n当网络数据包到达网卡时，网卡会将数据通过 DMA（直接内存访问）方式拷贝到内核的内存缓冲区中 。接着，内核协议栈开始工作，它会对数据包进行解析，比如解析 TCP 头、UDP 头以及应用层协议头，以获取数据包的相关信息，如源 IP、目的 IP、源端口、目的端口等。在解析过程中，如果协议栈发现某个 socket 对应的接收缓冲区有新的数据到达（或者 socket 可写，即发送缓冲区有空闲空间等其他事件发生），它就会触发一个回调机制来通知 epoll。\\n具体来说，这个回调函数是在 epoll_ctl 函数将 socket 添加到 epoll 实例时注册到 socket 上的 。当协议栈检测到事件时，它会调用这个回调函数。回调函数会根据 socket 的五元组信息（源 IP、源端口、目的 IP、目的端口和协议类型），在 epoll 维护的红黑树中查找对应的节点。由于红黑树的高效查找特性（时间复杂度为 O (log n)），能够快速定位到对应的 socket 节点 。找到节点后，回调函数会将该节点加入到 epoll 的就绪链表中，表示这个 socket 上有事件发生，需要应用程序进行处理。\\n举个例子，假设有一个在线聊天服务器，有大量用户同时在线聊天。当某个用户发送一条消息时，消息以数据包的形式通过网络传输到服务器的网卡 。协议栈接收到数据包后，解析出是某个聊天 socket 有新数据到达，于是调用回调函数。回调函数通过 socket 的五元组信息，在红黑树中迅速找到对应的 socket 节点，将其加入就绪链表。这样，服务器程序调用 epoll_wait 时，就能获取到这个就绪的 socket，进而读取用户发送的消息并进行处理，比如将消息转发给其他聊天用户 。\\nEpoll 的回调机制 epoll 的回调机制是其高效的关键所在 。当一个文件描述符（比如 socket）就绪时（即有数据可读、可写或者发生错误等事件），内核会调用预先注册的回调函数 。这个回调函数的主要任务是将就绪的 socket 放入 epoll 的就绪链表中，然后唤醒正在等待的应用程序（通过 epoll_wait 阻塞的应用程序线程）。\\n我们来深入分析一下这个过程。当 socket 有数据可读时，内核首先会将数据从内核缓冲区拷贝到 socket 的接收缓冲区 。完成数据拷贝后，内核触发回调函数。回调函数会将该 socket 对应的 epitem 结构体（epitem 是 epoll 内部用于管理文件描述符的数据结构，它同时是红黑树节点和就绪链表节点）从红黑树中取出（由于红黑树节点和就绪链表节点是同一结构体，所以不需要额外的操作来关联），然后将其加入到就绪链表的尾部 。接着，回调函数会检查 epoll 的等待队列，看是否有应用程序线程在等待事件发生。如果有，就通过回调函数 default_wake_func 唤醒这些线程 。\\n对比一下 select 和 poll，它们没有这样的回调机制。在 select 和 poll 中，应用程序需要不断地轮询所有注册的文件描述符，检查是否有事件发生 。假设一个服务器注册了 1000 个 socket，每次调用 select 或 poll 时，都需要对这 1000 个 socket 逐一检查，即使其中只有 1 个 socket 有事件发生，也需要遍历完所有 socket 。这种方式在高并发场景下效率极低，会浪费大量的 CPU 资源。而 epoll 通过回调机制，只有在真正有事件发生时才会将 socket 加入就绪链表，应用程序调用 epoll_wait 时，只需要处理就绪链表中的 socket，大大减少了无效的轮询操作，提高了效率 。\\n再以刚才的在线聊天服务器为例，在 select 或 poll 模式下，服务器每次检查是否有新消息时，都要遍历所有在线用户的 socket，即使大部分用户没有发送消息，也需要检查一遍 。而在 epoll 模式下，只有当某个用户发送消息时，对应的 socket 才会被加入就绪链表，服务器只需要处理就绪链表中的 socket，无需对大量没有消息的 socket 进行无效检查，从而能够更高效地处理高并发的聊天消息 。\\n四、epoll 的实现原理 epoll 常见问题 ⑴ 为什么需要 epoll？\\nepoll 是 Linux 操作系统提供的一种事件驱动的 I/O 模型，用于高效地处理大量并发连接的网络编程。它相比于传统的 select 和 poll 方法，具有更高的性能和扩展性。使用 epoll 可以实现以下几个优势：\\n高效处理大量并发连接：epoll 采用了事件驱动的方式，只有当有可读或可写事件发生时才会通知应用程序，避免了遍历所有文件描述符的开销。 内核与用户空间数据拷贝少：使用 epoll 时，内核将就绪的文件描述符直接填充到用户空间的事件数组中，减少了内核与用户空间之间数据拷贝次数。 支持边缘触发（Edge Triggered）模式：边缘触发模式下，仅在状态变化时才通知应用程序。这意味着每次通知只包含最新状态的文件描述符信息，可以有效避免低效循环检查。 支持水平触发（Level Triggered）模式：水平触发模式下，在就绪期间不断地进行通知，直到应用程序处理完该文件描述符。 ⑵select 与 poll 的缺陷？\\nselect 和 poll 都是 Unix 系统中用来监视一组文件描述符的变化的系统调用。它们可以监视文件描述符的三种变化：可读性、可写性和异常条件。select 和 poll 的主要缺陷如下：\\n文件描述符数量限制：select 和 poll 都有一个限制，就是它们只能监视少于 1024 个文件描述符的变化。这对于现代的网络编程来说是不够的，因为一个进程往往需要监视成千上万的连接。 效率问题：虽然 select 和 poll 可以监视多个文件描述符，但是它们在每次调用的时候都需要传递所有要监视的文件描述符集合，这会导致效率的降低。 信息不足：select 和 poll 返回的只是哪些文件描述符已经准备好了，但是它们并不告诉你具体是哪一个。这就需要对所有要监视的文件描述符进行遍历，直到找到准备好的文件描述符为止。 信号中断：select 和 poll 调用可以被信号中断，这可能会导致调用失败。 为了解决这些问题，现代操作系统中引入了新的系统调用 epoll 来替代 select 和 poll。epoll 没有文件描述符的限制，它可以监视大量的文件描述符，并且可以实现即开即用，无需传递所有文件描述符集合。此外，epoll 可以直接告诉你哪些文件描述符已经准备好，这大大提高了处理效率。 epoll 操作 epoll 在 linux 内核中申请了一个简易的文件系统，把原先的一个 select 或者 poll 调用分为了三个部分：调用 epoll_create 建立一个 epoll 对象（在 epoll 文件系统中给这个句柄分配资源）、调用 epoll_ctl 向 epoll 对象中添加连接的套接字、调用 epoll_wait 收集发生事件的连接。这样只需要在进程启动的时候建立一个 epoll 对象，并在需要的时候向它添加或者删除连接就可以了，因此，在实际收集的时候，epoll_wait 的效率会非常高，因为调用的时候只是传递了发生 IO 事件的连接。\\n⑴epoll 实现\\n我们以 linux 内核 2.6 为例，说明一下 epoll 是如何高效的处理事件的，当某一个进程调用 epoll_create 方法的时候，Linux 内核会创建一个 eventpoll 结构体，这个结构体中有两个重要的成员。\\n第一个是 rb_root rbr，这是红黑树的根节点，存储着所有添加到 epoll 中的事件，也就是这个 epoll 监控的事件。 第二个是 list_head rdllist 这是一个双向链表，保存着将要通过 epoll_wait 返回给用户的、满足条件的事件。 每一个 epoll 对象都有一个独立的 eventpoll 结构体，这个结构体会在内核空间中创造独立的内存，用于存储使用 epoll_ctl 方法向 epoll 对象中添加进来的事件。这些事件都会挂到 rbr 红黑树中，这样就能够高效的识别重复添加的节点。\\n所有添加到 epoll 中的事件都会与设备（如网卡等）驱动程序建立回调关系，也就是说，相应的事件发生时会调用这里的方法。这个回调方法在内核中叫做 ep_poll_callback，它把这样的事件放到 rdllist 双向链表中。在 epoll 中，对于每一个事件都会建立一个 epitem 结构体。\\n当调用 epoll_wait 检查是否有发生事件的连接时，只需要检查 eventpoll 对象中的 rdllist 双向链表中是否有 epitem 元素，如果 rdllist 链表不为空，则把这里的事件复制到用户态内存中的同时，将事件数量返回给用户。通过这种方法，epoll_wait 的效率非常高。epoll-ctl 在向 epoll 对象中添加、修改、删除事件时，从 rbr 红黑树中查找事件也非常快。这样，epoll 就能够轻易的处理百万级的并发连接。\\n⑵epoll 工作模式\\nepoll 有两种工作模式，LT（水平触发）模式与 ET（边缘触发）模式。默认情况下，epoll 采用 LT 模式工作。两个的区别是：\\nLevel_triggered(水平触发)：当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据一次性全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait() 时，它还会通知你在上没读写完的文件描述符上继续读写，当然如果你一直不去读写，它会一直通知你。如果系统中有大量你不需要读写的就绪文件描述符，而它们每次都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率。 Edge_triggered(边缘触发)：当被监控的文件描述符上有可读写事件发生时，epoll_wait() 会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用 epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪 文件描述符。 当然，在 LT 模式下开发基于 epoll 的应用要简单一些，不太容易出错，而在 ET 模式下事件发生时，如果没有彻底地将缓冲区的数据处理完，则会导致缓冲区的用户请求得不到响应。注意，默认情况下 Nginx 采用 ET 模式使用 epoll 的。\\nI/O 多路复用 (1)阻塞 OR 非阻塞\\n我们知道，对于 linux 来说，I/O 设备为特殊的文件，读写和文件是差不多的，但是 I/O 设备因为读写与内存读写相比，速度差距非常大。与 cpu 读写速度更是没法比，所以相比于对内存的读写，I/O 操作总是拖后腿的那个。网络 I/O 更是如此，我们很多时候不知道网络 I/O 什么时候到来，就好比我们点了一份外卖，不知道外卖小哥们什么时候送过来，这个时候有两个处理办法：\\n第一个是我们可以先去睡觉，外卖小哥送到楼下了自然会给我们打电话，这个时候我们在醒来取外卖就可以了。 第二个是我们可以每隔一段时间就给外卖小哥打个电话，这样就能实时掌握外卖的动态信息了。 第一种方式对应的就是阻塞的 I/O 处理方式，进程在进行 I/O 操作的时候，进入睡眠，如果有 I/O 时间到达，就唤醒这个进程。第二种方式对应的是非阻塞轮询的方式，进程在进行 I/O 操作后，每隔一段时间向内核询问是否有 I/O 事件到达，如果有就立刻处理。\\n① 阻塞的原理\\n工作队列\\n阻塞是进程调度的关键一环，指的是进程在等待某事件（如接收到网络数据）发生之前的等待状态，recv、select 和 epoll 都是阻塞方法，以简单网络编程为例。\\n下图中的计算机中运行着 A、B、C 三个进程，其中进程 A 执行着上述基础网络程序，一开始，这 3 个进程都被操作系统的工作队列所引用，处于运行状态，会分时执行：\\n当进程 A 执行到创建 socket 的语句时，操作系统会创建一个由文件系统管理的 socket 对象（如下图）。这个 socket 对象包含了发送缓冲区、接收缓冲区、等待队列等成员。等待队列是个非常重要的结构，它指向所有需要等待该 socket 事件的进程。\\n当程序执行到 recv 时，操作系统会将进程 A 从工作队列移动到该 socket 的等待队列中（如下图）。由于工作队列只剩下了进程 B 和 C，依据进程调度，cpu 会轮流执行这两个进程的程序，不会执行进程 A 的程序。所以进程 A 被阻塞，不会往下执行代码，也不会占用 cpu 资源。\\nps：操作系统添加等待队列只是添加了对这个“等待中”进程的引用，以便在接收到数据时获取进程对象、将其唤醒，而非直接将进程管理纳入自己之下。上图为了方便说明，直接将进程挂到等待队列之下。\\n② 唤醒进程\\n当 socket 接收到数据后，操作系统将该 socket 等待队列上的进程重新放回到工作队列，该进程变成运行状态，继续执行代码。也由于 socket 的接收缓冲区已经有了数据，recv 可以返回接收到的数据。\\n(2)线程池 OR 轮询\\n在现实中，我们当然选择第一种方式，但是在计算机中，情况就要复杂一些。我们知道，在 linux 中，不管是线程还是进程都会占用一定的资源，也就是说，系统总的线程和进程数是一定的。如果有许多的线程或者进程被挂起，无疑是白白消耗了系统的资源。而且，线程或者进程的切换也是需要一定的成本的，需要上下文切换，如果频繁的进行上下文切换，系统会损失很大的性能。一个网络服务器经常需要连接成千上万个客户端，而它能创建的线程可能之后几百个，线程耗光就不能对外提供服务了。这些都是我们在选择 I/O 机制的时候需要考虑的。这种阻塞的 I/O 模式下，一个线程只能处理一个流的 I/O 事件，这是问题的根源。\\n这个时候我们首先想到的是采用线程池的方式限制同时访问的线程数，这样就能够解决线程不足的问题了。但是这又会有第二个问题了，多余的任务会通过队列的方式存储在内存只能够，这样很容易在客户端过多的情况下出现内存不足的情况。\\n还有一种方式是采用轮询的方式，我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了。\\n(3)代理\\n采用轮询的方式虽然能够处理多个 I/O 事件，但是也有一个明显的缺点，那就是会导致 CPU 空转。试想一下，如果所有的流中都没有数据，那么 CPU 时间就被白白的浪费了。\\n为了避免 CPU 空转，可以引进了一个代理。这个代理比较厉害，可以同时观察许多流的 I/O 事件，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中醒来，于是我们的程序就会轮询一遍所有的流，这就是 select 与 poll 所做的事情，可见，采用 I/O 复用极大的提高了系统的效率。\\n内核接收网络数据全过程 如下图所示，进程在 recv 阻塞期间，计算机收到了对端传送的数据（步骤 ①）。数据经由网卡传送到内存（步骤 ②），然后网卡通过中断信号通知 CPU 有数据到达，CPU 执行中断程序（步骤 ③）。此处的中断程序主要有两项功能，先将网络数据写入到对应 socket 的接收缓冲区里面（步骤 ④），再唤醒进程 A（步骤 ⑤），重新将进程 A 放入工作队列中。\\n唤醒线程的过程如下图所示：\\n五、协议栈如何与 epoll 通信？ 协议栈和 epoll 模块之间的通信是异步的，没有耦合，不需要等待。\\n通知时机：\\n协议栈三次握手完成，往 accept 全连接队列里加入这个节点时，通知 epoll 有事件来了 epollin； 客户端发了 1 个数据到协议栈，协议栈此时要返回 ack 给客户端的这里的时机，会通知 epoll 有事件可读 epollin。 六、epoll 线程安全如何加锁？ 在使用 epoll 时，如果你有多个线程同时对同一个 epoll 实例进行操作（例如添加或删除文件描述符），就需要确保线程安全。可以通过以下几种方式加锁：\\n对红黑树枷锁：一种是锁整棵树，另一种是锁子树。一般使用互斥锁。 对就绪队列枷锁：用自旋锁，队列操作比较简单，等到一些时间比让出线程更高效点。 等待队列实现原理 (1)功能介绍\\n进程有多种状态，当进程做好准备后，它就处于就绪状态（TASK_RUNNING），放入运行队列，等待内核调度器来调度。当然，同一时刻可能有多个进程进入就绪状态，但是却可能只有 1 个 CPU 是空闲的，所以最后能不能在 CPU 上运行，还要取决于优先级等多种因素。当进程进行外部设备的 IO 等待操作时，由于外部设备的操作速度一般是非常慢的，所以进程会从就绪状态变为等待状态（休眠），进入等待队列，把 CPU 让给其它进程。直到 IO 操作完成，内核“唤醒”等待的进程，于是进程再度从等待状态变为就绪状态。\\n在用户态，进程进行 IO 操作时，可以有多种处理方式，如阻塞式 IO，非阻塞式 IO，多路复用(select/poll/epoll)，AIO（aio_read/aio_write）等等。这些操作在内核态都要用到等待队列。\\n(2)相关的结构体\\ntypedef struct __wait_queue wait_queue_t;\\nstruct __wait_queue { unsigned int flags; #define WQ_FLAG_EXCLUSIVE 0x01 struct task_struct * task; // 等待队列节点对应的进程 wait_queue_func_t func; // 等待队列的回调函数 ，在进程被唤醒 struct list_head task_list; }; 这个是等待队列的节点，在很多等待队列里，这个func函数指针默认为空函数。 但是，在select/poll/epoll函数中，这个func函数指针不为空，并且扮演着重要的角色。 struct __wait_queue_head { spinlock_t lock; struct list_head task_list; }; typedef struct __wait_queue_head wait_queue_head_t;这个是等待队列的头部。其中 task_list 里有指向下一个节点的指针。为了保证对等待队列的操作是原子的，还需要一个自旋锁 lock。\\n这里需要提一下内核队列中被广泛使用的结构体 struct list_head。\\nstruct list_head { struct list_head *next, *prev; }; (3)实现原理\\n可以看到，等待队列的核心是一个 list_head 组成的双向链表。其中，第一个节点是队列的头，类型为 wait_queue_head_t，里面包含了一个 list_head 类型的成员 task_list。\\n接下去的每个节点类型为 wait_queue_t，里面也有一个 list_head 类型的成员 task_list，并且有个指针指向等待的进程。通过这种方式，内核组织了一个等待队列。\\n那么，这个等待队列怎样与一个事件关联呢？\\n在内核中，进程在文件操作等事件上的等待，一定会有一个对应的等待队列的结构体与之对应。例如，等待管道的文件操作（在内核看来，管道也是一种文件）的进程都放在管道对应 inode.i_pipe-\\u0026gt;wait 这个等待队列中。这样，如果管道文件操作完成，就可以很方便地通过 inode.i_pipe-\\u0026gt;wait 唤醒等待的进程。\\n在大部分情况下（如系统调用 read），当前进程等待 IO 操作的完成，只要在内核堆栈中分配一个 wait_queue_t 的结构体，然后初始化，把 task 指向当前进程的 task_struct，然后调用 add_wait_queue（）放入等待队列即可。\\n但是，在 select/poll 中，由于系统调用要监视多个文件描述符的操作，因此要把当前进程放入多个文件的等待队列，并且要分配多个 wait_queue_t 结构体。这时候，在堆栈上分配是不合适的。因为内核堆栈很小。所以要通过动态分配的方式来分配 wait_queue_t 结构体。除了在一些结构体里直接定义等待队列的头部，内核的信号量机制也大量使用了等待队列。信号量是为了进行进程同步而引入的。与自旋锁不同的是，当一个进程无法获得信号量时，它会把自己放到这个信号量的等待队列中，转变为等待状态。当其它进程释放信号量时，会唤醒等待的进程。\\nepoll 关键结构体：\\nstruct ep_pqueue { poll_table pt; struct epitem *epi; }; 这个结构体类似于 select/poll 中的 struct poll_wqueues。由于 epoll 需要在内核态保存大量信息，所以光光一个回调函数指针已经不能满足要求，所以在这里引入了一个新的结构体 struct epitem。\\nstruct epitem { struct rb_node rbn; 红黑树，用来保存eventpoll struct list_head rdllink; 双向链表，用来保存已经完成的eventpoll struct epoll_filefd ffd; 这个结构体对应的被监听的文件描述符信息 int nwait; poll操作中事件的个数 struct list_head pwqlist; 双向链表，保存着被监视文件的等待队列，功能类似于select/poll中的poll_table struct eventpoll *ep; 指向eventpoll，多个epitem对应一个eventpoll struct epoll_event event; 记录发生的事件和对应的fd atomic_t usecnt; 引用计数 struct list_head fllink; 双向链表，用来链接被监视的文件描述符对应的struct file。因为file里有f_ep_link， 用来保存所有监视这个文件的epoll节点 struct list_head txlink; 双向链表，用来保存传输队列 unsigned int revents; 文件描述符的状态，在收集和传输时用来锁住空的事件集合 }; 该结构体用来保存与 epoll 节点关联的多个文件描述符，保存的方式是使用红黑树实现的 hash 表。至于为什么要保存，下文有详细解释。它与被监听的文件描述符一一对应。\\nstruct eventpoll { spinlock_t lock; 读写锁 struct mutex mtx; 读写信号量 wait_queue_head_t wq; wait_queue_head_t poll_wait; struct list_head rdllist; 已经完成的操作事件的队列。 struct rb_root rbr; 保存epoll监视的文件描述符 struct epitem *ovflist; struct user_struct *user; }; 这个结构体保存了 epoll 文件描述符的扩展信息，它被保存在 file 结构体的 private_data 中。它与 epoll 文件节点一一对应。通常一个 epoll 文件节点对应多个被监视的文件描述符。所以一个 eventpoll 结构体会对应多个 epitem 结构体。\\n那么，epoll 中的等待事件放在哪里呢？见下面\\nstruct eppoll_entry { struct list_head llink; void *base; wait_queue_t wait; wait_queue_head_t *whead; }; 与select/poll的struct poll_table_entry相比，epoll的表示等待队列节点的结构体只是稍有不同， 与struct poll_table_entry比较一下。 struct poll_table_entry { struct file * filp; wait_queue_t wait; wait_queue_head_t * wait_address; }; 由于 epitem 对应一个被监视的文件，所以通过 base 可以方便地得到被监视的文件信息。又因为一个文件可能有多个事件发生，所以用 llink 链接这些事件。\\n相关内核代码:fs/eventpoll.c\\n判断一个 tcp 套接字上是否有激活事件:net/ipv4/tcp.c:tcp_poll 函数，每个 epollfd 在内核中有一个对应的 eventpoll 结构对象。\\n其中关键的成员是一个 readylist(eventpoll:rdllist)和一棵红黑树(eventpoll:rbr)，eventpoll 的红黑树中，红黑树的作用是使用者调用 EPOLL_MOD 的时候可以快速找到 fd 对应的 epitem。\\nepoll_ctl 的功能是实现一系列操作，如把文件与 eventpollfs 文件系统的 inode 节点关联起来。这里要介绍一下 eventpoll 结构体，它保存在 file-\\u0026gt;f_private 中，记录了 eventpollfs 文件系统的 inode 节点的重要信息，其中成员 rbr 保存了该 epoll 文件节点监视的所有文件描述符。组织的方式是一棵红黑树，这种结构体在查找节点时非常高效。首先它调用 ep_find()从 eventpoll 中的红黑树获得 epitem 结构体。然后根据 op 参数的不同而选择不同的操作。如果 op 为 EPOLL_CTL_ADD，那么正常情况下 epitem 是不可能在 eventpoll 的红黑树中找到的，所以调用 ep_insert 创建一个 epitem 结构体并插入到对应的红黑树中。\\nep_insert()首先分配一个 epitem 对象，对它初始化后，把它放入对应的红黑树。此外，这个函数还要作一个操作，就是把当前进程放入对应文件操作的等待队列。这一步是由下面的代码完成的。\\ninit_poll_funcptr(\\u0026amp;epq.pt, ep_ptable_queue_proc); ...... revents = tfile-\\u0026gt;f_op-\\u0026gt;poll(tfile, \\u0026amp;epq.pt); 函数先调用 init_poll_funcptr 注册了一个回调函数 ep_ptable_queue_proc，ep_ptable_queue_proc 函数会在调用 f_op-\\u0026gt;poll 时被执行。\\nstatic void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) { struct epitem *epi = ep_item_from_epqueue(pt); struct eppoll_entry *pwq; if (epi-\\u0026gt;nwait \\u0026gt;= 0 \\u0026amp;\\u0026amp; (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) { init_waitqueue_func_entry(\\u0026amp;pwq-\\u0026gt;wait, ep_poll_callback); pwq-\\u0026gt;whead = whead; pwq-\\u0026gt;base = epi; add_wait_queue(whead, \\u0026amp;pwq-\\u0026gt;wait); list_add_tail(\\u0026amp;pwq-\\u0026gt;llink, \\u0026amp;epi-\\u0026gt;pwqlist); epi-\\u0026gt;nwait++; } else { epi-\\u0026gt;nwait = -1; } } 该函数分配一个 epoll 等待队列结点 eppoll_entry：一方面把它挂到文件操作的等待队列中，另一方面把它挂到 epitem 的队列中。此外，它还注册了一个等待队列的回调函数 ep_poll_callback。当文件操作完成，唤醒当前进程之前，会调用 ep_poll_callback()，把 eventpoll 放到 epitem 的完成队列中（注释：通过查看代码，此处应该是把 epitem 放到 eventpoll 的完成队列，只有这样才能在 epoll_wait()中只要看 eventpoll 的完成队列即可得到所有的完成文件描述符），并唤醒等待进程。\\n如果在执行 f_op-\\u0026gt;poll 以后，发现被监视的文件操作已经完成了，那么把它放在完成队列中了，并立即把等待操作的那些进程唤醒。\\nif (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL))) return -ENOMEM; ep_rbtree_insert(ep, epi); 调用 epoll_wait 的时候,将 readylist 中的 epitem 出列,将触发的事件拷贝到用户空间.之后判断 epitem 是否需要重新添加回 readylist。\\nepitem 重新添加到 readylist 必须满足下列条件：\\nepitem 上有用户关注的事件触发. epitem 被设置为水平触发模式(如果一个 epitem 被设置为边界触发则这个 epitem 不会被重新添加到 readylist 中，在什么时候重新添加到 readylist 请继续往下看)。 注意，如果 epitem 被设置为 EPOLLONESHOT 模式，则当这个 epitem 上的事件拷贝到用户空间之后,会将这个 epitem 上的关注事件清空(只是关注事件被清空,并没有从 epoll 中删除，要删除必须对那个描述符调 EPOLL_DEL)，也就是说即使这个 epitem 上有触发事件，但是因为没有用户关注的事件所以不会被重新添加到 readylist 中。\\nepitem 被添加到 readylist 中的各种情况(当一个 epitem 被添加到 readylist 如果有线程阻塞在 epoll_wait 中,那个线程会被唤醒)：\\n1)对一个 fd 调用 EPOLL_ADD，如果这个 fd 上有用户关注的激活事件，则这个 fd 会被添加到 readylist 2)对一个 fd 调用 EPOLL_MOD 改变关注的事件，如果新增加了一个关注事件且对应的 fd 上有相应的事件激活，则这个 fd 会被添加到 readylist. 3)当一个 fd 上有事件触发时(例如一个 socket 上有外来的数据)会调用 ep_poll_callback(见 eventpoll::ep_ptable_queue_proc), 如果触发的事件是用户关注的事件，则这个 fd 会被添加到 readylist 中，了解了 epoll 的执行过程之后,可以回答一个在使用边界触发时常见的疑问.在一个 fd 被设置为边界触发的情况下,调用 read/write,如何正确的判断那个 fd 已经没有数据可读/不再可写.epoll 文档中的建议是直到触发 EAGAIN 错误.而实际上只要你请求字节数小于 read/write 的返回值就可以确定那个 fd 上已经没有数据可读/不再可写，最后用一个 epollfd 监听另一个 epollfd 也是合法的,epoll 通过调用 eventpoll::ep_eventpoll_poll 来判断一个 epollfd 上是否有触发的事件(只能是读事件)。\\n以下是个人读代码总结：\\nSYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event) epoll_ctl的机制大致如下： mutex_lock(\\u0026amp;ep-\\u0026gt;mtx); epi = ep_find(ep, tfile, fd); //这里就是去ep-\\u0026gt;rbr 红黑树查找 error = -EINVAL; switch (op) { case EPOLL_CTL_ADD if (!epi) { epds.events |= POLLERR | POLLHUP; error = ep_insert(ep, \\u0026amp;epds, tfile, fd); } else error = -EEXIST; break; case EPOLL_CTL_DEL: if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: if (epi) { epds.events |= POLLERR | POLLHUP; error = ep_modify(ep, epi, \\u0026amp;epds); } else error = -ENOENT; break; } mutex_unlock(\\u0026amp;ep-\\u0026gt;mtx); 源码分析 (1)sys_epoll_wait()函数：\\n/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { int error; struct file *file; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ /* * 检查maxevents参数。 */ if (maxevents \\u0026lt;= 0 || maxevents \\u0026gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ /* * 检查用户空间传入的events指向的内存是否可写。参见__range_not_ok()。 */ if (!access_ok(VERIFY_WRITE, events, maxevents * sizeof(struct epoll_event))) { error = -EFAULT; goto error_return; } /* Get the \\u0026quot;struct file *\\u0026quot; for the eventpoll file */ /* * 获取epfd对应的eventpoll文件的file实例，file结构是在epoll_create中创建 */ error = -EBADF; file = fget(epfd); if (!file) goto error_return; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ /* * 通过检查epfd对应的文件操作是不是eventpoll_fops * 来判断epfd是否是一个eventpoll文件。如果不是 * 则返回EINVAL错误。 */ error = -EINVAL; if (!is_file_epoll(file)) goto error_fput; /* * At this point it is safe to assume that the \\u0026quot;private_data\\u0026quot; contains * our own data structure. */ ep = file-\\u0026gt;private_data; /* Time to fish for events ... */ error = ep_poll(ep, events, maxevents, timeout); error_fput: fput(file); error_return: return error; } sys_epoll_wait（）是 epoll_wait()对应的系统调用，主要用来获取文件状态已经就绪的事件，该函数检查参数、获取 eventpoll 文件后调用 ep_poll（）来完成主要的工作。在分析 ep_poll（）函数之前，先介绍一下使用 epoll_wait（）时可能犯的错误（接下来介绍的就是我犯过的错误）：\\n返回 EBADF 错误\\n除非你故意指定一个不存在的文件描述符，否则几乎百分百肯定，你的程序有 BUG 了！从源码中可以看到调用 fget（）函数返回 NULL 时，会返回此错误。fget（）源码如下：\\nstruct file *fget(unsigned int fd) { struct file *file; struct files_struct *files = current-\\u0026gt;files; rcu_read_lock(); file = fcheck_files(files, fd); if (file) { if (!atomic_long_inc_not_zero(\\u0026amp;file-\\u0026gt;f_count)) { /* File object ref couldn't be taken */ rcu_read_unlock(); return NULL; } } rcu_read_unlock(); return file; } 主要看这句(struct files_struct *files = current-\\u0026gt;files;)，这条语句是获取描述当前进程已经打开的文件的 files_struct 结构，然后从这个结构中查找传入的 fd 对应的 file 实例，如果没有找到，说明当前进程中打开的文件不包括这个 fd，所以几乎百分百肯定是程序设计的问题。我的程序出错，就是因为在父进程中创建了文件描述符，但是将子进程变为守护进程了，也就没有继承父进程中打开的文件。\\n死循环（一般不会犯，但是我是第一次用，犯了）\\nepoll_wait（）中有一个设置超时时间的参数，所以我在循环中没有使用睡眠队列的操作，想依赖 epoll 的睡眠操作，所以在返回值小于等于 0 时，直接进行下一次循环，没有充分考虑 epoll_wait（）的返回值小于 0 时的不同情况，所以代码写成了下面的样子：\\nfor(;;) { ...... events = epoll_wait(fcluster_epfd, fcluster_wait_events, fcluster_wait_size, 3000); if (unlikely(events \\u0026lt;= 0)) { continue; } ....... } 当 epoll_wait（）返回 EBADF 或 EFAULT 时，就会陷入死循环，因此此时还没有进入睡眠的操作。\\n(2)ep_poll（）函数\\nstatic int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) { int res, eavail; unsigned long flags; long jtimeout; wait_queue_t wait; /* * Calculate the timeout by checking for the \\u0026quot;infinite\\u0026quot; value (-1) * and the overflow condition. The passed timeout is in milliseconds, * that why (t * HZ) / 1000. */ /* * timeout是以毫秒为单位，这里是要转换为jiffies时间。 * 这里加上999(即1000-1)，是为了向上取整。 */ jtimeout = (timeout \\u0026lt; 0 || timeout \\u0026gt;= EP_MAX_MSTIMEO) ? MAX_SCHEDULE_TIMEOUT : (timeout * HZ + 999) / 1000; retry: spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); res = 0; if (list_empty(\\u0026amp;ep-\\u0026gt;rdllist)) { /* * We don't have any available event to return to the caller. * We need to sleep here, and we will be wake up by * ep_poll_callback() when events will become available. */ init_waitqueue_entry(\\u0026amp;wait, current); wait.flags |= WQ_FLAG_EXCLUSIVE; /* * 将当前进程加入到eventpoll的等待队列中， * 等待文件状态就绪或直到超时，或被 * 信号中断。 */ __add_wait_queue(\\u0026amp;ep-\\u0026gt;wq, \\u0026amp;wait); for (;;) { /* * We don't want to sleep if the ep_poll_callback() sends us * a wakeup in between. That's why we set the task state * to TASK_INTERRUPTIBLE before doing the checks. */ set_current_state(TASK_INTERRUPTIBLE); /* * 如果就绪队列不为空，也就是说已经有文件的状态 * 就绪或者超时，则退出循环。 */ if (!list_empty(\\u0026amp;ep-\\u0026gt;rdllist) || !jtimeout) break; /* * 如果当前进程接收到信号，则退出 * 循环，返回EINTR错误 */ if (signal_pending(current)) { res = -EINTR; break; } spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* * 主动让出处理器，等待ep_poll_callback()将当前进程 * 唤醒或者超时,返回值是剩余的时间。从这里开始 * 当前进程会进入睡眠状态，直到某些文件的状态 * 就绪或者超时。当文件状态就绪时，eventpoll的回调 * 函数ep_poll_callback()会唤醒在ep-\\u0026gt;wq指向的等待队列中的进程。 */ jtimeout = schedule_timeout(jtimeout); spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); } __remove_wait_queue(\\u0026amp;ep-\\u0026gt;wq, \\u0026amp;wait); set_current_state(TASK_RUNNING); } /* Is it worth to try to dig for events ? */ /* * ep-\\u0026gt;ovflist链表存储的向用户传递事件时暂存就绪的文件。 * 所以不管是就绪队列ep-\\u0026gt;rdllist不为空，或者ep-\\u0026gt;ovflist不等于 * EP_UNACTIVE_PTR，都有可能现在已经有文件的状态就绪。 * ep-\\u0026gt;ovflist不等于EP_UNACTIVE_PTR有两种情况，一种是NULL，此时 * 可能正在向用户传递事件，不一定就有文件状态就绪， * 一种情况时不为NULL，此时可以肯定有文件状态就绪， * 参见ep_send_events()。 */ eavail = !list_empty(\\u0026amp;ep-\\u0026gt;rdllist) || ep-\\u0026gt;ovflist != EP_UNACTIVE_PTR; spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* * Try to transfer events to user space. In case we get 0 events and * there's still timeout left over, we go trying again in search of * more luck. */ /* * 如果没有被信号中断，并且有事件就绪， * 但是没有获取到事件(有可能被其他进程获取到了)， * 并且没有超时，则跳转到retry标签处，重新等待 * 文件状态就绪。 */ if (!res \\u0026amp;\\u0026amp; eavail \\u0026amp;\\u0026amp; !(res = ep_send_events(ep, events, maxevents)) \\u0026amp;\\u0026amp; jtimeout) goto retry; /* * 返回获取到的事件的个数或者错误码 */ return res; } ep_poll（）的主要过程是：首先将超时时间（以毫秒为单位）转换为 jiffies 时间，然后检查是否有事件发生，如果没有事件发生，则将当前进程加入到 eventpoll 中的等待队列中，直到事件发生或者超时。如果有事件发生，则调用 ep_send_events（）将发生的事件传入用户空间的内存。ep_send_events（）函数将用户传入的内存简单封装到 ep_send_events_data 结构中，然后调用 ep_scan_ready_list（）将就绪队列中的事件传入用户空间的内存。\\n(3)ep_scan_ready_list（）函数\\n/** * ep_scan_ready_list - Scans the ready list in a way that makes possible for * the scan code, to call f_op-\\u0026gt;poll(). Also allows for * O(NumReady) performance. * * @ep: Pointer to the epoll private data structure. * @sproc: Pointer to the scan callback. * @priv: Private opaque data passed to the @sproc callback. * * Returns: The same integer error code returned by the @sproc callback. */ static int ep_scan_ready_list(struct eventpoll *ep, int (*sproc)(struct eventpoll *, struct list_head *, void *), void *priv) { int error, pwake = 0; unsigned long flags; struct epitem *epi, *nepi; LIST_HEAD(txlist); /* * We need to lock this because we could be hit by * eventpoll_release_file() and epoll_ctl(). */ /* * 获取互斥锁，该互斥锁在移除eventpoll文件(eventpoll_release_file() )、 * 操作文件描述符(epoll_ctl())和向用户传递事件(epoll_wait())之间进行互斥 */ mutex_lock(\\u0026amp;ep-\\u0026gt;mtx); /* * Steal the ready list, and re-init the original one to the * empty list. Also, set ep-\\u0026gt;ovflist to NULL so that events * happening while looping w/out locks, are not lost. We cannot * have the poll callback to queue directly on ep-\\u0026gt;rdllist, * because we want the \\u0026quot;sproc\\u0026quot; callback to be able to do it * in a lockless way. */ spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); /* * 将就绪队列中就绪的文件链表暂存在临时 * 表头txlist中，并且初始化就绪队列。 */ list_splice_init(\\u0026amp;ep-\\u0026gt;rdllist, \\u0026amp;txlist); /* * 将ovflist置为NULL，表示此时正在向用户空间传递 * 事件。如果此时有文件状态就绪，不会放在 * 就绪队列中，而是放在ovflist链表中。 */ ep-\\u0026gt;ovflist = NULL; spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* * Now call the callback function. */ /* * 调用ep_send_events_proc()将就绪队列中的事件 * 存入用户传入的内存中。 */ error = (*sproc)(ep, \\u0026amp;txlist, priv); spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); /* * During the time we spent inside the \\u0026quot;sproc\\u0026quot; callback, some * other events might have been queued by the poll callback. * We re-insert them inside the main ready-list here. */ /* * 在调用sproc指向的函数将就绪队列中的事件 * 传递到用户传入的内存的过程中，可能有文件 * 状态就绪，这些事件会暂存在ovflist链表中， * 所以这里要将ovflist中的事件移到就绪队列中。 */ for (nepi = ep-\\u0026gt;ovflist; (epi = nepi) != NULL; nepi = epi-\\u0026gt;next, epi-\\u0026gt;next = EP_UNACTIVE_PTR) { /* * We need to check if the item is already in the list. * During the \\u0026quot;sproc\\u0026quot; callback execution time, items are * queued into -\\u0026gt;ovflist but the \\u0026quot;txlist\\u0026quot; might already * contain them, and the list_splice() below takes care of them. */ if (!ep_is_linked(\\u0026amp;epi-\\u0026gt;rdllink)) list_add_tail(\\u0026amp;epi-\\u0026gt;rdllink, \\u0026amp;ep-\\u0026gt;rdllist); } /* * We need to set back ep-\\u0026gt;ovflist to EP_UNACTIVE_PTR, so that after * releasing the lock, events will be queued in the normal way inside * ep-\\u0026gt;rdllist. */ /* * 重新初始化ovflist，表示传递事件已经完成， * 之后再有文件状态就绪，这些事件会直接 * 放在就绪队列中。 */ ep-\\u0026gt;ovflist = EP_UNACTIVE_PTR; /* * Quickly re-inject items left on \\u0026quot;txlist\\u0026quot;. */ /* * 如果sproc指向的函数ep_send_events_proc()中处理出错或者某些文件的 * 触发方式设置为水平触发(Level Trigger)，txlist中可能还有事件，需要 * 将这些就绪的事件重新添加回eventpoll文件的就绪队列中。 */ list_splice(\\u0026amp;txlist, \\u0026amp;ep-\\u0026gt;rdllist); if (!list_empty(\\u0026amp;ep-\\u0026gt;rdllist)) { /* * Wake up (if active) both the eventpoll wait list and * the -\\u0026gt;poll() wait list (delayed after we release the lock). */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;wq)) wake_up_locked(\\u0026amp;ep-\\u0026gt;wq); if (waitqueue_active(\\u0026amp;ep-\\u0026gt;poll_wait)) pwake++; } spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); mutex_unlock(\\u0026amp;ep-\\u0026gt;mtx); /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(\\u0026amp;ep-\\u0026gt;poll_wait); return error; } ep_scan_ready_list（）函数的参数 sproc 指向的函数是 ep_send_events_proc（），参见 ep_send_events（）函数。\\n(4)ep_send_events_proc（）函数\\n/* * @head:已经就绪的文件列表 * @priv:用来存储已经就绪的文件 */ static int ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv) { struct ep_send_events_data *esed = priv; int eventcnt; unsigned int revents; struct epitem *epi; struct epoll_event __user *uevent; /* * We can loop without lock because we are passed a task private list. * Items cannot vanish during the loop because ep_scan_ready_list() is * holding \\u0026quot;mtx\\u0026quot; during this call. */ for (eventcnt = 0, uevent = esed-\\u0026gt;events; !list_empty(head) \\u0026amp;\\u0026amp; eventcnt \\u0026lt; esed-\\u0026gt;maxevents;) { epi = list_first_entry(head, struct epitem, rdllink); list_del_init(\\u0026amp;epi-\\u0026gt;rdllink); /* * 调用文件的poll函数有两个作用，一是在文件的唤醒 * 队列上注册回调函数，二是返回文件当前的事件状 * 态，如果第二个参数为NULL，则只是查看文件当前 * 状态。 */ revents = epi-\\u0026gt;ffd.file-\\u0026gt;f_op-\\u0026gt;poll(epi-\\u0026gt;ffd.file, NULL) \\u0026amp; epi-\\u0026gt;event.events; /* * If the event mask intersect the caller-requested one, * deliver the event to userspace. Again, ep_scan_ready_list() * is holding \\u0026quot;mtx\\u0026quot;, so no operations coming from userspace * can change the item. */ if (revents) { /* * 向用户内存传值失败时，将当前epitem实例重新放回 * 到链表中，从这里也可以看出，在处理失败后，head指向的 * 链表(对应ep_scan_ready_list()中的临时变量txlist)中 * 有可能会没有完全处理完，因此在ep_scan_ready_list()中 * 需要下面的语句 * list_splice(\\u0026amp;txlist, \\u0026amp;ep-\\u0026gt;rdllist); * 来将未处理的事件重新放回到eventpoll文件的就绪队列中。 */ if (__put_user(revents, \\u0026amp;uevent-\\u0026gt;events) || __put_user(epi-\\u0026gt;event.data, \\u0026amp;uevent-\\u0026gt;data)) { list_add(\\u0026amp;epi-\\u0026gt;rdllink, head); /* * 如果此时已经获取了部分事件，则返回已经获取的事件个数， * 否则返回EFAULT错误。 */ return eventcnt ? eventcnt : -EFAULT; } eventcnt++; uevent++; if (epi-\\u0026gt;event.events \\u0026amp; EPOLLONESHOT) epi-\\u0026gt;event.events \\u0026amp;= EP_PRIVATE_BITS; /* * 如果是触发方式不是边缘触发(Edge Trigger)，而是水平 * 触发(Level Trigger)，需要将当前的epitem实例添加回 * 链表中，下次读取事件时会再次上报。 */ else if (!(epi-\\u0026gt;event.events \\u0026amp; EPOLLET)) { /* * If this file has been added with Level * Trigger mode, we need to insert back inside * the ready list, so that the next call to * epoll_wait() will check again the events * availability. At this point, noone can insert * into ep-\\u0026gt;rdllist besides us. The epoll_ctl() * callers are locked out by * ep_scan_ready_list() holding \\u0026quot;mtx\\u0026quot; and the * poll callback will queue them in ep-\\u0026gt;ovflist. */ list_add_tail(\\u0026amp;epi-\\u0026gt;rdllink, \\u0026amp;ep-\\u0026gt;rdllist); } } } return eventcnt; } 如何加锁 3 个 api 做什么事情：\\nepoll_create() ===》创建红黑树的根节点 epoll_ctl() ===》add,del,mod 增加、删除、修改结点 epoll_wait() ===》把就绪队列的结点copy到用户态放到events里面，跟recv函数很像 分析加锁\\n如果有 3 个线程同时操作 epoll，有哪些地方需要加锁？我们用户层面一共就只有 3 个 api 可以使用 如果同时调用 epoll_create() ，那就是创建三颗红黑树，没有涉及到资源竞争，没有关系。 如果同时调用 epoll_ctl() ，对同一颗红黑树进行，增删改，这就涉及到资源竞争需要加锁了，此时我们对整棵树进行加锁。 如果同时调用 epoll_wait() ，其操作的是就绪队列，所以需要对就绪队列进行加锁。 我们要扣住 epoll 的工作环境，在应用程序调用 epoll_ctl() ，协议栈会不会有回调操作红黑树结点？调用 epoll_wait() copy 出来的时候，协议栈会不会操作操作红黑树结点加入就绪队列？综上所述：\\nepoll_ctl() 对红黑树加锁epoll_wait()对就绪队列加锁回调函数() 对红黑树加锁,对就绪队列加锁 那么红黑树加什么锁，就绪队列加什么锁呢？\\n对于红黑树这种节点比较多的时候，采用互斥锁来加锁。就绪队列就跟生产者消费者一样，结点是从协议栈回调函数来生产的，消费是 epoll_wait()来消费。那么对于队列而言，用自旋锁（对于队列而言，插入删除比较简单，cpu 自旋等待比让出的成本更低，所以用自旋锁）。\\n七、ET 与 LT 的实现 ET 边沿触发，只触发一次 LT 水平触发，如果没有读完就一直触发 代码如何实现 ET 和 LT 的效果呢？\\n水平触发和边沿触发不是故意设计出来的，这是自然而然，水到渠成的功能。水平触发和边沿触发代码只需要改一点点就能实现。从协议栈检测到接收数据，就调用一次回调，这就是 ET，接收到数据，调用一次回调。而 LT 水平触发，检测到 recvbuf 里面有数据就调用回调。所以 ET 和 LT 就是在使用回调的次数上面的差异。\\n那么具体如何实现呢？\\n协议栈流程里面触发回调，是天然的符合 ET 只触发一次的。那么如果是 LT，在 recv 之后，如果缓冲区还有数据那么加入到就绪队列。那么如果是 LT，在 send 之后，如果缓冲区还有空间那么加入到就绪队列。那么这样就能实现 LT 了。\\n八、epoll 内核源码详解 网上很多博客说 epoll 使用了共享内存,这个是完全错误的 ,可以阅读源码,会发现完全没有使用共享内存的任何 api，而是 使用了 copy_from_user 跟__put_user 进行内核跟用户虚拟空间数据交互。\\n/* * fs/eventpoll.c (Efficient event retrieval implementation) * Copyright (C) 2001,...,2009\\tDavide Libenzi * * This program is free software; you can redistribute it and/or modify * it under the terms of the GNU General Public License as published by * the Free Software Foundation; either version 2 of the License, or * (at your option) any later version. * * Davide Libenzi \\u0026lt;davidel@xmailserver.org\\u0026gt; * */ /* * 在深入了解epoll的实现之前, 先来了解内核的3个方面. * 1. 等待队列 waitqueue * 我们简单解释一下等待队列: * 队列头(wait_queue_head_t)往往是资源生产者, * 队列成员(wait_queue_t)往往是资源消费者, * 当头的资源ready后, 会逐个执行每个成员指定的回调函数, * 来通知它们资源已经ready了, 等待队列大致就这个意思. * 2. 内核的poll机制 * 被Poll的fd, 必须在实现上支持内核的Poll技术, * 比如fd是某个字符设备,或者是个socket, 它必须实现 * file_operations中的poll操作, 给自己分配有一个等待队列头. * 主动poll fd的某个进程必须分配一个等待队列成员, 添加到 * fd的对待队列里面去, 并指定资源ready时的回调函数. * 用socket做例子, 它必须有实现一个poll操作, 这个Poll是 * 发起轮询的代码必须主动调用的, 该函数中必须调用poll_wait(), * poll_wait会将发起者作为等待队列成员加入到socket的等待队列中去. * 这样socket发生状态变化时可以通过队列头逐个通知所有关心它的进程. * 这一点必须很清楚的理解, 否则会想不明白epoll是如何 * 得知fd的状态发生变化的. * 3. epollfd本身也是个fd, 所以它本身也可以被epoll, * 可以猜测一下它是不是可以无限嵌套epoll下去... * * epoll基本上就是使用了上面的1,2点来完成. * 可见epoll本身并没有给内核引入什么特别复杂或者高深的技术, * 只不过是已有功能的重新组合, 达到了超过select的效果. */ /* * 相关的其它内核知识: * 1. fd我们知道是文件描述符, 在内核态, 与之对应的是struct file结构, * 可以看作是内核态的文件描述符. * 2. spinlock, 自旋锁, 必须要非常小心使用的锁, * 尤其是调用spin_lock_irqsave()的时候, 中断关闭, 不会发生进程调度, * 被保护的资源其它CPU也无法访问. 这个锁是很强力的, 所以只能锁一些 * 非常轻量级的操作. * 3. 引用计数在内核中是非常重要的概念, * 内核代码里面经常有些release, free释放资源的函数几乎不加任何锁, * 这是因为这些函数往往是在对象的引用计数变成0时被调用, * 既然没有进程在使用在这些对象, 自然也不需要加锁. * struct file 是持有引用计数的. */ /* --- epoll相关的数据结构 --- */ /* * This structure is stored inside the \\u0026quot;private_data\\u0026quot; member of the file * structure and rapresent the main data sructure for the eventpoll * interface. */ /* 每创建一个epollfd, 内核就会分配一个eventpoll与之对应, 可以说是 * 内核态的epollfd. */ struct eventpoll { /* Protect the this structure access */ spinlock_t lock; /* * This mutex is used to ensure that files are not removed * while epoll is using them. This is held during the event * collection loop, the file cleanup path, the epoll file exit * code and the ctl operations. */ /* 添加, 修改或者删除监听fd的时候, 以及epoll_wait返回, 向用户空间 * 传递数据时都会持有这个互斥锁, 所以在用户空间可以放心的在多个线程 * 中同时执行epoll相关的操作, 内核级已经做了保护. */ struct mutex mtx; /* Wait queue used by sys_epoll_wait() */ /* 调用epoll_wait()时, 我们就是\\u0026quot;睡\\u0026quot;在了这个等待队列上... */ wait_queue_head_t wq; /* Wait queue used by file-\\u0026gt;poll() */ /* 这个用于epollfd本事被poll的时候... */ wait_queue_head_t poll_wait; /* List of ready file descriptors */ /* 所有已经ready的epitem都在这个链表里面 */ struct list_head rdllist; /* RB tree root used to store monitored fd structs */ /* 所有要监听的epitem都在这里 */ struct rb_root rbr; /* 这是一个单链表链接着所有的struct epitem当event转移到用户空间时 */ * This is a single linked list that chains all the \\u0026quot;struct epitem\\u0026quot; that * happened while transfering ready events to userspace w/out * holding -\\u0026gt;lock. */ struct epitem *ovflist; /* The user that created the eventpoll descriptor */ /* 这里保存了一些用户变量, 比如fd监听数量的最大值等等 */ struct user_struct *user; }; /* * Each file descriptor added to the eventpoll interface will * have an entry of this type linked to the \\u0026quot;rbr\\u0026quot; RB tree. */ /* epitem 表示一个被监听的fd */ struct epitem { /* RB tree node used to link this structure to the eventpoll RB tree */ /* rb_node, 当使用epoll_ctl()将一批fds加入到某个epollfd时, 内核会分配 * 一批的epitem与fds们对应, 而且它们以rb_tree的形式组织起来, tree的root * 保存在epollfd, 也就是struct eventpoll中. * 在这里使用rb_tree的原因我认为是提高查找,插入以及删除的速度. * rb_tree对以上3个操作都具有O(lgN)的时间复杂度 */ struct rb_node rbn; /* List header used to link this structure to the eventpoll ready list */ /* 链表节点, 所有已经ready的epitem都会被链到eventpoll的rdllist中 */ struct list_head rdllink; /* * Works together \\u0026quot;struct eventpoll\\u0026quot;-\\u0026gt;ovflist in keeping the * single linked chain of items. */ /* 这个在代码中再解释... */ struct epitem *next; /* The file descriptor information this item refers to */ /* epitem对应的fd和struct file */ struct epoll_filefd ffd; /* Number of active wait queue attached to poll operations */ int nwait; /* List containing poll wait queues */ struct list_head pwqlist; /* The \\u0026quot;container\\u0026quot; of this item */ /* 当前epitem属于哪个eventpoll */ struct eventpoll *ep; /* List header used to link this item to the \\u0026quot;struct file\\u0026quot; items list */ struct list_head fllink; /* The structure that describe the interested events and the source fd */ /* 当前的epitem关系哪些events, 这个数据是调用epoll_ctl时从用户态传递过来 */ struct epoll_event event; }; struct epoll_filefd { struct file *file; int fd; }; /* poll所用到的钩子Wait structure used by the poll hooks */ struct eppoll_entry { /* List header used to link this structure to the \\u0026quot;struct epitem\\u0026quot; */ struct list_head llink; /* The \\u0026quot;base\\u0026quot; pointer is set to the container \\u0026quot;struct epitem\\u0026quot; */ struct epitem *base; /* * Wait queue item that will be linked to the target file wait * queue head. */ wait_queue_t wait; /* The wait queue head that linked the \\u0026quot;wait\\u0026quot; wait queue item */ wait_queue_head_t *whead; }; /* Wrapper struct used by poll queueing */ struct ep_pqueue { poll_table pt; struct epitem *epi; }; /* Used by the ep_send_events() function as callback private data */ struct ep_send_events_data { int maxevents; struct epoll_event __user *events; }; /* --- 代码注释 --- */ /* 你没看错, 这就是epoll_create()的真身, 基本啥也不干直接调用epoll_create1了, * 另外你也可以发现, size这个参数其实是没有任何用处的... */ SYSCALL_DEFINE1(epoll_create, int, size) { if (size \\u0026lt;= 0) return -EINVAL; return sys_epoll_create1(0); } /* 这才是真正的epoll_create啊~~ */ SYSCALL_DEFINE1(epoll_create1, int, flags) { int error; struct eventpoll *ep = NULL;//主描述符 /* Check the EPOLL_* constant for consistency. */ /* 这句没啥用处... */ BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC); /* 对于epoll来讲, 目前唯一有效的FLAG就是CLOEXEC */ if (flags \\u0026amp; ~EPOLL_CLOEXEC) return -EINVAL; /* * Create the internal data structure (\\u0026quot;struct eventpoll\\u0026quot;). */ /* 分配一个struct eventpoll, 分配和初始化细节我们随后深聊~ */ error = ep_alloc(\\u0026amp;ep); if (error \\u0026lt; 0) return error; /* * Creates all the items needed to setup an eventpoll file. That is, * a file structure and a free file descriptor. */ /* 这里是创建一个匿名fd, 说起来就话长了...长话短说: * epollfd本身并不存在一个真正的文件与之对应, 所以内核需要创建一个 * \\u0026quot;虚拟\\u0026quot;的文件, 并为之分配真正的struct file结构, 而且有真正的fd. * 这里2个参数比较关键: * eventpoll_fops, fops就是file operations, 就是当你对这个文件(这里是虚拟的)进行操作(比如读)时, * fops里面的函数指针指向真正的操作实现, 类似C++里面虚函数和子类的概念. * epoll只实现了poll和release(就是close)操作, 其它文件系统操作都有VFS全权处理了. * ep, ep就是struct epollevent, 它会作为一个私有数据保存在struct file的private指针里面. * 其实说白了, 就是为了能通过fd找到struct file, 通过struct file能找到eventpoll结构. * 如果懂一点Linux下字符设备驱动开发, 这里应该是很好理解的, * 推荐阅读 \\u0026lt;Linux device driver 3rd\\u0026gt; */ error = anon_inode_getfd(\\u0026quot;[eventpoll]\\u0026quot;, \\u0026amp;eventpoll_fops, ep, O_RDWR | (flags \\u0026amp; O_CLOEXEC)); if (error \\u0026lt; 0) ep_free(ep); return error; } /* * 创建好epollfd后, 接下来我们要往里面添加fd咯 * 来看epoll_ctl * epfd 就是epollfd * op ADD,MOD,DEL * fd 需要监听的描述符 * event 我们关心的events */ SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event) { int error; struct file *file, *tfile; struct eventpoll *ep; struct epitem *epi; struct epoll_event epds; error = -EFAULT; /* * 错误处理以及从用户空间将epoll_event结构copy到内核空间. */ if (ep_op_has_event(op) \\u0026amp;\\u0026amp; copy_from_user(\\u0026amp;epds, event, sizeof(struct epoll_event))) goto error_return; /* Get the \\u0026quot;struct file *\\u0026quot; for the eventpoll file */ /* 取得struct file结构, epfd既然是真正的fd, 那么内核空间 * 就会有与之对于的一个struct file结构 * 这个结构在epoll_create1()中, 由函数anon_inode_getfd()分配 */ error = -EBADF; file = fget(epfd); if (!file) goto error_return; /* Get the \\u0026quot;struct file *\\u0026quot; for the target file */ /* 我们需要监听的fd, 它当然也有个struct file结构, 上下2个不要搞混了哦 */ tfile = fget(fd); if (!tfile) goto error_fput; /* The target file descriptor must support poll */ error = -EPERM; /* 如果监听的文件不支持poll, 那就没辙了. * 你知道什么情况下, 文件会不支持poll吗? */ if (!tfile-\\u0026gt;f_op || !tfile-\\u0026gt;f_op-\\u0026gt;poll) goto error_tgt_fput; /* * We have to check that the file structure underneath the file descriptor * the user passed to us _is_ an eventpoll file. And also we do not permit * adding an epoll file descriptor inside itself. */ error = -EINVAL; /* epoll不能自己监听自己... */ if (file == tfile || !is_file_epoll(file)) goto error_tgt_fput; /* * At this point it is safe to assume that the \\u0026quot;private_data\\u0026quot; contains * our own data structure. */ /* 取到我们的eventpoll结构, 来自与epoll_create1()中的分配 */ ep = file-\\u0026gt;private_data; /* 接下来的操作有可能修改数据结构内容, 锁之~ */ mutex_lock(\\u0026amp;ep-\\u0026gt;mtx); /* * Try to lookup the file inside our RB tree, Since we grabbed \\u0026quot;mtx\\u0026quot; * above, we can be sure to be able to use the item looked up by * ep_find() till we release the mutex. */ /* 对于每一个监听的fd, 内核都有分配一个epitem结构, * 而且我们也知道, epoll是不允许重复添加fd的, * 所以我们首先查找该fd是不是已经存在了. * ep_find()其实就是RBTREE查找, 跟C++STL的map差不多一回事, O(lgn)的时间复杂度. */ epi = ep_find(ep, tfile, fd); error = -EINVAL; switch (op) { /* 首先我们关心添加 */ case EPOLL_CTL_ADD: if (!epi) { /* 之前的find没有找到有效的epitem, 证明是第一次插入, 接受! * 这里我们可以知道, POLLERR和POLLHUP事件内核总是会关心的 * */ epds.events |= POLLERR | POLLHUP; /* rbtree插入, 详情见ep_insert()的分析 * 其实我觉得这里有insert的话, 之前的find应该 * 是可以省掉的... */ error = ep_insert(ep, \\u0026amp;epds, tfile, fd); } else /* 找到了!? 重复添加! */ error = -EEXIST; break; /* 删除和修改操作都比较简单 */ case EPOLL_CTL_DEL: if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: if (epi) { epds.events |= POLLERR | POLLHUP; error = ep_modify(ep, epi, \\u0026amp;epds); } else error = -ENOENT; break; } mutex_unlock(\\u0026amp;ep-\\u0026gt;mtx); error_tgt_fput: fput(tfile); error_fput: fput(file); error_return: return error; } /* 分配一个eventpoll结构 */ static int ep_alloc(struct eventpoll **pep) { int error; struct user_struct *user; struct eventpoll *ep; /* 获取当前用户的一些信息, 比如是不是root啦, 最大监听fd数目啦 */ user = get_current_user(); error = -ENOMEM; ep = kzalloc(sizeof(*ep), GFP_KERNEL); if (unlikely(!ep)) goto free_uid; /* 这些都是初始化啦 */ spin_lock_init(\\u0026amp;ep-\\u0026gt;lock); mutex_init(\\u0026amp;ep-\\u0026gt;mtx); init_waitqueue_head(\\u0026amp;ep-\\u0026gt;wq);//初始化自己睡在的等待队列 init_waitqueue_head(\\u0026amp;ep-\\u0026gt;poll_wait);//初始化 INIT_LIST_HEAD(\\u0026amp;ep-\\u0026gt;rdllist);//初始化就绪链表 ep-\\u0026gt;rbr = RB_ROOT; ep-\\u0026gt;ovflist = EP_UNACTIVE_PTR; ep-\\u0026gt;user = user; *pep = ep; return 0; free_uid: free_uid(user); return error; } /* * Must be called with \\u0026quot;mtx\\u0026quot; held. */ /* * ep_insert()在epoll_ctl()中被调用, 完成往epollfd里面添加一个监听fd的工作 * tfile是fd在内核态的struct file结构 */ static int ep_insert(struct eventpoll *ep, struct epoll_event *event, struct file *tfile, int fd) { int error, revents, pwake = 0; unsigned long flags; struct epitem *epi; struct ep_pqueue epq; /* 查看是否达到当前用户的最大监听数 */ if (unlikely(atomic_read(\\u0026amp;ep-\\u0026gt;user-\\u0026gt;epoll_watches) \\u0026gt;= max_user_watches)) return -ENOSPC; /* 从著名的slab中分配一个epitem */ if (!(epi = kmem_***_alloc(epi_***, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ /* 这些都是相关成员的初始化... */ INIT_LIST_HEAD(\\u0026amp;epi-\\u0026gt;rdllink); INIT_LIST_HEAD(\\u0026amp;epi-\\u0026gt;fllink); INIT_LIST_HEAD(\\u0026amp;epi-\\u0026gt;pwqlist); epi-\\u0026gt;ep = ep; /* 这里保存了我们需要监听的文件fd和它的file结构 */ ep_set_ffd(\\u0026amp;epi-\\u0026gt;ffd, tfile, fd); epi-\\u0026gt;event = *event; epi-\\u0026gt;nwait = 0; /* 这个指针的初值不是NULL哦... */ epi-\\u0026gt;next = EP_UNACTIVE_PTR; /* Initialize the poll table using the queue callback */ /* 好, 我们终于要进入到poll的正题了 */ epq.epi = epi; /* 初始化一个poll_table * 其实就是指定调用poll_wait(注意不是epoll_wait!!!)时的回调函数,和我们关心哪些events, * ep_ptable_queue_proc()就是我们的回调啦, 初值是所有event都关心 */ init_poll_funcptr(\\u0026amp;epq.pt, ep_ptable_queue_proc); /* * Attach the item to the poll hooks and get current event bits. * We can safely use the file* here because its usage count has * been increased by the caller of this function. Note that after * this operation completes, the poll callback can start hitting * the new item. */ /* 这一部很关键, 也比较难懂, 完全是内核的poll机制导致的... * 首先, f_op-\\u0026gt;poll()一般来说只是个wrapper, 它会调用真正的poll实现, * 拿UDP的socket来举例, 这里就是这样的调用流程: f_op-\\u0026gt;poll(), sock_poll(), * udp_poll(), datagram_poll(), sock_poll_wait(), 最后调用到我们上面指定的 * ep_ptable_queue_proc()这个回调函数...(好深的调用路径...). * 完成这一步, 我们的epitem就跟这个socket关联起来了, 当它有状态变化时, * 会通过ep_poll_callback()来通知. * 最后, 这个函数还会查询当前的fd是不是已经有啥event已经ready了, 有的话 * 会将event返回. */ revents = tfile-\\u0026gt;f_op-\\u0026gt;poll(tfile, \\u0026amp;epq.pt); /* * We have to check if something went wrong during the poll wait queue * install process. Namely an allocation for a wait queue failed due * high memory pressure. */ error = -ENOMEM; if (epi-\\u0026gt;nwait \\u0026lt; 0) goto error_unregister; /* Add the current item to the list of active epoll hook for this file */ /* 这个就是每个文件会将所有监听自己的epitem链起来 */ spin_lock(\\u0026amp;tfile-\\u0026gt;f_lock); list_add_tail(\\u0026amp;epi-\\u0026gt;fllink, \\u0026amp;tfile-\\u0026gt;f_ep_links); spin_unlock(\\u0026amp;tfile-\\u0026gt;f_lock); /* * Add the current item to the RB tree. All RB tree operations are * protected by \\u0026quot;mtx\\u0026quot;, and ep_insert() is called with \\u0026quot;mtx\\u0026quot; held. */ /* 都搞定后, 将epitem插入到对应的eventpoll中去 */ ep_rbtree_insert(ep, epi); /* We have to drop the new item inside our item list to keep track of it */ spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); /* If the file is already \\u0026quot;ready\\u0026quot; we drop it inside the ready list */ /* 到达这里后, 如果我们监听的fd已经有事件发生, 那就要处理一下 */ if ((revents \\u0026amp; event-\\u0026gt;events) \\u0026amp;\\u0026amp; !ep_is_linked(\\u0026amp;epi-\\u0026gt;rdllink)) { /* 将当前的epitem加入到ready list中去 */ list_add_tail(\\u0026amp;epi-\\u0026gt;rdllink, \\u0026amp;ep-\\u0026gt;rdllist); /* Notify waiting tasks that events are available */ /* 谁在epoll_wait, 就唤醒它... */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;wq)) wake_up_locked(\\u0026amp;ep-\\u0026gt;wq); /* 谁在epoll当前的epollfd, 也唤醒它... */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;poll_wait)) pwake++; } spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); atomic_inc(\\u0026amp;ep-\\u0026gt;user-\\u0026gt;epoll_watches); /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(\\u0026amp;ep-\\u0026gt;poll_wait); return 0; error_unregister: ep_unregister_pollwait(ep, epi); /* * We need to do this because an event could have been arrived on some * allocated wait queue. Note that we don't care about the ep-\\u0026gt;ovflist * list, since that is used/cleaned only inside a section bound by \\u0026quot;mtx\\u0026quot;. * And ep_insert() is called with \\u0026quot;mtx\\u0026quot; held. */ spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); if (ep_is_linked(\\u0026amp;epi-\\u0026gt;rdllink)) list_del_init(\\u0026amp;epi-\\u0026gt;rdllink); spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); kmem_***_free(epi_***, epi); return error; } /* * This is the callback that is used to add our wait queue to the * target file wakeup lists. */ /* * 该函数在调用f_op-\\u0026gt;poll()时会被调用. * 也就是epoll主动poll某个fd时, 用来将epitem与指定的fd关联起来的. * 关联的办法就是使用等待队列(waitqueue) */ static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt) { struct epitem *epi = ep_item_from_epqueue(pt); struct eppoll_entry *pwq; if (epi-\\u0026gt;nwait \\u0026gt;= 0 \\u0026amp;\\u0026amp; (pwq = kmem_***_alloc(pwq_***, GFP_KERNEL))) { /* 初始化等待队列, 指定ep_poll_callback为唤醒时的回调函数, * 当我们监听的fd发生状态改变时, 也就是队列头被唤醒时, * 指定的回调函数将会被调用. */ init_waitqueue_func_entry(\\u0026amp;pwq-\\u0026gt;wait, ep_poll_callback); pwq-\\u0026gt;whead = whead; pwq-\\u0026gt;base = epi; /* 将刚分配的等待队列成员加入到头中, 头是由fd持有的 */ add_wait_queue(whead, \\u0026amp;pwq-\\u0026gt;wait); list_add_tail(\\u0026amp;pwq-\\u0026gt;llink, \\u0026amp;epi-\\u0026gt;pwqlist); /* nwait记录了当前epitem加入到了多少个等待队列中, * 我认为这个值最大也只会是1... */ epi-\\u0026gt;nwait++; } else { /* We have to signal that an error occurred */ epi-\\u0026gt;nwait = -1; } } /* * This is the callback that is passed to the wait queue wakeup * machanism. It is called by the stored file descriptors when they * have events to report. */ /* * 这个是关键性的回调函数, 当我们监听的fd发生状态改变时, 它会被调用. * 参数key被当作一个unsigned long整数使用, 携带的是events. */ static int ep_poll_callback(wait_queue_t *wait, unsigned mode, int sync, void *key) { int pwake = 0; unsigned long flags; struct epitem *epi = ep_item_from_wait(wait);//从等待队列获取epitem.需要知道哪个进程挂载到这个设备 struct eventpoll *ep = epi-\\u0026gt;ep;//获取 spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); /* * If the event mask does not contain any poll(2) event, we consider the * descriptor to be disabled. This condition is likely the effect of the * EPOLLONESHOT bit that disables the descriptor when an event is received, * until the next EPOLL_CTL_MOD will be issued. */ if (!(epi-\\u0026gt;event.events \\u0026amp; ~EP_PRIVATE_BITS)) goto out_unlock; /* * Check the events coming with the callback. At this stage, not * every device reports the events in the \\u0026quot;key\\u0026quot; parameter of the * callback. We need to be able to handle both cases here, hence the * test for \\u0026quot;key\\u0026quot; != NULL before the event match test. */ /* 没有我们关心的event... */ if (key \\u0026amp;\\u0026amp; !((unsigned long) key \\u0026amp; epi-\\u0026gt;event.events)) goto out_unlock; /* * If we are trasfering events to userspace, we can hold no locks * (because we're accessing user memory, and because of linux f_op-\\u0026gt;poll() * semantics). All the events that happens during that period of time are * chained in ep-\\u0026gt;ovflist and requeued later on. */ /* * 这里看起来可能有点费解, 其实干的事情比较简单: * 如果该callback被调用的同时, epoll_wait()已经返回了, * 也就是说, 此刻应用程序有可能已经在循环获取events, * 这种情况下, 内核将此刻发生event的epitem用一个单独的链表 * 链起来, 不发给应用程序, 也不丢弃, 而是在下一次epoll_wait * 时返回给用户. */ if (unlikely(ep-\\u0026gt;ovflist != EP_UNACTIVE_PTR)) { if (epi-\\u0026gt;next == EP_UNACTIVE_PTR) { epi-\\u0026gt;next = ep-\\u0026gt;ovflist; ep-\\u0026gt;ovflist = epi; } goto out_unlock; } /* If this file is already in the ready list we exit soon */ /* 将当前的epitem放入ready list */ if (!ep_is_linked(\\u0026amp;epi-\\u0026gt;rdllink)) list_add_tail(\\u0026amp;epi-\\u0026gt;rdllink, \\u0026amp;ep-\\u0026gt;rdllist); /* * Wake up ( if active ) both the eventpoll wait list and the -\\u0026gt;poll() * wait list. */ /* 唤醒epoll_wait... */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;wq)) wake_up_locked(\\u0026amp;ep-\\u0026gt;wq); /* 如果epollfd也在被poll, 那就唤醒队列里面的所有成员. */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;poll_wait)) pwake++; out_unlock: spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(\\u0026amp;ep-\\u0026gt;poll_wait); return 1; } /* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) { int error; struct file *file; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ if (maxevents \\u0026lt;= 0 || maxevents \\u0026gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ /* 这个地方有必要说明一下: * 内核对应用程序采取的策略是\\u0026quot;绝对不信任\\u0026quot;, * 所以内核跟应用程序之间的数据交互大都是copy, 不允许(也时候也是不能...)指针引用. * epoll_wait()需要内核返回数据给用户空间, 内存由用户程序提供, * 所以内核会用一些手段来验证这一段内存空间是不是有效的. */ if (!access_ok(VERIFY_WRITE, events, maxevents * sizeof(struct epoll_event))) { error = -EFAULT; goto error_return; } /* Get the \\u0026quot;struct file *\\u0026quot; for the eventpoll file */ error = -EBADF; /* 获取epollfd的struct file, epollfd也是文件嘛 */ file = fget(epfd); if (!file) goto error_return; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ error = -EINVAL; /* 检查一下它是不是一个真正的epollfd... */ if (!is_file_epoll(file)) goto error_fput; /* * At this point it is safe to assume that the \\u0026quot;private_data\\u0026quot; contains * our own data structure. */ /* 获取eventpoll结构 */ ep = file-\\u0026gt;private_data; /* Time to fish for events ... */ /* OK, 睡觉, 等待事件到来~~ */ error = ep_poll(ep, events, maxevents, timeout); error_fput: fput(file); error_return: return error; } /* 这个函数真正将执行epoll_wait的进程带入睡眠状态... */ static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) { int res, eavail; unsigned long flags; long jtimeout; wait_queue_t wait;//等待队列 /* * Calculate the timeout by checking for the \\u0026quot;infinite\\u0026quot; value (-1) * and the overflow condition. The passed timeout is in milliseconds, * that why (t * HZ) / 1000. */ /* 计算睡觉时间, 毫秒要转换为HZ */ jtimeout = (timeout \\u0026lt; 0 || timeout \\u0026gt;= EP_MAX_MSTIMEO) ? MAX_SCHEDULE_TIMEOUT : (timeout * HZ + 999) / 1000; retry: spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); res = 0; /* 如果ready list不为空, 就不睡了, 直接干活... */ if (list_empty(\\u0026amp;ep-\\u0026gt;rdllist)) { /* * We don't have any available event to return to the caller. * We need to sleep here, and we will be wake up by * ep_poll_callback() when events will become available. */ /* OK, 初始化一个等待队列, 准备直接把自己挂起, * 注意current是一个宏, 代表当前进程 */ init_waitqueue_entry(\\u0026amp;wait, current);//初始化等待队列,wait表示当前进程 __add_wait_queue_exclusive(\\u0026amp;ep-\\u0026gt;wq, \\u0026amp;wait);//挂载到ep结构的等待队列 for (;;) { /* * We don't want to sleep if the ep_poll_callback() sends us * a wakeup in between. That's why we set the task state * to TASK_INTERRUPTIBLE before doing the checks. */ /* 将当前进程设置位睡眠, 但是可以被信号唤醒的状态, * 注意这个设置是\\u0026quot;将来时\\u0026quot;, 我们此刻还没睡! */ set_current_state(TASK_INTERRUPTIBLE); /* 如果这个时候, ready list里面有成员了, * 或者睡眠时间已经过了, 就直接不睡了... */ if (!list_empty(\\u0026amp;ep-\\u0026gt;rdllist) || !jtimeout) break; /* 如果有信号产生, 也起床... */ if (signal_pending(current)) { res = -EINTR; break; } /* 啥事都没有,解锁, 睡觉... */ spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* jtimeout这个时间后, 会被唤醒, * ep_poll_callback()如果此时被调用, * 那么我们就会直接被唤醒, 不用等时间了... * 再次强调一下ep_poll_callback()的调用时机是由被监听的fd * 的具体实现, 比如socket或者某个设备驱动来决定的, * 因为等待队列头是他们持有的, epoll和当前进程 * 只是单纯的等待... **/ jtimeout = schedule_timeout(jtimeout);//睡觉 spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); } __remove_wait_queue(\\u0026amp;ep-\\u0026gt;wq, \\u0026amp;wait); /* OK 我们醒来了... */ set_current_state(TASK_RUNNING); } /* Is it worth to try to dig for events ? */ eavail = !list_empty(\\u0026amp;ep-\\u0026gt;rdllist) || ep-\\u0026gt;ovflist != EP_UNACTIVE_PTR; spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* * Try to transfer events to user space. In case we get 0 events and * there's still timeout left over, we go trying again in search of * more luck. */ /* 如果一切正常, 有event发生, 就开始准备数据copy给用户空间了... */ if (!res \\u0026amp;\\u0026amp; eavail \\u0026amp;\\u0026amp; !(res = ep_send_events(ep, events, maxevents)) \\u0026amp;\\u0026amp; jtimeout) goto retry; return res; } /* 这个简单, 我们直奔下一个... */ static int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) { struct ep_send_events_data esed; esed.maxevents = maxevents; esed.events = events; return ep_scan_ready_list(ep, ep_send_events_proc, \\u0026amp;esed); } /** * ep_scan_ready_list - Scans the ready list in a way that makes possible for * the scan code, to call f_op-\\u0026gt;poll(). Also allows for * O(NumReady) performance. * * @ep: Pointer to the epoll private data structure. * @sproc: Pointer to the scan callback. * @priv: Private opaque data passed to the @sproc callback. * * Returns: The same integer error code returned by the @sproc callback. */ static int ep_scan_ready_list(struct eventpoll *ep, int (*sproc)(struct eventpoll *, struct list_head *, void *), void *priv) { int error, pwake = 0; unsigned long flags; struct epitem *epi, *nepi; LIST_HEAD(txlist); /* * We need to lock this because we could be hit by * eventpoll_release_file() and epoll_ctl(). */ mutex_lock(\\u0026amp;ep-\\u0026gt;mtx); /* * Steal the ready list, and re-init the original one to the * empty list. Also, set ep-\\u0026gt;ovflist to NULL so that events * happening while looping w/out locks, are not lost. We cannot * have the poll callback to queue directly on ep-\\u0026gt;rdllist, * because we want the \\u0026quot;sproc\\u0026quot; callback to be able to do it * in a lockless way. */ spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); /* 这一步要注意, 首先, 所有监听到events的epitem都链到rdllist上了, * 但是这一步之后, 所有的epitem都转移到了txlist上, 而rdllist被清空了, * 要注意哦, rdllist已经被清空了! */ list_splice_init(\\u0026amp;ep-\\u0026gt;rdllist, \\u0026amp;txlist); /* ovflist, 在ep_poll_callback()里面我解释过, 此时此刻我们不希望 * 有新的event加入到ready list中了, 保存后下次再处理... */ ep-\\u0026gt;ovflist = NULL; spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); /* * Now call the callback function. */ /* 在这个回调函数里面处理每个epitem * sproc 就是 ep_send_events_proc, 下面会注释到. */ error = (*sproc)(ep, \\u0026amp;txlist, priv); spin_lock_irqsave(\\u0026amp;ep-\\u0026gt;lock, flags); /* * During the time we spent inside the \\u0026quot;sproc\\u0026quot; callback, some * other events might have been queued by the poll callback. * We re-insert them inside the main ready-list here. */ /* 现在我们来处理ovflist, 这些epitem都是我们在传递数据给用户空间时 * 监听到了事件. */ for (nepi = ep-\\u0026gt;ovflist; (epi = nepi) != NULL; nepi = epi-\\u0026gt;next, epi-\\u0026gt;next = EP_UNACTIVE_PTR) { /* * We need to check if the item is already in the list. * During the \\u0026quot;sproc\\u0026quot; callback execution time, items are * queued into -\\u0026gt;ovflist but the \\u0026quot;txlist\\u0026quot; might already * contain them, and the list_splice() below takes care of them. */ /* 将这些直接放入readylist */ if (!ep_is_linked(\\u0026amp;epi-\\u0026gt;rdllink)) list_add_tail(\\u0026amp;epi-\\u0026gt;rdllink, \\u0026amp;ep-\\u0026gt;rdllist); } /* * We need to set back ep-\\u0026gt;ovflist to EP_UNACTIVE_PTR, so that after * releasing the lock, events will be queued in the normal way inside * ep-\\u0026gt;rdllist. */ ep-\\u0026gt;ovflist = EP_UNACTIVE_PTR; /* * Quickly re-inject items left on \\u0026quot;txlist\\u0026quot;. */ /* 上一次没有处理完的epitem, 重新插入到ready list */ list_splice(\\u0026amp;txlist, \\u0026amp;ep-\\u0026gt;rdllist); /* ready list不为空, 直接唤醒... */ if (!list_empty(\\u0026amp;ep-\\u0026gt;rdllist)) { /* * Wake up (if active) both the eventpoll wait list and * the -\\u0026gt;poll() wait list (delayed after we release the lock). */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;wq)) wake_up_locked(\\u0026amp;ep-\\u0026gt;wq); if (waitqueue_active(\\u0026amp;ep-\\u0026gt;poll_wait)) pwake++; } spin_unlock_irqrestore(\\u0026amp;ep-\\u0026gt;lock, flags); mutex_unlock(\\u0026amp;ep-\\u0026gt;mtx); /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(\\u0026amp;ep-\\u0026gt;poll_wait); return error; } /* 该函数作为callbakc在ep_scan_ready_list()中被调用 * head是一个链表, 包含了已经ready的epitem, * 这个不是eventpoll里面的ready list, 而是上面函数中的txlist. */ static int ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv) { struct ep_send_events_data *esed = priv; int eventcnt; unsigned int revents; struct epitem *epi; struct epoll_event __user *uevent; /* * We can loop without lock because we are passed a task private list. * Items cannot vanish during the loop because ep_scan_ready_list() is * holding \\u0026quot;mtx\\u0026quot; during this call. */ /* 扫描整个链表... */ for (eventcnt = 0, uevent = esed-\\u0026gt;events; !list_empty(head) \\u0026amp;\\u0026amp; eventcnt \\u0026lt; esed-\\u0026gt;maxevents;) { /* 取出第一个成员 */ epi = list_first_entry(head, struct epitem, rdllink); /* 然后从链表里面移除 */ list_del_init(\\u0026amp;epi-\\u0026gt;rdllink); /* 读取events, * 注意events我们ep_poll_callback()里面已经取过一次了, 为啥还要再取? * 1. 我们当然希望能拿到此刻的最新数据, events是会变的~ * 2. 不是所有的poll实现, 都通过等待队列传递了events, 有可能某些驱动压根没传 * 必须主动去读取. */ revents = epi-\\u0026gt;ffd.file-\\u0026gt;f_op-\\u0026gt;poll(epi-\\u0026gt;ffd.file, NULL) \\u0026amp; epi-\\u0026gt;event.events; if (revents) { /* 将当前的事件和用户传入的数据都copy给用户空间, * 就是epoll_wait()后应用程序能读到的那一堆数据. */ if (__put_user(revents, \\u0026amp;uevent-\\u0026gt;events) || __put_user(epi-\\u0026gt;event.data, \\u0026amp;uevent-\\u0026gt;data)) { list_add(\\u0026amp;epi-\\u0026gt;rdllink, head); return eventcnt ? eventcnt : -EFAULT; } eventcnt++; uevent++; if (epi-\\u0026gt;event.events \\u0026amp; EPOLLONESHOT) epi-\\u0026gt;event.events \\u0026amp;= EP_PRIVATE_BITS; else if (!(epi-\\u0026gt;event.events \\u0026amp; EPOLLET)) { /* 嘿嘿, EPOLLET和非ET的区别就在这一步之差呀~ * 如果是ET, epitem是不会再进入到readly list, * 除非fd再次发生了状态改变, ep_poll_callback被调用. * 如果是非ET, 不管你还有没有有效的事件或者数据, * 都会被重新插入到ready list, 再下一次epoll_wait * 时, 会立即返回, 并通知给用户空间. 当然如果这个 * 被监听的fds确实没事件也没数据了, epoll_wait会返回一个0, * 空转一次. */ list_add_tail(\\u0026amp;epi-\\u0026gt;rdllink, \\u0026amp;ep-\\u0026gt;rdllist); } } } return eventcnt; } /* ep_free在epollfd被close时调用, * 释放一些资源而已, 比较简单 */ static void ep_free(struct eventpoll *ep) { struct rb_node *rbp; struct epitem *epi; /* We need to release all tasks waiting for these file */ if (waitqueue_active(\\u0026amp;ep-\\u0026gt;poll_wait)) ep_poll_safewake(\\u0026amp;ep-\\u0026gt;poll_wait); /* * We need to lock this because we could be hit by * eventpoll_release_file() while we're freeing the \\u0026quot;struct eventpoll\\u0026quot;. * We do not need to hold \\u0026quot;ep-\\u0026gt;mtx\\u0026quot; here because the epoll file * is on the way to be removed and no one has references to it * anymore. The only hit might come from eventpoll_release_file() but * holding \\u0026quot;epmutex\\u0026quot; is sufficent here. */ mutex_lock(\\u0026amp;epmutex); /* * Walks through the whole tree by unregistering poll callbacks. */ for (rbp = rb_first(\\u0026amp;ep-\\u0026gt;rbr); rbp; rbp = rb_next(rbp)) { epi = rb_entry(rbp, struct epitem, rbn); ep_unregister_pollwait(ep, epi); } /* * Walks through the whole tree by freeing each \\u0026quot;struct epitem\\u0026quot;. At this * point we are sure no poll callbacks will be lingering around, and also by * holding \\u0026quot;epmutex\\u0026quot; we can be sure that no file cleanup code will hit * us during this operation. So we can avoid the lock on \\u0026quot;ep-\\u0026gt;lock\\u0026quot;. */ /* 之所以在关闭epollfd之前不需要调用epoll_ctl移除已经添加的fd, * 是因为这里已经做了... */ while ((rbp = rb_first(\\u0026amp;ep-\\u0026gt;rbr)) != NULL) { epi = rb_entry(rbp, struct epitem, rbn); ep_remove(ep, epi); } mutex_unlock(\\u0026amp;epmutex); mutex_destroy(\\u0026amp;ep-\\u0026gt;mtx); free_uid(ep-\\u0026gt;user); kfree(ep); } /* File callbacks that implement the eventpoll file behaviour */ static const struct file_operations eventpoll_fops = { .release\\t= ep_eventpoll_release, .poll\\t= ep_eventpoll_poll }; /* Fast test to see if the file is an evenpoll file */ static inline int is_file_epoll(struct file *f) { return f-\\u0026gt;f_op == \\u0026amp;eventpoll_fops; } /* OK, eventpoll我认为比较重要的函数都注释完了... */ (1)epoll_create\\n从 slab 缓存中创建一个 eventpoll 对象,并且创建一个匿名的 fd 跟 fd 对应的 file 对象, 而 eventpoll 对象保存在 struct file 结构的 private 指针中,并且返回, 该 fd 对应的 file operations 只是实现了 poll 跟 release 操作。\\n创建 eventpoll 对象的初始化操作，获取当前用户信息,是不是 root,最大监听 fd 数目等并且保存到 eventpoll 对象中 初始化等待队列,初始化就绪链表,初始化红黑树的头结点。\\n(2)epoll_ctl 操作\\n将 epoll_event 结构拷贝到内核空间中，并且判断加入的 fd 是否支持 poll 结构(epoll,poll,selectI/O 多路复用必须支持 poll 操作)，并且从 epfd-\\u0026gt;file-\\u0026gt;privatedata 获取 event_poll 对象,根据 op 区分是添加删除还是修改, 首先在 eventpoll 结构中的红黑树查找是否已经存在了相对应的 fd,没找到就支持插入操作,否则报重复的错误，相对应的修改,删除比较简单就不啰嗦了。\\n插入操作时,会创建一个与 fd 对应的 epitem 结构,并且初始化相关成员,比如保存监听的 fd 跟 file 结构之类的，重要的是指定了调用 poll_wait 时的回调函数用于数据就绪时唤醒进程,(其内部,初始化设备的等待队列,将该进程注册到等待队列)完成这一步, 我们的 epitem 就跟这个 socket 关联起来了, 当它有状态变化时, 会通过 ep_poll_callback()来通知，最后调用加入的 fd 的 file operation-\\u0026gt;poll 函数(最后会调用 poll_wait 操作)用于完成注册操作，最后将 epitem 结构添加到红黑树中。\\n(4)epoll_wait 操作\\n计算睡眠时间(如果有),判断 eventpoll 对象的链表是否为空,不为空那就干活不睡眠，并且初始化一个等待队列,把自己挂上去,设置自己的进程状态，为可睡眠状态.判断是否有信号到来(有的话直接被中断醒来,),如果啥事都没有那就调用 schedule_timeout 进行睡眠，如果超时或者被唤醒,首先从自己初始化的等待队列删除,然后开始拷贝资源给用户空间了，拷贝资源则是先把就绪事件链表转移到中间链表,然后挨个遍历拷贝到用户空间, 并且挨个判断其是否为水平触发,是的话再次插入到就绪链表。\\n九、Epoll 性能优势 Epoll 与 Select/Poll 的对比分析 在网络编程领域，epoll 能脱颖而出，离不开和 select、poll 的对比。从数据拷贝的角度来看，select 和 poll 每次调用时，都需要把大量的文件描述符集合从用户态拷贝到内核态 。假设一个服务器需要监听 1000 个文件描述符，每次调用 select 或 poll，这 1000 个文件描述符都要在用户态和内核态之间来回拷贝，这无疑会消耗大量的时间和系统资源。而 epoll 则不同，它通过 epoll_ctl 函数将文件描述符添加到内核的红黑树中时就完成了一次拷贝，后续 epoll_wait 等待事件时，无需再次拷贝大量数据，因为就绪的 socket 是通过共享内存（内核态和用户态共享内存）的方式，直接从内核态的就绪链表中获取的，大大减少了数据拷贝的开销 。\\n再看时间复杂度。select 和 poll 的时间复杂度都是 O (n) ，这里的 n 是监听的文件描述符数量。这意味着，随着监听的文件描述符数量增加，它们的性能会急剧下降。比如，当监听的文件描述符达到 1 万个时，每次调用 select 或 poll，都需要线性遍历这 1 万个文件描述符，检查是否有事件发生，这会消耗大量的 CPU 时间。而 epoll 的时间复杂度是 O (1) ，它通过红黑树快速定位文件描述符，通过回调机制将就绪的 socket 加入双向链表，epoll_wait 只需要遍历双向链表，就能获取到就绪的 socket，无论监听的文件描述符有多少，它的时间复杂度都不会改变，性能非常稳定 。\\n文件描述符数量限制也是一个关键区别。select 有文件描述符数量的限制，在 32 位系统中，默认的文件描述符数量上限通常是 1024，64 位系统中一般是 2048。虽然可以通过修改系统参数来调整这个限制，但这并不是一个理想的解决方案，而且这种修改可能会带来其他潜在问题。poll 虽然没有像 select 那样严格的固定数量限制，但它基于链表存储文件描述符，在处理大量文件描述符时，链表的遍历效率较低，性能也会受到影响。而 epoll 没有这样的限制，它可以轻松处理大量的文件描述符，理论上只受限于系统的内存资源。在一个拥有 1GB 内存的机器上，epoll 可以支持大约 10 万个左右的文件描述符，这使得它在高并发场景下具有极大的优势 。\\n高效性能的具体体现 在实际的高并发场景中，epoll 的高效性能得到了充分体现 。以大型电商网站为例，在促销活动期间，会有海量的用户同时访问网站，产生大量的并发连接。假设每秒有 10 万用户访问，每个用户与服务器建立一个 TCP 连接，这就意味着服务器需要同时处理 10 万个并发连接 。如果使用 select 或 poll，由于它们的性能瓶颈，在处理如此大量的连接时，服务器的 CPU 很快就会被耗尽，响应速度会变得极慢，甚至出现服务不可用的情况。而采用 epoll，服务器可以轻松应对这些并发连接 。epoll 通过其高效的事件通知机制，能够快速地将有数据可读或可写的连接通知给应用程序，应用程序可以及时处理这些连接上的事件，比如读取用户的购买请求、返回商品信息等 。这样，服务器能够在高并发的情况下，保持较高的吞吐量和快速的响应速度，为用户提供流畅的购物体验 。\\n再比如即时通讯软件，它需要实时处理大量用户的消息收发。假设一个即时通讯软件有 100 万在线用户，每个用户可能随时发送消息。如果使用传统的 select 或 poll 技术，在处理这 100 万用户的连接时，由于频繁的轮询和大量的数据拷贝，系统资源会被大量消耗，导致消息处理延迟严重，用户发送的消息可能要等很久才能被接收和转发。而 epoll 可以高效地管理这些连接，当某个用户发送消息时，epoll 能迅速感知到，并将对应的 socket 加入就绪链表，通知应用程序读取和处理消息，实现消息的快速收发，满足即时通讯对实时性的严格要求 。\\n十、实际应用案例 知名项目中的 Epoll 应用 epoll 在许多知名项目中都发挥着关键作用，成为提升性能的 “秘密武器”。Nginx 作为一款高性能的 Web 服务器和反向代理服务器，就大量运用了 epoll 来实现高效的网络通信 。Nginx 在处理大量并发请求时，每个请求都对应一个 socket 连接，也就是一个文件描述符。通过 epoll，Nginx 可以同时监听这些大量的 socket，当有新的请求到达或者某个连接上有数据可读 / 可写时，epoll 能够迅速感知并通知 Nginx 进行处理。在一个高并发的电商网站中，Nginx 可能同时需要处理成千上万的用户请求，epoll 的高效事件通知机制使得 Nginx 能够快速响应这些请求，保证网站的流畅运行 ，大大提高了用户体验。\\nRedis 同样是 epoll 的忠实用户。Redis 是一个基于内存的高性能键值对数据库，它需要处理大量的客户端连接和数据读写操作 。Redis 利用 epoll 来管理这些客户端连接对应的 socket，实现了单线程高效处理大量并发请求。当有新的客户端连接时，Redis 通过 epoll 将新连接的 socket 添加到事件监听列表中 。当某个客户端发送数据（比如执行 SET、GET 等命令）时，epoll 会检测到对应的 socket 有可读事件发生，通知 Redis 读取数据并执行相应的命令，然后将结果返回给客户端 。在一个大型的社交平台中，用户频繁地进行点赞、评论等操作，这些操作都会产生大量的 Redis 请求，epoll 帮助 Redis 高效地处理这些并发请求，保证社交平台的实时性和高性能 。\\n代码示例与性能测试 为了更直观地展示 epoll 在实际编程中的使用，我们来看一个简单的代码示例 。下面是一个使用 epoll 实现的简单的 TCP 服务器代码（以 C 语言为例）：\\n#include \\u0026lt;stdio.h\\u0026gt; #include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;string.h\\u0026gt; #include \\u0026lt;unistd.h\\u0026gt; #include \\u0026lt;arpa/inet.h\\u0026gt; #include \\u0026lt;sys/socket.h\\u0026gt; #include \\u0026lt;sys/epoll.h\\u0026gt; #define MAX_EVENTS 10 #define PORT 8888 int main() { int listenfd, connfd, nfds, epfd; struct sockaddr_in servaddr, cliaddr; socklen_t clilen; struct epoll_event ev, events[MAX_EVENTS]; // 创建监听socket listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { perror(\\u0026quot;socket creation failed\\u0026quot;); exit(EXIT_FAILURE); } // 初始化服务器地址结构 memset(\\u0026amp;servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = INADDR_ANY; servaddr.sin_port = htons(PORT); // 绑定socket到地址 if (bind(listenfd, (struct sockaddr *)\\u0026amp;servaddr, sizeof(servaddr)) == -1) { perror(\\u0026quot;bind failed\\u0026quot;); close(listenfd); exit(EXIT_FAILURE); } // 监听socket if (listen(listenfd, 10) == -1) { perror(\\u0026quot;listen failed\\u0026quot;); close(listenfd); exit(EXIT_FAILURE); } // 创建epoll实例 epfd = epoll_create1(0); if (epfd == -1) { perror(\\u0026quot;epoll_create1 failed\\u0026quot;); close(listenfd); exit(EXIT_FAILURE); } // 将监听socket添加到epoll实例中 ev.events = EPOLLIN; ev.data.fd = listenfd; if (epoll_ctl(epfd, EPOLL_CTL_ADD, listenfd, \\u0026amp;ev) == -1) { perror(\\u0026quot;epoll_ctl: listenfd\\u0026quot;); close(listenfd); close(epfd); exit(EXIT_FAILURE); } while (1) { // 等待事件发生 nfds = epoll_wait(epfd, events, MAX_EVENTS, -1); if (nfds == -1) { perror(\\u0026quot;epoll_wait failed\\u0026quot;); break; } for (int i = 0; i \\u0026lt; nfds; i++) { if (events[i].data.fd == listenfd) { // 处理新的连接 clilen = sizeof(cliaddr); connfd = accept(listenfd, (struct sockaddr *)\\u0026amp;cliaddr, \\u0026amp;clilen); if (connfd == -1) { perror(\\u0026quot;accept failed\\u0026quot;); continue; } // 将新连接的socket添加到epoll实例中 ev.events = EPOLLIN; ev.data.fd = connfd; if (epoll_ctl(epfd, EPOLL_CTL_ADD, connfd, \\u0026amp;ev) == -1) { perror(\\u0026quot;epoll_ctl: connfd\\u0026quot;); close(connfd); } } else { // 处理已连接socket上的读事件 connfd = events[i].data.fd; char buffer[1024] = {0}; int valread = read(connfd, buffer, 1024); if (valread == -1) { perror(\\u0026quot;read failed\\u0026quot;); close(connfd); continue; } else if (valread == 0) { // 客户端关闭连接 close(connfd); } else { // 处理接收到的数据 printf(\\u0026quot;Received: %s\\\\n\\u0026quot;, buffer); // 简单回显数据给客户端 write(connfd, buffer, strlen(buffer)); } } } } // 关闭socket和epoll实例 close(listenfd); close(epfd); return 0; } 这个代码首先创建了一个监听 socket，绑定到指定端口并开始监听。然后创建了一个 epoll 实例，并将监听 socket 添加到 epoll 中，监听读事件（EPOLLIN）。在主循环中，通过 epoll_wait 等待事件发生，当有新连接到达时，接受连接并将新连接的 socket 也添加到 epoll 中；当已连接的 socket 有数据可读时，读取数据并进行简单的处理（这里是回显数据给客户端） 。\\n为了测试 epoll 的性能，我们可以进行一个简单的性能测试。假设我们使用一个客户端程序向上述服务器发送大量的请求，分别使用 epoll、select 和 poll 三种 I/O 模型来实现服务器，并记录它们在处理相同数量请求时的时间和吞吐量等性能指标 。测试环境为一台配置为 Intel Core i7-10700K CPU、16GB 内存的 Linux 服务器，客户端和服务器在同一局域网内 。测试结果如下表所示：\\nI/O 模型 处理 10000 个请求时间（秒） 吞吐量（请求 / 秒） epoll 1.2 8333.33 select 5.6 1785.71 poll 4.8 2083.33 从测试结果可以明显看出，epoll 在处理大量并发请求时，无论是时间还是吞吐量上，都远远优于 select 和 poll。epoll 处理 10000 个请求只需要 1.2 秒，吞吐量达到了 8333.33 请求 / 秒，而 select 和 poll 处理相同数量的请求所需时间分别是 5.6 秒和 4.8 秒，吞吐量也远低于 epoll 。我们还可以通过图表更直观地展示这些数据，比如使用柱状图，横坐标为 I/O 模型，纵坐标为吞吐量，这样可以清晰地看到 epoll 在性能上的巨大优势 。\\n\"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"网络编程\",\"epoll\"]",
      series: [],
      date: "\"2025-05-04\""
    });
  
    searchIndex.push({
      title: "\"共享内存详解 | [转载](https://mp.weixin.qq.com/s/wOySn0oi0xXREpFRBXCMmQ)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/05/04/%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E8%AF%A6%E8%A7%A3/\"",
      content: "\"解锁Linux共享内存：进程间通信的超高速通道 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 解锁Linux共享内存：进程间通信的超高速通道 在 Linux 系统的进程间通信 “江湖” 中，众多通信方式各显神通。管道，如同隐秘的地下通道，让有亲缘关系的进程能够悄然传递信息；消息队列则似邮局，进程可投递和接收格式化的消息包裹。然而，有一种通信方式却以其独特的 “高速” 特性脱颖而出，它就是共享内存。想象一下，进程们原本各自生活在独立的 “小天地” 里，有着自己专属的虚拟地址空间。但共享内存却如同神奇的 “任意门”，打破了进程间的隔阂，让多个进程能够直接访问同一块内存区域。这种独特的机制，使得数据在进程间的传递无需繁琐的复制过程，极大地提升了通信效率，堪称进程间通信的超高速通道。\\n在使用共享内存时，需要注意对于并发访问的控制，如使用锁或其他同步机制来保证数据的一致性和安全性。此外，还需要谨慎处理资源管理问题，确保正确地释放共享内存以避免内存泄漏。接下来，就让我们一同深入探索 Linux 共享内存的奥秘，揭开它神秘的面纱，看看它是如何在 Linux 系统中发挥这一独特且强大的作用 。\\n一、Linux 内存管理初窥 1.1 虚拟内存与物理内存 Linux 采用虚拟内存管理机制，为每个进程分配独立的虚拟地址空间。这意味着每个进程都可以认为自己拥有 4GB（32 位系统）或更大（64 位系统）的连续内存空间，而不必担心物理内存的实际大小和其他进程的干扰。虚拟内存与物理内存通过内存映射机制建立联系，进程访问的虚拟地址会被转换为实际的物理地址。\\n举个例子，当你在 Linux 系统上同时运行多个程序时，每个程序都觉得自己独占了大量内存，但实际上物理内存是有限的。通过虚拟内存管理，操作系统可以巧妙地在物理内存和磁盘之间交换数据，使得系统能够运行比物理内存更大的程序集。就好比一个小型图书馆，虽然书架空间有限（物理内存），但通过一个庞大的仓库（磁盘）来存放暂时不用的书籍（数据），当读者需要某本书时，管理员（操作系统）会从仓库中取出并放到书架上供读者使用。\\n1.2 内存分页 为了更高效地管理内存，Linux 采用内存分页机制。将虚拟内存和物理内存按照固定大小的页（通常为 4KB）进行划分，页是内存管理的最小单位。操作系统通过维护页表来记录虚拟页和物理页之间的映射关系，当进程访问某个虚拟地址时，CPU 会根据页表将其转换为对应的物理地址。\\n想象一下，内存就像一本巨大的书籍，每一页都有固定的页码（虚拟页号和物理页号）。当你想要查找书中的某个内容（访问内存数据）时，通过目录（页表）可以快速定位到具体的页码，从而找到所需内容。\\n1.3 内存分配与回收 内存管理包括内存的分配和回收。当进程需要内存时，它会向操作系统请求分配内存，操作系统根据一定的算法从空闲内存中分配相应大小的内存块给进程；当进程不再需要某些内存时，它会将这些内存释放回操作系统，以便操作系统重新分配给其他需要的进程。\\n例如，当你在 Linux 系统上运行一个新的程序时，程序会向操作系统申请内存来存放代码和数据。操作系统会从空闲内存池中找到合适大小的内存块分配给该程序。当程序运行结束后，它占用的内存会被操作系统回收，重新加入空闲内存池，等待下一个程序的请求。\\n二、共享内存详解 2.1 共享内存是什么 共享内存是一种高效的进程间通信（IPC，Inter - Process Communication）机制，它允许两个或多个进程直接访问同一块物理内存区域。简单来说，就好比多个房间（进程）都有一扇门可以直接通向同一个储物间（共享内存），大家可以直接在这个储物间里存放和取用物品（数据） 。\\n在 Linux 系统中，共享内存的实现依赖于操作系统的支持。当一个进程创建共享内存时，操作系统会在物理内存中分配一块区域，并为这块区域生成一个唯一的标识符。其他进程可以通过这个标识符将该共享内存映射到自己的虚拟地址空间中，从而实现对共享内存的访问。\\n2.2 为什么要用共享内存 在进程间通信的众多方式中，共享内存之所以备受青睐，是因为它具有其他方式难以比拟的优势。\\n首先，与管道和消息队列等通信方式相比，共享内存的速度极快。管道和消息队列在数据传输时，需要进行多次数据拷贝，数据要在内核空间和用户空间之间来回传递，这会消耗大量的时间和系统资源。而共享内存则不同，多个进程直接访问同一块内存区域，数据不需要在不同进程的地址空间之间拷贝，大大减少了数据传输的开销，提高了通信效率。例如，在一个实时数据处理系统中，多个进程需要频繁地交换大量数据，如果使用管道或消息队列，可能会因为数据传输的延迟而影响系统的实时性；而使用共享内存，就可以快速地传递数据，满足系统对实时性的要求。\\n其次，共享内存的使用非常灵活。它可以用于任何类型的进程间通信，无论是有亲缘关系的进程（如父子进程）还是毫无关系的进程，都可以通过共享内存进行数据共享和交互。而且，共享内存区域可以存储各种类型的数据结构，开发者可以根据实际需求自定义数据格式，这为复杂应用场景的实现提供了便利。比如，在一个多进程协作的图形处理程序中，不同进程可以通过共享内存共享图像数据和处理参数，各自完成不同的处理任务，如一个进程负责图像的滤波处理，另一个进程负责图像的边缘检测，共享内存使得它们能够高效地协同工作。\\n此外，共享内存还能有效地节省内存资源。多个进程共享同一块内存区域，而不是每个进程都单独开辟一块内存来存储相同的数据，这在内存资源有限的情况下显得尤为重要。例如，在一个服务器系统中，可能同时有多个进程需要访问一些公共的配置信息或缓存数据，使用共享内存可以避免这些数据在每个进程中重复存储，从而提高内存的利用率。\\n2.3 共享内存原理 共享内存是 System V 版本的最后一个进程间通信方式。共享内存，顾名思义就是允许两个不相关的进程访问同一个逻辑内存，共享内存是两个正在运行的进程之间共享和传递数据的一种非常有效的方式。不同进程之间共享的内存通常为同一段物理内存。进程可以将同一段物理内存连接到他们自己的地址空间中，所有的进程都可以访问共享内存中的地址。如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。\\n特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前，并无自动机制可以阻止第二个进程开始对它进行读取，所以我们通常需要用其他的机制来同步对共享内存的访问，例如信号量。\\n在 Linux 中，每个进程都有属于自己的进程控制块（PCB）和地址空间（Addr Space），并且都有一个与之对应的页表，负责将进程的虚拟地址与物理地址进行映射，通过内存管理单元（MMU）进行管理。两个不同的虚拟地址通过页表映射到物理空间的同一区域，它们所指向的这块区域即共享内存。\\n共享内存的通信原理示意图：\\n对于上图我的理解是：当两个进程通过页表将虚拟地址映射到物理地址时，在物理地址中有一块共同的内存区，即共享内存，这块内存可以被两个进程同时看到。这样当一个进程进行写操作，另一个进程读操作就可以实现进程间通信。但是，我们要确保一个进程在写的时候不能被读，因此我们使用信号量来实现同步与互斥。\\n对于一个共享内存，实现采用的是引用计数的原理，当进程脱离共享存储区后，计数器减一，挂架成功时，计数器加一，只有当计数器变为零时，才能被删除。当进程终止时，它所附加的共享存储区都会自动脱离。\\n为什么共享内存速度最快？\\n借助上图说明：Proc A 进程给内存中写数据， Proc B 进程从内存中读取数据，在此期间一共发生了两次复制\\n（1）Proc A 到共享内存 （2）共享内存到 Proc B 因为直接在内存上操作，所以共享内存的速度也就提高了。\\n三、共享内存使用指南 3.1 关键函数全解析 在 Linux 中使用共享内存，离不开一些关键的系统调用函数，它们是我们操作共享内存的有力工具。\\n(1)shmget 函数 ：用于创建共享内存段或获取已存在的共享内存段的标识符。其函数原型为：\\n#include \\u0026lt;sys/ipc.h\\u0026gt; #include \\u0026lt;sys/shm.h\\u0026gt; int shmget(key_t key, size_t size, int shmflg); key：是一个用于标识共享内存段的键值，它就像是共享内存的 “门牌号”。通常可以使用 ftok 函数根据文件路径和项目 ID 生成一个唯一的 key 值。例如：\\nkey_t key = ftok(\\u0026quot;/tmp/somefile\\u0026quot;, 1); 这里/tmp/somefile 是一个已存在的文件路径，1 是项目 ID。如果 key 取值为 IPC_PRIVATE，则会创建一个新的私有共享内存段，通常用于父子进程间的通信。\\nsize：指定共享内存段的大小，单位是字节。例如，若要创建一个 1024 字节大小的共享内存段，可以这样设置：\\nint shmid = shmget(key, 1024, IPC_CREAT | 0666); shmflg：是一组标志位，常用的标志包括 IPC_CREAT（如果共享内存不存在则创建）和 IPC_EXCL（与 IPC_CREAT 一起使用，确保创建新的共享内存段，若已存在则报错）。权限设置与文件权限类似，如 0666 表示所有者、组和其他用户都有读写权限 。如果 shmget 函数执行成功，会返回一个非负整数，即共享内存段的标识符 shmid；若失败，则返回 -1。 (2)shmat 函数 ：将共享内存段连接到调用进程的地址空间，使得进程可以访问共享内存中的数据。\\n其函数原型为：\\nvoid *shmat(int shmid, const void *shmaddr, int shmflg); shmid：是由 shmget 函数返回的共享内存标识符。 shmaddr：指定共享内存连接到当前进程中的地址位置，通常设置为 NULL，表示让系统自动选择合适的地址。例如： void *shared_mem = shmat(shmid, NULL, 0); shmflg：通常为 0，表示默认的连接方式。如果设置了 SHM_RDONLY，则以只读方式连接共享内存。如果 shmat 函数调用成功，会返回一个指向共享内存起始地址的指针；若失败，返回(void *)-1。\\n(3)shmdt 函数 ：用于将共享内存段从当前进程的地址空间中分离。函数原型为：\\nint shmdt(const void *shmaddr); shmaddr：是 shmat 函数返回的共享内存起始地址。调用该函数后，进程不再能够访问该共享内存，但共享内存本身并不会被删除。例如：\\nint result = shmdt(shared_mem); if (result == -1) { perror(\\u0026quot;shmdt failed\\u0026quot;); } 如果分离成功，shmdt 返回 0；若失败，返回 -1。\\n(4)shmctl 函数 ：用于对共享内存进行控制操作，如获取共享内存信息、设置权限、删除共享内存等。函数原型为：\\nint shmctl(int shmid, int cmd, struct shmid_ds *buf); shmid：共享内存标识符。 cmd：指定要执行的控制命令，常用的命令有 IPC_STAT（获取共享内存的状态信息，存入 buf 指向的结构体）、IPC_SET（设置共享内存的状态信息，如权限等，从 buf 指向的结构体中获取设置值）和 IPC_RMID（删除共享内存段）。 buf：是一个指向 shmid_ds 结构体的指针，用于传递或获取共享内存的相关信息。当 cmd 为 IPC_RMID 时，buf 通常设置为 NULL。例如，删除共享内存段的操作如下： int result = shmctl(shmid, IPC_RMID, NULL); if (result == -1) { perror(\\u0026quot;shmctl IPC_RMID failed\\u0026quot;); } 如果操作成功，shmctl 返回 0；若失败，返回 -1。\\n3.2 代码实战：共享内存的读写操作 下面通过一个完整的代码示例，展示如何在两个进程间使用共享内存进行数据读写。假设我们要在一个进程中写入数据，另一个进程读取这些数据。\\n首先，定义一个数据结构，用于在共享内存中存储数据。这里我们定义一个简单的结构体，包含一个整数和一个字符数组：\\n#include \\u0026lt;stdio.h\\u0026gt; #include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;string.h\\u0026gt; #include \\u0026lt;sys/ipc.h\\u0026gt; #include \\u0026lt;sys/shm.h\\u0026gt; #include \\u0026lt;unistd.h\\u0026gt; #define SHM_SIZE 1024 // 定义共享内存中使用的数据结构 typedef struct { int num; char text[100]; } SharedData; int main() { int shmid; key_t key; SharedData *shared_data; // 生成唯一的key值 key = ftok(\\u0026quot;.\\u0026quot;, 'a'); if (key == -1) { perror(\\u0026quot;ftok\\u0026quot;); exit(EXIT_FAILURE); } // 创建共享内存段 shmid = shmget(key, sizeof(SharedData), IPC_CREAT | 0666); if (shmid == -1) { perror(\\u0026quot;shmget\\u0026quot;); exit(EXIT_FAILURE); } // 将共享内存连接到当前进程的地址空间 shared_data = (SharedData *)shmat(shmid, NULL, 0); if (shared_data == (SharedData *)-1) { perror(\\u0026quot;shmat\\u0026quot;); exit(EXIT_FAILURE); } // 写入数据到共享内存 shared_data-\\u0026gt;num = 42; strcpy(shared_data-\\u0026gt;text, \\u0026quot;Hello, shared memory!\\u0026quot;); printf(\\u0026quot;Data written to shared memory: num = %d, text = %s\\\\n\\u0026quot;, shared_data-\\u0026gt;num, shared_data-\\u0026gt;text); // 分离共享内存 if (shmdt(shared_data) == -1) { perror(\\u0026quot;shmdt\\u0026quot;); exit(EXIT_FAILURE); } return 0; } 上述代码中，首先使用 ftok 函数生成一个 key 值，然后通过 shmget 创建一个共享内存段，其大小为 SharedData 结构体的大小。接着使用 shmat 将共享内存连接到当前进程地址空间，向共享内存中写入数据，最后使用 shmdt 分离共享内存。\\n下面是读取共享内存数据的代码：\\n#include \\u0026lt;stdio.h\\u0026gt; #include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;sys/ipc.h\\u0026gt; #include \\u0026lt;sys/shm.h\\u0026gt; #include \\u0026lt;unistd.h\\u0026gt; #define SHM_SIZE 1024 // 定义共享内存中使用的数据结构 typedef struct { int num; char text[100]; } SharedData; int main() { int shmid; key_t key; SharedData *shared_data; // 生成唯一的key值，必须与写入进程一致 key = ftok(\\u0026quot;.\\u0026quot;, 'a'); if (key == -1) { perror(\\u0026quot;ftok\\u0026quot;); exit(EXIT_FAILURE); } // 获取已存在的共享内存段 shmid = shmget(key, sizeof(SharedData), 0666); if (shmid == -1) { perror(\\u0026quot;shmget\\u0026quot;); exit(EXIT_FAILURE); } // 将共享内存连接到当前进程的地址空间 shared_data = (SharedData *)shmat(shmid, NULL, 0); if (shared_data == (SharedData *)-1) { perror(\\u0026quot;shmat\\u0026quot;); exit(EXIT_FAILURE); } // 从共享内存读取数据 printf(\\u0026quot;Data read from shared memory: num = %d, text = %s\\\\n\\u0026quot;, shared_data-\\u0026gt;num, shared_data-\\u0026gt;text); // 分离共享内存 if (shmdt(shared_data) == -1) { perror(\\u0026quot;shmdt\\u0026quot;); exit(EXIT_FAILURE); } // 删除共享内存段（这里仅演示，实际应用中需谨慎操作） if (shmctl(shmid, IPC_RMID, NULL) == -1) { perror(\\u0026quot;shmctl IPC_RMID\\u0026quot;); exit(EXIT_FAILURE); } return 0; } 在读取代码中，同样先使用 ftok 生成与写入进程相同的 key 值，然后通过 shmget 获取共享内存段（注意这里没有使用 IPC_CREAT 标志，因为共享内存已经由写入进程创建），接着连接共享内存并读取数据，最后分离共享内存并删除共享内存段（在实际应用中，删除共享内存段的操作需要谨慎考虑，确保没有其他进程再使用该共享内存）。\\n3.3 模拟共享内存 我们用 server 来创建共享存储段，用 client 获取共享存储段的标识符，二者关联起来之后 server 将数据写入共享存储段，client 从共享区读取数据。通信结束之后 server 与 client 断开与共享区的关联，并由 server 释放共享存储段。\\ncomm.h\\n//comm.h #ifndef _COMM_H__ #define _COMM_H__ #include\\u0026lt;stdio.h\\u0026gt; #include\\u0026lt;sys/types.h\\u0026gt; #include\\u0026lt;sys/ipc.h\\u0026gt; #include\\u0026lt;sys/shm.h\\u0026gt; #define PATHNAME \\u0026quot;.\\u0026quot; #define PROJ_ID 0x6666 int CreateShm(int size); int DestroyShm(int shmid); int GetShm(int size); #endif comm.c\\n//comm.c #include\\u0026quot;comm.h\\u0026quot; static int CommShm(int size,int flags) { key_t key = ftok(PATHNAME,PROJ_ID); if(key \\u0026lt; 0) { perror(\\u0026quot;ftok\\u0026quot;); return -1; } int shmid = 0; if((shmid = shmget(key,size,flags)) \\u0026lt; 0) { perror(\\u0026quot;shmget\\u0026quot;); return -2; } return shmid; } int DestroyShm(int shmid) { if(shmctl(shmid,IPC_RMID,NULL) \\u0026lt; 0) { perror(\\u0026quot;shmctl\\u0026quot;); return -1; } return 0; } int CreateShm(int size) { return CommShm(size,IPC_CREAT | IPC_EXCL | 0666); } int GetShm(int size) { return CommShm(size,IPC_CREAT); } client.c\\n//client.c #include\\u0026quot;comm.h\\u0026quot; int main() { int shmid = GetShm(4096); sleep(1); char *addr = shmat(shmid,NULL,0); sleep(2); int i = 0; while(i \\u0026lt; 26) { addr[i] = 'A' + i; i++; addr[i] = 0; sleep(1); } shmdt(addr); sleep(2); return 0; } server.c\\n//server.c #include\\u0026quot;comm.h\\u0026quot; int main() { int shmid = CreateShm(4096); char *addr = shmat(shmid,NULL,0); sleep(2); int i = 0; while(i++ \\u0026lt; 26) { printf(\\u0026quot;client# %s\\\\n\\u0026quot;,addr); sleep(1); } shmdt(addr); sleep(2); DestroyShm(shmid); return 0; } Makefile\\n//Makefile .PHONY:all all:server client client:client.c comm.c gcc -o $@ $^ server:server.c comm.c gcc -o $@ $^ .PHONY:clean clean: rm -f client server 运行结果：\\n优点：我们可以看到使用共享内存进行进程之间的通信是非常方便的，而且函数的接口也比较简单，数据的共享还使进程间的数据不用传送，而是直接访问内存，加快了程序的效率。 缺点：共享内存没有提供同步机制，这使得我们在使用共享内存进行进程之间的通信时，往往需要借助其他手段来保证进程之间的同步工作。 3.4 权限与生命周期管理 权限设置：在创建共享内存时，可以通过 shmget 函数的 shmflg 参数设置共享内存的访问权限。权限设置与文件权限类似，使用三位八进制数表示，分别对应所有者、组和其他用户的读、写、执行权限。例如，0666 表示所有者、组和其他用户都有读写权限；0644 表示所有者有读写权限，组和其他用户只有读权限。合理的权限设置可以保证共享内存的安全性，防止未经授权的进程访问或修改共享内存中的数据。比如，在一个多用户的服务器环境中，如果有一些共享内存用于存储敏感数据，就需要严格设置权限，只允许特定的用户或用户组访问。\\n生命周期管理：共享内存的生命周期独立于使用它的进程。当最后一个使用共享内存的进程将其分离（调用 shmdt）后，共享内存仍然存在于系统中，直到被显式删除（调用 shmctl 并传入 IPC_RMID 命令）或系统重启。这就需要开发者在使用共享内存时，谨慎管理其生命周期。在程序结束时，应该确保及时删除不再使用的共享内存，以避免内存泄漏和资源浪费。\\n比如，在一个长期运行的服务器程序中，如果不断创建共享内存而不删除，随着时间的推移，系统中会残留大量无用的共享内存，占用系统资源，影响系统性能。同时，在删除共享内存之前，要确保所有使用该共享内存的进程都已经将其分离，否则可能会导致其他进程访问非法内存地址，引发程序崩溃等问题。\\n四、深入共享内存的实现原理 4.1 内核视角：共享内存的数据结构 在 Linux 内核中，有几个关键的数据结构用于管理共享内存，其中 struct shmid_kernel 和 struct shmid_ds 起着重要作用。\\nstruct shmid_kernel 是内核中用于表示共享内存对象的内部数据结构，它包含了共享内存的各种属性和状态信息。虽然这个结构体对于普通开发者来说并不直接可见，但了解它有助于深入理解共享内存的工作机制。它记录了共享内存段的大小、所属的进程组、创建时间、最后访问时间等重要信息。例如，通过这个结构体，内核可以跟踪共享内存的使用情况，判断哪些进程正在使用它，以及何时需要回收共享内存资源。\\n而 struct shmid_ds 则是一个更常用的数据结构，开发者可以通过 shmctl 函数来访问和修改这个结构体中的信息。它的定义如下：\\nstruct shmid_ds { struct ipc_perm shm_perm; /* 所有权和权限相关信息 */ size_t shm_segsz; /* 共享内存段的大小（字节） */ time_t shm_atime; /* 最后一次连接到共享内存的时间 */ time_t shm_dtime; /* 最后一次从共享内存分离的时间 */ time_t shm_ctime; /* 共享内存状态最后一次改变的时间 */ pid_t shm_cpid; /* 创建共享内存的进程ID */ pid_t shm_lpid; /* 最后一次执行shmat或shmdt操作的进程ID */ shmatt_t shm_nattch; /* 当前连接到共享内存的进程数 */ ... }; shm_perm：包含了共享内存的所有权和权限信息，如所有者 ID、组 ID、访问权限等，类似于文件的权限管理。例如，通过设置 shm_perm 中的权限位，可以控制哪些进程可以访问共享内存，以及以何种方式（读、写等）访问。 shm_segsz：明确了共享内存段的大小，以字节为单位。在创建共享内存时，开发者需要根据实际需求指定合适的大小。比如，在一个简单的进程间通信场景中，如果只是传递少量的状态信息，可能只需要分配几十或几百字节的共享内存；而在一个需要共享大量数据的场景中，如共享视频帧数据，可能需要分配几兆甚至更大的共享内存空间。 shm_atime、shm_dtime 和 shm_ctime：分别记录了共享内存的连接时间、分离时间和状态改变时间。这些时间戳对于调试和性能分析非常有帮助，例如，通过查看 shm_atime 和 shm_dtime，可以了解进程对共享内存的使用时间间隔，判断是否存在长时间占用共享内存而不释放的情况；shm_ctime 则可以帮助开发者追踪共享内存的状态变化历史。 shm_cpid 和 shm_lpid：记录了创建共享内存的进程 ID 和最后一次执行 shmat 或 shmdt 操作的进程 ID。这对于调试和管理共享内存的使用非常有用，当出现共享内存相关的问题时，可以通过这些 ID 来追溯问题的源头，查看是哪个进程创建了共享内存，以及最近哪些进程对共享内存进行了连接或分离操作。 shm_nattch：表示当前连接到共享内存的进程数。内核通过这个字段来管理共享内存的生命周期，当 shm_nattch 变为 0 时，并且没有其他进程持有对该共享内存的引用，内核可以考虑回收该共享内存资源。例如，在一个多进程协作的服务器程序中，当所有使用共享内存的进程都完成任务并与共享内存分离后，shm_nattch 变为 0，此时内核可以及时释放共享内存，避免内存资源的浪费。 4.2 映射机制：虚拟内存与物理内存的桥梁 共享内存能够实现高效的进程间通信，关键在于其巧妙的内存映射机制，通过页表将虚拟内存映射到物理内存。\\n在 Linux 系统中，每个进程都有自己独立的虚拟地址空间。当进程创建或连接到共享内存时，操作系统会在进程的虚拟地址空间中分配一段虚拟地址范围，并将这段虚拟地址与共享内存所在的物理内存区域建立映射关系。这个映射关系是通过页表来维护的。\\n页表是一种数据结构，它记录了虚拟页号（VPN，Virtual Page Number）与物理页号（PPN，Physical Page Number）之间的对应关系。当进程访问共享内存中的数据时，CPU 首先会根据当前进程的页表，将虚拟地址中的虚拟页号转换为物理页号，然后再加上页内偏移量，得到实际的物理内存地址，从而访问到共享内存中的数据。\\n例如，假设进程 A 和进程 B 共享一块大小为 4KB 的共享内存。当进程 A 创建共享内存时，操作系统会在物理内存中分配一块 4KB 大小的内存区域，并为这块区域分配一个物理页号。然后，操作系统在进程 A 的页表中创建一个页表项，将虚拟页号与该物理页号关联起来，使得进程 A 可以通过虚拟地址访问这块共享内存。当进程 B 连接到该共享内存时，操作系统同样在进程 B 的页表中创建一个页表项，将其虚拟地址空间中的一段虚拟页号也映射到相同的物理页号上。这样，进程 A 和进程 B 就可以通过各自的虚拟地址访问同一块物理内存区域，实现数据共享。\\n在这个过程中，如果所需的共享内存数据不在物理内存中（例如，由于内存不足，共享内存的部分数据被交换到磁盘上），会发生页面错误（page fault）。此时，操作系统会负责将所需的数据从磁盘读入物理内存，并更新页表，确保进程能够正确访问共享内存。这种动态的内存管理机制使得共享内存能够在有限的物理内存条件下高效运行，同时也保证了进程间通信的稳定性和可靠性。\\nLinux 提供了内存映射函数 mmap, 它把文件内容映射到一段内存上(准确说是虚拟内存上，运行着进程), 通过对这段内存的读取和修改, 实现对文件的读取和修改。mmap()系统调用使得进程之间可以通过映射一个普通的文件实现共享内存。普通文件映射到进程地址空间后，进程可以像访问内存的方式对文件进行访问，不需要其他内核态的系统调用(read,write)去操作。\\n这里是讲设备或者硬盘存储的一块空间映射到物理内存，然后操作这块物理内存就是在操作实际的硬盘空间，不需要经过内核态传递。比如你的硬盘上有一个文件，你可以使用 linux 系统提供的 mmap 接口，将这个文件映射到进程一块虚拟地址空间，这块空间会对应一块物理内存，当你读写这块物理空间的时候，就是在读取实际的磁盘文件，就是这么直接高效。通常诸如共享库的加载都是通过内存映射的方式加载到物理内存的。\\nmmap 系统调用并不完全是为了共享内存来设计的，它本身提供了不同于一般对普通文件的访问的方式，进程可以像读写内存一样对普通文件进行操作，IPC 的共享内存是纯粹为了共享。\\n内存映射指的是将 ：进程中的 1 个虚拟内存区域 \\u0026amp; 1 个磁盘上的对象，使得二者存在映射关系。当然，也可以多个进程同时映射到一个对象上面。\\n实现过程\\n内存映射的实现过程主要是通过 Linux 系统下的系统调用函数：mmap（） 该函数的作用 = 创建虚拟内存区域 + 与共享对象建立映射关系 其函数原型、具体使用 \\u0026amp; 内部流程 如下：\\n/** * 函数原型 */ void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); /** * 具体使用（用户进程调用mmap（）） * 下述代码即常见了一片大小 = MAP_SIZE的接收缓存区 \\u0026amp; 关联到共享对象中（即建立映射） */ mmap(NULL, MAP_SIZE, PROT_READ, MAP_PRIVATE, fd, 0); /** * 内部原理 * 步骤1：创建虚拟内存区域 * 步骤2：实现地址映射关系，即：进程的虚拟地址空间 -\\u0026gt;\\u0026gt; 共享对象 * 注： * a. 此时，该虚拟地址并没有任何数据关联到文件中，仅仅只是建立映射关系 * b. 当其中1个进程对虚拟内存写入数据时，则真正实现了数据的可见 */ 优点\\n进程在读写磁盘的时候，大概的流程是：\\n以 write 为例：进程（用户空间） -\\u0026gt; 系统调用，进入内核 -\\u0026gt; 将要写入的数据从用户空间拷贝到内核空间的缓存区 -\\u0026gt; 调用磁盘驱动 -\\u0026gt; 写在磁盘上面。\\n使用 mmap 之后进程（用户空间）\\u0026ndash;\\u0026gt; 读写映射的内存 \\u0026ndash;\\u0026gt; 写在磁盘上面。 （这样的优点是 避免了频繁的进入内核空间，进行系统调用，提高了效率）\\n(1)mmap 系统调用\\nvoid *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); 这就是 mmap 系统调用的接口，mmap 函数成功返回指向内存区域的指针，失败返回 MAP_FAILED。\\naddr，某个特定的地址作为起始地址，当被设置为 NULL，标识系统自动分配地址。实实在在的物理区域。 length 说的是内存段的长度。 prot 是用来设定内存段的访问权限。 PROT_READ\\t内存段可读 PROT_WRITE\\t内存段可写 PROT_EXEC\\t内存段可执行 PROT_NONE\\t内存段不能被访问 flags 参数控制内存段内容被修改以后程序的行为。\\nMAP_SHARED\\t进程间共享内存，对该内存段修改反映到映射文件中。提供了POSIX共享内存 MAP_PRIVATE\\t内存段为调用进程所私有。对该内存段的修改不会反映到映射文件 MAP_ANNOYMOUS\\t这段内存不是从文件映射而来的。内容被初始化为全0 MAP_FIXED\\t内存段必须位于start参数指定的地址处，start必须是页大小的整数倍（4K整数倍） MAP_HUGETLB\\t按照大内存页面来分配内存空间 fd 参数是用来被映射文件对应的文件描述符，通过 open 系统调用得到，offset 设定从何处进行映射。\\n(2)mmap 用于共享内存的方式\\n我们可以使用普通文件进行提供内存映射，例如，open 系统调用打开一个文件，然后进行 mmap 操作，得到共享内存，这种方式适用于任何进程之间。 可以使用特殊文件进行匿名内存映射，这个相对的是具有血缘关系的进程之间，当父进程调用 mmap，然后进行 fork，这样父进程创建的子进程会继承父进程匿名映射后的地址空间，这样，父子进程之间就可以进行通信了。相当于是 mmap 的返回地址此时是父子进程同时来维护。 另外 POSIX 版本的共享内存底层也是使用了 mmap。所以，共享内存在在 posix 上一定程度上就是指的内存映射了。 五、Mmap 和 System V 共享内存的比较 共享内存：\\n这是 System V 版本的共享内存（以下我们统称为 shm），下面看下 mmap 的：\\nmmap 是在磁盘上建立一个文件，每个进程地址空间中开辟出一块空间进行映射。而 shm 共享内存，每个进程最终会映射到同一块物理内存。shm 保存在物理内存，这样读写的速度肯定要比磁盘要快，但是存储量不是特别大，相对于 shm 来说，mmap 更加简单，调用更加方便，所以这也是大家都喜欢用的原因。\\n另外 mmap 有一个好处是当机器重启，因为 mmap 把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以 mmap 不会丢失，但是 shmget 在内存里面就会丢失，总之，共享内存是在内存中创建空间，每个进程映射到此处。内存映射是创建一个文件，并且映射到每个进程开辟的空间中，但在 posix 中的共享内存就是指这种使用文件的方式“内存映射”。\\n六、POSIX 共享内存 6.1 IPC 机制 共享内存是最快的可用 IPC 形式。它允许多个不相关(无亲缘关系)的进程去访问同一部分逻辑内存。\\n如果需要在两个进程之间传输数据，共享内存将是一种效率极高的解决方案。一旦这样的内存区映射到共享它的进程的地址空间，这些进程间数据的传输就不再涉及内核。这样就可以减少系统调用时间，提高程序效率。\\n共享内存是由 IPC 为一个进程创建的一个特殊的地址范围，它将出现在进程的地址空间中。其他进程可以把同一段共享内存段“连接到”它们自己的地址空间里去。所有进程都可以访问共享内存中的地址。如果一个进程向这段共享内存写了数据，所做的改动会立刻被有访问同一段共享内存的其他进程看到。\\n要注意的是共享内存本身没有提供任何同步功能。也就是说，在第一个进程结束对共享内存的写操作之前，并没有什么自动功能能够预防第二个进程开始对它进行读操作。共享内存的访问同步问题必须由程序员负责。可选的同步方式有互斥锁、条件变量、读写锁、纪录锁、信号灯。\\n实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止。\\n6.2 POSIX 共享内存 API 使用 POSIX 共享内存需要用到下面这些 API：\\n#include \\u0026lt;sys/types.h\\u0026gt; #include \\u0026lt;sys/stat.h\\u0026gt; /* For mode constants */ #include \\u0026lt;sys/mman.h\\u0026gt; #include \\u0026lt;fcntl.h\\u0026gt; /* For O_* constants */ #include \\u0026lt;unistd.h\\u0026gt; int shm_open(const char *name, int oflag, mode_t mode); int shm_unlink(const char *name); int ftruncate(int fildes, off_t length); void *mmap(void *addr, size_t len, int prot, int flags, int fildes, off_t off); int munmap(void *addr, size_t len); int close(int fildes); int fstat(int fildes, struct stat *buf); int fchown(int fildes, uid_t owner, gid_t group); int fchmod(int fildes, mode_t mode); shm_open：穿件并打开一个新的共享内存对象或者打开一个既存的共享内存对象, 与函数 open 的用法是类似的函数返回值是一个文件描述符,会被下面的 API 使用。 ftruncate：设置共享内存对象的大小,新创建的共享内存对象大小为 0。 mmap：将共享内存对象映射到调用进程的虚拟地址空间。 munmap：取消共享内存对象到调用进程的虚拟地址空间的映射。 shm_unlink：删除一个共享内存对象名字。 close：当 shm_open 函数返回的文件描述符不再使用时,使用 close 函数关闭它。 fstat：获得共享内存对象属性的 stat 结构体. 结构体中会包含共享内存对象的大小(st_size), 权限(st_mode), 所有者(st_uid), 归属组 (st_gid)。 fchown：改变一个共享内存对象的所有权。 fchmod：改变一个共享内存对象的权限。 七、共享内存的同步问题 虽然共享内存为进程间通信提供了高效的数据共享方式，但由于多个进程可以同时访问同一块内存区域，这就带来了同步和互斥的问题。如果没有合适的同步机制，可能会出现以下情况：\\n竞态条件（Race Condition）：当多个进程同时访问和修改共享内存中的数据时，由于进程执行的先后顺序不确定，可能导致最终的数据结果不可预测。例如，有两个进程 P1 和 P2 同时读取共享内存中的一个整数变量 count，然后各自对其加 1，最后再写回共享内存。如果没有同步机制，可能会出现 P1 和 P2 读取到相同的 count 值，然后各自加 1 后写回，这样 count 只增加了 1，而不是预期的 2 。 数据不一致性：一个进程正在对共享内存中的数据进行修改时，另一个进程可能同时读取这些未完全修改的数据，从而导致数据不一致。比如，一个进程正在更新共享内存中的一个复杂数据结构，在更新过程中，另一个进程读取该数据结构，可能会读到部分更新的数据，使数据处于不一致的状态，进而导致程序出现错误。 解决方案：信号量与互斥锁的应用\\n为了解决共享内存带来的同步和互斥问题，通常会使用信号量（Semaphore）和互斥锁（Mutex）等同步机制。\\n(1)信号量 ：信号量是一种计数器，用于控制对共享资源的访问。它可以用来实现进程间的同步和互斥。在共享内存的场景中，信号量可以用来控制对共享内存的访问权限。例如，我们可以创建一个信号量，初始值设为 1，表示共享内存资源可用。当一个进程要访问共享内存时，它首先尝试获取信号量（通过对信号量执行 P 操作，即减 1 操作）。如果信号量的值大于等于 0，说明资源可用，进程可以继续执行对共享内存的访问操作；如果信号量的值小于 0，说明资源已被其他进程占用，该进程会被阻塞，直到信号量的值大于等于 0。当进程完成对共享内存的访问后，它会释放信号量（通过对信号量执行 V 操作，即加 1 操作），通知其他进程可以访问共享内存。在 Linux 中，有 POSIX 有名信号量、POSIX 无名信号量和 System V 信号量等不同类型，开发者可以根据具体需求选择使用。例如，使用 POSIX 有名信号量实现共享内存同步的代码示例如下：\\n#include \\u0026lt;stdio.h\\u0026gt; #include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;semaphore.h\\u0026gt; #include \\u0026lt;sys/mman.h\\u0026gt; #include \\u0026lt;fcntl.h\\u0026gt; #include \\u0026lt;unistd.h\\u0026gt; #include \\u0026lt;sys/stat.h\\u0026gt; #define SHM_SIZE 1024 #define SEM_NAME \\u0026quot;/my_semaphore\\u0026quot; int main() { int shm_fd; void *shared_memory; sem_t *sem; // 创建共享内存对象 shm_fd = shm_open(\\u0026quot;/my_shared_memory\\u0026quot;, O_CREAT | O_RDWR, 0666); if (shm_fd == -1) { perror(\\u0026quot;shm_open\\u0026quot;); exit(1); } // 配置共享内存大小 if (ftruncate(shm_fd, SHM_SIZE) == -1) { perror(\\u0026quot;ftruncate\\u0026quot;); exit(1); } // 将共享内存映射到进程地址空间 shared_memory = mmap(0, SHM_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0); if (shared_memory == MAP_FAILED) { perror(\\u0026quot;mmap\\u0026quot;); exit(1); } // 创建信号量 sem = sem_open(SEM_NAME, O_CREAT, 0666, 1); if (sem == SEM_FAILED) { perror(\\u0026quot;sem_open\\u0026quot;); exit(1); } // 等待信号量，获取共享内存访问权限 if (sem_wait(sem) == -1) { perror(\\u0026quot;sem_wait\\u0026quot;); exit(1); } // 访问共享内存 printf(\\u0026quot;Accessed shared memory: %s\\\\n\\u0026quot;, (char *)shared_memory); // 释放信号量，允许其他进程访问共享内存 if (sem_post(sem) == -1) { perror(\\u0026quot;sem_post\\u0026quot;); exit(1); } // 取消映射并关闭共享内存 if (munmap(shared_memory, SHM_SIZE) == -1) { perror(\\u0026quot;munmap\\u0026quot;); exit(1); } if (close(shm_fd) == -1) { perror(\\u0026quot;close\\u0026quot;); exit(1); } // 删除共享内存对象 if (shm_unlink(\\u0026quot;/my_shared_memory\\u0026quot;) == -1) { perror(\\u0026quot;shm_unlink\\u0026quot;); exit(1); } // 关闭并删除信号量 if (sem_close(sem) == -1) { perror(\\u0026quot;sem_close\\u0026quot;); exit(1); } if (sem_unlink(SEM_NAME) == -1) { perror(\\u0026quot;sem_unlink\\u0026quot;); exit(1); } return 0; } (2)互斥锁 ：互斥锁是一种二元信号量，用于保证在同一时刻只有一个进程能够访问共享资源，即实现对共享内存的互斥访问。当一个进程获取到互斥锁后，其他进程如果试图获取该互斥锁，会被阻塞，直到持有互斥锁的进程释放它。在 Linux 中，使用 pthread 库中的互斥锁相关函数来实现互斥锁的操作。例如，初始化互斥锁可以使用 pthread_mutex_init 函数，获取互斥锁使用 pthread_mutex_lock 函数，释放互斥锁使用 pthread_mutex_unlock 函数，销毁互斥锁使用 pthread_mutex_destroy 函数。以下是使用互斥锁实现共享内存同步的简单代码示例：\\n#include \\u0026lt;stdio.h\\u0026gt; #include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;pthread.h\\u0026gt; #include \\u0026lt;sys/mman.h\\u0026gt; #include \\u0026lt;fcntl.h\\u0026gt; #include \\u0026lt;unistd.h\\u0026gt; #include \\u0026lt;sys/stat.h\\u0026gt; #define SHM_SIZE 1024 typedef struct { pthread_mutex_t mutex; char data[SHM_SIZE]; } SharedData; int main() { int shm_fd; SharedData *shared_data; // 创建共享内存对象 shm_fd = shm_open(\\u0026quot;/my_shared_memory\\u0026quot;, O_CREAT | O_RDWR, 0666); if (shm_fd == -1) { perror(\\u0026quot;shm_open\\u0026quot;); exit(1); } // 配置共享内存大小 if (ftruncate(shm_fd, sizeof(SharedData)) == -1) { perror(\\u0026quot;ftruncate\\u0026quot;); exit(1); } // 将共享内存映射到进程地址空间 shared_data = (SharedData *)mmap(0, sizeof(SharedData), PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0); if (shared_data == MAP_FAILED) { perror(\\u0026quot;mmap\\u0026quot;); exit(1); } // 初始化互斥锁 pthread_mutexattr_t attr; pthread_mutexattr_init(\\u0026amp;attr); pthread_mutexattr_setpshared(\\u0026amp;attr, PTHREAD_PROCESS_SHARED); if (pthread_mutex_init(\\u0026amp;shared_data-\\u0026gt;mutex, \\u0026amp;attr) != 0) { perror(\\u0026quot;pthread_mutex_init\\u0026quot;); exit(1); } // 获取互斥锁，访问共享内存 if (pthread_mutex_lock(\\u0026amp;shared_data-\\u0026gt;mutex) != 0) { perror(\\u0026quot;pthread_mutex_lock\\u0026quot;); exit(1); } printf(\\u0026quot;Accessed shared memory: %s\\\\n\\u0026quot;, shared_data-\\u0026gt;data); // 释放互斥锁 if (pthread_mutex_unlock(\\u0026amp;shared_data-\\u0026gt;mutex) != 0) { perror(\\u0026quot;pthread_mutex_unlock\\u0026quot;); exit(1); } // 取消映射并关闭共享内存 if (munmap(shared_data, sizeof(SharedData)) == -1) { perror(\\u0026quot;munmap\\u0026quot;); exit(1); } if (close(shm_fd) == -1) { perror(\\u0026quot;close\\u0026quot;); exit(1); } // 删除共享内存对象 if (shm_unlink(\\u0026quot;/my_shared_memory\\u0026quot;) == -1) { perror(\\u0026quot;shm_unlink\\u0026quot;); exit(1); } return 0; } 通过合理使用信号量和互斥锁等同步机制，可以有效地解决共享内存带来的同步和互斥问题，确保多个进程能够安全、高效地共享内存数据。\\n八、实际应用场景及常见问题解答 8.1 实际应用场景 (1)数据库缓存优化\\n在数据库系统中，共享内存发挥着至关重要的作用，尤其是在缓存优化方面。以 Oracle 数据库为例，它使用共享全局区（SGA，Shared Global Area）来实现共享内存。SGA 是一个共享的内存结构，用于存储数据块、SQL 语句和其他共享信息 。\\n当数据库接收到查询请求时，首先会在共享内存的缓存中查找相关数据。如果数据存在于缓存中，即命中缓存，数据库可以直接从共享内存中读取数据并返回给用户，这大大减少了磁盘 I/O 操作。因为从磁盘读取数据的速度远远低于从内存读取数据的速度，通过共享内存缓存数据，可以显著提高查询性能。例如，在一个高并发的在线交易系统中，大量用户频繁查询订单信息。如果没有共享内存缓存，每次查询都需要从磁盘读取数据，磁盘 I/O 很快就会成为系统的瓶颈，导致查询响应时间变长。而使用共享内存缓存订单数据后，大部分查询可以直接从内存中获取数据，大大提高了系统的响应速度和吞吐量。\\n同时，共享内存还可以减少内存的重复使用，提高内存利用率。多个数据库进程可以共享同一块内存区域，避免了每个进程都单独开辟内存来存储相同的数据，从而节省了内存资源。比如，在一个包含多个数据库实例的系统中，这些实例可以共享 SGA 中的数据缓存，减少了内存的浪费，使得系统能够在有限的内存资源下高效运行。\\n(2)高性能计算中的数据共享\\n在高性能计算领域，共享内存同样有着广泛的应用。在大规模的科学计算和工程模拟中，往往需要处理海量的数据和复杂的计算任务，这些任务通常需要多个处理器核心或多个计算节点协同工作。\\n以分子动力学模拟为例，这是一种用于研究分子系统微观行为的计算方法，需要对大量分子的运动轨迹进行模拟计算。在计算过程中，不同的处理器核心需要共享分子的初始位置、速度等数据，以及模拟过程中的中间结果。通过共享内存，这些数据可以被多个处理器核心直接访问，避免了数据在不同处理器之间通过网络或其他方式传输的开销，提高了计算效率。\\n再比如，在气象预报模型中，需要对全球范围内的气象数据进行分析和预测。这些数据量巨大，计算任务复杂，通常会在分布式计算集群上进行。共享内存可以用于在不同计算节点之间共享气象数据和计算参数，使得各个节点能够协同工作，共同完成气象预报的计算任务。在这种场景下，共享内存不仅提高了数据共享的效率，还减少了节点之间的通信开销，对于提高整个高性能计算系统的性能起着关键作用。\\n7.2 避坑指南与常见问题解答 在使用 Linux 共享内存的过程中，开发者常常会遇到一些棘手的问题，下面我们就来总结一下这些常见问题，并给出相应的解决方案。\\n(1)共享内存创建失败\\n① 问题描述：调用 shmget 函数创建共享内存时，返回值为 -1，导致创建失败。\\n② 可能原因\\n系统资源限制：系统对共享内存的数量和大小有限制，如 SHMMAX（单个共享内存段的最大大小）和 SHMMNI（系统中共享内存段的最大数量）等参数。如果要创建的共享内存超过了这些限制，就会导致创建失败。例如，当系统的 SHMMAX 设置为 32MB，而你尝试创建一个 64MB 的共享内存段时，就会失败。 权限不足：创建共享内存需要适当的权限。如果当前用户没有足够的权限（如在一些安全限制较严格的系统中），shmget 调用也会失败。比如，普通用户在没有特殊权限配置的情况下，无法创建共享内存。 ③ 解决方案\\n检查系统参数：通过 cat /proc/sys/kernel/shmmax 和 cat /proc/sys/kernel/shmmni 等命令查看系统的共享内存参数设置。如果需要，可以通过修改/etc/sysctl.conf 文件来调整这些参数，例如：\\necho \\u0026quot;kernel.shmmax = 2147483648\\u0026quot; \\u0026gt;\\u0026gt; /etc/sysctl.conf sysctl -p 上述命令将 SHMMAX 设置为 2GB，并使其立即生效。\\n④ 确认权限：确保当前用户具有创建共享内存的权限，必要时可以切换到具有足够权限的用户（如 root 用户）来创建共享内存，或者通过修改文件权限和用户组等方式来赋予相应权限。\\n(2)共享内存访问异常\\n① 问题描述：在进程访问共享内存时，出现段错误（Segmentation Fault）或其他访问异常。\\n② 可能原因\\n未正确映射共享内存：调用 shmat 函数时，可能由于参数设置错误，导致共享内存没有正确映射到进程的地址空间。例如，shmat 返回的指针为(void *)-1，表示映射失败，但程序没有正确处理这种情况，仍然尝试使用该指针访问共享内存，就会导致访问异常。 内存越界访问：在对共享内存进行读写操作时，没有正确检查边界条件，导致访问超出了共享内存的范围。比如，共享内存大小为 1024 字节，而程序尝试写入 2048 字节的数据，就会造成内存越界。 同步问题：多个进程同时访问共享内存时，如果没有正确的同步机制（如信号量、互斥锁等），可能会导致数据竞争和访问冲突，进而引发访问异常。例如，一个进程正在修改共享内存中的数据，另一个进程同时读取这些未完全修改的数据，就可能导致数据不一致和访问错误。 ③ 解决方案\\n检查映射结果：在调用 shmat 后，仔细检查返回值。如果返回(void *)-1，则根据 errno 变量的值进行错误处理，例如：\\nvoid *shared_mem = shmat(shmid, NULL, 0); if (shared_mem == (void *)-1) { perror(\\u0026quot;shmat failed\\u0026quot;); exit(EXIT_FAILURE); } 边界检查：在对共享内存进行读写操作时，务必进行严格的边界检查，确保不会越界访问。例如，在写入数据时，要检查数据大小是否超过共享内存的剩余空间；在读取数据时，要确保读取的长度不超过共享内存的有效范围。 完善同步机制：引入合适的同步机制，如使用信号量或互斥锁来确保对共享内存的访问是安全的。在访问共享内存之前，先获取同步锁（如信号量的 P 操作或互斥锁的加锁操作），访问完成后再释放同步锁（如信号量的 V 操作或互斥锁的解锁操作）。 (3)共享内存未及时释放\\n① 问题描述：共享内存不再被使用，但没有被及时删除，导致系统资源浪费。\\n② 可能原因\\n程序逻辑错误：在程序中没有正确处理共享内存的生命周期，例如没有在合适的时机调用 shmctl 函数并传入 IPC_RMID 命令来删除共享内存。 进程异常退出：使用共享内存的进程由于某种原因（如程序崩溃、收到异常信号等）异常退出，而没有来得及执行共享内存的删除操作。 ③ 解决方案\\n优化程序逻辑：在程序设计时，明确共享内存的生命周期，确保在不再需要共享内存时，及时调用 shmctl 函数删除共享内存。例如，在程序结束时，添加如下代码：\\nif (shmctl(shmid, IPC_RMID, NULL) == -1) { perror(\\u0026quot;shmctl IPC_RMID failed\\u0026quot;); exit(EXIT_FAILURE); } 捕获异常信号 ：在进程中捕获常见的异常信号（如 SIGSEGV、SIGABRT 等），在信号处理函数中添加释放共享内存的操作。例如，使用 signal 函数注册信号处理函数：\\n#include \\u0026lt;signal.h\\u0026gt; void cleanup_shared_memory(int signum) { // 释放共享内存相关资源 if (shmctl(shmid, IPC_RMID, NULL) == -1) { perror(\\u0026quot;shmctl IPC_RMID in signal handler failed\\u0026quot;); } exit(EXIT_FAILURE); } int main() { // 注册信号处理函数 signal(SIGSEGV, cleanup_shared_memory); signal(SIGABRT, cleanup_shared_memory); // 其他程序逻辑 } 通过上述方法，可以有效避免共享内存未及时释放的问题，提高系统资源的利用率。\\n‍\\n\"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"网络编程\"]",
      series: [],
      date: "\"2025-05-04\""
    });
  
    searchIndex.push({
      title: "\"Asio 基本使用与核心设计思想 | [转载](https://blog.csdn.net/gma999/article/details/143983035)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/04/17/asio-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%A0%B8%E5%BF%83%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3/\"",
      content: "\"【Boost】Asio 基本使用与核心设计思想_boost::asio-CSDN博客 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 【Boost】Asio 基本使用与核心设计思想_boost::asio-CSDN博客 概述 基本了解\\n主要用于网络编程和底层I/O操作，支持同步异步操作，提供队列各种接口，从而帮助我们快速构建网路哦应用程序，目的就是简化I/O代码，提高性能和可维护性\\n主要特点总结\\n跨平台支持：Boost.Asio 支持 Windows、Linux、Mac OS 等多个操作系统。它封装了底层的 I/O 机制，使得开发者能够无缝地在不同平台之间切换 同步和异步操作：Boost.Asio 提供了同步和异步两种操作模型。在同步模式下，操作会阻塞线程直到完成；在异步模式下，操作会立即返回，并通过回调函数在操作完成时通知应用程序。异步操作通过 io_service 或 io_context 来管理事件和任务调度 支持各种 I/O 类型 网络编程：Boost.Asio 提供了对 TCP 和 UDP 网络编程的支持，可以用来开发高效的服务器和客户端程序 定时器：Boost.Asio 可以设置定时器来在指定的时间点执行操作，广泛应用于定时任务和超时控制。 串行端口：通过 Boost.Asio，开发者还可以进行串行端口的通信操作 不依赖于线程池：Boost.Asio 本身不依赖于线程池，它使用 io_service（在新版中为 io_context）来调度异步操作。开发者可以灵活地决定如何管理线程池，或者在单线程模式下使用 核心概念\\no_service / io_context：io_service（在新版本中为 io_context）是 Boost.Asio 的核心组件，负责管理和调度所有异步操作。通过 io_service，可以注册异步操作，并在操作完成时通过回调函数得到通知\\n异步操作：Boost.Asio 提供的异步操作模型基于回调函数。开发者可以通过 async_ 系列函数（如 async_read、async_write 等）启动异步操作。这些操作不会阻塞线程，而是将操作提交给 io_service，并在操作完成时执行回调\\n套接字（Socket）：Boost.Asio 提供了对 TCP 和 UDP 套接字的支持。TCP 套接字（tcp::socket）用于建立面向连接的通信，UDP 套接字（udp::socket）则用于无连接的通信。开发者可以通过这些类实现网络通信功能\\n常用接口与应用 boost::asio::io_context 主要作用\\n主要作用就是调用异步操作和处理这些操作的核心函数，内部提供了事件循环机制\\n调度异步任务：io_context 是一个任务队列，可以调度和执行异步任务。所有异步操作都需要绑定到一个io_context 对象 事件循环：io_context 提供事件循环（通过 run() 方法），用于不断检查和执行任务队列中的任务 线程安全：可以被多个线程共享，使得多个线程可以并发地处理同一个 io_context 上的任务 同步与异步支持：它既支持异步任务，也可以在事件循环内执行同步任务 常用方法总结\\nrun() 启动事件循环，处理所有挂起的任务，直到任务队列清空为止 run_one() 处理任务队列中的一个任务，然后立即返回 poll() 非阻塞地处理任务队列中的所有任务。如果任务队列为空，则立即返回 poll_one() 非阻塞地处理一个任务。如果任务队列中没有任务，则立即返回 stop() 停止事件循环。run() 方法会尽快返回，但不会清空未处理的任务队列 reset() 重置事件循环的状态，使得可以再次调用 run() 或 poll() 方法。通常在调用 stop() 后使用 get_executor() 获取与当前 io_context 关联的执行器（executor） post(handler) 将一个任务添加到任务队列。任务是通过 handler 函数对象定义的 dispatch(handler) 如果可能的话，立即在当前线程中执行任务；否则，将其添加到任务队列中 work_guard（类） 用于确保 io_context 不会因为任务队列为空而自动退出。它能够保持事件循环处于活跃状态 使用步骤总结\\n创建 io_context 对象 为异步操作或回调绑定 io_context 调用 run() 或其他事件循环方法启动 io_context 单任务循环 #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; int main() { // 创建 io_context 对象 boost::asio::io_context io_context; // 提交一个简单任务到 io_context io_context.post([]() { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Hello, Boost.Asio!\\u0026quot; \\u0026lt;\\u0026lt; std::endl; }); // 启动事件循环 io_context.run(); return 0; } 多任务调度 int main() { boost::asio::io_context io_context; io_context.post([](){ std::cout\\u0026lt;\\u0026lt;\\u0026quot;Hello,Boost.Asio\\u0026quot;\\u0026lt;\\u0026lt;std::endl; }); io_context.post([]() { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Task 1\\u0026quot; \\u0026lt;\\u0026lt; std::endl; }); io_context.post([]() { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Task 2\\u0026quot; \\u0026lt;\\u0026lt; std::endl; }); io_context.post([]() { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Task 3\\u0026quot; \\u0026lt;\\u0026lt; std::endl; }); io_context.run(); return 0; } 多线程共享一个io_context对象，实现并发处理\\n#include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; #include \\u0026lt;thread\\u0026gt; void worker(boost::asio::io_context\\u0026amp; io_context, int id) { io_context.run(); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Thread \\u0026quot; \\u0026lt;\\u0026lt; id \\u0026lt;\\u0026lt; \\u0026quot; finished.\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } int main() { boost::asio::io_context io_context; // 提交任务 for (int i = 0; i \\u0026lt; 10; ++i) { io_context.post([i]() { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Task \\u0026quot; \\u0026lt;\\u0026lt; i \\u0026lt;\\u0026lt; \\u0026quot; is running\\u0026quot; \\u0026lt;\\u0026lt; std::endl; }); } // 创建线程池 std::vector\\u0026lt;std::thread\\u0026gt; threads; for (int i = 0; i \\u0026lt; 4; ++i) { threads.emplace_back(worker, std::ref(io_context), i); } // 等待所有线程完成 for (auto\\u0026amp; t : threads) { t.join(); } return 0; } boost::asio::ip::tcp::socket 处理 TCP 连接的类，用于发送和接收数据。它支持异步操作，可以在后台完成网络通信任务，而不会阻塞主线程\\n主要功能\\n连接到服务器或监听来自客户端的连接 发送和接收数据 支持异步操作，如 async_read(), async_write()，可以通过回调处理结果 常用方法\\n构造函数\\ntcp::socket(io_context) 创建一个未绑定的 TCP 套接字，需通过后续操作指定使用目标 tcp::socket(io_context, endpoint) 创建并绑定到指定端点的 TCP 套接字 tcp::socket(io_context, protocol) 使用指定协议（如 IPv4 或 IPv6）初始化一个 TCP 套接字 成员函数\\nconnect(endpoint) 同步连接到指定的远程端点，阻塞直到连接完成 async_connect(endpoint, handler) 异步连接到远程端点，完成时调用指定的处理函数 handler read_some(buffer) 从套接字同步读取数据到缓冲区，返回读取的字节数 async_read_some(buffer, handler) 异步读取数据到缓冲区，完成时调用处理函数 handler write_some(buffer) 从缓冲区同步写入数据到套接字，返回写入的字节数 async_write_some(buffer, handler) 异步写入数据到套接字，完成时调用处理函数 handler close() 关闭套接字以释放资源 is_open() 检查套接字是否处于打开状态 cancel() 取消挂起的异步操作，操作结果将通过处理函数返回 remote_endpoint() 获取远程连接的 IP 和端口信息 local_endpoint() 获取本地绑定的 IP 和端口信息 使用步骤\\n创建和初始化 tcp::socket 对象： 通过绑定 io_context 来初始化套接字 连接远程端点（客户端）或接受连接（服务器）： 使用 connect() 或 accept() 建立连接 发送和接收数据： 使用 read()、write()（同步）或 async_read()、async_write()（异步） 关闭套接字： 通过 close() 方法关闭套接字 同步TCP客户端与服务端搭建 // ///TCP同步客户端 // int main() { try { // 创建 io_context 和 socket boost::asio::io_context io_context; boost::asio::ip::tcp::socket socket(io_context); // 定义远程端点（IP 和端口） boost::asio::ip::tcp::endpoint endpoint( boost::asio::ip::address::from_string(\\u0026quot;127.0.0.1\\u0026quot;), 8080); // 连接到服务器 socket.connect(endpoint); // 发送数据到服务器 std::string message = \\u0026quot;Hello, Server!\\u0026quot;; boost::asio::write(socket, boost::asio::buffer(message)); // 接收服务器响应 char buffer[128]; size_t len = socket.read_some(boost::asio::buffer(buffer)); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Server response: \\u0026quot; \\u0026lt;\\u0026lt; std::string(buffer, len) \\u0026lt;\\u0026lt; std::endl; // 关闭连接 socket.close(); } catch (const std::exception\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } // ///TCP同步服务器 // int main() { try { boost::asio::io_context io_context; // 创建监听器 boost::asio::ip::tcp::acceptor acceptor( io_context, boost::asio::ip::tcp::endpoint(boost::asio::ip::tcp::v4(), 8080)); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Server is running on port 8080...\\u0026quot; \\u0026lt;\\u0026lt; std::endl; // 接受客户端连接 boost::asio::ip::tcp::socket socket(io_context); acceptor.accept(socket); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Client connected: \\u0026quot; \\u0026lt;\\u0026lt; socket.remote_endpoint() \\u0026lt;\\u0026lt; std::endl; // 接收客户端数据 char buffer[128]; size_t len = socket.read_some(boost::asio::buffer(buffer)); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Received: \\u0026quot; \\u0026lt;\\u0026lt; std::string(buffer, len) \\u0026lt;\\u0026lt; std::endl; // 发送响应 std::string response = \\u0026quot;Hello, Client!\\u0026quot;; boost::asio::write(socket, boost::asio::buffer(response)); // 关闭连接 socket.close(); } catch (const std::exception\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } 异步TCP客户端与服务端搭建 // ///TCP异步服务器 // void on_accept(const boost::system::error_code\\u0026amp; ec, boost::asio::ip::tcp::socket socket) { if (!ec) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Client connected: \\u0026quot; \\u0026lt;\\u0026lt; socket.remote_endpoint() \\u0026lt;\\u0026lt; std::endl; // 异步读取数据 auto buffer = std::make_shared\\u0026lt;std::vector\\u0026lt;char\\u0026gt;\\u0026gt;(128); socket.async_read_some(boost::asio::buffer(*buffer), [buffer](const boost::system::error_code\\u0026amp; ec, std::size_t length) { if (!ec) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Received: \\u0026quot; \\u0026lt;\\u0026lt; std::string(buffer-\\u0026gt;data(), length) \\u0026lt;\\u0026lt; std::endl; } }); } else { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Accept failed: \\u0026quot; \\u0026lt;\\u0026lt; ec.message() \\u0026lt;\\u0026lt; std::endl; } } int main() { boost::asio::io_context io_context; // 创建监听器 boost::asio::ip::tcp::acceptor acceptor( io_context, boost::asio::ip::tcp::endpoint(boost::asio::ip::tcp::v4(), 8080)); // 异步接受连接 acceptor.async_accept( [\\u0026amp;acceptor](const boost::system::error_code\\u0026amp; ec, boost::asio::ip::tcp::socket socket) { on_accept(ec, std::move(socket)); }); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Server is running on port 8080...\\u0026quot; \\u0026lt;\\u0026lt; std::endl; // 启动事件循环 io_context.run(); return 0; } // ///TCP异步步客户端 // void on_connect(const boost::system::error_code\\u0026amp; ec) { if (!ec) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Connected to server!\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } else { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Failed to connect: \\u0026quot; \\u0026lt;\\u0026lt; ec.message() \\u0026lt;\\u0026lt; std::endl; } } int main() { boost::asio::io_context io_context; boost::asio::ip::tcp::socket socket(io_context); // 定义远程端点 boost::asio::ip::tcp::endpoint endpoint( boost::asio::ip::address::from_string(\\u0026quot;127.0.0.1\\u0026quot;), 8080); // 异步连接 socket.async_connect(endpoint, on_connect); // 运行事件循环 io_context.run(); return 0; } boost::asio::ip::tcp::acceptor acceptor 类用于监听进入的 TCP 连接。它用于接受客户端发起的连接，并为每个连接创建一个新的 socket 实例\\n主要功能\\n监听端口，等待客户端连接 一旦有客户端连接成功，创建一个新的 socket 来处理与客户端的通信 构造函数\\nio_context：参考上文 endpoint：绑定的端点，一般是服务器的IP和端口号 boost::asio::ip::tcp::acceptor(io_context, const endpoint\\u0026amp;); // 使用事例 boost::asio::io_context io_context; boost::asio::ip::tcp::endpoint endpoint(boost::asio::ip::tcp::v4(), 8080); boost::asio::ip::tcp::acceptor acceptor(io_context, endpoint); accept（socket）：接收一个客户端连接请求，该方法是阻塞的直到客户端连接成功\\nsocket：接收客户端连接的 boost::asio::ip::tcp::socket 实例。成功连接后，socket 会被自动填充为新的连接 ：无返回值。如果连接成功，socket 已经准备好与客户端进行通信 boost::asio::ip::tcp::socket socket(io_context); acceptor.accept(socket); // 阻塞，直到有客户端连接 async_accept(socket , handler）\\n异步接收客户端的连接请求，调用的时候不会阻塞，接受连接的操作在后台执行，操作完成后的会调用handler函数 参数：一个Socket对象一个handle回调函数 boost::asio::ip::tcp::socket socket(io_context); acceptor.async_accept(socket, [](const boost::system::error_code\\u0026amp; ec) { if (!ec) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Client connected successfully!\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } else { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; ec.message() \\u0026lt;\\u0026lt; std::endl; } }); io_context.run(); // 运行事件循环，处理异步操作 local_endpoint()\\n获取acceptor绑定的本地端点 返回一个boost::asio::ip::tcp::endpoint ，表示绑定到服务器的IP地址和端口 boost::asio::ip::tcp::endpoint local_endpoint = acceptor.local_endpoint(); std::cout \\u0026lt;\\u0026lt; \\u0026quot;Server is listening on \\u0026quot; \\u0026lt;\\u0026lt; local_endpoint \\u0026lt;\\u0026lt; std::endl; close（）\\n关闭acceptor，停止监听新连接，一般是在应用程序退出的时候调用，释放资源 具体使用参考同步与异步服务器搭建\\nboost::asio::deadline_timer / steady_timer 这两个类是用于异步编程中的定时操作类，主要用于设置延时操作\\ndeadline_timer 是基于绝对时间的定时器，适用于在某一指定时刻执行操作 steady_timer 是基于相对时间的定时器，适用于相对延迟 主要功能\\n异步定时操作 定时器过期时，调用指定的回调函数 deadline_timer（基于绝对时间） 构造函数\\nptime：定时器到期的绝对时间点 time_duration：从当前时间开始，持续时间 boost::asio::deadline_timer(io_context, const boost::posix_time::ptime\\u0026amp;); boost::asio::deadline_timer(io_context, const boost::posix_time::time_duration\\u0026amp;); 常用方法\\nasync_wait(handler)：异步等待定时器到期，handler是定时器到期时候的回调函数 expires_at(ptime)：设置定时器的到期时间为指定的绝对时间点 expires_from_now(time_duration)：设置定时器到期时间为相对时间 cancel()：取消定时器 具体使用\\n定时器1 #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;boost/date_time/posix_time/posix_time.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; void handler(const boost::system::error_code\\u0026amp; /*ec*/) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Deadline timer expired!\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } int main() { try { boost::asio::io_context io_context; // 设置绝对到期时间（5秒后） boost::asio::deadline_timer timer(io_context, boost::posix_time::seconds(5)); // 异步等待定时器到期 timer.async_wait(handler); // 启动事件循环 io_context.run(); } catch (const std::exception\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } steady_timer（相对时间） 相对时间也就是到期时间是从当前时间开始的延迟\\n构造函数\\nboost::asio::steady_timer(io_context, const boost::chrono::steady_clock::duration\\u0026amp;); 常用方法\\nasync_wait(handler)：异步等待到期后调用handler回调函数 expires_after(duration)：设置定时器的到期时间为从当前时间开始的相对时间 cancel()：取消定时器 #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; void handler(const boost::system::error_code\\u0026amp; /*ec*/) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Steady timer expired!\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } int main() { try { boost::asio::io_context io_context; // 设置相对到期时间（5秒后） boost::asio::steady_timer timer(io_context, boost::asio::chrono::seconds(5)); // 异步等待定时器到期 timer.async_wait(handler); // 启动事件循环 io_context.run(); } catch (const std::exception\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } boost::asio::ip::tcp::resolver resolver 是用来解析主机名和服务名的类。它将域名解析为具体的 IP 地址，用于建立连接\\n主要功能\\n解析主机名或 IP 地址，返回可以用于连接的端点（endpoint） 异步解析支持，通过 async_resolve() 实现 主要功能\\n解析主机名和服务名：resolver可以将主机名或者服务名解析成为一个或者多个IP地址和端口对 支持同步和异步两种操作 返回endpoint列表，返回一个boost::asio::ip::tcp::resolver::results_type类型的对象，其可以解析一个或者多个endpoint，这些endpoint直接用于建立连接 构造函数\\nboost::asio::ip::tcp::resolver(io_context); 常用方法\\nresolve(const std::string\\u0026amp; host, const std::string\\u0026amp; service)：指定主机名和服务名然后返回一个endpoint列表 async_resolve(const std::string\\u0026amp; host, const std::string\\u0026amp; service, handler)：异步解析 同步解析 int main() { try { boost::asio::io_context io_context; // 创建一个 resolver 对象 boost::asio::ip::tcp::resolver resolver(io_context); // 同步解析主机名和服务名 auto endpoints = resolver.resolve(\\u0026quot;example.com\\u0026quot;, \\u0026quot;http\\u0026quot;); for (const auto\\u0026amp; endpoint : endpoints) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Resolved endpoint: \\u0026quot; \\u0026lt;\\u0026lt; endpoint.endpoint() \\u0026lt;\\u0026lt; std::endl; } } catch (const boost::system::system_error\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } 异步解析 void on_resolve(const boost::system::error_code\\u0026amp; ec, boost::asio::ip::tcp::resolver::results_type endpoints) { if (!ec) { for (const auto\\u0026amp; endpoint : endpoints) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Resolved endpoint: \\u0026quot; \\u0026lt;\\u0026lt; endpoint.endpoint() \\u0026lt;\\u0026lt; std::endl; } } else { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Resolve failed: \\u0026quot; \\u0026lt;\\u0026lt; ec.message() \\u0026lt;\\u0026lt; std::endl; } } int main() { try { boost::asio::io_context io_context; // 创建 resolver 对象 boost::asio::ip::tcp::resolver resolver(io_context); // 异步解析主机名和服务名 resolver.async_resolve(\\u0026quot;example.com\\u0026quot;, \\u0026quot;http\\u0026quot;, on_resolve); // 启动事件循环，等待解析完成 io_context.run(); } catch (const boost::system::system_error\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } boost::asio::buffer / mutable_buffer buffer 是 Boost.Asio 中用于封装数据块的类。它用于表示读写操作的数据区，支持多种数据类型（如数组、std::vector、std::string）\\n主要功能\\n用于缓冲区管理，通常用于传递给异步读写操作 mutable_buffer 用于可以修改的数据缓冲区，const_buffer 用于只读缓冲区 Buffer 创建使用\\n该函数将数据容器封装成一个缓冲区对象 通过该接口可以将容器包装成一个可以传递给异步读写操作的缓冲区对象 支持的数据类型 oost::asio::buffer(my_array)数组类型 vector 、 string、array #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;vector\\u0026gt; #include \\u0026lt;iostream\\u0026gt; int main() { std::vector\\u0026lt;char\\u0026gt; data(128); // 创建一个存储 128 字节的 vector boost::asio::buffer(data); // 使用 boost::asio::buffer() 创建一个缓冲区 std::cout \\u0026lt;\\u0026lt; \\u0026quot;Buffer size: \\u0026quot; \\u0026lt;\\u0026lt; data.size() \\u0026lt;\\u0026lt; std::endl; return 0; } mutable_buffer 表示一个可修改的数据缓冲区，表示可以修改缓冲区的数据，异步操作中一般用于读取缓冲区数据或者发送数据\\n构造函数\\ndata：指向数据存储区域的指针 size：缓冲区的大小，字节为单位 boost::asio::mutable_buffer buffer(void* data, std::size_t size); 测试\\nint main() { std::vector\\u0026lt;char\\u0026gt; data(128); // 创建一个存储 128 字节的 vector boost::asio::mutable_buffer buffer(data.data(), data.size()); // 创建一个可修改的缓冲区 std::cout \\u0026lt;\\u0026lt; \\u0026quot;Mutable buffer size: \\u0026quot; \\u0026lt;\\u0026lt; buffer.size() \\u0026lt;\\u0026lt; std::endl; return 0; } boost::asio::streambuf streambuf 是一个内存缓冲区类，提供了一个流接口来读写数据。它常用于处理异步读取的数据\\n主要功能\\n为流式输入/输出提供一个缓冲区 适用于处理流数据，如 HTTP 请求/响应、网络协议等 构造函数\\n通过默认构造函数创建一个空的缓冲区，可以通过异步读写操作将数据存入或者从中读取 boost::asio::streambuf buf; // 创建一个空的 streambuf 对象 常用方法\\n获取或写入缓冲区数据：通过data()获取数据区域，consume()方法从缓冲区中消费数据 streambuf对象的转换为boost::asio::mutable_buffer或者boost::asio::const_buffer，然后进行读写操作 std::istream和std::ostream构造函数接收streambuf对象，然后就可以像标准流一样读写或者写入数据 异步读取数据 #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; void read_handler(const boost::system::error_code\\u0026amp; ec, std::size_t bytes_transferred) { if (!ec) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Successfully read \\u0026quot; \\u0026lt;\\u0026lt; bytes_transferred \\u0026lt;\\u0026lt; \\u0026quot; bytes.\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } else { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error during read: \\u0026quot; \\u0026lt;\\u0026lt; ec.message() \\u0026lt;\\u0026lt; std::endl; } } int main() { try { boost::asio::io_context io_context; boost::asio::ip::tcp::socket socket(io_context); boost::asio::ip::tcp::resolver resolver(io_context); auto endpoints = resolver.resolve(\\u0026quot;example.com\\u0026quot;, \\u0026quot;http\\u0026quot;); // 连接到服务器 boost::asio::connect(socket, endpoints); boost::asio::streambuf buf; // 创建一个 streambuf 对象 boost::asio::async_read(socket, buf, read_handler); // 异步读取数据到 streambuf 中 io_context.run(); // 启动事件循环 } catch (const boost::system::system_error\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } 异步写入数据 #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; void write_handler(const boost::system::error_code\\u0026amp; ec, std::size_t bytes_transferred) { if (!ec) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Successfully sent \\u0026quot; \\u0026lt;\\u0026lt; bytes_transferred \\u0026lt;\\u0026lt; \\u0026quot; bytes.\\u0026quot; \\u0026lt;\\u0026lt; std::endl; } else { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error during write: \\u0026quot; \\u0026lt;\\u0026lt; ec.message() \\u0026lt;\\u0026lt; std::endl; } } int main() { try { boost::asio::io_context io_context; boost::asio::ip::tcp::socket socket(io_context); boost::asio::ip::tcp::resolver resolver(io_context); auto endpoints = resolver.resolve(\\u0026quot;example.com\\u0026quot;, \\u0026quot;http\\u0026quot;); // 连接到服务器 boost::asio::connect(socket, endpoints); // 将数据放入 streambuf boost::asio::streambuf buf; std::ostream os(\\u0026amp;buf); os \\u0026lt;\\u0026lt; \\u0026quot;GET / HTTP/1.1\\\\r\\\\nHost: example.com\\\\r\\\\n\\\\r\\\\n\\u0026quot;; // 向 buf 中写入 HTTP 请求 // 异步写入数据 boost::asio::async_write(socket, buf, write_handler); io_context.run(); // 启动事件循环 } catch (const boost::system::system_error\\u0026amp; e) { std::cerr \\u0026lt;\\u0026lt; \\u0026quot;Error: \\u0026quot; \\u0026lt;\\u0026lt; e.what() \\u0026lt;\\u0026lt; std::endl; } return 0; } boost::asio::async_read() / write() 这两个函数用于异步地从 socket 读取数据或写入数据。它们支持回调机制，在操作完成时调用指定的回调函数\\n主要功能\\n异步读写操作，避免阻塞主线程 支持传输数据（如字符串、文件等） 接口在前面的事例中已经被广泛使用\\nboost::asio::async_read(socket, boost::asio::buffer(data), handler); // 异步读取数据 boost::asio::async_write(socket, boost::asio::buffer(data), handler); // 异步写入数据 boost::asio::connect() / async_connect() connect 用于同步连接到远程主机，而 async_connect 用于异步连接，后者更常用于高性能网络编程\\n主要功能\\n用于客户端连接远程服务器。 async_connect 支持异步连接，在连接成功后调用回调函数 boost::asio::async_connect(socket, endpoints, handler); boost::asio::post() post 是一个简单的异步任务调度器，它将任务投递到 io_context 中，任务会在 io_context.run() 循环中执行\\n主要功能\\n在事件循环中调度任务执行，类似于线程池的任务调度\\nboost::asio::post(io_context, [](){ std::cout \\u0026lt;\\u0026lt; \\u0026quot;Hello, Asio!\\u0026quot; \\u0026lt;\\u0026lt; std::endl; }); boost::asio::strand strand 是 Boost.Asio 中用于处理线程安全问题的类。在多线程环境中，它确保多个异步操作的回调函数不会同时执行，从而避免数据竞争和不一致性\\n主要功能\\n提供线程安全的任务执行模型 确保同一 strand 中的回调函数按顺序执行 使用strand可以避免在多线程环境中出现数据竞争或者死锁，尤其是在需要访问共享资源的时候 构造函数\\nio_context.get_executor()提供了io_context的执行器，定义了strand中的任务执行上下文 boost::asio::strand\\u0026lt;boost::asio::io_context::executor_type\\u0026gt; strand(io_context.get_executor()); boost::asio::post(strand, handler)\\n使用strand提交一个回调函数，然后strand会确保这些回调函数按照顺序执行 boost::asio::post(strand, handler); // 保证 handler 按顺序执行 strand 和 async_*\\nboost::asio::async_read(socket, buffer, strand.wrap(handler)); // wrap 使回调函数按顺序执行 strand保证回调顺序 /// ///strand 保证回调顺序 /// void handler(int id) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Handler \\u0026quot; \\u0026lt;\\u0026lt; id \\u0026lt;\\u0026lt; \\u0026quot; executed in thread: \\u0026quot; \\u0026lt;\\u0026lt; std::this_thread::get_id() \\u0026lt;\\u0026lt; std::endl; } int main() { boost::asio::io_context io_context; boost::asio::strand\\u0026lt;boost::asio::io_context::executor_type\\u0026gt; strand(io_context.get_executor()); // 提交多个任务到同一个 strand，确保它们按顺序执行 boost::asio::post(strand, std::bind(handler, 1)); // 提交任务1 boost::asio::post(strand, std::bind(handler, 2)); // 提交任务2 boost::asio::post(strand, std::bind(handler, 3)); // 提交任务3 // 在多线程环境中运行 io_context std::thread t1([\\u0026amp;io_context](){ io_context.run(); }); std::thread t2([\\u0026amp;io_context](){ io_context.run(); }); t1.join(); t2.join(); return 0; } strand.wrap()\\n将异步操作的回调函数打包在一起，从而保证回调函数在同一strand中按照顺序执行，主要是在多线程中使用\\nboost::asio::async_read(socket, buffer, strand.wrap(handler)); strand.wrap() 保证顺序执行 #include \\u0026lt;boost/asio.hpp\\u0026gt; #include \\u0026lt;iostream\\u0026gt; #include \\u0026lt;thread\\u0026gt; void handler(int id) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;Handler \\u0026quot; \\u0026lt;\\u0026lt; id \\u0026lt;\\u0026lt; \\u0026quot; executed in thread: \\u0026quot; \\u0026lt;\\u0026lt; std::this_thread::get_id() \\u0026lt;\\u0026lt; std::endl; } int main() { boost::asio::io_context io_context; boost::asio::strand\\u0026lt;boost::asio::io_context::executor_type\\u0026gt; strand(io_context.get_executor()); // 提交多个任务到同一个 strand，确保它们按顺序执行 boost::asio::async_read_some(socket, buffer, strand.wrap(std::bind(handler, 1))); boost::asio::async_read_some(socket, buffer, strand.wrap(std::bind(handler, 2))); boost::asio::async_read_some(socket, buffer, strand.wrap(std::bind(handler, 3))); // 在多线程环境中运行 io_context std::thread t1([\\u0026amp;io_context](){ io_context.run(); }); std::thread t2([\\u0026amp;io_context](){ io_context.run(); }); t1.join(); t2.join(); return 0; } 核心设计思想 异步模型与事件循环机制 整体逻辑\\n当调用一个异步操作的时候，io_service会启动事件循环\\n提交异步操作 进入事件循环，不断监视异步操作的状态，直到其完成 回调通知，如果操作完成，会调用其预先注册的好的回调函数 继续执行其他任务 内部实现结合具体方法\\npost() 和 dispatch()\\npost方法就是将任务投递到任务队列，任务不会打断线程，而是会在队列中等待执行 dispath(）方法则是提交给当前线程立即执行，不会将任务放到队列中，而是直接在当前线程中执行 io_service/io_context\\nrun()方法：会将程序进入循环，开始调度和执行已经提交的异步操作 io_serive：则可以将回调函数添加到任务队列中，等待线程进行处理 多线程与事件循环机制结合\\n多核机器上通过多核线程可以提高运行性能，多线程设计的核心之一就是确保其互相不会打扰，高效的执行异步任务，所以通过循环机制和任务队列。该处的核心思想可以参考modou网络库的设计思想\\n多路复用机制 asio中对于多路复用机制的使用在于确保在I/O操作时及时触发回调函数，不需要为每一个I/O操作都创建新的线程\\nstrand设计\\nasio设计stand机制的核心目的就是保证异步编程中回调函数的顺序性，避免多个回调函数并发执行时的竞态条件。因为多线程环境中，多个异步操作的回调可能会在不同的线程中并发执行，那么就有可能造成数据不一致或者竞争情况\\nstrand的核心作用就是让异步操作放入一个队列中，然后让其排队，从而确保同一strand中的回调函数按顺序执行，这样即使多个回调函数在被不同线程执行的时候，也不会出现竞态条件\\n核心特点：通过队列确保顺序性；通过事件循环机制执行任务，从而减少了锁的开销\\n拓展1：设计高效I/O复用机制，减少阻塞和提高吞吐量的思路\\n非阻塞 I/O： 采用非阻塞 I/O 操作，避免线程被阻塞，浪费计算资源。当某个文件描述符或套接字准备好进行 I/O 操作时，才通知事件循环来处理 事件通知机制： 在高并发环境中，尽量使用高效的事件通知机制 线程池： 如果 I/O 操作涉及复杂的计算，可以使用线程池来处理。通过将计算密集型任务从主线程中分离出来，避免阻塞事件循环，从而提升系统的并发性 事件循环设计： 确保事件循环高效执行，可以通过优化任务调度、减少空转等待等方式提高事件循环的吞吐量。要避免将阻塞的操作放入事件循环中，避免影响其他异步任务的执行 批量操作和分片： 对于大量的 I/O 操作，可以将它们合并为批量操作，减少每次 I/O 操作的开销，提升整体吞吐量。另外，拆分大任务为多个小任务也能提高并发执行效率 其他设计思想 之前学习modou网络库中接触并总结过这些思想，所以此处省略\\n**内存缓冲区机制：**预先设置一块缓冲区，从而减少内存分配从而提高内存利用率 **定时器与异步事件调度：**其中核心思想就是时间轮的设计 **回调函数与生命周期管理：**通过智能指针以及绑定到连接从而控制其生命周期 \"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"asio\"]",
      series: "[\"网络编程\"]",
      date: "\"2025-04-17\""
    });
  
    searchIndex.push({
      title: "\"GoogleTest与gMock进阶指南 | [转载](https://www.cnblogs.com/jinyunshaobing/p/16804309.html)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/04/16/googletest%E4%B8%8Egmock%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97/\"",
      content: "\"【C++】GoogleTest 入门指南 - 缙云烧饼 - 博客园 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 【C++】GoogleTest 入门指南 参考：\\nGoogleTest 官网 基本概念 要使用 GoogleTest，需要包含 header gtest/gtest.h\\n断言 Assertions # 断言是检查条件是否为真的语句，其结果可能是成功或失败，失败分为非致命失败和致命失败两种，后者会终止当前运行，前者则会继续运行。\\nGoogleTest 中，断言类似于函数调用的宏，断言失败时，GoogleTest 会输出断言的源文件和行号位置以及失败消息（所有断言都可以使用\\u0026laquo;输出自定义失败消息）\\nASSERT_* # 会抛出致命失败故障的断言，断言失败时中止当前测试函数的运行（不是中断整个 TEST）。\\nASSERT_EQ(x.size(),y.size()) \\u0026quot;x与y的大小不相同\\u0026quot; EXPECT_* # 会抛出非致命失败故障的断言，不会停止当前函数运行，而是继续往下运行下去\\nEXPECT_EQ(x,y) \\u0026quot;x与y不相等\\u0026quot; 断言分类 # 前缀都会是 ASSERT_或者 EXPECT_,它们的区别上面已经进行了说明，所以以下都用 X_来略写\\n基本断言 # X_TRUE(condition)：断言 condition 为 True X_FALSE(condition)：断言 condition 为 False 普通比较型断言 # X_EQ(v1,v2)：== X_NE(v1,v2)：!= X_LT(v1,v2)：\\u0026lt; X_LE(v1,v2)：\\u0026lt;= X_GT(v1,v2)：\\u0026gt; X_GE(v1,v2)：\\u0026gt;= C 字符串比较型断言 # X_STREQ(s1,s2)：s1==s2 X_STRNE(s1,s2)：s1!=s2 X_STRCASEEQ(s1,s2)：忽略大小写，s1==s2 X_STRCASENE(s1,s2)：忽略大小写，s1!=s2 注意： Null 指针和空字符\\u0026quot;\\u0026ldquo;是不相同的 假如 char *s1 = \\u0026ldquo;abc\\u0026rdquo;，char *s2 = \\u0026ldquo;abc\\u0026rdquo;，那么 X_EQ(s1,s2)不通过，因为 s1 与 s2 实际上是地址指针，不相同;X_STREQ(s1,s2)通过，因为字符串相同 浮点数比较型断言 # 对于浮点数，断言只是判断几乎相等\\nX_FLOAT_EQ(f1,f2)：f1 和 f2 两个 float 值几乎相等 X_DOUBLE_EQ(f1,f2)：f1 和 f2 两个 double 值几乎相等 X_NEAR(v1,v2,abs_error)：v1 和 v2 两个浮点数的值差的绝对值不超过 abs_error 明确的成功与失败 # SUCCEED()：生成一个成功，放行，但是并不代表整个测试成功 FAIL()：生成致命错误，立即终止当前测试 ADD_FAILURE()：生成非致命错误，继续运行测试 ADD_FAILURE_AT(\\u0026ldquo;file_path\\u0026rdquo;,line_number)：生成非致命错误，输出文件名和行号 GTEST_SKIP()：直接结束当前测试 明确的成功与失败相较于前面的断言更适合判断条件复杂的情况，因为判断条件复杂不适合写成一个表达式 condition 用于判断。例如if...else if...else if... else... 异常断言 # 用于验证一段代码是否抛出给定类型的异常\\nX_THROW(statement,exception_type)：statement 代码会抛出 exception_type 的异常 X_ANY_THROW(statement)：statement 代码会抛出异常，不限异常类型 X_NO_THROW(statement)：statement 代码不会抛出任何类型异常 自定义布尔函数断言（谓词断言） # X_PREDn(fun,v1,v2\\u0026hellip;)：拥有 n 个参数的函数 fun 会返回 True 例如有一个函数 equal(a,b)，那么就是 ASSERT_PRED2(equal,a,b) 与 ASSERT_EQ、ASSERT_TRUE()这些断言的区别在于输出的错误信息不同，同时它的功能更加强大 谓词格式化程序断言 # 普通的断言输出信息的内容是预定好的，如果想要自定义输出的内容，可以使用谓词格式化程序断言 具体接口使用可参考： EXPECT_PRED_FORMAT 为了避免新的断言宏爆炸式增长，GoogleTest 提供了很多谓词格式函数，它们可以使用谓词断言的方式组装成需要的断言，例如浮点数的小于等于\\nusing ::testing::FloatLE; using ::testing::DoubleLE; ... EXPECT_PRED_FORMAT2(FloatLE, val1, val2); EXPECT_PRED_FORMAT2(DoubleLE, val1, val2); 匹配器断言 # X_THAT(value, matcher)：value 的值满足 matcher 的要求\\n#include \\u0026quot;gmock/gmock.h\\u0026quot; using ::testing::AllOf; using ::testing::Gt; using ::testing::Lt; using ::testing::MatchesRegex; using ::testing::StartsWith; ... EXPECT\\\\_THAT(value1, StartsWith(\\u0026quot;Hello\\u0026quot;)); EXPECT\\\\_THAT(value2, MatchesRegex(\\u0026quot;Line \\\\\\\\d+\\u0026quot;)); ASSERT\\\\_THAT(value3, AllOf(Gt(5), Lt(10))); 关于 matcher 的具体接口文档，详见 matchers 类型断言 # 调用函数::testing::StaticAssertTypeEq\\u0026lt;T1,T2\\u0026gt;(); 用于断言 T1 和 T2 是同一种类型，如果断言满足，该函数什么也不做，如果不同，函数调用会无法编译并报错T1 and T2 are not the same type 注意：如果是在类模板或者函数模板中使用时，仅当该函数被实例化（被调用）时才会生效报错，否则不会报错\\n断言使用的位置 # 除了在测试代码中使用断言外，在任何 C++函数中也都可以使用断言。但是注意，产生致命错误的断言只能用在返回 void 的函数（构造与析构函数不是返回 void 的函数）\\n测试 # 简单测试 # 使用TEST()宏定义和命名测试函数，这个函数是不返回值的普通 C++函数\\n函数中可以包含任何有效的 C++语句以及各种 GoogleTest 断言来检查值\\n测试的结果由断言决定，如果测试时没有任何断言失败（致命或非致命）或者测试程序崩溃，则测试成功\\n第一个参数是测试套件的名称，第二个参数是测试套件中的测试名称，这两个名称都必须是有效的 C++标识符，并且不能含有任何下划线。测试的全名由测试套件和测试名称组成，不同测试套件的测试可以有相同的测试名称\\nTEST(TestSuiteName, TestName){ \\u0026hellip; test body \\u0026hellip; }\\n举个栗子 # 函数 funA 有一个输入 n，返回 n^2，两个测试都属于 FunATests 测试套件，名字分别是 HandlesZeroInput 和 HandlesPositiveInput 用于测试不同的情况\\nint funA(int n); TEST(FunATests, HandlesZeroInput){ EXPECT_EQ(funA(0), 0); } TEST(FunATests, HandlesPositiveInput){ EXPECT_EQ(funA(1), 1); EXPECT_EQ(funA(2), 4); ... } 测试夹具 # 如果发现自己编写了两个或多个对相似数据进行操作的测试，可以使用测试夹具，它允许我们为多个不同的测试重用相同的对象配置\\n创建并使用夹具 # 从::tesing::Test 派生一个类，它的主体内容设置为 protected，因为我们要从子类中访问夹具成员 在类中，声明计划使用的所有对象数据 如有必要，编写一个默认构造函数或者 SetUp()函数来为每个测试准备对象 如有必要，编写一个析构函数或者 TearDown()函数来释放测试对象数据 如有需要，编写函数供使用该测试夹具的测试内使用 注意，GoogleTest 不会在多个测试中重用同一个测试夹具对象。对于每个 TEST_F，GoogleTest 会创建一个新的测试夹具对象并立刻调用 SetUp()，运行测试主题结束后调用 TearDown()，最后删除测试夹具对象 使用测试夹具的时候，用 TEST_F 代替 TEST，TEST_F 的第一个参数不再是测试套件名，而是测试夹具类名，具体见下方样例 举个栗子 # 假设我们有一个类 Queue 需要进行测试，它长这样：\\ntemplate \\u0026lt;typename E\\u0026gt; // E is the element type. class Queue { public: Queue(); void Enqueue(const E element); E* Dequeue(); // Returns NULL if the queue is empty. size_t size() const; ... }; 定义它的测试夹具类，一般情况下测试夹具类名=类名+Test\\nclass QueueTest : public ::testing::Test { protected: void SetUp() override { q1_.Enqueue(1); q2_.Enqueue(2); q2_.Enqueue(3); } // void TearDown() override {} Queue\\u0026lt;int\\u0026gt; q0_; Queue\\u0026lt;int\\u0026gt; q1_; Queue\\u0026lt;int\\u0026gt; q2_; }; 在这里，TearDown()并不需要，因为我们并不需要进行任何清理工作，直接析构就可以了\\n使用测试夹具进行测试\\nTEST_F(QueueTest, IsEmptyInitially) { EXPECT_EQ(q0_.size(), 0); } TEST_F(QueueTest, DequeueWorks) { int* n = q0_.Dequeue(); EXPECT_EQ(n, nullptr); n = q1_.Dequeue(); ASSERT_NE(n, nullptr); EXPECT_EQ(*n, 1); EXPECT_EQ(q1_.size(), 0); delete n; n = q2_.Dequeue(); ASSERT_NE(n, nullptr); EXPECT_EQ(*n, 2); EXPECT_EQ(q2_.size(), 1); delete n; } 在这个栗子里，第一个 TEST_F 创建一个 QueueTest 对象 t1，t1.SetUp()后进入测试内容进行使用。测试结束后 t1.TearDown()然后销毁。对于第二个 TEST_F 进行相同的过程\\n调用测试 # TEST()和 TEST_F 都会自动的隐式注册到 GoogleTest，所以并不需要为了测试再重新列举所有定义的测试 在定义测试之后，可以直接使用 RUN_ALL_TESTS()来运行所有测试，如果所有测试都通过了，它会返回 0。注意，RUNN_ALL_TESTS()会运行所有测试，哪怕这些测试来源于不同的测试套件、不同的源文件。\\n运行测试的过程 # 保存所有 googletest 标志的状态 为第一个测试创建测试夹具对象，通过 SetUp()初始化 使用测试夹具对象运行测试 测试结束，调用 TearDown()清理夹具然后销毁夹具对象 恢复所有 googletest 标志的状态 对下一个测试重复以上步骤，直到所有测试都运行结束 注意：不能忽略 RUN_ALL_TESTS()的返回值，否则会产生编译器错误。自动化测试服务根据退出代码来判断测试是否通过，而不是通过 stdout/sederr 来判断，所以 main()函数必须返回 RUN_ALL_TESTS(); main()的编写 # 大部分情况下，我们并不需要自己编写 main 方法，而是直接链接 gtest_main(注意不是 gtest)，这个链接库定义了合适的接入点会帮我们进行测试 如果想自行书写 main 方法，它需要返回 RUN_ALL_TESTS()的返回值\\nint main(int argc, char **argv) { ::testing::InitGoogleTest(argc, argv); return RUN_ALL_TESTS(); } 在这段代码里，InitGoogleTest()的作用是解析命令行里 GoogleTest 的指令参数，这允许用户控制测试程序的行为。它必须在 RUN_ALL_TESTS 之前调用，否则命令行参数不会生效\\n在旧版本里，使用的是 ParseGUnitFlags()，但是目前它已经被弃用，需要使用 InitGoogleTest()\\n后续可填坑 # gMock\\n【C++】GoogleTest 进阶之 gMock - 缙云烧饼 - 博客园 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 【C++】GoogleTest 进阶之 gMock 当我们去写测试时，有些测试对象很单纯简单，例如一个函数完全不依赖于其他的对象，那么就只需要验证其输入输出是否符合预期即可。\\n但是如果测试对象很复杂或者依赖于其他的对象呢？例如一个函数中需要访问数据库或者消息队列，那么要想按照之前的思路去测试就必须创建好数据库和消息队列的客户端实例，然后放在该函数内使用。很多时候这种操作是很麻烦的，此时 Mock Object 就能帮助我们解决这个问题。一个 Mock Object 实现与真实对象相同的接口，它可以替代真实对象去使用，而我们要做的就是制定好该 Mock Object 的行为（调用多少次、参数、返回值等等）\\n参考文档：\\ngMock 官方文档 安装 gMock # gMock 现在与 gTest 是组合使用的关系，因此在安装 gTest 时默认就会安装 gMock，具体的安装方式见 github 上的官方说明\\nhttps://github.com/google/googletest/tree/main/googletest 使用 gMock 的基本思路 # 首先，使用一些简单的 gMock 宏来描述想要模拟的接口，它们会实现你的 mock 类 然后，创建一些 mock object 然后使用 gMock 提供的语法指定好它们的行为 最后，运行需要使用这些 mock object 的代码，gMock 会在 mock object 的行为不符合预期的时候发现并指出 gMock 快速入门 假设我们在做一个用户的账户系统，一个用户会有一个账户，用户提供接口 salary，账户提供接口 add 和 getAccount，在用户的 salary 内会调用账户的 add 和 getAccount 接口\\n特别注意：此处的账户就是我们要 mock 的对象，它是用户的一个依赖。要想模拟它，它内部必须有虚析构函数，各个接口也建议是虚函数乃至纯虚函数。这里我的理解是，实际上 mock object 是对真实对象的代理/替换，在代理模式中比较常见的一种做法就是代理类和被代理类继承自同一个父类/接口\\n基本样例 # User # #ifndef USER_H #define USER_H #include iostream #include \\u0026quot;account.h\\u0026quot; class User{ public: /// @brief User类的对象依赖于Account的对象 /// @param account Account实例，被User所依赖 User(Account *account){ account_ = account; } /// @brief 模拟发工资的场景 /// @param money 发的钱数 /// @return 账户余额 int salary(int money){ account_-add(money); return account_-getAccount(); } private: Account *account_; }; #endif //USER_H Account # #ifndef ACCOUNT_H #define ACCOUNT_H class Account { public: virtual ~Account() {} virtual void add(int money) = 0; virtual int getAccount() = 0; }; #endif //ACCOUNT_H mock 类编写 # 我们要 mock 的是 Account 的一个对象，所以书写 mock 类实现 Account 接口\\n#ifndef MOCK_ACCOUNT_H #define MOCK_ACCOUNT_H #include \\u0026quot;account.h\\u0026quot; #include gmock/gmock.h class MockAccount : public Account { public: MOCK_METHOD(void, add, (int money), (override)); MOCK_METHOD(int, getAccount, (), (override)); }; #endif // MOCK_ACCOUNT_H 其中的关键部分在于 MOCK_METHOD，很多老的教程中会使用 MOCK_METHOD0、MOCK_METHOD1\\u0026hellip;这些宏，它们分别代表 0 参数、1 参数、2 参数的接口。在新的官方教程中没有这种写法，统一都是 MOCK_METHOD，内部有四个参数\\n接口返回值类型 接口名 接口形参列表，注意，如果有泛型，需要多加一层括号，例如MOCK_METHOD(void, funName, (int, (map\\u0026lt;int,string\\u0026gt;)),(override)) 为生成的 mock object 的方法添加关键字（如果是 override 这个参数其实可以不写，但是如果接口是 const 的，就必须写 const 关键字了） mock 类放在哪 # 按照 google 的建议，除非整个接口就是你自己持有的，否则 mock 类不要放在 xx_test 下，因为一旦 Account 接口被它的所有者改变，MockAccount 也必须改变才能继续使用 一般来说，我们不应该 mock 不是自己持有的接口。如果真的需要 mock 不是自己持有的，mock 对象的目录或者 testing 的子目录下创建一个.h 文件和一个 cc_library with testonly=true，这样一来，每个人都可以使用同一个地方定义的 mock 类\\nmock 的使用 # 创建好 mock 类之后，要使用它一般分以下几步\\n创建 Mock Object 规定 Mock Object 的预期行为 使用 Mock Object 测试业务代码，业务代码部分可以使用 gTest 的各种断言 一旦 Mock Object 的方法被调用的情况与前面规定的预期行为不符，测试就会不通过（在 Mock Object 被析构时也会再次检查） 其中比较核心代码有两部分：规定 Mock Object 的预期行为和业务代码测试，前者将会在下面详细展开，后者可以参考 Google Test 那篇文章 google test 入门指南 样例 # user_test.cc 文件\\n#include gtest/gtest.h #include gmock/gmock.h #include \\u0026quot;user.h\\u0026quot; #include \\u0026quot;mock_account.h\\u0026quot; using ::testing::AtLeast; using ::testing::Return; TEST(UserTest, SalaryIsOK) { MockAccount mAccount;//创建Mock Object EXPECT_CALL(mAccount, add(100)).Times(AtLeast(1)); EXPECT_CALL(mAccount, getAccount()).Times(AtLeast(1));//规范Mock Object的行为，此处是说该mock对象的getAccount()方法至少被调用1次 User user(mAccount);//将Mock Obejct注入到user中使用（依赖注入） int res = user.salary(100);//测试User业务逻辑 ASSERT_GE(res, 0);//gTest的断言，res大于等于0则通过 } 编译运行 # 这里我使用 CMake 来做构建，注意 gTest 和 gMock 需要 C++14 及以上，在链接时直接链接 gtest_main，这样就不需要自己写 main 方法了\\nCMakeLists.txt # cmake_minimum_required(VERSION 3.14) project(user LANGUAGES C CXX) set(CMAKE_CXX_STANDARD 14) enable_testing() find_package(GTest REQUIRED) add_executable(test_user \\u0026quot;${PROJECT_SOURCE_DIR}/user_test.cc\\u0026quot;) target_link_libraries(test_user GTest::gtest_main gmock) include(GoogleTest) gtest_discover_tests(test_user) 运行结果 # [==========] Running 1 test from 1 test suite. [----------] Global test environment set-up. [----------] 1 test from UserTest [ RUN ] UserTest.SalaryIsOK [ OK ] UserTest.SalaryIsOK (0 ms) [----------] 1 test from UserTest (0 ms total) [----------] Global test environment tear-down [==========] 1 test from 1 test suite ran. (0 ms total) [ PASSED ] 1 test. 测试通过了\\n设置预期行为 使用 Mock 最核心的点就在于给一个 Mock Object 规定好预期行为。这部分也是我们需要斟酌的地方。预期行为是设置的严格一点还是松一点全看需求。\\n一般语法 # 在 gMock 中使用 EXPECT_CALL()这个断言宏去设置一个 Mock Object 的预期行为 EXPECT_CALL(mock_object, mock_method(params))... 其中有两个核心参数，第一个是 mock_object，第二个是 mock_object 中的方法，如果有参数同时要把参数传进去，注意，不同参数的 mock_method 可以认为是不同的预期行为 \\u0026hellip;部分可以填写很多链式调用的逻辑来指定该对象该方法的调用运行情况\\nusing ::testing::Return; ... EXPECT_CALL(mock_object, mock_method(params)).Times(5).WillOnce(Return(100)).WillOnce(Return(150)).WillRepeatedly(Return(200)); 在以上的栗子中，为该对象的该方法指定了四个预期行为： 首先它会被调用 5 次，第一次返回 100，第二次返回 150，之后的每次都返回 200\\n关于方法的参数 params # 不确定参数值 # 很多时候我们不想让参数值变得固定，这个时候可以使用::testing::_来表示任意参数值\\nusing ::testing::_; ... EXPECT_CALL(mock_object, mock_method(_))... 如果参数有多个，而且全部都是不确定参数值，我们可以这样写： EXPECT_CALL(mock_object, mock_method)...\\n参数值需要满足某种条件 # 对于传入确切参数的情况，相当于是使用 Eq(100)，以下的前两个写法是等价的\\nEXPECT_CALL(mock_object, mock_method(100))... EXPECT_CALL(mock_object, mock_method(Eq(100)))... EXPECT_CALL(mock_object, mock_method(Ge(50)))...//参数大于等于50的所有情况 那么除了 Eq 之外，gMock 还提供了其他的一些，可以自行探索\\n预期调用的次数 # 在预期行为部分，我们可以手动写上 Times(3)来指定它需要被调用 3 次，多或少都会导致测试不通过。 AtLeast()是在次数预期里比较常用的一个方法，如果是 Times(3)，那方法必须调用且只能调用 3 次，但是如果是 Times(AtLeast(3))，那么就是至少调用 3 次的意思了。 我们也可以省略 Times()，此时 gMock 会默认根据我们写的链式调用情况添加 Times()，具体规则见下面的部分。\\n关于次数的预期，核心的方法有两个，分别是 WillOnce()和 WillRepeatedly()，前者表示调用一次，后者表示重复调用，它们可以组合使用，使用的具体规则如下：\\n如果没有 WillOnce 和 WillRepeatedly()，则默认添加 Times(1) 如果有 n 个 WillOnce，没有 WillRepeatedly()，则默认添加 Times(n) 如果有 n 个 WillOnce，有一个 WillRepeatedly()，则默认添加 Times(AtLeast(n))，这意味着 WillRepeatedly 可以匹配调用 0 次的情况 预期发生的行为 # 一个 mock object 的所有方法中都没有具体的实现体，那么它的返回值情况是怎么样设定预期的呢？ 默认情况下我们如果不设定返回值预期，也会有默认的返回值（只是我们不使用而已），bool 会返回 false，int 等等的会返回 0. 如果需要它有指定的预期返回值，我们可以在次数预期中加入返回值预期\\nusing ::testing::Return; ... EXPECT_CALL(mock_object, mock_method(params)) .Times(5) .WillOnce(Return(100)) .WillOnce(Return(150)) .WillRepeatedly(Return(200)); 在以上的栗子中，为该对象的该方法指定了四个预期行为： 首先它会被调用 5 次，第一次返回 100，第二次返回 150，之后的每次都返回 200 如果去掉 Times(5)，那就是第一次返回 100，第二次返回 150，之后每次都返回 200，调用次数不少于 2 次（WillRepeatedly 可以调用 0 次）\\n预期发生顺序 # 默认情况下，我们设定好一个 mock 对象的多个预期行为时，是不关心它们的发生顺序的。例如以下代码中，先调用 PenDown()或者先调用了 Forward(100)都是无所谓的，都能通过测试：\\nEXPECT_CALL(turtle, PenDown()); EXPECT_CALL(turtle, Forward(100)); 那么如果我们想指定预期发生顺序，我们需要创建 InSequence 对象，该对象创建处的代码块（scope）内的所有预期行为都必须按照声明顺序发生。\\nusing ::testing::InSequence; ... TEST(FooTest, DrawsLineSegment) { ... { InSequence seq; EXPECT_CALL(turtle, PenDown()); EXPECT_CALL(turtle, Forward(100)); EXPECT_CALL(turtle, PenUp()); } Foo(); } 一些需要注意的点 # 预期行为的一次性写入 # EXPECT_CALL()的链式调用中所有预期都会一次性写入，这意味着不要在链式调用中写运算，可能不会满足预期需求。举个栗子，以下并不能匹配返回 100，101，102\\u0026hellip;而是只匹配返回 100 的情况，因为++是在预期行为被设定好之后才发生\\nusing ::testing::Return; ... int n = 100; EXPECT_CALL(turtle, GetX()) .Times(4) .WillRepeatedly(Return(n++)); mock 对象方法的预期行为多重定义 # 在前面，我们看到的都是单对象单方法仅有 1 种预期行为定义的情况，如果定义了多个呢？例如：\\nusing ::testing::_; ... EXPECT_CALL(turtle, Forward(_)); // #1 EXPECT_CALL(turtle, Forward(10)) // #2 .Times(2); 假如我们在后面调用了三次 Forwar(10)，那么测试会报错不通过。如果调用了两次 Forward(10)，一次 Forward(20)，那么测试会通过。\\n预期行为粘连问题 # gMock 中的预期行为默认是粘连的，它们会一直保持存活状态（哪怕它所规定的预期行为已经完全被匹配过了） 例如以下的情况可能会出错，这种写法下可能最初想的是返回 50、40、30、20、10 的调用各一次，但是发生调用时就报错了（例如第一次调用返回 10，而第二次调用返回 20 时，预期返回 10 的那个也还存活着会报错(不满足 Once 了)）\\nusing ::testing::Return; ... for (int i = 5; i 0; i--) { EXPECT_CALL(turtle, GetX()) .WillOnce(Return(10*i)); } 我的理解：所谓预期行为(Expectations)，它所针对的是**一个 Mock 对象的一个方法在某一种参数**情况下的行为，如果不显式的声明让它在被满足后退休，它会一直存活，一直干活\\u0026hellip; 要想解决上面的问题，可以显式的声明饱和退休\\nusing ::testing::Return; ... for (int i = n; i 0; i--) { EXPECT_CALL(turtle, GetX()) .WillOnce(Return(10*i)) .RetiresOnSaturation(); } 在以上这种写法下，每个.WillOnce()一旦被满足就会退休，后面发生了什么它不会去管了，也就不会报错了 当然这也可以结合前面的预期发生顺序来写，以下的写法意味着第一次调用返回 10，第二次返回 20\\u0026hellip;..\\nusing ::testing::InSequence; using ::testing::Return; ... { InSequence s; for (int i = 1; i = n; i++) { EXPECT_CALL(turtle, GetX()) .WillOnce(Return(10*i)) .RetiresOnSaturation(); } } 后续可填坑 gMock 进阶指南\\n\"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"GoogleTest\"]",
      series: [],
      date: "\"2025-04-16\""
    });
  
    searchIndex.push({
      title: "\"GTest / GMock 单元测试实践手册 | [转载](https://imageslr.com/2023/gtest.html)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/04/16/gtest_gmock-%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%AE%9E%E8%B7%B5%E6%89%8B%E5%86%8C/\"",
      content: "\"GTest / GMock 单元测试实践手册 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 💻【C++】研发基本功 - GTest / GMock 单元测试实践手册 一、前言 📌 本文来自 Ads Infra 内部分享， 欢迎加入 👉🏻 作为架构部门，我们的很多核心仓库都是 C++ 编写，目前基本都有 80% 的增量单测覆盖率卡点。编写单测的好处不言而喻：通过构造各种 case，可以发现空指针、大数越界等肉眼不容易发现的 bug。此外，单测也可以在不引流的情况下，测试功能是否正确。因此，编写单测是必要的，为新增代码补充单测是每个研发同学的基本功。\\n但是，C++ 编写单测也是最麻烦的。根据日常观察，大部分同学没有系统地写过单测，基本依赖照抄现有代码，单测写得慢，且不标准。此外，没有掌握常见的调试技巧，主要通过 cout 逐行打日志和重新编译来定位问题，进一步降低了单测编写效率。\\n本文旨在解决上述问题：\\n本文的受众：开发过 C++ 模块、知道 GTest / GMock 的基本使用、编写过单测代码、能完成简单场景的单测需求、但对于复杂的代码则无从下手的同学；写单测感觉很不爽、知道痛点在哪儿、但不知道如何解决的同学；平时 review 代码只看业务逻辑、不看单测合理性的 reviewer 同学。 本文的内容：分享 GTest、GMock 的核心用法、常用技巧 + 单测编写的思路 + GDB 调试方法。只讲最必要的、最常用的内容，能覆盖大部分场景的单测需求。不讲花活儿，但会引用外部文档供扩展阅读。 本文的目标：(1) 通过分享上述内容，让大家系统掌握单测编写和调试方法，写起来更丝滑，查问题更高效。(2) 对齐认知，让单测真正发挥作用。知道什么是正确的、有效的、好的单测，并写出这样的单测。知道什么是无效的、差的单测，并避免写出 / 合入这样的单测。以对待线上代码的标准来对待单测。 二、Hello, world：从一个单测示例开始 为下面这段代码编写单测：\\nint check_threshold(RequestContext ctx, Ad ad) { if (ad.pricing == CPT) { return -1; } if (ad.pricing == CPM) { if (ctx.params.use_stable_thresh || ad.use_stable_thresh()) { return 2; } return ctx.get_threshold(ad); } ... } 编写出来的单测代码可能是这样的：\\n// Case 1 TEST(ChecksThresholdTest, CheckThreshForCPT) { // 1. 构造输入 RequestContext ctx; Ad ad; ad.pricing = CPT; // 2. 检查输出 EXPECT_EQ(check_threshold(ctx, ad), -1); } // Case 2 TEST(CheckThresholdTest, CheckThreshForCPM) { // 1. 构造输入 MockRequestContext ctx; // 这是一个 GMock 对象 // 使用大括号分隔不同 case { Ad ad; ad.pricing = CPM; ctx.params.use_stable_thresh = true; EXPECT_EQ(check_threshold(ctx, ad), 2); ctx.params.use_stable_thresh = false; // reset } // 上面对于 if(a||b) 的分支来说，只达到了 50% 分支覆盖率 // 尝试达到 100% 覆盖率 { Ad ad; ad.pricing = CPM; ad.should_use_stable_thresh = true; // 假设 ad.use_stable_thresh() 函数内部用了这个字段来判断 ASSERT_TRUE(ad.use_stable_thresh()); // 上一行修改是为了控制这个函数的结果，所以最好 ASSERT 一下 EXPECT_EQ(check_threshold(ctx, ad), 2); } // 默认分支 { Ad ad; ad.pricing = CPM; EXPECT_CALL(ctx, get_threshold).WillOnce(Return(100)); EXPECT_EQ(check_threshold(ctx, ad), 100); } } 涉及到的方面：\\n构造输入：手动 检测输出：EXPECT 控制外部函数的返回值：EXPECT_CALL 分支覆盖率：对于 if(a||b)，需要分别构造 a == true 和 b == true 两个 case。 三、GTest 基本概念：Test Suite、Test Case Test Suite TEST(TestSuiteName, TestCaseName) { // 单测代码 EXPECT_EQ(func(0), 0); } TestSuiteName 用来汇总 test case，相关的 test case 应该是相同的 TestSuiteName。一个文件里只能有一个 TestSuiteName，建议命名为这个文件测试的类名。 TestCaseName 是测试用例的名称。建议有意义，比如“被测试的函数名称”，或者被测试的函数名的不同输入的情况。 TestSuiteName_TestCaseName 的组合应该是唯一的。 GTest 生成的类名是带下划线的，所以上面这些名字里不建议有下划线。 Test Case 一个 TEST(Foo, Bar){...} 就是一个 Test Case。考虑到构造输入有成本，通常一个 TEST(Foo, Bar) 里会反复修改输入，构造多个 case，测试不同的执行流程。这里建议用大括号分隔不同的 case，整体更条理。另一个好处在于：每个变量的生命周期仅限于大括号内。这样就可以反复使用相同的变量名，而不用给变量名编号。\\nTEST(Foo, bar) { // case 1: enable = true { Context ctx; params.enable_refresh = true; ASSERT_EQ(ctx-\\u0026gt;is_enable_fresh(), true); } // case 2: enable = false { Context ctx; params.enable_refresh = false; ASSERT_EQ(ctx-\\u0026gt;is_enable_fresh(), false); } } 此外，如果待测函数十分复杂，建议拆分多个 TEST(Foo, Bar){...}，避免 Test Case 代码膨胀。比如：\\n// 待测函数 int foo(Ad ad) { if (!ad) return -1; switch(ad.pricing) { case CPT: ... case GD: ... } } // 输入为空 TEST(Foo, IsNil) { ... } // 输入是 CPT 广告 TEST(Foo, IsCpt) { ... } // 输入是 GD 广告 TEST(Foo, IsGd) { ... } 善用 TEST_F，避免写重复的代码 GTest 提供了多种测试宏，其中最为常用的是 TEST、TEST_F，它们的区别如下：\\nTEST：这是最基本的测试宏，代表一个最小测试单元。在执行 TEST 宏时，gtest 会为每个 TEST 定义一个独立的实例，使其互相隔离，避免对同一个变量进行修改或共享等可能带来的副作用。 TEST_F：这是 TestFixture 的测试宏。TestFixture 是一个类，可以在多个测试用例之间共享数据结构或方法。对于同一个 Test Suite 的所有 Test Cases，会创建一个 TestFixture 对象，其 SetUp 函数会在每个 Test Case 执行之前被调用，而 TearDown 函数则会在每个 Test Case 执行之后被调用。 使用 Test Fixture Class，可以避免写重复的代码：\\n将共享的变量作为成员变量，可以在 test case 中直接访问；变量初始化、回收逻辑放到 SetUp()、TearDown() 提供公共方法，可以在 test case 中直接使用 示例代码：\\nclass FooTest : public ::testing::Test { protected: // 在每个 Test Case 运行开始前，都会调用 SetUp，这里可以初始化 void SetUp() override { ctx = RequestContext(\\u0026quot;123\\u0026quot;); } // 在每个 Test Case 运行结束后，都会调用 TearDown void TearDown() override {} // 所有 Test Case 都可以直接访问这些变量和方法 Ad new_ad() { return Ad(ctx); } RequestContext ctx; }; TEST_F(FooTest, enable_foo) { // 这里会初始化 FooTest 对象 ctx-\\u0026gt;params.enable_foo = true; // 可以访问 FooTest 中的变量 auto item = new_ad(); // 可以调用 FooTest 中的方法 ... } // 每个 test case 都是独立的，这里会初始化另一个 FooTest 对象 TEST_F(FooTest, OnTestProgramStart) { // ... } 实际使用技巧：\\n共享一些变量，比如预先初始化好单测依赖的 Context 对象 封装一些公共方法，尤其是构造通用数据对象的方法 派生更多子类： 建议每个服务有一个公共的 BaseTestFixture，继承 ::testing::Test，封装全局通用的方法 其他单测可以再继承 BaseTestFixture，提供某个测试场景下共享变量和方法 断言：EXPECT 与 ASSERT 宏 用来判断某个变量的值是否符合预期。前者在校验失败时会打印失败信息，然后继续运行。后者会直接终止。\\n💡 正确使用 ASSERT 和 EXPECT 前缀：\\n如果某个判断不通过时，会影响后续步骤，要使用 ASSERT。常见的是空指针，或者数组访问越界。\\n如果某个 EXPECT 失败会导致后续一连串 EXPECT 失败，那么第一个 EXPECT 应该换成 ASSERT。这就像编译时的报错信息，往往只有第一个是有用的，其他错误都只是刷屏。\\n其他情况，可以使用 EXPECT，尽可能多测试几个用例。\\n下面罗列一些最常用的 EXPECT 宏，把前缀换成 ASSERT 也可以使用。完整列表见 文档 。\\n(1) 一元 / 二元比较 EXPECT_TRUE(foo)、EXPECT_FALSE(foo)：判断一个变量是否是 true 或 false。 二元比较： EXPECT_EQ(foo, bar)：判断两个变量是否相等。 只要重载了==运算符就可以，所以也可以判断两个 vector 是否相等。 EXPECT_NE(foo, bar)：判断 foo != bar。 EXPECT_LT(foo, bar)：foo \\u0026lt; bar，less than。 EXPECT_LE(foo, bar): foo ≤ bar，less or equal。 EXPECT_GT(foo, bar)：foo \\u0026gt; bar，greater than。 EXPECT_GE(foo, bar): foo ≥ bar，greater or equal。 (2) 浮点数比较 EXPECT_DOUBLE_EQ(foo, 0.1)：浮点数比较不能使用 EXPECT_EQ。\\nEXPECT_FLOAT_EQ：同上。\\nEXPECT_NEAR(foo, bar, abs_val)：判断两个数字的绝对值相差是否小于等于 abs_val。\\ndouble pi = 3.141592653589793238; double approx_pi = 3.14; EXPECT_NEAR(pi, approx_pi, 0.01); // 检测两个 π 值，允许误差在 0.01 以内 (3) 字符串比较 EXPECT_STREQ(foo, \\u0026quot;bar\\u0026quot;)：判断两个字符串是否相等。这里比较的是 C 风格的字符串，即 char*。如果某个对象是 std::string，需要调用其 c_str() 方法。如果两个对象都是 std::string，可以使用 EXPECT_EQ。\\nstd::string str = \\u0026quot;hello\\u0026quot;; EXPECT_STREQ(str.c_str(), \\u0026quot;hello\\u0026quot;); EXPECT_STRNE：不相等。\\nEXPECT_STRCASEEQ：忽略大小写，是否相等。\\nEXPECT_STRCASENE：忽略大小写，是否相等。\\n(4) 其他 EXPECT_THROW/EXPECT_NO_THROW：处理异常，不要自行try-catch。\\nEXPECT_THAT：这实际上是 GMock 提供的宏，需要和 匹配器 Matcher 配合使用，详见下文。这是写出优雅单测的必备技能。\\nEXPECT_CALL：同样是 GMock 提供的宏，判断函数被调用的次数，详见下文。\\nEXPECT_PRED(func, arg1, arg2, ...)：自定义一个返回 bool 的谓词，传给该谓词一系列参数，判断是否返回 true。如果失败，会依次打印传入的参数值。\\nstd::vector\\u0026lt;int\\u0026gt; vec = {1, 2, 3}; EXPECT_PRED([](const std::vector\\u0026lt;int\\u0026gt;\\u0026amp; v) { return v.size() == 3; }, vec); 断言失败时输出自定义信息 默认当 EXPECT 或 ASSERT 失败时，GTest 会打印预期值和实际值：\\nEXPECT_EQ(4, 3); /path/to/test.cpp:7: Failure Expected equality of these values: 4 result Which is: 3 但有时候，这些信息不够定位具体的失败原因。可以像这样输出自定义日志，这些日志仅在 EXPECT 失败时才打印：\\nfor (int i = 0; i \\u0026lt; x.size(); i++) { EXPECT_EQ(x[i], y[i]) \\u0026lt;\\u0026lt; \\u0026quot;x and y differ at index \\u0026quot; \\u0026lt;\\u0026lt; i; } 还可以在 TestFixture 中封装 debug 函数，输出更详细的信息。比如，被测对象中包含了一些位图 std::bitset。在 EXPECT 失败时打印位图信息，有助于排查单测失败的原因：\\nclass BitsetTest : public BaseTest { public: std::string debug_message() { stringstream ss; for (const auto\\u0026amp; iter : bitset_maps) { ss \\u0026lt;\\u0026lt; \\u0026quot;bitset: name=\\u0026quot; \\u0026lt;\\u0026lt; iter.first \\u0026lt;\\u0026lt; \\u0026quot; value=\\u0026quot; \\u0026lt;\\u0026lt; iter.second \\u0026lt;\\u0026lt; std::endl; } return ss.string(); } } TEST_F(BitsetTest, validate) { // ... EXPECT_TRUE(validate(ad, pos)) \\u0026lt;\\u0026lt; debug_message(); } 四、GMock Info 使用GMock要先明白GMock是做什么的。它模拟了接口的行为，所以如果你验证接口的结果的话，那肯定怎么验证都是对的。这会接口还不存在呢，它验证的是你的函数与接口的交互方式，比如\\n被测代码是否正确调用了依赖接口：验证被测代码在特定条件下是否调用了正确的接口方法。 调用顺序是否符合预期：验证方法调用的顺序是否正确。 调用次数是否符合预期：验证方法被调用的次数是否符合预期。 调用参数是否正确：验证调用接口时传递的参数是否正确。 被测代码对接口返回值的响应是否正确：我们设置模拟返回值，然后验证被测代码是否正确处理了这些返回值。 Idea 也就是说，你写测试的时候，脑袋瓜子是清醒的，你知道你的函数应该怎么使用接口。比如数据库连接场景，你写好了客户端，但是数据库封装类Database还没有实现。你想验证的只是你的客户端行为是否符合预期，\\n比如一次正确的查询的预期过程应该是：\\n调用connect创建连接 调用query查询 调用disconnect释放连接 **那么你的函数中是否调用了，以及是否是按顺序调用了这些呢？**再比如一次错误的连接，那么就应该校验非法，然后就应该调用接口中的HandleBadMan函数，那么是否调用了呢？明白没，重点不是在接口的结果是否正确，不是验证connect函数是否能帮你连接到数据库，而是验证你写的客户端代码，是否正确执行了接口的调用流程。\\n原理与示例 GMock 是 Google Test 提供的一个 C++ mocking 框架，可以用于创建虚拟的对象和方法。GMock 的原理是利用 C++ 的多态特性，覆盖 virtual 函数，将函数调用转发到相应的 mock 函数中。\\nGMock 基本使用流程如下：\\n继承被 mock 的类，定义一个新的 Mock 类 使用 GMock 提供的 mock 宏，用于实现 Mock 类的方法 通过上面的 Mock 类，创建一个模拟对象 通过 EXPECT_CALL 宏，控制模拟方法的返回值 #include \\u0026lt;gmock/gmock.h\\u0026gt; class FooInterface { public: virtual int foo(int) { return 3; } // ① 需要定义为虚函数 }; // ② 需要声明一个 Mock 类，并声明 MOCK_METHOD class MockFoo: public FooInterface { public: MOCK_METHOD1(foo, int(int)); // 记录函数名字 + 类型信息到 MockFoo 对象上 }; using ::testing::Return; TEST(FooInterface, foo) { MockFoo mockFoo; // ③ 需要声明 Mock 出来的子类 EXPECT_CALL(mockFoo, foo(3)).Times(1). // 自定义函数返回值 WillOnce(Return(10)); EXPECT_EQ(mockFoo.foo(3), 10); // return 10 } 使用 GMock 有两个前提：\\n(1) 被 Mock 的方法必须是虚函数；\\n(2) 必须替换掉被 mock 的对象，将其赋值为 mock 对象。\\n其不足之处：\\n(1) 使用 GMock 时必须定义一个 Mock class；\\n(2) 如果想 mock 非虚函数，需要变更函数签名，这可能不太安全；\\n(3) 对于函数内部的局部变量，无法赋值，也就无法 mock。\\nEXPECT_CALL 语法：\\nEXPECT_CALL(mock_object, method(matchers)) .Times(cardinality) .WillOnce(action) .WillRepeatedly(action); 比如下面代码的含义是：调用 turtle 对象的 GetX(string) 方法 5 次，每次传入的参数都是”hello”，第一次返回 100，第二次返回 150，之后几次返回 200：\\nusing ::testing::Return; ... EXPECT_CALL(turtle, GetX(\\u0026quot;hello\\u0026quot;)) .Times(5) .WillOnce(Return(100)) .WillOnce(Return(150)) .WillRepeatedly(Return(200)); 基数：判断函数调用次数 Times(n)：调用 n 次 Times(0)：不被调用 Times(AtLeast(n))：至少被调用 n 次 WillOnce(action)：被调用 1 次，执行自定义行为 WillRepeatedly(action)：被调用任意次，执行自定义行为 Action：控制被调用时的行为 Will 开头的接口可以传入一个 Action 参数，设置 mock 函数被调用时的行为。常用的：\\nReturn：返回指定值。比如 WillOnce(Return(100))。\\nReturnRef、ByRef：Return 不支持返回引用类型的变量，需要用这两个宏。\\nSetArgReferee\\u0026lt;n\\u0026gt;(value)：修改传入的第 n 个引用类型的参数的值，下标 n 从 0 开始。\\nclass MockGetter : public Getter { public: MOCK_METHOD(int, get, (const string\\u0026amp;, string\\u0026amp;)); }; TEST(MockGetter, SetArgRefereeTest) { const std::string key = \\u0026quot;foo_key\\u0026quot;; std::string value; MockGetter getter; EXPECT_CALL(getter, get(key, _)) .WillOnce(SetArgReferee\\u0026lt;1\\u0026gt;(\\u0026quot;bar_value\\u0026quot;)); getter.get(key ,value); EXPECT_EQ(sum, \\u0026quot;bar_value\\u0026quot;); } DoAll(action1, action2, ...)：执行多个 Action，比如修改参数的值 + 设定返回值：\\nEXPECT_CALL(calc, Add(_, _, _)) .WillOnce(DoAll(SetArgReferee\\u0026lt;2\\u0026gt;(8), Return(true))); 直接传入一个 lambda 函数，或者 Invoke(function)：执行自定义的函数，比如：\\n// 传入 lambda 函数 EXPECT_CALL(calc, Add).WillOnce([](int a, int b)) { return a + b + 1; }); // 传入函数指针 int AddFunc(int a, int b) { return a + b + 1; } EXPECT_CALL(calc, Add(_, _)).WillOnce(Invoke(AddFunc)); // 传入类方法 class AddHelper { public: int Add(int a, int b) { return a + b + 1; } }; AddHelper helper; EXPECT_CALL(calc, Add(_, _)).WillOnce(Invoke(\\u0026amp;helper, \\u0026amp;AddHelper::Add)); Lambda 函数的签名必须和被 Mock 的函数一致。 Invoke 函数可接受任何可调用对象作为参数，包括函数指针、函数对象、Lambda 表达式等 Matcher：匹配传给函数的参数 Matcher 能够实现在复杂场景下进行断言，可以让测试用例更加灵活和可读，是写出优雅单测的必备工具。\\nMatcher 提供了一系列常用的比较函数，例如 Eq、Ne、Lt、Gt、Le、Ge 等，可以满足不同类型变量的比较。\\nMatcher 有两个使用场景：\\n和 EXPECT_CALL 配合使用，用于检查传递给函数的参数值是否符合预期\\n// 期望第一个参数大于 2，第二个参数小于 6 EXPECT_CALL(calc, Add(Gt(2), Le(6))); calc.Add(3, 5); // 可以通过检测 calc.Add(2, 7); // 不能通过检测 和 EXPECT_THAT 配合使用，用于检查某个变量的值是否符合预期\\n// int_foo \\u0026gt; 6 EXPECT_THAT(int_foo, Gt(6)); // 判断一个 vector 的元素值 std::vector\\u0026lt;int\\u0026gt; result = {1, 2, 5}; EXPECT_THAT(result, ElementsAre(1, 2, Gt(3))); // 判断一个 unordered_map 的元素值 std::unordered_map\\u0026lt;string, int\\u0026gt; result = {{\\u0026quot;idt_a\\u0026quot;, 1}, {\\u0026quot;idt_b\\u0026quot;， 2}}; EXPECT_THAT(result, UnorderedElementsAre(Pair(\\u0026quot;idt_a\\u0026quot;, 1), Pair(\\u0026quot;idt_b\\u0026quot;, 2))); // 期望 foo 包含子串 \\u0026quot;hello\\u0026quot; EXPECT_THAT(foo, HasSubStr(\\u0026quot;hello\\u0026quot;)); 通配符：_，A\\u0026lt;type\\u0026gt; _ 可以匹配任意类型的任意变量。它位于 ::testing 命名空间下。示例：\\nusing namespace testing; EXPECT_CALL(calc, Add(_, _)).Times(1); EXPECT_CALL(calc, Add).Times(1); // 省略参数列表，和上面等价 A\\u0026lt;type\\u0026gt;() 或者 An\\u0026lt;type\\u0026gt;() 匹配类型是 type 的任意变量。其应用场景主要是匹配重载函数。示例：\\nclass Foo { void DoSomething(int a, int b); void DoSomething(int a, string b); } EXPECT_CALL(foo, DoSomething(_, A\\u0026lt;int\\u0026gt;())); // 预期调用第一个函数 常用匹配器 完整列表见 http://google.github.io/googletest/reference/matchers.html ，下面罗列常用的匹配器：\\n一般比较\\nvalue：写出字面量的值，就是精确匹配，等价于 Eq(value)。\\nEXPECT_CALL(foo, method(100)).Times(1); EXPECT_CALL(foo, method(Eq(100))).Times(1); // 和上面等价 Ge(value)、Gt、Le、Lt：\\u0026gt;= (greater or equal)、\\u0026gt; (greater)、\\u0026lt;= (less or equal)、\\u0026lt; (less)。\\nEXPECT_THAT(int_foo, Gt(100)); // int_foo \\u0026gt; 100 EXPECT_THAT(int_foo, Le(200)); // int_foo \\u0026lt;= 200 Ne(value)：不等于，not equal。\\nIsFalse()、IsTrue()：转成 bool 值后是 false 或 true。非 0 值、非空指针等都可以视为 true。\\nIsNull()、NotNull()：指针是否为空。\\n浮点数比较\\nDoubleEq(a_double)、FloatEq(a_float)：浮点数相等。\\ndouble foo = 0.01 + 0.02; EXPECT_THAT(foo, Eq(0.03)); // 会失败 EXPECT_THAT(foo, DoubleEq(0.03)); // 会成功 DoubleNear(a_double, max_abs_error)：浮点数近似，差值的绝对值小于给定的 abs_error。\\ndouble foo = 0.03 + 0.001; EXPECT_THAT(foo, DoubleNear(0.01)); // 会失败 EXPECT_THAT(foo, DoubleNear(0.001)); // 会成功 FloatNear(a_float, max_abs_error)：同上。\\n字符串比较\\nStartsWith(prefix)：指定前缀\\nEndsWith(suffix)：指定后缀\\nHasSubstr(string)：包含子串\\nstd::string str = \\u0026quot;hello, world\\u0026quot;; EXPECT_THAT(str, StartsWith(\\u0026quot;hello\\u0026quot;)); EXPECT_THAT(str, EndsWith(\\u0026quot;world\\u0026quot;)); EXPECT_THAT(str, HasSubstr(\\u0026quot;llo\\u0026quot;)); IsEmpty()：字符串为空\\nStrEq(string)、StrNe(string)：字符串相等或不等\\nEXPECT_CALL(m, foo(StrEq(\\u0026quot;hello, world\\u0026quot;)).Times(1); m.foo(\\u0026quot;hello, world\\u0026quot;); // 符合预期 StrCaseEq(string)、StrCaseNe(string)：忽略大小写，字符串相等或不等\\nEXPECT_CALL(m, foo(StrCaseEq(\\u0026quot;hello, world\\u0026quot;)).Times(1); m.foo(\\u0026quot;HELLO, WORLD\\u0026quot;); // 符合预期 ContainsRegex(string)：正则表达式匹配\\n容器比较\\nElementsAre(e0, e1, ..., en)：每个元素依次是什么，用于 vector、map、set 等。\\nstd:vector\\u0026lt;int\\u0026gt; v = {1, 2, 4}; EXPECT_THAT(v, ElementsAre(1, 2, 4)); // 值是 {1, 2, 4} EXPECT_THAT(v, ElementsAre(1, 2, Gt(3))); // 值是 {1, 2, 大于 3 的任意值} // 下面这样也可以，但不如上面只写一行优雅，不推荐 vector\\u0026lt;int\\u0026gt; expect_vector = {1, 2, 4}; EXPECT_EQ(v, expected_vector); UnorderedElementsAre(e0, e1, ..., en)：同上，用于 unordered_set、unordered_map 等。\\nstd:set\\u0026lt;int\\u0026gt; v = {1, 2, 4}; EXPECT_THAT(v, UnorderedElementsAre(1, 2, 4)); // 值包含 {1, 2, 4} EXPECT_THAT(v, UnorderedElementsAre(1, 2, Gt(3))); // 值包含 {1, 2, 大于 3 的任意值} ContainerEq(container)：效果同上，但会打印出哪些元素不一致。\\nContains(e)：包含一个元素和 e 匹配，这里 e 可以是一个精确值，也可以是一个匹配器。\\nContains(e).Times(n)：检测 e 指定的元素出现 n 次。Times(0) 表示不能包含这样的元素。\\nEXPECT_THAT(v, Contains(5)); // 需要包含一个值为 5 的元素 EXPECT_THAT(v, Contains(Lt(5))); // 需要包含一个值 \\u0026lt;5 的元素 EXPECT_THAT(v, Contains(Lt(5)).Times(3)); // 需要包含 3 个值 \\u0026lt;5 的元素 Each(e)：每个元素都要匹配 e。\\nEXPECT_THAT(v, Each(Lt(5))); // 每个元素都需要 \\u0026lt;5 EXPECT_THAT(v, Each(AllOf(Lt(5), Gt(3))); // 每个元素都需要 \\u0026gt;3 且 \\u0026lt;5 IsSubsetOf(array)、IsSubsetOf(begin, end)：参数是指定数组的子集，顺序可以不一致。\\n成员匹配\\nField(\\u0026amp;class::field, m)：匹配字段值，用于结构体检测，比如：\\nstruct MyStruct { int value = 42; std::string greeting = \\u0026quot;aloha\\u0026quot;; }; MyStruct s; EXPECT_THAT(s, FieldsAre(42, \\u0026quot;aloha\\u0026quot;)); Pair(m1, m2)：匹配一个 std::pair，经常和 ElementsAre 配合使用，匹配一个 map：\\nstd::map m = { {\\u0026quot;hello\\u0026quot;, 1}, {\\u0026quot;world\\u0026quot;, 2}, }; EXPECT_THAT(m, ElementsAre(Pair(\\u0026quot;hello\\u0026quot;, 1), Pair(\\u0026quot;world\\u0026quot;, 2))); 指针匹配\\nPointee：匹配一个指针或 shared_ptr，常和 Field 一起检测某个指针的字段值：\\nstruct Item { int id; }; std::shared_ptr\\u0026lt;Item\\u0026gt; obj = std::make_shared\\u0026lt;Item\\u0026gt;(); obj-\\u0026gt;id = 1; EXPECT_THAT(obj, Pointee(Field(\\u0026amp;Item::id, 1)); 复合匹配\\nAllOf(m1, m2, ..., mn)：匹配所有给定的匹配器。\\nstd:vector\\u0026lt;int\\u0026gt; v = {4, 5}; EXPECT_THAT(v, Each(AllOf(Le(5), Gt(3))); // 每个元素都需要 \\u0026gt;3 且 \\u0026lt;=5 AnyOf(m1, m2, ..., mn)：匹配任何一个给定的匹配器。\\nstd:vector\\u0026lt;int\\u0026gt; v = {1, 2, 6, 7}; EXPECT_THAT(v, Each(AnyOf(Lt(3), Gt(5))); // 每个元素要么 \\u0026lt;3，要么 \\u0026gt;5 Not(m)：不匹配给定的匹配器，可以和 AllOf、AnyOf 配合使用。\\nEXPECT_THAT(v, Each(AllOf(Gt(3), Lt(5))); // 3 \\u0026lt; each_item \\u0026lt; 5 EXPECT_THAT(v, Each(Not(AllOf(Gt(3), Lt(5)))); // each_item \\u0026lt;= 3 || each_item \\u0026gt;=5 Conditional(cond, m1, m2)：cond 为 true 时匹配 m1，否则匹配 m2。\\nEXPECT_THAT(v, Conditional(is_ad, Gt(5), Lt(3)); // v = is_ad ? v \\u0026gt; 5 : v \\u0026lt; 3 匹配器的优先级 在使用 GMock 的 EXPECT_CALL 宏进行 mock 函数参数匹配时，一次函数调用可能命中多个匹配器：\\nEXPECT_CALL(calc, add).Times(1); // 任意参数 EXPECT_CALL(calc, add(_, _)).Times(1); // 和上面等价 EXPECT_CALL(calc, add(3, 5)).Times(1); // 字面量，精确匹配 EXPECT_CALL(calc, add(Gt(2), Lt(6))).Times(1); // 比较，模糊匹配 calc.add(3, 5); // 这一行理论上可以匹配上面每一个 EXPECT_CALL 匹配的优先级如下：模糊匹配器 \\u0026gt; 精确匹配器 \\u0026gt; 通配符\\n模糊匹配器：Lt (小于)、Gt (大于) 等 精确匹配器：字面量、Eq (相等) 等 通配符：_ 等 当优先级相同时，越近的声明优先级越高。 这引入了一些使用技巧：\\n只设置必要的匹配器。如果对某个参数的值不感兴趣，请写 _ 作为参数，这意味着“一切皆有可能”。\\nEXPECT_CALL(calc, add(5, _).Times(1); // 如果只关心第一个参数的值，第二个参数就写成 _ EXPECT_CALL(calc, add(5, 3).Times(1); // 如果这样写，之后代码变动，单测可能就不通过了 如果对所有参数的值都不感兴趣，可以省略参数列表，这和把每个参数都写成 _ 是一致的。好处是后续改了函数签名后，比如新增了一个参数，单测是不需要改动的。\\nEXPECT_CALL(calc, add).Times(1); // 任意参数 EXPECT_CALL(calc, add(_, _)).Times(1); // 和上面等价 利用匹配器的优先级，可以细粒度地控制函数在不同参数下的返回值。比如 mock 一个 getter，我们希望在 key == foo 时返回 bar、key == hello 时返回 world，其他 key 通通返回空字符串，那么可以这样写：\\nEXPECT_CALL(getter, get).WillRepeatedly(Return(\\u0026quot;\\u0026quot;)); EXPECT_CALL(getter, get(\\u0026quot;foo\\u0026quot;)).WillRepeatedly(Return(\\u0026quot;bar\\u0026quot;)); EXPECT_CALL(getter, get(\\u0026quot;hello\\u0026quot;)).WillRepeatedly(Return(\\u0026quot;world\\u0026quot;)); EXPECT_STREQ(getter.get(\\u0026quot;foo\\u0026quot;), \\u0026quot;bar\\u0026quot;); EXPECT_STREQ(getter.get(\\u0026quot;hello\\u0026quot;), \\u0026quot;world\\u0026quot;); EXPECT_STREQ(getter.get(\\u0026quot;aaa\\u0026quot;), \\u0026quot;\\u0026quot;); EXPECT_STREQ(getter.get(\\u0026quot;bbb\\u0026quot;), \\u0026quot;\\u0026quot;); Uninteresting call：处理非预期调用 非预期调用是指未被 EXPECT_CALL 匹配的调用。当有非预期调用时，会有 warning 日志输出：\\nUninteresting mock function call - returning default value. Function call: foo(42) Returns: 0 有两种处理方式。\\nNiceMock：不要输出 warning 信息 GMock 有三种级别：Nice Mock、Naggy Mock、Strict Mock。\\n默认是 Naggy Mock，当有非预期调用时，输出 warning 日志。\\nUninteresting mock function call - returning default value. Function call: foo(42) Returns: 0 如果我们希望非预期调用不要有 warning，可以用 NiceMock。NiceMock 是一个模板类：\\nclass MyMockClass : public MyClass { MOCK_METHOD(...) }; MyMockClass mock; // 这非预期调用会有 warning 日志 NiceMock\\u0026lt;MyMockClass\\u0026gt; mock; // 改成这样就不会有 warning 日志了 也可以在 Mock Class 定义的时候，直接继承 NiceMock：\\nclass MyMockClass : public NiceMock\\u0026lt;MyClass\\u0026gt; { MOCK_METHOD(...) }; MyMockClass mock; // 这里非预期调用会返回默认值，不会有 warning 日志 Strict Mock 在有非预期调用时会直接 fail。也是一个模板类，使用方法和 NiceMock 类似。\\n打印调用栈：检查非预期调用来自哪里 当有非预期调用时，如果我们希望检查非预期调用来自哪里，可以打印调用栈。有两种方式。\\n一种是通过 EXPECT_CALL 打印调用栈：\\n#include \\u0026lt;boost/stacktrace.hpp\\u0026gt; void print_stack_trace() { std::cout \\u0026lt;\\u0026lt; \\u0026quot;call stack:\\u0026quot; \\u0026lt;\\u0026lt; std::endl; const auto frames = boost::stacktrace::stacktrace(); for (const auto\\u0026amp; frame : frames) { std::cout \\u0026lt;\\u0026lt; \\u0026quot; \\u0026quot; \\u0026lt;\\u0026lt; frame \\u0026lt;\\u0026lt; std::endl; } } EXPECT_CALL(...).WillRepeatedly([](){ print_stack_trace(); return xxx; // 返回默认值 }); 另一种方式是使用 GTest 提供的选项 --gmock_verbose=info，该选项会打印每次 Mock Method 被调用时的参数和调用栈。需要在单测 main 函数执行 ::testing::InitGoogleMock(\\u0026amp;argc, argv)**。\\nON_CALL ON_CALL 可以和 EXPECT_CALL 配合使用。ON_CALL 设置函数的默认行为，EXPECT_CALL 临时修改其行为。\\n💡 ON_CALL 和 EXPECT_CALL 的语法很像，但提供了不同的语义。EXPECT_CALL 目的在于定义一个预期，即我们期望被测试函数在某些特定条件下应该调用哪些函数，如果没有满足预期的调用，则认为是一次失败。ON_CALL 只是为了指定被测试函数的默认行为。\\nON_CALL 通常用在 Mock 类的构造函数、或者 TestFixture 的 SetUp 函数里：\\n令 mock 函数始终返回某个自定义的值\\n将 mock 函数的默认操作委托给基类或其他实例进行。一个具体使用场景：希望 Mock 某个函数，默认还是执行原有操作，但当有需要的时候，可以临时更改其行为。这时就可以在 ON_CALL 里把默认操作委托给基类，后续再在 EXPECT_CALL 里临时控制其返回值。\\nclass MockFoo : public Foo { public: // Normal mock method definitions using gMock. MOCK_METHOD(char, DoThis, (int n), (override)); MOCK_METHOD(void, DoThat, (const char* s, int* p), (override)); // 构造函数里，委托 Mock 接口的操作给其他类 MockFoo() { // 委托给基类 ON_CALL(*this, DoThat).WillByDefault([this](const char* s, int* p) { Foo::DoThat(s, p); }); // 委托给另一个对象 ON_CALL(*this, DoThis).WillByDefault([this](int n) { return fake_.DoThis(n); }); } private: FakeFoo fake_; // Keeps an instance of the fake in the mock. }; 五、Tips 编译参数 访问私有变量 错误的做法：#define private public，或者定义 getter 函数。前者可能导致编译报错，后者需要修改代码。\\n正确的做法：-fno-access-control，放在单测的 optimize 参数里。\\n修改 Const 字段 错误的做法：定义 setter 函数。需要修改代码。\\n较好的做法：使用 const_cast\\u0026lt;Type\\u0026amp;\\u0026gt; 修改常量类型。\\n优化级别改为 O0 好处：单测覆盖率报告更准。\\n运行单测 运行特定单测：--gtest_filter 什么时候需要运行特定单测：\\n运行所有单测，发现某个单测失败了。但这个时候单测日志已经刷屏，看不到这个单测的具体失败原因了。 修复单测 bug 后重新编译，只希望运行上次失败的那个单测。 语法：--gtest_filter=TestSuite.TestCase。支持****通配符 \\\\* 和排除符 -。\\n--gtest_filter=FooTest.Bar，只运行 FooTest.Bar。 --gtest_filter=*FooTest*，运行所有名称里包含 FooTest 的单测。 --gtest_filter=FooTest.*:BarTest.*，运行 FooTest 和 BarTest 两个 suites 下的所有单测。 --gtest_filter=FooTest.*-FooTest.Bar，运行 FooTest 下的所有单测，但不运行 FooTest.Bar。 --gtest_filter=FooTest.*:BarTest.*-FooTest.Bar:BarTest.Foo，运行 FooTest 和 BarTest 下的所有单测，但不运行 FooTest.Bar 和 BarTest.Foo。 详细的匹配规则见 文档 。 重复运行单测多次：--gtest_repeat、--gtest_break_on_failure 有些单元测试涉及到多线程，可能会偶发性的不通过。\\n可以使用 --gtest_repeat=-1、--gtest_break_on_failure运行多次来复现。\\n临时禁用某个单测：DISABLED_ 可以使用DISABLED_前缀来跳过某项测试：\\nTEST_F(DISABLED_BarTest, DoesXyz) { ... } TEST_F(BarTest, DISABLED_DoesXyz) { ... } DISABLED 之后，单测日志会输出 DISABLED 的单测数量：\\n之后在修理单测过程中，可以使用 --gtest_also_run_disabled_tests 或者 --gtest_filter 来执行被 DISABLED 的单测。\\n相比于把整段单测代码全部注释掉，加一个 DISABLED_ 前缀的 diff 更少，而且后续可以直接运行。\\n输出日志 std::cout 输出的日志会直接展示在终端。\\n💡 建议：能用 EXPECT 就不要写 std::cout\\n如果 cout 的日志是确定性的，那么应该写成断言。 如果是 debug 用的，那么在写完单测后应该删除。 如果期望单测失败时打印，那么应该放在 EXPECT_CALL()... \\u0026lt;\\u0026lt; ... 后面，而不是直接输出。 除此之外，这些日志没有任何意义，只会刷屏，没有保留的必要。 使用 GDB 运行和调试程序 🔗 GDB 快速入门 / 速查手册： https://imageslr.com/2023/gdb.html GDB 也是研发基本功之一。使用 GDB 断点调试的效率远高于加日志+重新编译单测，但大部分人依然使用后面这种调试方式，原因可能是认为 GDB 的上手成本太高。但实际上，GDB 入门只需要 3 分钟。这里罗列 GDB 的基本使用姿势，足够覆盖大部分单测场景。上面高亮块里也提供了一个速查手册。\\n进入 GDB，同时加载单测程序：\\ngdb ./path/to/unit_test 加载动态链接库：\\nset env LD_LIBRARY_PATH=... 运行单测：r。如果要运行指定单测，加 --gtest_filter 参数：\\nr --gtest_filter=FooTest.bar_method 打断点：b。比如：\\nb 文件名:行号 b prime/src/auction/validator/frame/validator.cpp:52 从断点处继续运行：c\\n逐行执行：n\\n打印变量：p 变量名\\n查看 core 栈：bt\\n六、单测编写规范 💡 单测代码也需要经过 Code Review。单测代码和线上代码同等重要。\\n目录结构、文件与命名规范 单测的目录结构，要和源码的目录结构一致 [强制] 单测文件的路径名，等价于源码的文件名加上 _test 后缀。\\n目的在于：让写单测的人能很快定位是否已经有这个文件或这个类的单测，让新增代码更聚合，避免写重复单测。\\n// bad src/ common/ item_data.cpp frame/ request_context.cpp unittest/ item_data_test.cpp // 这里直接平铺在 unittest 目录下了，和 src 目录层级不一致 request_context_test.cpp // good src/ common/ item_data.cpp frame/ request_context.cpp unittest/ common/ item_data_test.cpp frame/ request_context_test.cpp TestSuite、TestCase 命名规范 [建议] TestSuite 建议命名为被测试的类名加上 Test 后缀：\\n// bad TEST(MyTest, foo) {...} // good TEST(RequestContextTest, foo) {...} TestCase 建议命名为被测试的函数名，不要随意起名，也不需要增加不必要的前缀：\\n// bad TEST(RequestContextTest, test_uav) { ASSERT_EQ(ctx-\\u0026gt;init_uav_to_group_bid(), 1); } // good TEST(RequestContextTest, init_uav_to_group_bid) { // 不需要加 test_ 前缀 ASSERT_EQ(ctx-\\u0026gt;init_uav_to_group_bid(), 1); } GTest 生成的类名是带下划线的，所以上面这些名字建议用驼峰形式。\\n写有用的单测，而不只是通过单测覆盖率卡点 禁止写无用单测 [强制] 经典问题：“假单测”。为了通过单测覆盖率卡点、便只是在单测里执行了一下新增函数，但不检测其返回值，没有任何断言逻辑。之前遇到过有同学写了几百行单测，reviewer 从头看到尾，居然一行 EXPECT 都没有，（╯‵□′）╯。\\n还有一种场景是“蹭****单测”：新增了一个分支逻辑，引入了一坨逻辑，但只是在某个已有单测里，把这分支的控制参数打开了，完全没有自己构造输入去覆盖新增逻辑。这样即使覆盖率也能达标，也属于无用单测。\\n测试不符合预期的边界情况，而不是只测试符合预期的情况 [建议] 单测的目的之一在于测试程序的鲁棒性，即当输入不符合预期时，是否能正确处理。比如一个 stoi 函数 —— 将字符串转成整数。在构造输入时，最基本的是 123 这种合法字符串，此外还应当构造 0.9999 (小数)、123abc (含非法字符) 等非法输入，以及 1781234123412341234 这种合法但越界的输入。\\n写优雅的、可理解的、易于维护的单测：代码风格与注释 不要用 std::cout 输出变量值，改为用 ASSERT / EXPECT 检查 [强制] 能用 EXPECT 就不要写 std::cout：\\n如果 cout 的日志是确定性的，那么应该写成断言。 如果是 debug 用的，那么在写完单测后应该删除。 如果期望单测失败时打印，那么应该放在 EXPECT_CALL()... \\u0026lt;\\u0026lt; ... 后面，而不是直接输出。 除此之外，这些日志没有任何意义，只会刷屏，没有保留的必要。 // bad std::cout \\u0026lt;\\u0026lt; \\u0026quot;ads_size = \\u0026quot; \\u0026lt;\\u0026lt; rsp.ads.size() \\u0026lt;\\u0026lt; std::endl; // 这一行多此一举 EXPECT_EQ(rsp.ads.size(), 1); // good EXPECT_EQ(rsp.size(), 1); // 这一行在检测失败时，会打印 rsp.size() 的值 EXPECT_EQ(rsp.size(), 1) \\u0026lt;\\u0026lt; rsp.ads.debug_string() \\u0026lt;\\u0026lt; std::endl; // 可以在检测失败时，打印更多 debug 日志 不要直接写数值，要写清楚这个数字是怎么算的 [建议] 直接写一个数字 2965，其他人并不知道这个数字是怎么算出来的，后续有问题也不好排查。\\n写出这个数字的计算过程，映射到代码分支上，其他人好看懂。这也是白盒化单测的表现之一。\\n// bad params.alpha = 2; params.beta = 2.5; ASSERT_EQ(params.get_score(), 2965); // 这 2965 咋算的？ // good params.alpha = 2; params.beta = 2.5; ASSERT_EQ(params.get_score(), 2 * 2.5 * 593); // alpha * beta * ctx.bid // good: 把变量名直接注释在字面量后面 ASSERT_EQ(params.get_score(), 2 /* alpha */ * 2.5 /* beta */ * 593 /* ctx.bid */); 使用大括号分隔、缩进不同的 Test Case [建议] 一个 TEST(Foo, Bar){...} 就是一个 Test Case。考虑到构造输入有成本，通常一个 TEST(Foo, Bar) 里会反复修改输入，构造多个 case，测试不同的执行流程。这里建议用大括号分隔不同的 case，整体更条理。另一个好处在于：每个变量的生命周期仅限于大括号内。这样就可以反复使用相同的变量名，而不用给变量名编号。\\n// bad TEST(Foo, bar) { Context ctx1; params.enable_refresh = true; ASSERT_EQ(ctx1-\\u0026gt;is_enable_fresh(), true); Context ctx2; params.enable_refresh = false; ASSERT_EQ(ctx2-\\u0026gt;is_enable_fresh(), false); } // good TEST(Foo, bar) { // case 1: enable = true { Context ctx; params.enable_refresh = true; ASSERT_EQ(ctx-\\u0026gt;is_enable_fresh(), true); } // case 2: enable = false { Context ctx; params.enable_refresh = false; ASSERT_EQ(ctx-\\u0026gt;is_enable_fresh(), false); } } 此外，如果待测函数十分复杂，建议拆分多个 TEST(Foo, Bar){...}，避免 Test Case 代码膨胀。比如：\\n// 待测函数 int foo(Ad ad) { if (!ad) return -1; switch(ad.pricing) { case CPT: ... case GD: ... } } // 输入为空 TEST(Foo, IsNil) { ... } // 输入是 CPT 广告 TEST(Foo, IsCpt) { ... } // 输入是 GD 广告 TEST(Foo, IsGd) { ... } 正确使用 ASSERT 和 EXPECT 前缀 [建议] 前者在校验失败时会直接终止，后者则会继续运行。\\n如果某个判断不通过时会影响后续步骤 ，需要使用 ASSERT。常见的是空指针，或者数组访问越界。\\n如果某个 EXPECT 失败会导致后续一连串 EXPECT 失败，那么第一个 EXPECT 应该换成 ASSERT。这就像编译时的报错信息，往往只有第一个是有用的，其他错误都只是刷屏。\\n其他情况，可以使用 EXPECT，尽可能多测试几个用例。\\n此外，如果修改了某个字段的目的是影响某个函数的返回值，那么最好补一行 ASSERT。好处显而易见：代码即注释；且在查单测 bug 的时候，这些断言能够预先排除一些问题。\\n// bad req.type = Type::foo; // 其他人看不懂这一行的目的是什么 EXPECT_EQ(req.get_value(), 1); // good req.type = Type::foo; ASSERT_TRUE(context.is_foo()); // 这里表明，上一行是为了影响代码里这个判断函数的结果 EXPECT_EQ(req.get_value(), 1); 解除对外部逻辑的依赖 / 耦合 [建议] 如果被测代码里用到了某个全局变量： Bad：从请求入口开始执行全部代码、间接构造该变量。这样太黑盒了。 Good：直接就地构造变量，然后赋值到全局字段上。 如果被测代码里调用了某个函数： Bad：想办法构造外部函数的输入，以此来影响其返回结果。这样会导致被测函数与外部函数耦合 —— 需要看外部函数的实现逻辑，且如果后续外部函数改动了，当前函数的单测可能会不通过。 Good：使用 GMock 劫持该函数，在单测里控制其返回结果。完全不需要关心外部函数的实现。 为单测补充详细的注释 [建议] 单测写出来必须的白盒的、可理解的、可维护的。如果不补充注释，其他人根本看不懂这些单测在测试什么逻辑，也无法确保其有效，后续修单测也很痛苦。\\n为单测补充注释时，重点要说明「这些赋值对应了哪个分支条件」，目标是让其他人扫一眼源码就能知道这些单测在测试哪些逻辑。\\n// bad req.type = Type::foo; req.from = \\u0026quot;localhost\\u0026quot;; EXPECT_EQ(ctx.get_value(), 5); // good：补充注释 req.type = Type::foo; // is_foo() req.from = \\u0026quot;localhost\\u0026quot;; // is_local_req() EXPECT_EQ(ctx.get_value(), 5); // 本地请求，默认值是 5 // best：代码即注释 req.type = Type::foo; ASSERT_TRUE(ctx-\\u0026gt;is_foo()); req.from = \\u0026quot;localhost\\u0026quot;; ASSERT_TRUE(ctx-\\u0026gt;is_local_req()); EXPECT_EQ(ctx.get_value(), 5); // 本地请求，默认值是 5 写稳定的单测 Mock 所有 IO，不要依赖外部数据 [强制] 单测里禁止访问外部服务，最好是整个单测能够断网。\\n之前遇到的实际 case：\\n单测依赖线上服务，导致必须在一台线上环境的容器里才能启动单测。 单测依赖了线上 redis 里的测试数据，过了半年后数据过期了，线上单测突然挂了。 参考文档 Gtest 官方手册 (Google Test Primer) ，以及部门内的分享。\\n\"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"GoogleTest\"]",
      series: [],
      date: "\"2025-04-16\""
    });
  
    searchIndex.push({
      title: "\"Docker 网络模式详解及容器间网络通信 | [转载](https://www.cnblogs.com/mrhelloworld/p/docker11.html)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/04/15/docker-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%E8%AF%A6%E8%A7%A3%E5%8F%8A%E5%AE%B9%E5%99%A8%E9%97%B4%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/\"",
      content: "\"Docker 网络模式详解及容器间网络通信 - 哈喽沃德先生 - 博客园 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: Docker 网络模式详解及容器间网络通信 当项目大规模使用 Docker 时，容器通信的问题也就产生了。要解决容器通信问题，必须先了解很多关于网络的知识。Docker 作为目前最火的轻量级容器技术，有很多令人称道的功能，如 Docker 的镜像管理。然而，Docker 同样有着很多不完善的地方，网络方面就是 Docker 比较薄弱的部分。因此，我们有必要深入了解 Docker 的网络知识，以满足更高的网络需求。\\n安装 Docker 以后，会默认创建三种网络，可以通过 docker network ls 查看。\\n[root@localhost ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 688d1970f72e bridge bridge local 885da101da7d host host local f4f1b3cf1b7f none null local 在学习 Docker 网络之前，我们有必要先来了解一下这几种网络模式都是什么意思。\\n网络模式 简介 bridge 为每一个容器分配、设置 IP 等，并将容器连接到一个 docker0 虚拟网桥，默认为该模式。 host 容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。 none 容器有独立的 Network namespace，但并没有对其进行任何网络设置，如分配 veth pair 和网桥连接，IP 等。 container 新创建的容器不会创建自己的网卡和配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。 在该模式中，Docker 守护进程创建了一个虚拟以太网桥 docker0，新建的容器会自动桥接到这个接口，附加在其上的任何网卡之间都能自动转发数据包。\\n默认情况下，守护进程会创建一对对等虚拟设备接口 veth pair，将其中一个接口设置为容器的 eth0 接口（容器的网卡），另一个接口放置在宿主机的命名空间中，以类似 vethxxx 这样的名字命名，从而将宿主机上的所有容器都连接到这个内部网络上。\\n比如我运行一个基于 busybox 镜像构建的容器 bbox01，查看 ip addr：\\nbusybox 被称为嵌入式 Linux 的瑞士军刀，整合了很多小的 unix 下的通用功能到一个小的可执行文件中。\\n然后宿主机通过 ip addr 查看信息如下：\\n通过以上的比较可以发现，证实了之前所说的：守护进程会创建一对对等虚拟设备接口 veth pair，将其中一个接口设置为容器的 eth0 接口（容器的网卡），另一个接口放置在宿主机的命名空间中，以类似 vethxxx 这样的名字命名。\\n同时，守护进程还会从网桥 docker0 的私有地址空间中分配一个 IP 地址和子网给该容器，并设置 docker0 的 IP 地址为容器的默认网关。也可以安装 yum install -y bridge-utils 以后，通过 brctl show 命令查看网桥信息。\\n对于每个容器的 IP 地址和 Gateway 信息，我们可以通过 docker inspect 容器名称|ID 进行查看，在 NetworkSettings 节点中可以看到详细信息。\\n我们可以通过 docker network inspect bridge 查看所有 bridge 网络模式下的容器，在 Containers 节点中可以看到容器名称。\\n关于 bridge 网络模式的使用，只需要在创建容器时通过参数 --net bridge 或者 --network bridge 指定即可，当然这也是创建容器默认使用的网络模式，也就是说这个参数是可以省略的。\\nBridge 桥接模式的实现步骤主要如下：\\nDocker Daemon 利用 veth pair 技术，在宿主机上创建一对对等虚拟网络接口设备，假设为 veth0 和 veth1。而 veth pair 技术的特性可以保证无论哪一个 veth 接收到网络报文，都会将报文传输给另一方。\\nDocker Daemon 将 veth0 附加到 Docker Daemon 创建的 docker0 网桥上。保证宿主机的网络报文可以发往 veth0；\\nDocker Daemon 将 veth1 添加到 Docker Container 所属的 namespace 下，并被改名为 eth0。如此一来，宿主机的网络报文若发往 veth0，则立即会被 Container 的 eth0 接收，实现宿主机到 Docker Container 网络的联通性；同时，也保证 Docker Container 单独使用 eth0，实现容器网络环境的隔离性。\\nhost 网络模式需要在创建容器时通过参数 --net host 或者 --network host 指定；\\n采用 host 网络模式的 Docker Container，可以直接使用宿主机的 IP 地址与外界进行通信，若宿主机的 eth0 是一个公有 IP，那么容器也拥有这个公有 IP。同时容器内服务的端口也可以使用宿主机的端口，无需额外进行 NAT 转换；\\nhost 网络模式可以让容器共享宿主机网络栈，这样的好处是外部主机与容器直接通信，但是容器的网络缺少隔离性。\\n比如我基于 host 网络模式创建了一个基于 busybox 镜像构建的容器 bbox02，查看 ip addr：\\n然后宿主机通过 ip addr 查看信息如下：\\n对，你没有看错，返回信息一模一样，我也可以肯定我没有截错图，不信接着往下看。我们可以通过 docker network inspect host 查看所有 host 网络模式下的容器，在 Containers 节点中可以看到容器名称。\\nnone 网络模式是指禁用网络功能，只有 lo 接口 local 的简写，代表 127.0.0.1，即 localhost 本地环回接口。在创建容器时通过参数 --net none 或者 --network none 指定； none 网络模式即不为 Docker Container 创建任何的网络环境，容器内部就只能使用 loopback 网络设备，不会再有其他的网络资源。可以说 none 模式为 Docke Container 做了极少的网络设定，但是俗话说得好“少即是多”，在没有网络配置的情况下，作为 Docker 开发者，才能在这基础做其他无限多可能的网络定制开发。这也恰巧体现了 Docker 设计理念的开放。 比如我基于 none 网络模式创建了一个基于 busybox 镜像构建的容器 bbox03，查看 ip addr：\\n我们可以通过 docker network inspect none 查看所有 none 网络模式下的容器，在 Containers 节点中可以看到容器名称。\\nContainer 网络模式是 Docker 中一种较为特别的网络的模式。在创建容器时通过参数 --net container:已运行的容器名称|ID 或者 --network container:已运行的容器名称|ID 指定； 处于这个模式下的 Docker 容器会共享一个网络栈，这样两个容器之间可以使用 localhost 高效快速通信。 Container 网络模式即新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样两个容器除了网络方面相同之外，其他的如文件系统、进程列表等还是隔离的。\\n比如我基于容器 bbox01 创建了 container 网络模式的容器 bbox04，查看 ip addr：\\n容器 bbox01 的 ip addr 信息如下：\\n宿主机的 ip addr 信息如下：\\n通过以上测试可以发现，Docker 守护进程只创建了一对对等虚拟设备接口用于连接 bbox01 容器和宿主机，而 bbox04 容器则直接使用了 bbox01 容器的网卡信息。\\n这个时候如果将 bbox01 容器停止，会发现 bbox04 容器就只剩下 lo 接口了。\\n然后 bbox01 容器重启以后，bbox04 容器也重启一下，就又可以获取到网卡信息了。\\ndocker run --link 可以用来链接两个容器，使得源容器（被链接的容器）和接收容器（主动去链接的容器）之间可以互相通信，并且接收容器可以获取源容器的一些数据，如源容器的环境变量。\\n这种方式官方已不推荐使用，并且在未来版本可能会被移除，所以这里不作为重点讲解，感兴趣可自行了解。\\n官网警告信息： https://docs.docker.com/network/links/ 虽然 Docker 提供的默认网络使用比较简单，但是为了保证各容器中应用的安全性，在实际开发中更推荐使用自定义的网络进行容器管理，以及启用容器名称到 IP 地址的自动 DNS 解析。\\n从 Docker 1.10 版本开始，docker daemon 实现了一个内嵌的 DNS server，使容器可以直接通过容器名称通信。方法很简单，只要在创建容器时使用 --name 为容器命名即可。\\n但是使用 Docker DNS 有个限制：只能在 user-defined 网络中使用。也就是说，默认的 bridge 网络是无法使用 DNS 的，所以我们就需要自定义网络。\\n通过 docker network create 命令可以创建自定义网络模式，命令提示如下：\\n进一步查看 docker network create 命令使用详情，发现可以通过 --driver 指定网络模式且默认是 bridge 网络模式，提示如下：\\n创建一个基于 bridge 网络模式的自定义网络模式 custom_network，完整命令如下：\\ndocker network create custom_network 通过 docker network ls 查看网络模式：\\n[root@localhost ~]# docker network ls NETWORK ID NAME DRIVER SCOPE b3634bbd8943 bridge bridge local 062082493d3a custom_network bridge local 885da101da7d host host local f4f1b3cf1b7f none null local 通过自定义网络模式 custom_network 创建容器：\\ndocker run -di --name bbox05 --net custom_network busybox 通过 docker inspect 容器名称|ID 查看容器的网络信息，在 NetworkSettings 节点中可以看到详细信息。\\n通过 docker network connect 网络名称 容器名称 为容器连接新的网络模式。\\ndocker network connect bridge bbox05 通过 docker inspect 容器名称|ID 再次查看容器的网络信息，多增加了默认的 bridge。\\n通过 docker network disconnect 网络名称 容器名称 命令断开网络。\\ndocker network disconnect custom_network bbox05 通过 docker inspect 容器名称|ID 再次查看容器的网络信息，发现只剩下默认的 bridge。\\n可以通过 docker network rm 网络名称 命令移除自定义网络模式，网络模式移除成功会返回网络模式名称。\\ndocker network rm custom_network 注意：如果通过某个自定义网络模式创建了容器，则该网络模式无法删除。\\n接下来我们通过所学的知识实现容器间的网络通信。首先明确一点，容器之间要互相通信，必须要有属于同一个网络的网卡。\\n我们先创建两个基于默认的 bridge 网络模式的容器。\\ndocker run -di --name default_bbox01 busybox docker run -di --name default_bbox02 busybox 通过 docker network inspect bridge 查看两容器的具体 IP 信息。\\n然后测试两容器间是否可以进行网络通信。\\n经过测试，从结果得知两个属于同一个网络的容器是可以进行网络通信的，但是 IP 地址可能是不固定的，有被更改的情况发生，那容器内所有通信的 IP 地址也需要进行更改，能否使用容器名称进行网络通信？继续测试。\\n经过测试，从结果得知使用容器进行网络通信是不行的，那怎么实现这个功能呢？\\n从 Docker 1.10 版本开始，docker daemon 实现了一个内嵌的 DNS server，使容器可以直接通过容器名称通信。方法很简单，只要在创建容器时使用 --name 为容器命名即可。\\n但是使用 Docker DNS 有个限制：只能在 user-defined 网络中使用。也就是说，默认的 bridge 网络是无法使用 DNS 的，所以我们就需要自定义网络。\\n我们先基于 bridge 网络模式创建自定义网络 custom_network，然后创建两个基于自定义网络模式的容器。\\ndocker run -di --name custom_bbox01 --net custom_network busybox docker run -di --name custom_bbox02 --net custom_network busybox 通过 docker network inspect custom_network 查看两容器的具体 IP 信息。\\n然后测试两容器间是否可以进行网络通信，分别使用具体 IP 和容器名称进行网络通信。\\n经过测试，从结果得知两个属于同一个自定义网络的容器是可以进行网络通信的，并且可以使用容器名称进行网络通信。\\n那如果此时我希望 bridge 网络下的容器可以和 custom_network 网络下的容器进行网络又该如何操作？其实答案也非常简单：让 bridge 网络下的容器连接至新的 custom_network 网络即可。\\ndocker network connect custom_network default_bbox01 学完容器网络通信，大家就可以练习使用多个容器完成常见应用集群的部署了。后面就该学习 Docker 进阶部分的内容 Docker Compose 和 Docker Swarm。\\n本文采用 知识共享「署名-非商业性使用-禁止演绎 4.0 国际」许可协议 。\\n大家可以通过 分类 查看更多关于 Docker 的文章。\\n🤗 您的点赞和转发是对我最大的支持。\\n📢 扫码关注 哈喽沃德先生「文档 + 视频」每篇文章都配有专门视频讲解，学习更轻松噢 ~\\n\"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"Docker\"]",
      series: [],
      date: "\"2025-04-15\""
    });
  
    searchIndex.push({
      title: "\"万字长文简述Apollo中CyberRT框架基础概念 | [转载](https://zhuanlan.zhihu.com/p/479518561#CTZ_DEFAULT)\"",
      permalink: "\"/%E8%BD%AC%E8%BD%BD/2025/04/15/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E7%AE%80%E8%BF%B0apollo%E4%B8%ADcyberrt%E6%A1%86%E6%9E%B6%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/\"",
      content: "\"万字长文简述Apollo中CyberRT框架基础概念 - 知乎 声明 本文由插件 Markdown Web Clipper 自动提取网页正文而来，并未获取原作者授权！ 本文仅作个人存档学习使用，如有任何疑问/需求请查看 原文 ！ 如有侵权，请联系本人立刻删除！ 原文链接: 万字长文简述Apollo中CyberRT框架基础概念 1. CyberRT 是什么？ Apollo Cyber RT 是专为自动驾驶场景设计的开源、高性能运行时框架。 基于中心化计算模型，主要价值是提升自动驾驶系统的高并发、低延迟、高吞吐。\\nApollo 并不是一开始就使用 CyberRT，在 v3.0 之前用的都是基于 ROS 框架进行开发。但在之前的版本中发现了很多问题，随着 Apollo 的发展，对最高水平的稳健性和性能的需求， Apollo Cyber RT 应运而生，它满足了一个面向商业化的自动驾驶解决方案的基础需求。\\nCyberRT 最明显的 3 个优点：\\n加速算法 简化部署 增强自动驾驶系统能力 本文的目的有 2 个：\\n弄清楚 CyberRT 的整体框架结构 弄清楚 CyberRT 内部大致协作机制 2. CyberRT 里面有什么？ CyberRT 是一堆庞大复杂的代码，因为我只是一个学习者，我事先也并不知道 CyberRT 的架构图，所以，也只能从代码中分析并从中找线索。 我注意到 Cyber 目录下有 cyber.h 这个文件，我认为它可能是最源头或者是最基础的元素，所以选择了从 cyber.h 入手。\\n这里面只有一个 Create Node 方法，返回的是 Node 的引用。根据头文件引用及对代码的敏感性，刨去一些 log、time 之类的辅助类代码，我相信 CyberRT 中这些概念很重要：\\ncomponent node task timer 所以，研究 CyberRT 得到 CyberRT 全貌，我们可以从这些概念相应的代码入手。\\n2.1 Node 在 Node.h 文件中发现了很多有意义的东西。\\n注释中有提到一些关键信息：\\nNode 是 CyberRT 的基础构件 任何 Module 包含相应的 Node Module 之间的通信也是通过 Node 进行交互 Node 之间的通信可以设定不同的模式 Read/Write 是一种 Node 之间的通信方式 Service/Client 是另外一种 Node 之间的通信方式 另外，node 中的private属性指示了一些关键的成员变量\\n我们可以知道一个 Node 有一系列相关的 Reader 。 也可以有相应的 Node Channel Impl 和 NodeServiceImpl。\\n2.2 Reader 注释说了 3 点：\\nReader 通过订阅 Channel 获取信息 收到信息时会触发传递到 Reader 的回调 callback 也可以监听 Blocker 中的缓存信息 而上面的代码可以告诉我们，Reader 会和一种 Topology 网络发生关系，可以加入，也可以卸载。\\n并且, Reader 和 Channel 是相关联的,由 ChannelManager 进行管理。\\n2.3 ChannelImpl Channel 是 Node 之间通信的桥梁，用来给 Reader 和 Writer 之间建立通信。\\n2.4 TopologyManager 前方讲到 Reader 会和一种 Topology 网络发生关系，可以加入，也可以卸载。其实 Writer 也一样。所以，我们仍然需要去观察与 Topology 相关的类。\\n注释里面写明白了我想要的东西：\\nCyberRT 中的元素之间的关系由 Topology 呈现 Topology 相当于一个有向图 DAG Node 是 DAG 中的顶点 Channel 是 Writer 流向 Reader 的边 Service 是 Server 流向 Client 的边 Topology 是由 TopologyManager 生成的 TopologyManager 内容有 3 个子 Mannager:NodeManager、ChannelManager、ServiceManager NodeManager 是来查找 Node 是否在 Topology 当中 ChannelManager 用来查找 Channel 是否在 Topology 当中，以及对应的 Writer 和 Reader ServiceManager 用来查找 Service 是否在 Topology 当中，以及对应的 Server 和 Client TopologyManager 依靠 fast-rtps 进行通信 ，可以监听元素加入和离开 topology 网络 可以自己注册 ChangeFunc 来监听 Topology 网络的变化 所以，大概可以得到下面的示意图。\\n有了这张图基本上就可以解释 CyberRT 中大多数内容了，但是我注意到前面 Node 中有 Component 和 TimerComponent 的存在，所以，还需要去看看它们到底是什么。\\n2.5 Component Component 的基类是 ComponentBase。\\n从相应的头文件可以看到一些信息提示：\\nComponent 可以通过一些 .proto 配置 class loader 可能会加载它 内置 Reader 有相应的 Node 通过 Scheduler 进行调度 我们接下来看 Component 相关的头文件。\\n感谢 CyberRT 的开发者，关键代码注释的很明白。\\n一个 Component 最多可以支撑 4 个 Channel 进行消息处理 Component 继承自 Component，开发者可以自定义 Component，只要继承 Component 并复写它的 Init() 和 Proc() Init 和 Proc 的调用是由 CyberRT Frame 驱动的，不要主动去调用它们 Initialize 由 protocol 文件进行配置。 Proc 是一个 Component 的逻辑处理单元，包含 4 个参数，分别代表 4 个 channel 的消息。\\n2.6 TimerComponent 看名字就知道它是一个定时器组件。\\nTimerComponent 同样继承自 ComponentBase，不过内部有一个定时器 Timer。\\nTimer 的内部又有两个关键成员变量类型 TimingWheel 和 TimerTask，顾名思义是定时器时间轮换和定时器任务相关的类。\\n问题是谁触发 TimerTask 呢？\\n我们很容易想到调度器，而 CyberRT 代码中也正好有一个 scheduler。\\n问题是 scheduler 又是谁触发的呢？\\n2.7 scheduler 在一个线团中去找线头是件很难的事情，所以，需要借助于猜测。\\n我猜测整个 cyberRT 的起源是 init.c 这个文件。\\n出现了 scheduler 的身影，但这里是设置 log 相关的线程。 所以，我将目光移到 SysMo 上。\\nSysMo 创建的时候会建立一个线程，里面执行一个 while 循环，然后每次调用 scheduler 的 CheckSchedStatus 方法。\\n所以，我们终于可以去阅读 scheduler 相应的代码了。\\n它是一个工厂类，根据策略不同有 SchedulerClassic 和 SchedulerChoreography 两种实现，我在这随便挑选一种也就是 SchedulerClassic 看看它内部长什么样子。\\n看它的头文件可以发现一些关键要素：\\n采用协程调度 内部会创建 Processor，并会定期触发通知信息 有一些 ClassicTask，可能代表常规的任务 但聊聊约约我察觉到代码路径离我的目标越来越远，我其实关注的是如何找到 Node 和 Component 的源头，它们是如何被周期触发 proc 方法的。\\n于是我跳出代码森林，重视审视整个代码目录，然后发现了 mainboard。\\n2.8 mainboard 发现新大陆了，原来 mainboard 是 cyberRT 的入口，init 方法都在这里触发。\\nModule 也在这里启动。\\nModuleController 几乎藏了我想了解的答案。classloadermanager、componentbase、dag。\\nclass_loader_manager 创建相应的 Component 和 TimerComponent 并对它们进行初始化。\\nComponent 前面的文章讲过，但现在需要关心的是它和 Scheduler 的关系。\\n在 Component 的 Initialize() 中，Scheduler 会根据 Node 的名字创建一个 Task\\n2.9 再看 Scheduler Scheduler 会将 node 与 CRoutine 建立联系，然后与 Processor 也建立联系。\\n核心点在于 cr，它是协程单元，在 Component 中通过 RoutineFactory 创建。\\nRoutine 是配合 DataVisitor 使用的。\\nroutine 中会创建一个 for 循环,通过 datavisitor 不断去抓取消息，如果有消息则调用 f() 函数处理，否则通过 Yield 将执行权让度出来。 那么 f 函数是什么呢？它是在 CreateRoutineFactory 传递进来的。 源头是 Component 中的 func。\\n这是一段函数式编程，最终核心逻辑其实是调用 Component 中的 Process()，真相已经很接近了。\\nProcess 中调用 Proc() 方法处理消息，也是本文要探究的目的，整个 CyberRT 的流程包括如何创建 Component，Component如何被消息驱动大致流程都明白了。\\n当然，与 Component 对应的是 TimerComponent，它应该是定时驱动而不是消息驱动。下面小节，开始分析它。\\n2.10 Timer Timer 是在 TimerComponent 中的 Initialize 中被实例化,传入了定时周期和回调函数 func。\\nfunc 本身其实是调用 TimerComponent 的 Proc()。\\n最终 Timer 会将 TimerComponent 中的 Proc 当成 callback 封装成 TimeTask，并设置它们的触发时间，然后添加到内部的 TimingWheel 当中进行任务轮换。基于篇幅，TimingWheel 不再详细分析，因为到此，TimerComponent 的回调函数触发逻辑也已经清楚了。\\n2.11 CyberRT 整体框架全貌 经过前面小结的分析，可以发现 CyberRT 还是比较复杂和庞大的，研究 CyberRT 一些核心的类展示如下：\\n核心类是 Component 和 TimerComponent\\n支撑 component 的是 Node、Scheduler、Timer、DataVisitor\\n其他的 Reader、Writer、ChannelImple、TimerTask 等等是具体的细节相关类\\n当然，全部的 CyberRT 不止上图中列出的这些，本文关注的是概貌，细节后续针对某些功能单独分析。\\n3. CyberRT 的协作机制是什么？ 在梳理 CyberRT 相关的类时，其实流程已经基本上弄明白了。\\n主要的流程有 2 个：\\nComponent 和 TimerComponent 的创建过程 它们的消息触发机制 上面的图显示了 CyberRT 创建流程和 Component 消息驱动简单的逻辑，我们可以通过它一览 CyberRT 的基本逻辑，而更精细化的场景则需要更仔细阅读和思考代码，这在后续文章中会陆续分析。\\n4. 总结 CyberRT 确实很复杂，但经过初步的代码快速阅读，我们可以发现其实它的底层原理也挺简单的。\\nCyberRT 是基于 Fast-RTPS 进行消息驱动的，所以业务模块可以基于此进行数据通讯，这个和 ROS2 没有多大差别; CyberRT 通过 Node 节点进行通信的底层对接，而 Component 则负责具体业务相关的逻辑; CRoutine 基于消息驱动的基础上，将 Component 中的 Proc 回调作为基础的协程执行单元，然后根据 Sheduler 相应的调度策略进行调度，它保证了多任务的执行顺序，但我自己也有个疑问的地方，它能保证进程级别的正常调度吗？ TimerComponent 依靠 Timer 进行定时触发，它的 proc 方法被封装成为 TimeTask 中的回调，TimingWheel 根据调度策略进行定时任务执行； CyberRT 强大之处在于它的 3 个拓扑网络，基于 fast-rtps 通过服务发现，能够快速找到相应的 Node 状态，也因为这个特性，这在我之前分析的系统监控 Monitor 中，能够轻松监控每个模块的健康状态。 \"",
      categories: "[\"博客剪藏\"]",
      tags: "[\"CyberRT\"]",
      series: [],
      date: "\"2025-04-15\""
    });
  
    searchIndex.push({
      title: "\"C++小技巧\"",
      permalink: "\"/cpp/c++%E5%B0%8F%E6%8A%80%E5%B7%A7/\"",
      content: "\"C++小技巧 Reference 小彭老师的C++大典 \"",
      categories: "[\"C++笔记\"]",
      tags: "[\"C++\"]",
      series: "[\"modern c++\"]",
      date: "\"2025-04-14\""
    });
  
    searchIndex.push({
      title: "\"tmux 快速上手\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/tmux%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/\"",
      content: "\"Tmux 快速上手 tmux是一个著名的终端复用工具\\n安装配置 Releases · tmux/tmux ，如果安装不了，或者C库版本不支持，可以直接下载 静态的tmux版本 - tmux3.3a 配置，可以参考我的配置： .dotfiles/.config/tmux at main · captainwc/.dotfiles ，将 tmux.conf和tmux.conf.local放到~/.local/tmux中。如果版本不支持，可以用一个简单版本的 .tmux.conf.only-one-for-lower-version 放到 ~/.tmux.conf\\n如果安装了 Nerd Fonts 后图标仍然显示不对，可以试下是否是没有 export LANG=en_US.UTF-8\\n核心概念 会话（session） 窗口（window） 窗格（pane） 快捷键 ctrl+b d — 分离当前会话（让它在后台运行） ctrl+b % — 左右分屏 ctrl+b \\u0026ldquo; — 上下分屏 ctrl+b c — 创建新的 window ctrl+b w — 查看所有的 window ctrl+b n or p — 切换到下一个或者上一个 window ctrl+b 1 (2,3\\u0026hellip;) — 移动到指定的window，通过 index ctrl+b q — 查看 pane 的标号 ctrl+b Arrow Key (Left, Right, Up, Down) — 切换当前活动 pane ctrl+b x — 关闭 pane ctrl+b : — 命令行执行命令（支持tab补全） ctrl+b ? — 查看所有的快捷键，按下 q 退出 命令 tmux ls 列出所有的tmux会话\\ntmux new-session/window -s [name]or tmux new/neww -s [name]创建\\ntmux kill-session/window/pane/server -t [name] 关闭\\ntmux attach -t [name] 附着到运行着的会话上\\n其他的命令直接参见脚本\\n脚本 tmux中的命名原则: [session_name]:[window_name/index].[pane_name/index] pane和window的默认编号都是从1开始（网上看到很多教程说是从0开始，但是，怎么说呢，实践出真知吧。反正我用的tmux3.2a是从1开始编号的） C-m 就是回车的意思 下面是一个完整的tmux脚本，可以体会下怎么做到分屏的\\n## 最终布局: # | | 2 | # | 1 | | # | | 3 | # 新建一个后台会话，-d 指定后台运行，-s 指定会话名称 tmux new-session -d -s client_server_test # 默认会创建一个window，index是1，所以直接选择 1 然后重命名就好。-t指定选中的目标 tmux rename-window -t client_server_test:1 cs-window # 想要第二个window的话，也可以创建。 -t 指定会话名， -n 指定了 window 的 name # tmux new-window -t client_server_test -n cs-window # 对窗口cs-window的 1号 pane（唯一一个）进行垂直分屏 tmux split-window -h -t client_server_test:cs-window.1 # 对cs-window的 2号 pane进行水平分屏（也即在右半部分上下分屏） -p 指定了新的 pane的尺寸百分比。 tmux split-window -v -t client_server_test:cs-window.2 -p 80 # 在左侧运行第一个程序 tmux send-keys -t client_server_test:cs-window.1 '/home/shuaikai/codes/quick-cmake/build/bin/serverTest' C-m # 等待 serverTest 初始化完成 sleep 1 # 在右侧上方运行第二个程序 tmux send-keys -t client_server_test:cs-window.2 '/home/shuaikai/codes/quick-cmake/build/bin/client' C-m # 在右侧下方运行第三个程序 tmux send-keys -t client_server_test:cs-window.3 '/home/shuaikai/codes/quick-cmake/build/bin/client' C-m # 附加到 tmux 会话 tmux attach-session -t client_server_test 上面的对 window 也进行了重命名和指定。如果你不关心多个window的话，直接找准pane然后进行分屏也是可以的\\ntmux new-session -d -s client_server_test # =\\u0026gt; # 1 | 2 tmux split-window -h # =\\u0026gt; # 1 | 2 # 3 tmux select-pane -t 2 tmux split-window -v -p 80 # 直接选中 pane进行操作 tmux select-pane -t 1 tmux send-keys '/home/shuaikai/codes/quick-cmake/build/bin/serverTest' C-m sleep 1 tmux select-pane -t 2 tmux send-keys '/home/shuaikai/codes/quick-cmake/build/bin/client' C-m tmux select-pane -t 3 tmux send-keys '/home/shuaikai/codes/quick-cmake/build/bin/client' C-m tmux attach-session -t client_server_test \"",
      categories: "[\"工具使用\"]",
      tags: "[\"tmux\"]",
      series: "[\"快速上手\"]",
      date: "\"2025-04-08\""
    });
  
    searchIndex.push({
      title: "\"Valgrind快速上手\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/valgrind%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/\"",
      content: "\"Valgrind 使用详解 转载自 Valgrind 使用详解-CSDN博客 Note 原博文的排版比较混乱，找不着真正的原出处了，所以拷过来对其进行了标题的修改，后续可能会对齐进行渐进修改。博文很详细，给了很多选项，这里的建议是：\\n基本用法 valgrind -tool=xxx ./\\u0026lt;excutable\\u0026gt;。tool有memcheck, cachegrind, helgrind, callgrind, massif, lackey ...(直接补全即可查看) 然后具体的哪个工具怎么用，直接搜或者问ai即可。 Valgrind包含的工具 Valgrind支持很多工具:memcheck，addrcheck，cachegrind，Massif，helgrind和Callgrind等。在运行Valgrind时，你必须指明想用的工具,如果省略工具名，默认运行memcheck。\\nmemcheck memcheck探测程序中内存管理存在的问题。它检查所有对内存的读/写操作，并截取所有的malloc/new/free/delete调用。因此memcheck工具能够探测到以下问题：\\n1）使用未初始化的内存\\n2）读/写已经被释放的内存\\n3）读/写内存越界\\n4）读/写不恰当的内存栈空间\\n5）内存泄漏\\n6）使用malloc/new/new[]和free/delete/delete[]不匹配。\\n7）src和dst的重叠\\ncachegrind cachegrind是一个cache剖析器。它模拟执行CPU中的L1, D1和L2 cache，因此它能很精确的指出代码中的cache未命中。如果你需要，它可以打印出cache未命中的次数，内存引用和发生cache未命中的每一行代码，每一个函数，每一个模块和整个程序的摘要。如果你要求更细致的信息，它可以打印出每一行机器码的未命中次数。在x86和amd64上， cachegrind通过CPUID自动探测机器的cache配置，所以在多数情况下它不再需要更多的配置信息了。\\nhelgrind helgrind查找多线程程序中的竞争数据。helgrind查找内存地址，那些被多于一条线程访问的内存地址，但是没有使用一致的锁就会被查出。这表示这些地址在多线程间访问的时候没有进行同步，很可能会引起很难查找的时序问题。\\n它主要用来检查多线程程序中出现的竞争问题。Helgrind 寻找内存中被多个线程访问，而又没有一贯加锁的区域，这些区域往往是线程之间失去同步的地方，而且会导致难以发掘的错误。Helgrind实现了名为”Eraser” 的竞争检测算法，并做了进一步改进，减少了报告错误的次数。\\nCallgrind Callgrind收集程序运行时的一些数据，函数调用关系等信息，还可以有选择地进行cache 模拟。在运行结束时，它会把分析数据写入一个文件。callgrind_annotate可以把这个文件的内容转化成可读的形式。\\n一般用法:\\nvalgrind --tool=callgrind ./sec_infod\\n会在当前目录下生成callgrind.out.[pid], 如果我们想结束程序, 可以\\nkillall callgrind\\n然后我们可以用\\ncallgrind_annotate --auto=yes callgrind.out.[pid] \\u0026gt; log\\nvim log\\nMassif 堆栈分析器，它能测量程序在堆栈中使用了多少内存，告诉我们堆块，堆管理块和栈的大小。Massif能帮助我们减少内存的使用，在带有虚拟内存的现代系统中，它还能够加速我们程序的运行，减少程序停留在交换区中的几率。\\nlackey lackey是一个示例程序，以其为模版可以创建你自己的工具。在程序结束后，它打印出一些基本的关于程序执行统计数据。\\nValgrind的参数 用法: valgrind [options] prog-and-args [options]: 常用选项，适用于所有Valgrind工具\\n\\u0026ndash;tool=：最常用的选项。运行 valgrind中名为toolname的工具。默认memcheck。\\n-h \\u0026ndash;help：显示所有选项的帮助，包括内核和选定的工具两者。\\n\\u0026ndash;version：显示valgrind内核的版本，每个工具都有各自的版本。\\n-q \\u0026ndash;quiet：安静地运行，只打印错误信息。\\n\\u0026ndash;verbose：更详细的信息。\\n\\u0026ndash;trace-children=\\u0026lt;yes|no\\u0026gt;：跟踪子线程? [default: no]\\n\\u0026ndash;track-fds=\\u0026lt;yes|no\\u0026gt;：跟踪打开的文件描述？[default: no]\\n\\u0026ndash;time-stamp=\\u0026lt;yes|no\\u0026gt;：增加时间戳到LOG信息? [default: no]\\n\\u0026ndash;log-fd=：输出LOG到描述符文件 [2=stderr]\\n\\u0026ndash;log-file=：将输出的信息写入到filename.PID的文件里，PID是运行程序的进行ID\\n\\u0026ndash;log-file-exactly=: 输出LOG信息到 file\\n\\u0026ndash;xml=yes：将信息以xml格式输出，只有memcheck可用\\n\\u0026ndash;num-callers=：show callers in stack traces [12]\\n\\u0026ndash;error-exitcode=：如果发现错误则返回错误代码 [0=disable]\\n\\u0026ndash;db-attach=\\u0026lt;yes|no\\u0026gt;： 当出现错误，valgrind会自动启动调试器gdb。[default: no]\\n\\u0026ndash;db-command=：启动调试器的命令行选项[gdb -nw %f %p]\\n\\u0026ndash;leak-check=\\u0026lt;no|summary|full\\u0026gt;：要求对leak给出详细信息? Leak是指，存在一块没有被引用的内存空间，或没有被释放的内存空间，如summary，只反馈一些总结信息，告诉你有多少个malloc，多少个free 等；如果是full将输出所有的leaks，也就是定位到某一个malloc/free。 [default: summary]\\n\\u0026ndash;show-reachable=\\u0026lt;yes|no\\u0026gt;：如果为no，只输出没有引用的内存leaks，或指向malloc返回的内存块中部某处的leaks [default: no]\\n更详细的参数指令见附录A。\\nValgrind的使用 首先，在编译程序的时候打开调试模式（gcc编译器的-g选项）。如果没有调试信息，即使最好的valgrind工具也将不能够猜测特定的代码是属于哪一个函数。打开调试选项进行编译后再用valgrind检查，valgrind将会给你的个详细的报告，比如哪一行代码出现了内存泄漏。\\n当检查的是C++程序的时候，还应该考虑另一个选项 -fno-inline。它使得函数调用链很清晰，这样可以减少你在浏览大型C++程序时的混乱。比如在使用这个选项的时候，用memcheck检查openoffice就很容易。当然，你可能不会做这项工作，但是使用这一选项使得valgrind生成更精确的错误报告和减少混乱。\\n一些编译优化选项(比如-O2或者更高的优化选项)，可能会使得memcheck提交错误的未初始化报告，因此，为了使得valgrind的报告更精确，在编译的时候最好不要使用优化选项。\\n如果程序是通过脚本启动的，可以修改脚本里启动程序的代码，或者使用\\u0026ndash;trace-children=yes选项来运行脚本。\\n下面是用memcheck检查sample.c的例子\\n这里用到的示例程序文件名为：sample.c（如下所示）,选用的编译器为gcc。\\n生成可执行程序\\ngcc –g sample.c –o sample\\nvalgrind --tool=memcheck ./sample\\n以下是运行上述命令后的输出：\\n左边显示类似行号的数字（10297）表示的是 Process ID。\\n最上面的表示的是 valgrind 的版本信息。\\n中间表示 valgrind 通过运行被测试程序，发现的内存问题\\n最下面是对发现的内存问题和内存泄漏问题的总结。内存泄漏的大小（40 bytes）也能够被检测出来。\\nValgrind的示例 例1．使用未初始化的内存 代码如下\\n#include \\u0026lt;stdio.h\\u0026gt; int main() { int x; if(x == 0) { printf(\\u0026quot;X is zero\\u0026quot;); } return 0; } Valgrind提示如下 ==14222== Conditional jump or move depends on uninitialised value(s) ==14222== at 0x400484: main (sample2.c:6) X is zero==14222== ==14222== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 5 from 1) ==14222== malloc/free: in use at exit: 0 bytes in 0 blocks. ==14222== malloc/free: 0 allocs, 0 frees, 0 bytes allocated. ==14222== For counts of detected errors, rerun with: -v ==14222== All heap blocks were freed -- no leaks are possible. 例2．内存读写越界 代码如下\\n#include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;stdio.h\\u0026gt; int main(int argc,char *argv[]) { int len=5; int i; int *pt=(int*)malloc(len*sizeof(int)); int *p=pt; for(i=0;i\\u0026lt;len;i++) {p++;} *p=5; printf(“%d”,*p); return; } Valgrind提示如下 ==23045== Invalid write of size 4 ==23045== at 0x40050A: main (sample2.c:11) ==23045== Address 0x4C2E044 is 0 bytes after a block of size 20 alloc'd ==23045== at 0x4A05809: malloc (vg_replace_malloc.c:149) ==23045== by 0x4004DF: main (sample2.c:7) ==23045== ==23045== Invalid read of size 4 ==23045== at 0x400514: main (sample2.c:12) ==23045== Address 0x4C2E044 is 0 bytes after a block of size 20 alloc'd ==23045== at 0x4A05809: malloc (vg_replace_malloc.c:149) ==23045== by 0x4004DF: main (sample2.c:7) 5==23045== ==23045== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 5 from 1) ==23045== malloc/free: in use at exit: 20 bytes in 1 blocks. ==23045== malloc/free: 1 allocs, 0 frees, 20 bytes allocated. ==23045== For counts of detected errors, rerun with: -v ==23045== searching for pointers to 1 not-freed blocks. ==23045== checked 66,584 bytes. ==23045== ==23045== LEAK SUMMARY: ==23045== definitely lost: 20 bytes in 1 blocks. ==23045== possibly lost: 0 bytes in 0 blocks. ==23045== still reachable: 0 bytes in 0 blocks. ==23045== suppressed: 0 bytes in 0 blocks. ==23045== Use --leak-check=full to see details of leaked memory. 例3．src和dst内存覆盖 代码如下\\n#include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;stdio.h\\u0026gt; #include \\u0026lt;string.h\\u0026gt; int main(int argc,char *argv[]) { char x[50]; int i; for(i=0;i\\u0026lt;50;i++) {x[i]=i;} strncpy(x+20,x,20); //Good strncpy(x+20,x,21); //Overlap x[39]=’\\\\\\\\0’; strcpy(x,x+20); //Good x[39]=40; x[40]=’\\\\\\\\0’; strcpy(x,x+20); //Overlap return 0; } Valgrind提示如下\\n==24139== Source and destination overlap in strncpy(0x7FEFFFC09, 0x7FEFFFBF5, 21) ==24139== at 0x4A0724F: strncpy (mc_replace_strmem.c:116) ==24139== by 0x400527: main (sample3.c:10) ==24139== ==24139== Source and destination overlap in strcpy(0x7FEFFFBE0, 0x7FEFFFBF4) ==24139== at 0x4A06E47: strcpy (mc_replace_strmem.c:106) ==24139== by 0x400555: main (sample3.c:15) ==24139== ==24139== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 5 from 1) ==24139== malloc/free: in use at exit: 0 bytes in 0 blocks. ==24139== malloc/free: 0 allocs, 0 frees, 0 bytes allocated. ==24139== For counts of detected errors, rerun with: -v ==24139== All heap blocks were freed -- no leaks are possible. 例4．动态内存管理错误 常见的内存分配方式分三种：静态存储，栈上分配，堆上分配。全局变量属于静态存储，它们是在编译时就被分配了存储空间，函数内的局部变量属于栈上分配，而最灵活的内存使用方式当属堆上分配，也叫做内存动态分配了。常用的内存动态分配函数包括：malloc, alloc, realloc, new等，动态释放函数包括free, delete。\\n一旦成功申请了动态内存，我们就需要自己对其进行内存管理，而这又是最容易犯错误的。常见的内存动态管理错误包括：\\nl 申请和释放不一致\\n由于 C++ 兼容 C，而 C 与 C++ 的内存申请和释放函数是不同的，因此在 C++ 程序中，就有两套动态内存管理函数。一条不变的规则就是采用 C 方式申请的内存就用 C 方式释放；用 C++ 方式申请的内存，用 C++ 方式释放。也就是用 malloc/alloc/realloc 方式申请的内存，用 free 释放；用 new 方式申请的内存用 delete 释放。在上述程序中，用 malloc 方式申请了内存却用 delete 来释放，虽然这在很多情况下不会有问题，但这绝对是潜在的问题。\\nl 申请和释放不匹配\\n申请了多少内存，在使用完成后就要释放多少。如果没有释放，或者少释放了就是内存泄露；多释放了也会产生问题。上述程序中，指针p和pt指向的是同一块内存，却被先后释放两次。\\nl 释放后仍然读写\\n本质上说，系统会在堆上维护一个动态内存链表，如果被释放，就意味着该块内存可以继续被分配给其他部分，如果内存被释放后再访问，就可能覆盖其他部分的信息，这是一种严重的错误，上述程序第16行中就在释放后仍然写这块内存。\\n下面的一段程序，就包括了内存动态管理中常见的错误。\\n#include \\u0026lt;stdlib.h\\u0026gt; #include \\u0026lt;stdio.h\\u0026gt; int main(int argc,char *argv[]) { char *p=(char*)malloc(10); char *pt=p; int i; for(i=0;i\\u0026lt;10;i++) {p[i]=’z’;} delete p; p[1]=’a’; free(pt); return 0; } Valgrind提示如下\\n==25811== Mismatched free() / delete / delete [] ==25811== at 0x4A05130: operator delete(void*) (vg_replace_malloc.c:244) ==25811== by 0x400654: main (sample4.c:9) ==25811== Address 0x4C2F030 is 0 bytes inside a block of size 10 alloc'd ==25811== at 0x4A05809: malloc (vg_replace_malloc.c:149) ==25811== by 0x400620: main (sample4.c:4) ==25811== ==25811== Invalid write of size 1 ==25811== at 0x40065D: main (sample4.c:10) ==25811== Address 0x4C2F031 is 1 bytes inside a block of size 10 free'd ==25811== at 0x4A05130: operator delete(void*) (vg_replace_malloc.c:244) ==25811== by 0x400654: main (sample4.c:9) ==25811== ==25811== Invalid free() / delete / delete[] ==25811== at 0x4A0541E: free (vg_replace_malloc.c:233) ==25811== by 0x400668: main (sample4.c:11) ==25811== Address 0x4C2F030 is 0 bytes inside a block of size 10 free'd ==25811== at 0x4A05130: operator delete(void*) (vg_replace_malloc.c:244) ==25811== by 0x400654: main (sample4.c:9) ==25811== ==25811== ERROR SUMMARY: 3 errors from 3 contexts (suppressed: 5 from 1) ==25811== malloc/free: in use at exit: 0 bytes in 0 blocks. ==25811== malloc/free: 1 allocs, 2 frees, 10 bytes allocated. ==25811== For counts of detected errors, rerun with: -v ==25811== All heap blocks were freed -- no leaks are possible. 例5．内存泄漏 代码如下\\n#include \\u0026lt;stdlib.h\\u0026gt; int main() { char *x = (char*)malloc(20); char *y = (char*)malloc(20); x=y; free(x); free(y); return 0; } Valgrind提示如下\\n==19013== Invalid free() / delete / delete[] ==19013== at 0x4A0541E: free (vg_replace_malloc.c:233) ==19013== by 0x4004F5: main (sample5.c:8) ==19013== Address 0x4C2E078 is 0 bytes inside a block of size 20 free'd ==19013== at 0x4A0541E: free (vg_replace_malloc.c:233) ==19013== by 0x4004EC: main (sample5.c:7) ==19013== ==19013== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 5 from 1) ==19013== malloc/free: in use at exit: 20 bytes in 1 blocks. ==19013== malloc/free: 2 allocs, 2 frees, 40 bytes allocated. ==19013== For counts of detected errors, rerun with: -v ==19013== searching for pointers to 1 not-freed blocks. ==19013== checked 66,584 bytes. ==19013== ==19013== LEAK SUMMARY: ==19013== definitely lost: 20 bytes in 1 blocks. ==19013== possibly lost: 0 bytes in 0 blocks. ==19013== still reachable: 0 bytes in 0 blocks. ==19013== suppressed: 0 bytes in 0 blocks. ==19013== Use --leak-check=full to see details of leaked memory. 例6．非法写/读 代码如下\\nint main() { int i, *x; x = (int *)malloc(10*sizeof(int)); for (i=0; i\\u0026lt;11; i++) x[i] = i; free(x); } Valgrind提示如下\\n==21483== Invalid write of size 4 ==21483== at 0x4004EA: main (sample6.c:6) ==21483== Address 0x4C2E058 is 0 bytes after a block of size 40 alloc'd ==21483== at 0x4A05809: malloc (vg_replace_malloc.c:149) ==21483== by 0x4004C9: main (sample6.c:4) ==21483== ==21483== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 5 from 1) ==21483== malloc/free: in use at exit: 0 bytes in 0 blocks. ==21483== malloc/free: 1 allocs, 1 frees, 40 bytes allocated. ==21483== For counts of detected errors, rerun with: -v ==21483== All heap blocks were freed -- no leaks are possible. 例7．无效指针 代码如下\\n#include \\u0026lt;stdlib.h\\u0026gt; int main() { char *x = malloc(10); x[10] = 'a'; free(x); return 0; } Valgrind提示如下\\n==15262== Invalid write of size 1 ==15262== at 0x4004D6: main (sample7.c:5) ==15262== Address 0x4C2E03A is 0 bytes after a block of size 10 alloc'd ==15262== at 0x4A05809: malloc (vg_replace_malloc.c:149) ==15262== by 0x4004C9: main (sample7.c:4) ==15262== ==15262== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 5 from 1) ==15262== malloc/free: in use at exit: 0 bytes in 0 blocks. ==15262== malloc/free: 1 allocs, 1 frees, 10 bytes allocated. ==15262== For counts of detected errors, rerun with: -v ==15262== All heap blocks were freed -- no leaks are possible. 例8．重复释放 代码如下\\n#include \\u0026lt;stdlib.h\\u0026gt; int main() { char *x = malloc(10); free(x); free(x); return 0; } Valgrind提示如下\\n==15005== Invalid free() / delete / delete[] ==15005== at 0x4A0541E: free (vg_replace_malloc.c:233) ==15005== by 0x4004DF: main (sample8.c:6) ==15005== Address 0x4C2E030 is 0 bytes inside a block of size 10 free'd ==15005== at 0x4A0541E: free (vg_replace_malloc.c:233) ==15005== by 0x4004D6: main (sample8.c:5) ==15005== ==15005== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 5 from 1) ==15005== malloc/free: in use at exit: 0 bytes in 0 blocks. ==15005== malloc/free: 1 allocs, 2 frees, 10 bytes allocated. ==15005== For counts of detected errors, rerun with: -v ==15005== All heap blocks were freed -- no leaks are possible. Valgrind的局限 Valgrind不对静态数组(分配在栈上)进行边界检查。如果在程序中声明了一个数组:\\nint main() { char x[10]; x[11] = 'a'; } Valgrind则不会警告你，你可以把数组改为动态在堆上分配的数组，这样就可能进行边界检查了。这个方法好像有点得不偿失的感觉。\\nValgrind占用了更多的内存\\u0026ndash;可达两倍于你程序的正常使用量。如果你用Valgrind来检测使用大量内存的程序就会遇到问题，它可能会用很长的时间来运行测试。大多数情况下，这都不是问题，即使速度慢也仅是检测时速度慢，如果你用Valgrind来检测一个正常运行时速度就很慢的程序，这下问题就大了。 Valgrind不可能检测出你在程序中犯下的所有错误\\u0026ndash;如果你不检查缓冲区溢出，Valgrind也不会告诉你代码写了它不应该写的内存。\\n附录A：参数指令 基本选项： 这些选项对所有工具都有效。\\n-h \\u0026ndash;help\\n显示所有选项的帮助，包括内核和选定的工具两者。\\n\\u0026ndash;help-debug\\n和\\u0026ndash;help相同，并且还能显示通常只有Valgrind的开发人员使用的调试选项。\\n\\u0026ndash;version\\n显示Valgrind内核的版本号。工具可以有他们自已的版本号。这是一种保证工具只在它们可以运行的内核上工作的一种设置。这样可以减少在工具和内核之间版本兼容性导致奇怪问题的概率。\\n-q \\u0026ndash;quiet\\n安静的运行，只打印错误信息。在进行回归测试或者有其它的自动化测试机制时会非常有用。\\n-v \\u0026ndash;verbose\\n显示详细信息。在各个方面显示你的程序的额外信息，例如：共享对象加载，使用的重置，执行引擎和工具的进程，异常行为的警告信息。重复这个标记可以增加详细的级别。\\n-d\\n调试Valgrind自身发出的信息。通常只有Valgrind开发人员对此感兴趣。重复这个标记可以产生更详细的输出。如果你希望发送一个bug报告，通过-v -v -d -d生成的输出会使你的报告更加有效。\\n\\u0026ndash;tool= [default: memcheck]\\n运行toolname指定的Valgrind，例如，Memcheck, Addrcheck, Cachegrind,等等。\\n\\u0026ndash;trace-children=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，Valgrind会跟踪到子进程中。这经常会导致困惑，而且通常不是你所期望的，所以默认这个选项是关闭的。\\n\\u0026ndash;track-fds=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，Valgrind会在退出时打印一个打开文件描述符的列表。每个文件描述符都会打印出一个文件是在哪里打开的栈回溯，和任何与此文件描述符相关的详细信息比如文件名或socket信息。\\n\\u0026ndash;time-stamp=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，每条信息之前都有一个从程序开始消逝的时间，用天，小时，分钟，秒和毫秒表示。\\n\\u0026ndash;log-fd= [default: 2, stderr]\\n指定Valgrind把它所有的消息都输出到一个指定的文件描述符中去。默认值2, 是标准错误输出(stderr)。注意这可能会干扰到客户端自身对stderr的使用, Valgrind的输出与客户程序的输出将穿插在一起输出到stderr。\\n\\u0026ndash;log-file=\\n指定Valgrind把它所有的信息输出到指定的文件中。实际上，被创建文件的文件名是由filename、\\u0026rsquo;.\\u0026lsquo;和进程号连接起来的（即.），从而每个进程创建不同的文件。\\n\\u0026ndash;log-file-exactly=\\n类似于\\u0026ndash;log-file，但是后缀\\u0026quot;.pid\\u0026quot;不会被添加。如果设置了这个选项，使用Valgrind跟踪多个进程，可能会得到一个乱七八糟的文件。\\n\\u0026ndash;log-file-qualifier=\\n当和\\u0026ndash;log-file一起使用时，日志文件名将通过环境变量$VAR来筛选。这对于MPI程序是有益的。更多的细节，查看手册2.3节 \\u0026ldquo;注解\\u0026rdquo;。\\n\\u0026ndash;log-socket= ip-address:port-number 指定Valgrind输出所有的消息到指定的IP，指定的端口。当使用1500端口时，端口有可能被忽略。如果不能建立一个到指定端口的连接，Valgrind将输出写到标准错误(stderr)。这个选项经常和一个Valgrind监听程序一起使用。更多的细节，查看手册2.3节 \\u0026ldquo;注解\\u0026rdquo;。\\n错误相关选项： 这些选项适用于所有产生错误的工具，比如Memcheck, 但是Cachegrind不行。\\n\\u0026ndash;xml=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，输出将是XML格式。这是为了使用Valgrind的输出做为输入的工具，例如GUI前端更加容易些。目前这个选项只在Memcheck时生效。\\n\\u0026ndash;xml-user-comment=\\n在XML开头 附加用户注释，仅在指定了\\u0026ndash;xml=yes时生效，否则忽略。\\n\\u0026ndash;demangle=\\u0026lt;yes|no\\u0026gt; [default: yes]\\n打开/关闭C++的名字自动解码。默认打开。当打开时，Valgrind将尝试着把编码过的C++名字自动转回初始状态。这个解码器可以处理g++版本为2.X,3.X或4.X生成的符号。一个关于名字编码解码重要的事实是，禁止文件中的解码函数名仍然使用他们未解码的形式。Valgrind在搜寻可用的禁止条目时不对函数名解码，因为这将使禁止文件内容依赖于Valgrind的名字解码机制状态，会使速度变慢，且无意义。\\n\\u0026ndash;num-callers= [default: 12]\\n默认情况下，Valgrind显示12层函数调用的函数名有助于确定程序的位置。可以通过这个选项来改变这个数字。这样有助在嵌套调用的层次很深时确定程序的位置。注意错误信息通常只回溯到最顶上的4个函数。(当前函数，和它的3个调用者的位置)。所以这并不影响报告的错误总数。这个值的最大值是50。注意高的设置会使Valgrind运行得慢，并且使用更多的内存,但是在嵌套调用层次比较高的程序中非常实用。\\n\\u0026ndash;error-limit=\\u0026lt;yes|no\\u0026gt; [default: yes]\\n当这个选项打开时，在总量达到10,000,000，或者1,000个不同的错误，Valgrind停止报告错误。这是为了避免错误跟踪机制在错误很多的程序下变成一个巨大的性能负担。\\n\\u0026ndash;error-exitcode= [default: 0]\\n指定如果Valgrind在运行过程中报告任何错误时的退出返回值，有两种情况；当设置为默认值(零)时，Valgrind返回的值将是它模拟运行的程序的返回值。当设置为非零值时，如果Valgrind发现任何错误时则返回这个值。在Valgrind做为一个测试工具套件的部分使用时这将非常有用，因为使测试工具套件只检查Valgrind返回值就可以知道哪些测试用例Valgrind报告了错误。\\n\\u0026ndash;show-below-main=\\u0026lt;yes|no\\u0026gt; [default: no]\\n默认地，错误时的栈回溯不显示main()之下的任何函数(或者类似的函数像glibc的__libc_start_main()，如果main()没有出现在栈回溯中)；这些大部分都是令人厌倦的C库函数。如果打开这个选项，在main()之下的函数也将会显示。\\n\\u0026ndash;suppressions= [default: $PREFIX/lib/valgrind/default.supp]\\n指定一个额外的文件读取不需要理会的错误；你可以根据需要使用任意多的额外文件。\\n\\u0026ndash;gen-suppressions=\\u0026lt;yes|no|all\\u0026gt; [default: no]\\n当设置为yes时，Valgrind将会在每个错误显示之后自动暂停并且打印下面这一行：\\u0026mdash;- Print suppression ? \\u0026mdash; [Return/N/n/Y/y/C/c] \\u0026mdash;-这个提示的行为和\\u0026ndash;db-attach选项(见下面)相同。如果选择是，Valgrind会打印出一个错误的禁止条目，你可以把它剪切然后粘帖到一个文件，如果不希望在将来再看到这个错误信息。当设置为all时，Valgrind会对每一个错误打印一条禁止条目，而不向用户询问。这个选项对C++程序非常有用，它打印出编译器调整过的名字。注意打印出来的禁止条目是尽可能的特定的。如果需要把类似的条目归纳起来，比如在函数名中添加通配符。并且，有些时候两个不同的错误也会产生同样的禁止条目，这时Valgrind就会输出禁止条目不止一次，但是在禁止条目的文件中只需要一份拷贝(但是如果多于一份也不会引起什么问题)。并且，禁止条目的名字像\\u0026lt;在这儿输入一个禁止条目的名字\\u0026gt;;名字并不是很重要，它只是和-v选项一起使用打印出所有使用的禁止条目记录。\\n\\u0026ndash;db-attach=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，Valgrind将会在每次打印错误时暂停并打出如下一行：\\u0026mdash;- Attach to debugger ? \\u0026mdash; [Return/N/n/Y/y/C/c] \\u0026mdash;- 按下回车,或者N、回车，n、回车，Valgrind不会对这个错误启动调试器。按下Y、回车，或者y、回车，Valgrind会启动调试器并设定在程序运行的这个点。当调试结束时，退出，程序会继续运行。在调试器内部尝试继续运行程序，将不会生效。按下C、回车，或者c、回车，Valgrind不会启动一个调试器，并且不会再次询问。注意：\\u0026ndash;db-attach=yes与\\u0026ndash;trace-children=yes有冲突。你不能同时使用它们。Valgrind在这种情况下不能启动。\\n2002.05: 这是一个历史的遗留物，如果这个问题影响到你，请发送邮件并投诉这个问题。\\n2002.11:如果你发送输出到日志文件或者到网络端口，我猜这不会让你有任何感觉。不须理会。\\n\\u0026ndash;db-command= [default: gdb -nw %f %p]\\n通过\\u0026ndash;db-attach指定如何使用调试器。默认的调试器是gdb.默认的选项是一个运行时扩展Valgrind的模板。 %f会用可执行文件的文件名替换，%p会被可执行文件的进程ID替换。\\n这指定了Valgrind将怎样调用调试器。默认选项不会因为在构造时是否检测到了GDB而改变,通常是/usr/bin/gdb.使用这个命令，你可以指定一些调用其它的调试器来替换。\\n给出的这个命令字串可以包括一个或多个%p %f扩展。每一个%p实例都被解释成将调试的进程的PID，每一个%f实例都被解释成要调试的进程的可执行文件路径。\\n\\u0026ndash;input-fd= [default: 0, stdin]\\n使用\\u0026ndash;db-attach=yes和\\u0026ndash;gen-suppressions=yes选项，在发现错误时，Valgrind会停下来去读取键盘输入。默认地，从标准输入读取，所以关闭了标准输入的程序会有问题。这个选项允许你指定一个文件描述符来替代标准输入读取。\\n\\u0026ndash;max-stackframe= [default: 2000000]\\n栈的最大值。如果栈指针的偏移超过这个数量，Valgrind则会认为程序是切换到了另外一个栈执行。如果在程序中有大量的栈分配的数组，你可能需要使用这个选项。valgrind保持对程序栈指针的追踪。如果栈指针的偏移超过了这个数量，Valgrind假定你的程序切换到了另外一个栈，并且Memcheck行为与栈指\\n针的偏移没有超出这个数量将会不同。通常这种机制运转得很好。然而，如果你的程序在栈上申请了大的结构，这种机制将会表现得愚蠢，并且Memcheck将会报告大量的非法栈内存访问。这个选项允许把这个阀值设置为其它值。应该只在Valgrind的调试输出中显示需要这么做时才使用这个选项。在这种情况下，它会告诉你应该指定的新的阀值。普遍地，在栈中分配大块的内存是一个坏的主意。因为这很容易用光你的栈空间，尤其是在内存受限的系统或者支持大量小堆栈的线程的系统上，因为Memcheck执行的错误检查，对于堆上的数据比对栈上的数据要高效很多。如果你使用这个选项，你可能希望考虑重写代码在堆上分配内存而不是在栈上分配。\\nMALLOC()相关的选项: 对于使用自有版本的malloc() (例如Memcheck和massif)，下面的选项可以使用。\\n\\u0026ndash;alignment= [default: 8]\\n默认Valgrind的malloc(),realloc(), 等等，是8字节对齐地址的。这是大部分处理器的标准。然而，一些程序可能假定malloc()等总是返回16字节或更多对齐的内存。提供的数值必须在8和4096区间之内，并且必须是2的幂数。\\n非通用选项：\\n这些选项可以用于所有的工具，它们影响Valgrind core的几个特性。大部分人不会用到这些选项。\\n\\u0026ndash;run-libc-freeres=\\u0026lt;yes|no\\u0026gt; [default: yes]\\nGNU C库(libc.so)，所有程序共用的，可能会分配一部分内存自已用。通常在程序退出时释放内存并不麻烦 \\u0026ndash; 这里没什么问题，因为Linux内核在一个进程退出时会回收进程全部的资源，所以这只是会造成速度慢。glibc的作者认识到这样会导致内存检查器，像Valgrind，在退出时检查内存错误的报告glibc的内存泄漏问题，为了避免这个问题，他们提供了一个__libc_freeres()例程特别用来让glibc释放分配的所有内存。因此Memcheck在退出时尝试着去运行__libc_freeres()。不幸的是，在glibc的一些版本中，__libc_freeres是有bug会导致段错误的。这在Red Hat 7.1上有特别声明。所以，提供这个选项来决定是否运行__libc_freeres。如果你的程序看起来在Valgrind上运行得很好，但是在退出时发生段错误，你可能需要指定\\u0026ndash;run-libc-freeres=no来修正，这将可能错误的报告libc.so的内存泄漏。\\n\\u0026ndash;sim-hints=hint1,hint2,\\u0026hellip;\\n传递杂凑的提示给Valgrind，轻微的修改模拟行为的非标准或危险方式，可能有助于模拟奇怪的特性。默认没有提示打开。小心使用！目前已知的提示有：\\nl lax-ioctls: 对ioctl的处理非常不严格，唯一的假定是大小是正确的。不需要在写时缓冲区完全的初始化。没有这个，用大量的奇怪的ioctl命令来使用一些设备驱动将会非常烦人。\\nl enable-inner:打开某些特殊的效果，当运行的程序是Valgrind自身时。\\n\\u0026ndash;kernel-variant=variant1,variant2,\\u0026hellip;\\n处理系统调用和ioctls在这个平台的默认核心上产生不同的变量。这有助于运行在改进过的内核或者支持非标准的ioctls上。小心使用。如果你不理解这个选项做的是什么那你几乎不需要它。已经知道的变量有：\\nl bproc: 支持X86平台上的sys_broc系统调用。这是为了运行在BProc，它是标准Linux的一个变种，有时用来构建集群。\\n\\u0026ndash;show-emwarns=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，Valgrind在一些特定的情况下将对CPU仿真产生警告。通常这些都是不引人注意的。\\n\\u0026ndash;smc-check=\\u0026lt;none|stack|all\\u0026gt; [default: stack]\\n这个选项控制Valgrind对自我修改的代码的检测。Valgrind可以不做检测，可以检测栈中自我修改的代码，或者任意地方检测自我修改的代码。注意默认选项是捕捉绝大多数情况，到目前我们了解的情况为止。使用all选项时会极大的降低速度。(但是用none选项运行极少影响速度，因为对大多数程序，非常少的代码被添加到栈中)\\n调试VALGRIND选项： 还有一些选项是用来调试Valgrind自身的。在运行一般的东西时不应该需要的。如果你希望看到选项列表，使用\\u0026ndash;help-debug选项。\\n内存检查选项：\\n\\u0026ndash;leak-check=\\u0026lt;no|summary|yes|full\\u0026gt; [default: summary]\\n当这个选项打开时，当客户程序结束时查找内存泄漏。内存泄漏意味着有用malloc分配内存块，但是没有用free释放，而且没有指针指向这块内存。这样的内存块永远不能被程序释放，因为没有指针指向它们。如果设置为summary，Valgrind会报告有多少内存泄漏发生了。如果设置为full或yes，Valgrind给出每一个独立的泄漏的详细信息。\\n\\u0026ndash;show-reachable=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项关闭时，内存泄漏检测器只显示没有指针指向的内存块，或者只能找到指向块中间的指针。当这个选项打开时，内存泄漏检测器还报告有指针指向的内存块。这些块是最有可能出现内存泄漏的地方。你的程序可能，至少在原则上，应该在退出前释放这些内存块。这些有指针指向的内存块和没有指针指向的内存块，或者只有内部指针指向的块，都可能产生内存泄漏，因为实际上没有一个指向块起始的指针可以拿来释放，即使你想去释放它。\\n\\u0026ndash;leak-resolution=\\u0026lt;low|med|high\\u0026gt; [default: low]\\n在做内存泄漏检查时，确定memcheck将怎么样考虑不同的栈是相同的情况。当设置为low时，只需要前两层栈匹配就认为是相同的情况；当设置为med，必须要四层栈匹配，当设置为high时，所有层次的栈都必须匹配。对于hardcore内存泄漏检查，你很可能需要使用\\u0026ndash;leak-resolution=high和\\u0026ndash;num-callers=40或者更大的数字。注意这将产生巨量的信息，这就是为什么默认选项是四个调用者匹配和低分辨率的匹配。注意\\u0026ndash;leak-resolution= 设置并不影响memcheck查找内存泄漏的能力。它只是改变了结果如何输出。\\n\\u0026ndash;freelist-vol= [default: 5000000]\\n当客户程序使用free(C中)或者delete(C++)释放内存时，这些内存并不是马上就可以用来再分配的。这些内存将被标记为不可访问的，并被放到一个已释放内存的队列中。这样做的目的是，使释放的内存再次被利用的点尽可能的晚。这有利于memcheck在内存块释放后这段重要的时间检查对块不合法的访问。这个选项指定了队列所能容纳的内存总容量，以字节为单位。默认的值是5000000字节。增大这个数目会增加memcheck使用的内存，但同时也增加了对已释放内存的非法使用的检测概率。\\n\\u0026ndash;workaround-gcc296-bugs=\\u0026lt;yes|no\\u0026gt; [default: no]\\n当这个选项打开时，假定读写栈指针以下的一小段距离是gcc 2.96的bug，并且不报告为错误。距离默认为256字节。注意gcc 2.96是一些比较老的Linux发行版(RedHat 7.X)的默认编译器，所以你可能需要使用这个选项。如果不是必要请不要使用这个选项，它可能会使一些真正的错误溜掉。一个更好的解决办法是使用较新的，修正了这个bug的gcc/g++版本。\\n\\u0026ndash;partial-loads-ok=\\u0026lt;yes|no\\u0026gt; [default: no]\\n控制memcheck如何处理从地址读取时字长度，字对齐，因此哪些字节是可以寻址的，哪些是不可以寻址的。当设置为yes是，这样的读取并不抛出一个寻址错误。而是从非法地址读取的V字节显示为未定义，访问合法地址仍然是像平常一样映射到内存。设置为no时，从部分错误的地址读取与从完全错误的地址读取同样处理：抛出一个非法地址错误，结果的V字节显示为合法数据。注意这种代码行为是违背ISO C/C++标准，应该被认为是有问题的。如果可能，这种代码应该修正。这个选项应该只是做为一个最后考虑的方法。\\n\\u0026ndash;undef-value-errors=\\u0026lt;yes|no\\u0026gt; [default: yes]\\n控制memcheck是否检查未定义值的危险使用。当设为yes时，Memcheck的行为像Addrcheck, 一个轻量级的内存检查工具，是Valgrind的一个部分，它并不检查未定义值的错误。使用这个选项，如果你不希望看到未定义值错误。\\nCACHEGRIND选项： 手动指定I1/D1/L2缓冲配置，大小是用字节表示的。这三个必须用逗号隔开，中间没有空格，例如： valgrind \\u0026ndash;tool=cachegrind \\u0026ndash;I1=65535,2,64你可以指定一个，两个或三个I1/D1/L2缓冲。如果没有手动指定，每个级别使用普通方式(通过CPUID指令得到缓冲配置，如果失败，使用默认值)得到的配置。\\n\\u0026ndash;I1=,,\\n指定第一级指令缓冲的大小，关联度和行大小。\\n\\u0026ndash;D1=,,\\n指定第一级数据缓冲的大小，关联度和行大小。\\n\\u0026ndash;L2=,,\\n指定第二级缓冲的大小，关联度和行大小。\\nCALLGRIND选项：\\n\\u0026ndash;heap=\\u0026lt;yes|no\\u0026gt; [default: yes]\\n当这个选项打开时，详细的追踪堆的使用情况。关闭这个选项时，massif.pid.txt或massif.pid.html将会非常的简短。\\n\\u0026ndash;heap-admin= [default: 8]\\n每个块使用的管理字节数。这只能使用一个平均的估计值，因为它可能变化。glibc使用的分配器每块需要4~15字节，依赖于各方面的因素。管理已经释放的块也需要空间，尽管massif不计算这些。\\n\\u0026ndash;stacks=\\u0026lt;yes|no\\u0026gt; [default: yes]\\n当打开时，在剖析信息中包含栈信息。多线程的程序可能有多个栈。\\n\\u0026ndash;depth= [default: 3]\\n详细的堆信息中调用过程的深度。增加这个值可以给出更多的信息，但是massif会更使这个程序运行得慢，使用更多的内存，并且产生一个大的massif.pid.txt或者massif.pid.hp文件。\\n\\u0026ndash;alloc-fn=\\n指定一个分配内存的函数。这对于使用malloc()的包装函数是有用的，可以用它来填充原来无效的上下文信息。(这些函数会给出无用的上下文信息，并在图中给出无意义的区域)。指定的函数在上下文中被忽略，例如，像对malloc()一样处理。这个选项可以在命令行中重复多次，指定多个函数。\\n\\u0026ndash;format=\\u0026lt;text|html\\u0026gt; [default: text]\\n产生text或者HTML格式的详细堆信息，文件的后缀名使用.txt或者.html。\\nHELGRIND选项： \\u0026ndash;private-stacks=\\u0026lt;yes|no\\u0026gt; [default: no]\\n假定线程栈是私有的。\\n\\u0026ndash;show-last-access=\\u0026lt;yes|some|no\\u0026gt; [default: no]\\n显示最后一次字访问出错的位置。\\nLACKEY选项： \\u0026ndash;fnname= [default: _dl_runtime_resolve()]\\n对函数计数。\\n\\u0026ndash;detailed-counts=\\u0026lt;no|yes\\u0026gt; [default: no]\\n对读取，存储和alu操作计数。\\n\"",
      categories: "[\"工具使用\"]",
      tags: "[\"valgrind\"]",
      series: "[\"快速上手\"]",
      date: "\"2025-04-08\""
    });
  
    searchIndex.push({
      title: "\"Mermaid快速上手\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/mermaid%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/\"",
      content: "\"Mermaid 快速上手 Reference 在线mermaid编辑器 Mermaid中文手册 Note 接受 front yaml 进行配置，可以在其中指定主题（theme: neutral, default, forest）、字体（fontFamily: \\u0026quot;Maple Mono NF\\u0026quot;）、title 等等 图表方向：LR RL TB/TD BT 流程图 (graph/flowchart) Tip 支持连对，以及一对多/多对多 A -\\u0026gt; B \\u0026amp; C -\\u0026gt; D \\u0026amp; E -\\u0026gt; F 常见线条：-.-\\u0026gt;, ==\\u0026gt;, == xx ==\\u0026gt;, ---\\u0026gt;, --.xx.--\\u0026gt; (一个短横是不行的；线上评论要空格) 更多箭头类型 : --o \\u0026lt;--\\u0026gt; --x 箭头动画 ：给边打上标记 A edge001@==\\u0026gt; B，然后配置边的属性 edge001@{ animate: true } 常见形状：() [] (()) [[]] [()] [/\\\\] [\\\\/] [\\\\\\\\] {} {{}} \\u0026gt;] 更多形状 A@{ shape: processes, label: \\u0026quot;Multiple processes\\u0026quot; } --- title: 流程图示例 --- graph TB subgraph subgraph1 direction LR A[A] e1@--\\u0026gt;|comment| B(B) \\u0026amp; C((C)) -.-\\u0026gt; D{{D}} \\u0026amp; E[(E)] ==\\u0026gt; F{F} end subgraph subgraph2 direction LR O[/O\\\\] -- comment2 --o G[\\\\G/] -. comment3 .-x H[\\\\H\\\\] G \\u0026lt;---\\u0026gt; I\\u0026gt;I] end subgraph1 edge002@==\\u0026gt; subgraph2 e1@{ animate: true } edge002@{ animate: true } 时序图 (sequenceDiagram) Note 箭头有特殊取法，单横线表示实线，双横线表示虚线，单箭头表示没有箭头，双箭头表示有箭头 即 -\\u0026gt;\\u0026gt; --\\u0026gt;\\u0026gt;表示有箭头的实线/虚线，-\\u0026gt; --\\u0026gt; 表示没箭头的实线/虚线 此外还有 双箭头、X、异步调用：\\u0026lt;-\\u0026gt;, -x, -)，其实线虚线表示方法不变 跟上加号减号可以描述启动/停止-\\u0026gt;\\u0026gt;+, --\\u0026gt;\\u0026gt;- participant, actor create participant xxx, destroy xxx 此外还有 loop, alt, opt 等类似plantuml的地方，参考 sequenceDiagram sequenceDiagram Alice-\\u0026gt;\\u0026gt;+Bob: Hello Bob, how are you ? Bob--\\u0026gt;\\u0026gt;-Alice: Fine, thank you. And you? create participant Carl Alice-\\u0026gt;\\u0026gt;Carl: Hi Carl! create actor D as Donald Carl-)D: Hi! destroy Carl Alice-xCarl: We are too many destroy Bob Bob--)Alice: I agree 状态图 (stateDiagram-v2) 语法兼容 plantUML。\\nNote [*] 表示 start 和 end，中间节点用线连就行了 节点信息不同于plantUML，但是差别不大。都是 A: msg1, A: another msg 这样往后加，区别是指定信息后，mermaid会删去A的名字，但是plantUML不会 --- config: theme: forest --- stateDiagram direction LR [*] --\\u0026gt; Still Still --\\u0026gt; [*] Still --\\u0026gt; Moving Moving --\\u0026gt; Still Moving --\\u0026gt; Crash Crash --\\u0026gt; [*] Moving: Moving Moving: Move to A Moving: Move to B 框图 (block-beta) 描述软件架构、组成的图。 Ref --- config: theme: default --- block-beta %% 总列数 columns 3 %% 指定某一元素占据多少列 a b(\\u0026quot;b\\u0026quot;):2 %% 可以将多个元素组合成一个块，指定块占据的列数，块内再次细分列数 block:group1:2 columns 3 h i j down\\u0026lt;[\\u0026quot; \\u0026quot;]\\u0026gt;(down) space:2 k end %% 框图里面的lable必须加上双引号 g(((\\u0026quot;This is a circle\\u0026quot;))) block:group2:3 %% columns auto (default) l left\\u0026lt;[\\u0026quot; \\u0026quot;]\\u0026gt;(left) m n space o p blockArrowId6\\u0026lt;[\\u0026quot; \\u0026quot;]\\u0026gt;(right) q r end m --\\u0026gt; o 思维导图 (mindmap) 只用缩进来描述层级关系\\n--- config: theme: default --- mindmap A((root)) B{{B}} C D E F G 雷达图 (radar-beta) --- title: \\u0026quot;Grades\\u0026quot; config: theme: default --- radar-beta axis m[\\u0026quot;C++\\u0026quot;], s[\\u0026quot;Python\\u0026quot;], e[\\u0026quot;Java\\u0026quot;] axis h[\\u0026quot;C#\\u0026quot;], g[\\u0026quot;Shell\\u0026quot;], a[\\u0026quot;JavaScript\\u0026quot;] curve a[\\u0026quot;Alice\\u0026quot;]{99, 90, 50, 10, 80, 30} curve b[\\u0026quot;Bob\\u0026quot;]{20, 70, 20, 60, 20, 99} curve b[\\u0026quot;Mike\\u0026quot;]{0, 90, 10, 30, 70, 90} max 100 min 0 饼图 (pie) --- config: theme: default --- pie title 示例饼图 \\u0026quot;类别A\\u0026quot; : 40 \\u0026quot;类别B\\u0026quot; : 30 \\u0026quot;类别C\\u0026quot; : 20 \\u0026quot;类别D\\u0026quot; : 10 看板图 (kanban) Note 看板条目格式：A[description]@{ticket: xx-xx-xx, priority: 'xx', assigned: 'xx'}\\nticket 表示时间\\npriority 的取值有 Very Low, Low, , High, Very High\\n--- config: theme: default --- kanban todo A[task A]@{ticket: 2025-04-11, priority: 'Very Low', assigned: 'zhangsan'} B[task B is a task named B, which is a quiet normal name]@{ticket: 2025-04-12, priority: 'Very High', assigned: 'lisi'} progress C[task C]@{ticket: 2025-04-07, assigned: 'wangermazi'} done D[task D]@{ticket: 2025-04-01, priority: 'Low', assigned: 'wangermazi'} D[task D]@{ticket: 2025-04-03, priority: 'High'} 甘特图 (gantt) --- config: theme: forest --- gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid excludes weekends %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\\u0026quot;sunday\\u0026quot;) or \\u0026quot;weekends\\u0026quot;, but not the word \\u0026quot;weekdays\\u0026quot;.) section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :until isadded Functionality added :milestone, isadded, 2014-01-25, 0d section Documentation Describe gantt syntax :active, a1, after des1, 3d Add gantt diagram to demo page :after a1 , 20h Add another diagram to demo page :doc1, after a1 , 48h section Last section Describe gantt syntax :after doc1, 3d Add gantt diagram to demo page :20h Add another diagram to demo page :48h \"",
      categories: "[\"工具使用\"]",
      tags: "[\"mermaid\"]",
      series: "[\"快速上手\"]",
      date: "\"2025-04-07\""
    });
  
    searchIndex.push({
      title: "\"CyberRT框架总览\"",
      permalink: "\"/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/cyberrt/cyberrt%E6%A1%86%E6%9E%B6%E6%80%BB%E8%A7%88/\"",
      content: "\"CyberRT框架总览 RTPS框架 flowchart TD subgraph \\u0026quot;Core Layer\\u0026quot; A[\\u0026quot;Core Runtime\\u0026quot;]:::core config[\\u0026quot;Configuration\\u0026quot;]:::config end subgraph \\u0026quot;Communication \\u0026amp; Data Transport\\u0026quot; B1[\\u0026quot;Transport\\u0026quot;]:::comm B2[\\u0026quot;Messaging\\u0026quot;]:::comm B3[\\u0026quot;Data\\u0026quot;]:::comm B4[\\u0026quot;IO\\u0026quot;]:::comm end subgraph \\u0026quot;Scheduling \\u0026amp; Task Management\\u0026quot; C1[\\u0026quot;Scheduler\\u0026quot;]:::sched C2[\\u0026quot;Task Management\\u0026quot;]:::sched C3[\\u0026quot;Timer\\u0026quot;]:::sched C4[\\u0026quot;Coroutine Handling\\u0026quot;]:::sched end subgraph \\u0026quot;Node \\u0026amp; Service Management\\u0026quot; D1[\\u0026quot;Node\\u0026quot;]:::node D2[\\u0026quot;Service\\u0026quot;]:::node D3[\\u0026quot;Parameter\\u0026quot;]:::node D4[\\u0026quot;Component\\u0026quot;]:::node end subgraph \\u0026quot;Discovery \\u0026amp; Dynamic Loading\\u0026quot; E1[\\u0026quot;Service Discovery\\u0026quot;]:::disc E2[\\u0026quot;Class Loader\\u0026quot;]:::disc end subgraph \\u0026quot;Logging \\u0026amp; Record\\u0026quot; F1[\\u0026quot;Logger\\u0026quot;]:::log F2[\\u0026quot;Record\\u0026quot;]:::log end subgraph \\u0026quot;External Interfaces \\u0026amp; Tools\\u0026quot; G1[\\u0026quot;Python Interface\\u0026quot;]:::external G2[\\u0026quot;Developer Tools\\u0026quot;]:::external end subgraph \\u0026quot;Third Party Dependencies\\u0026quot; H1[\\u0026quot;Third Party Libraries\\u0026quot;]:::third end %% Core Runtime interactions A --\\u0026gt;|\\u0026quot;publishes\\u0026quot;| B2 A --\\u0026gt;|\\u0026quot;manages\\u0026quot;| B1 A --\\u0026gt;|\\u0026quot;manages\\u0026quot;| B3 A --\\u0026gt;|\\u0026quot;manages\\u0026quot;| B4 A --\\u0026gt;|\\u0026quot;schedules\\u0026quot;| C1 A --\\u0026gt;|\\u0026quot;controls\\u0026quot;| D1 A --\\u0026gt;|\\u0026quot;controls\\u0026quot;| D2 A --\\u0026gt;|\\u0026quot;controls\\u0026quot;| D3 A --\\u0026gt;|\\u0026quot;controls\\u0026quot;| D4 A --\\u0026gt;|\\u0026quot;discovers\\u0026quot;| E1 A --\\u0026gt;|\\u0026quot;discovers\\u0026quot;| E2 A --\\u0026gt;|\\u0026quot;logsTo\\u0026quot;| F1 A --\\u0026gt;|\\u0026quot;recordsTo\\u0026quot;| F2 A --\\u0026gt;|\\u0026quot;configures\\u0026quot;| config %% External Interfaces interactions G1 --\\u0026gt;|\\u0026quot;callsAPI\\u0026quot;| A G2 --\\u0026gt;|\\u0026quot;monitors\\u0026quot;| A %% Node and Messaging interaction D1 --\\u0026gt;|\\u0026quot;sendsMsg\\u0026quot;| B2 %% Scheduler internal flow C1 --\\u0026gt;|\\u0026quot;dispatches\\u0026quot;| C2 C1 --\\u0026gt;|\\u0026quot;fires\\u0026quot;| C3 C1 --\\u0026gt;|\\u0026quot;orchestrates\\u0026quot;| C4 %% Service Discovery updates E1 --\\u0026gt;|\\u0026quot;updates\\u0026quot;| D1 E1 --\\u0026gt;|\\u0026quot;updates\\u0026quot;| D2 %% Third Party dependency H1 --\\u0026gt;|\\u0026quot;supports\\u0026quot;| A %% Styles classDef core fill:#00ffff,stroke:#000,stroke-width:2px; classDef comm fill:#ffcccc,stroke:#ff0000,stroke-width:2px; classDef sched fill:#ccffcc,stroke:#008000,stroke-width:2px; classDef node fill:#e6ccff,stroke:#0000ff,stroke-width:2px; classDef disc fill:#ffffcc,stroke:#cccc00,stroke-width:2px; classDef log fill:#ffeecc,stroke:#cc6600,stroke-width:2px; classDef external fill:#e0e0e0,stroke:#333333,stroke-width:2px; classDef config fill:#d0d0ff,stroke:#000080,stroke-width:2px; classDef third fill:#f0e68c,stroke:#b8860b,stroke-width:2px; %% Click Events click A \\u0026quot;https://github.com/captainwc/cyberrt/blob/master/cyber/cyber.cc\\u0026quot; _blank click config \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/conf\\u0026quot; _blank click B1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/transport\\u0026quot; _blank click B2 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/message\\u0026quot; _blank click B3 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/data\\u0026quot; _blank click B4 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/io\\u0026quot; _blank click C1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/scheduler\\u0026quot; _blank click C2 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/task\\u0026quot; _blank click C3 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/timer\\u0026quot; _blank click C4 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/croutine\\u0026quot; _blank click D1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/node\\u0026quot; _blank click D2 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/service\\u0026quot; _blank click D3 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/parameter\\u0026quot; _blank click D4 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/component\\u0026quot; _blank click E1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/service_discovery\\u0026quot; _blank click E2 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/class_loader\\u0026quot; _blank click F1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/logger\\u0026quot; _blank click F2 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/record\\u0026quot; _blank click G1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber_py3\\u0026quot; _blank click G2 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/cyber/tools\\u0026quot; _blank click H1 \\u0026quot;https://github.com/captainwc/cyberrt/tree/master/third_party\\u0026quot; _blank CyberRT的协程 graph TB %% 定义样式 classDef configClass fill:#e1f5fe,stroke:#01579b classDef initClass fill:#e8f5e9,stroke:#1b5e20 classDef routineClass fill:#fff3e0,stroke:#e65100 classDef scheduleClass fill:#f3e5f5,stroke:#4a148c classDef resourceClass fill:#fbe9e7,stroke:#bf360c %% 配置加载模块 subgraph ConfigurationModule[配置加载模块] A1[cyber/conf/scheduler.conf]:::configClass --\\u0026gt; B1[加载调度策略]:::configClass A2[cyber/conf/choreography.conf]:::configClass --\\u0026gt; B2[加载编排配置]:::configClass A3[cyber/conf/classic.conf]:::configClass --\\u0026gt; B3[加载经典配置]:::configClass B1 \\u0026amp; B2 \\u0026amp; B3 --\\u0026gt; C1[SchedulerFactory::Instance]:::configClass end %% 初始化模块 subgraph InitializationModule[初始化模块] D1[cyber::Init]:::initClass --\\u0026gt; E1[创建Node]:::initClass E1 --\\u0026gt; F1[创建Component]:::initClass F1 --\\u0026gt; G1[注册回调函数]:::initClass end %% 协程创建模块 subgraph RoutineModule[协程创建和管理模块] H1[new CRoutine创建协程]:::routineClass --\\u0026gt; I1[初始化RoutineContext]:::routineClass I1 --\\u0026gt; J1[分配栈空间]:::routineClass J1 --\\u0026gt; K1[设置入口函数]:::routineClass K1 --\\u0026gt; L1[设置初始状态READY]:::routineClass end %% 调度模块 subgraph SchedulerModule[调度模块] M1[Scheduler::Instance]:::scheduleClass --\\u0026gt; N1{调度策略选择}:::scheduleClass N1 --\\u0026gt;|Choreography| O1[ChoreographyContext]:::scheduleClass N1 --\\u0026gt;|Classic| P1[ClassicContext]:::scheduleClass O1 \\u0026amp; P1 --\\u0026gt; Q1[Processor::Run]:::scheduleClass Q1 --\\u0026gt; R1[NextRoutine获取协程]:::scheduleClass R1 --\\u0026gt; S1[Resume执行协程]:::scheduleClass S1 --\\u0026gt; T1[Yield让出执行权]:::scheduleClass T1 --\\u0026gt; R1 end %% 资源管理模块 subgraph ResourceModule[资源管理模块] U1[CCObjectPool管理]:::resourceClass --\\u0026gt; V1[协程上下文池]:::resourceClass V1 --\\u0026gt; W1[内存分配/释放]:::resourceClass X1[ProcessorManager]:::resourceClass --\\u0026gt; Y1[CPU亲和性设置]:::resourceClass Y1 --\\u0026gt; Z1[处理器调度]:::resourceClass end %% 状态转换模块 subgraph StateModule[状态管理模块] STATE_READY[READY状态] STATE_RUNNING[RUNNING状态] STATE_SLEEP[SLEEP状态] STATE_IO_WAIT[IO_WAIT状态] STATE_DATA_WAIT[DATA_WAIT状态] STATE_FINISHED[FINISHED状态] STATE_READY --\\u0026gt; STATE_RUNNING STATE_RUNNING --\\u0026gt; STATE_SLEEP STATE_RUNNING --\\u0026gt; STATE_IO_WAIT STATE_RUNNING --\\u0026gt; STATE_DATA_WAIT STATE_RUNNING --\\u0026gt; STATE_FINISHED STATE_SLEEP \\u0026amp; STATE_IO_WAIT \\u0026amp; STATE_DATA_WAIT --\\u0026gt; STATE_READY end %% 模块间的连接 ConfigurationModule --\\u0026gt; InitializationModule InitializationModule --\\u0026gt; RoutineModule RoutineModule --\\u0026gt; SchedulerModule SchedulerModule --\\u0026gt; ResourceModule SchedulerModule --\\u0026gt; StateModule %% 关键文件注释 %% note1[\\u0026quot;/cyber/croutine/croutine.h\\u0026quot;] %% note2[\\u0026quot;/cyber/scheduler/scheduler.h\\u0026quot;] %% note3[\\u0026quot;/cyber/scheduler/processor.h\\u0026quot;] %% note4[\\u0026quot;/cyber/croutine/routine_context.h\\u0026quot;] \"",
      categories: "[\"自动驾驶\"]",
      tags: "[\"CyberRT\"]",
      series: "[\"CyberRT专项总结\"]",
      date: "\"2025-04-02\""
    });
  
    searchIndex.push({
      title: "\"通信中间件术语表\"",
      permalink: "\"/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/cyberrt/%E6%9C%AF%E8%AF%AD%E8%A1%A8/\"",
      content: "\"术语表 术语 缩写 含义 备注 CDR Common Data Representation 通用数据表示 DDS Data Distribution Service 数据分发服务 EDP Endpoint Discovery Protocol 端点发现协议 GUID Globally Unique Indentifier 全局唯一标识符 PDP Participant DiscoveryProtocol 参与者发现协议 PIM Platform Independent Model 平台独立模型 PSM Platform Specific Model 平台专用模型 RTPS Real-Time Publish-Subscribe 实时发布订阅 SEDP Simple Endpoint Discovery Protocol 简单端点发现协议 WLP Write Liveliness Protocol 写入者活跃性协议 \"",
      categories: "[\"自动驾驶\"]",
      tags: [],
      series: "[\"CyberRT专项总结\"]",
      date: "\"2025-03-27\""
    });
  
    searchIndex.push({
      title: "\"现代C++开发环境配置指南\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/c++%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/\"",
      content: "\"现代c++环境配置指南 引言 作为一个高强度冲浪的cpper，经常能在各种地方看到各式各样的大家诟病cpp的地方，其中比较多（但是相对温和）的一条就是，环境配置麻烦。这个问题有多少人说呢？最直观的一条佐证是，迄今为止，我的阅读、点赞、收藏量最多的一篇博文，居然就是随手写的一篇很粗糙的 —— vscode搭配clangd配置现代c++环境-CSDN博客 ，这背后又有多少被这编程第一关折磨的旁友\\u0026hellip;\\u0026hellip;\\n本人的CPP水平一言难尽，平常喜欢的就是精通各类语言的hello world，以及配置各种有的没的环境，那么闲话少叙，下面就对这个粗糙的环境配置的坑进行补档。\\nGoal 所谓CPP环境，具体指的是什么？ 高亮、跳转、补全、错误提示、依赖管理、构建、调试、运行、发布 具体开发环境搭建 vscode、vim/nvim、sublime，or clion、vs 提示 本文会对我所认知范围内的，C++的环境做全流程的介绍。也会介绍具体的工具、环境该如何配置，但囿于篇幅和本人的水平以及耐心，可能不会特别详细，更无法兼顾到所有的conner case。\\n比如我会说编译器是g++，构建工具是cmake，但是gcc和cmake如何安装到你的电脑上这种就没有介绍了。不过我想既然看官能够在茫茫互联网中找到我这篇博文，那么继续搜索搜索解决这些小问题自然不在话下。网上有相当多的且优质的关于某一个工具、软件如何下载安装配置的教程，如果你不清楚，直接STFW即可！\\n至于本文，如果您能只凭本文顺着就把环境配好了，那实在是您天赋异禀，天生就是干C嘎嘎的料子。如果不能，那么直接搜索不清楚的内容就好。我希望的是本文能给各位刚接触C++的朋友们一个稍微完整一点的，关于C++开发环境的认识，知道有哪些工具，分别是做什么用的。然后根据自己的需要去按图索骥！\\nCPP开发环境都包括哪些？ 什么是CPP开发环境呢？其实就是，你现在想阅读C++代码，或者想写C++代码，或者想把一个C++代码/项目跑起来，或者你想修改一个C++代码/项目，但是直接用记事本看/写你有不乐意，干看呢代码也不会自己运行。所以你需要在你的电脑上安装一系列的东西，来让这个看代码写代码改代码的过程，首先是能走通，然后是走得更舒服、更规范，这个就是配C++环境。\\n那么C++程序需要什么环境呢？看你的需求。\\n如果你想看代码，那么有个高亮、点击函数能自动跳转就可以了（这个需要lsp（不用管是啥，反正就是一个能理解你代码，还能让你跳转的东西））； 如果你想编辑代码，那么最好还要有自动补全（这个也是需要lsp），写的过程中还得有错误提示（这个动作叫做lint），告诉你这样写不对/不规范，写着写着还想格式化一下（format），不然看着不舒服； 如果你还想把代码跑起来，那你害得安装个编译器（就是gcc、clang、msvc之类的），编译器就是负责把你看到的.cpp或者.c这种文件，转变成.exe的可执行程序的东西（你看代码用的vscode/记事本这些，叫做编辑器）； 如果你想跑的代码，还不是单个文件，是一个正儿八经的项目，那么一般就需要安装下构建工具了（也就是makefile、cmake、xmake、bazel这些，具体是啥看你的项目用的啥） 如果一跑发现，哎呀出错了，那这个时候就需要调试了。调试就是找到程序中哪里写的不对，然后改正。你可以瞪眼调试，也可以通过一些调试器来做（也就是gdb，或者你用什么clion、visual studio来做） 如果是你自己写项目，标准库不够你用了，你迫切地想使用别人写好的一些库，可是怎么整到自己的项目中来呢？从哪整进来呢？整进来了怎么运行呢？（这也算是构建的内容，但也有一部分包管理的部分。c++虽然以没有统一的包管理而饱受诟病，但不代表它就没有，比如用查cmake，或者专业的vcpkg、conan） 还是你写的项目，千辛万苦，程序终于跑起来了！但是跑起来了就算没问题了吗？会不会只是暂时没有执行到有错的地方，跑一会儿或者多跑几次就出错了呢？当然会，比如大名鼎鼎的错误：内存泄漏、指针问题等。那么这个时候还需要用到一些工具来帮助你扫描这些潜在的漏洞（也就是valgrind、sanitizer、cppcheck等等等） 正确性满足了，但是程序只是能正确地跑，跑得快不快呢？跑得慢具体是哪一部分拖慢了程序呢？有追求的化，还要对性能进行优化，找到性能的瓶颈，这时候可能会用到一些性能分析工具（比如perf） 终于，一切就绪了，你写好了，也跑好了，现在就差拿去给别人用了。但是别人一用，缺少库文件！格式不兼容！或者我怎么编译不通过！！这时候你发现：哎早知道不学C嘎嘎了。。。 下面对各个步骤的推荐工具配置进行注意介绍：\\n高亮、补全、跳转 TLDR 这三类可以统一由一个LSP提供，也是最推荐的——clangd，此外就是用IDE自带的，或者VSCODE-CPP插件包。（还有一个在更新中的项目 clice-project/clice 有望超过clangd，不过目前还处于不可用状态。）\\n介绍与使用 clangd是一个语言服务器，提供代码高亮、补全、跳转的功能，但是不能直接用，因为既然是服务器，那么就要配合客户端使用，使用不同的IDE或编辑器对应的客户端不同。\\n服务器：clangd.exe clangd有很多版本，依赖llvm项目的库，根据你的系统自行选择版本安装，比如 clangd-14.exe、clangd-18.exe 等等。 clangd服务器直接理解单个文件没问题，但是要理解你的整个项目，需要依赖一个compile_commands.json文件。使用不同的构建工具时有不同的生成该文件的办法，比如CMake是使用cmake .. -DCMAKE_EXPORT_COMPILE_COMMANDS=ON，至于Make、Bazel等怎么生成，这里不再赘述。 客户端： vscode：安装 clangd - Visual Studio Marketplace （本机没有安装clangd时，会提示你要不要帮你安装） vim：安装coc插件后，用 cocInstall 安装coc-clangd（无需自己安装clangd） nvim：mason 安装 clangd 插件（无需自己处理clangd.exe） clion：默认就是，不用管了。(都用IDE了应该就没配环境的烦恼了吧？) 配置 clangd也可以进行配置，参考 官方手册 ，比如可以指定在后台索引、指定对待源文件的方式、指定语法检查的工具Diagnostics（就是后文中 clang-tidy 的配置）等等。\\n配置文件的路径，Linux在 $HOME/.config/clangd/config.yaml，windows在 %APPDATALOCAL%/clangd/config.yaml。（如果有不对的，可以直接打开vscode，安装clangd插件，然后 ctrl+shift+p 搜索 clangd open user config 即可找到）\\n这里给出一份我的配置\\nIndex: Background: Build CompileFlags: Add: [-xc++, -Wall, -std=c++20] Compiler: clang++ Diagnostics: ClangTidy: Add: [\\u0026quot;*\\u0026quot;] Remove: [ abseil*, fuchsia*, llvmlib*, zircon*, altera*, bugprone-easily-swappable-parameters, #相邻同类型参数容易混淆 cppcoreguidelines-avoid-c-arrays, # 不要用 C 数组 cppcoreguidelines-avoid-do-while, cppcoreguidelines-avoid-magic-numbers, # 不要用魔法数字 cppcoreguidelines-macro-usage, # 宏定义用法，不要定义常数之类的 cppcoreguidelines-non-private-member-variables-in-classes, # 所有成员变量都得是private的 cppcoreguidelines-owning-memory, # 用gsl::owner\\u0026lt;\\u0026gt; 来表示指针拥有对象的所有权 cppcoreguidelines-pro-bounds-array-to-pointer-decay, # 数组传参退化为指针 cppcoreguidelines-pro-bounds-pointer-arithmetic, # 不要使用指针运算 cppcoreguidelines-pro-bounds-constant-array-index, # 数组index当为常量 google-build-using-namespace, # 不要用using namesapce xxx; google-readability-todo, hicpp-avoid-c-arrays, # 禁用c风格数组 hicpp-braces-around-statements, hicpp-no-array-decay, # 防止数组传参退化为指针 misc-no-recursion, #递归 misc-non-private-member-variables-in-classes, # public成员变量，或许不该用，但是想用 modernize-avoid-c-arrays, # 同上 modernize-use-nodiscard, # 推荐使用 [[nodiscard]] modernize-use-trailing-return-type, # 不要每个都加上尾返回值类型 readability-braces-around-statements, readability-convert-member-functions-to-static, # 转为静态成员函数 readability-identifier-length, # 不检查变量名长度 readability-implicit-bool-conversion, # 隐式布尔类型转换 readability-magic-numbers, #同上 ] 格式化 推荐 clangd-format 简介与使用 可能看一些开源项目的时候应该就见过了，很多项目中都会有一个.clang-format文件，这个就是clang-format需要使用的配置文件，可以在里面指定样式。\\n你可以直接从认可的开源项目中clone一份来用，也可以找一个基础版本在上面修改，具体的选项参考 官方文档 使用时，在编辑器/IDE里面可以配合相应的格式化插件使用，编辑文件的时候实时格式化一下。\\n也可以直接使用命令行对文件格式化。比如使用如下命令 fd -e cpp -e cc -e h -x clang-format -i 可以做到对项目中所有的头文件源文件按照当前.clang-format文件指定的格式重新格式化一下。\\n配置 这里给出一个我经常用的clang-format配置：\\nDisableFormat: false # 关闭格式化 BasedOnStyle: Google Language: Cpp Standard: Latest ColumnLimit: 120 # 在大括号前换行: Attach(始终将大括号附加到周围的上下文), Linux(除函数、命名空间和类定义，与Attach类似), # Mozilla(除枚举、函数、记录定义，与Attach类似), Stroustrup(除函数定义、catch、else，与Attach类似), # Allman(总是在大括号前换行), GNU(总是在大括号前换行，并对于控制语句的大括号增加额外的缩进), WebKit(在函数前换行), Custom # 注：这里认为语句块也属于函数 BreakBeforeBraces: Custom BraceWrapping: # case标签后面 AfterCaseLabel: false # class定义后面 AfterClass: false # 控制语句后面 AfterControlStatement: Never # enum定义后面 AfterEnum: false # 函数定义后面 AfterFunction: false # 命名空间定义后面 AfterNamespace: false # ObjC定义后面 AfterObjCDeclaration: false # struct定义后面 AfterStruct: false # union定义后面 AfterUnion: false #ExternBlock定义后面 AfterExternBlock: false # catch之前 BeforeCatch: false # else之前 BeforeElse: false # lambda块之前 BeforeLambdaBody: false # while之前 BeforeWhile: false # 缩进大括号 IndentBraces: false # 分割空函数 SplitEmptyFunction: true # 分割空记录 SplitEmptyRecord: true # 分割空命名空间 SplitEmptyNamespace: true # 在 @property 后面添加空格, \\\\@property (readonly) 而不是 \\\\@property(readonly). ObjCSpaceAfterProperty: true # 访问说明符(public、private等)的偏移 AccessModifierOffset: -4 # 开括号(开圆括号、开尖括号、开方括号)后的对齐: Align, DontAlign, AlwaysBreak(总是在开括号后换行) AlignAfterOpenBracket: Align # 连续赋值时，对齐所有等号 AlignConsecutiveAssignments: Consecutive # 连续声明时，对齐所有声明的变量名 AlignConsecutiveDeclarations: Consecutive # 连续宏声明时，对齐空格 AlignConsecutiveMacros: Consecutive # 对齐连接符: DontAlign(不对齐)， Left(左对齐), Right(右对齐) AlignEscapedNewlines: Left # 水平对齐二元和三元表达式的操作数 AlignOperands: Align # 对齐连续的尾随的注释 AlignTrailingComments: true # 允许函数调用的所有参数在放在下一行 AllowAllArgumentsOnNextLine: true # 允许函数声明的所有参数在放在下一行 AllowAllParametersOfDeclarationOnNextLine: true # 允许短的块放在同一行 AllowShortBlocksOnASingleLine: Empty # 允许短的case标签放在同一行 AllowShortCaseLabelsOnASingleLine: true # 允许短的枚举放在同一行 AllowShortEnumsOnASingleLine: true # 允许短的函数放在同一行: None, InlineOnly(定义在类中), Empty(空函数), Inline(定义在类中，空函数), All AllowShortFunctionsOnASingleLine: Inline # 允许短的if语句保持在同一行 AllowShortIfStatementsOnASingleLine: Never # 允许短的Lambdas语句保持在同一行 AllowShortLambdasOnASingleLine: All # 允许短的循环保持在同一行 AllowShortLoopsOnASingleLine: true # 总是在返回类型后换行: None, All, TopLevel(顶级函数，不包括在类中的函数), # AllDefinitions(所有的定义，不包括声明), TopLevelDefinitions(所有的顶级函数的定义) # (clang-format-19: Renamed to BreakAfterReturnType) AlwaysBreakAfterReturnType: None # 总是在多行string字面量前换行 AlwaysBreakBeforeMultilineStrings: false # 总是在template声明后换行(clang-format-19: Renamed to BreakTemplateDeclarations) AlwaysBreakTemplateDeclarations: Yes # false表示函数实参要么都在同一行，要么都各自一行 BinPackArguments: true # false表示所有形参要么都在同一行，要么都各自一行 BinPackParameters: true # 在二元运算符前换行: None(在操作符后换行), NonAssignment(在非赋值的操作符前换行), All(在操作符前换行) BreakBeforeBinaryOperators: NonAssignment # 在三元运算符前换行 BreakBeforeTernaryOperators: true # 在构造函数的初始化列表的逗号前换行 BreakConstructorInitializers: BeforeColon # 在类声明继承列表的逗号前换行 BreakInheritanceList: BeforeColon # 允许中断长字符串 BreakStringLiterals: true # 描述具有特殊意义的注释的正则表达式，它不应该被分割为多行或以其它方式改变 CommentPragmas: \\u0026quot;^ ONE[ ]?LINE\\u0026quot; # 允许连续的名称空间声明将在同一行 CompactNamespaces: false # 构造函数的初始化列表的缩进宽度 ConstructorInitializerIndentWidth: 4 # 延续的行的缩进宽度 ContinuationIndentWidth: 4 # 去除C++11的列表初始化的大括号{后和}前的空格 Cpp11BracedListStyle: true # 继承最常用的指针和引用的对齐方式 DerivePointerAlignment: true # 修饰符后放置空行 EmptyLineAfterAccessModifier: Never # 修饰符前放置空行 EmptyLineBeforeAccessModifier: LogicalBlock # 修正命名空间注释 FixNamespaceComments: true # 需要被解读为foreach循环而不是函数调用的宏 ForEachMacros: - foreach - Q_FOREACH - BOOST_FOREACH # 需要解读为if的函数 IfMacros: - KJ_IF_MAYBE # 对#include进行排序，匹配了某正则表达式的#include拥有对应的优先级，匹配不到的则默认优先级为INT_MAX(优先级越小排序越靠前)， # 可以定义负数优先级从而保证某些#include永远在最前面 IncludeBlocks: Regroup IncludeCategories: - Regex: '^\\u0026lt;ext/.*\\\\.h\\u0026gt;' Priority: 2 SortPriority: 0 CaseSensitive: false - Regex: '^\\u0026lt;.*\\\\.h\\u0026gt;' Priority: 1 SortPriority: 0 CaseSensitive: false - Regex: \\u0026quot;^\\u0026lt;.*\\u0026quot; Priority: 2 SortPriority: 0 CaseSensitive: false - Regex: \\u0026quot;.*\\u0026quot; Priority: 3 SortPriority: 0 CaseSensitive: false # include块排序 IncludeIsMainRegex: \\u0026quot;([-_](test|unittest))?$\\u0026quot; # 缩进修饰符 IndentAccessModifiers: false # 缩进case块 IndentCaseBlocks: false # 缩进case标签 IndentCaseLabels: true # 缩进goto标签 IndentGotoLabels: false # 预处理缩进 IndentPPDirectives: None # 缩进extern块 IndentExternBlock: AfterExternBlock # 缩进宽度 IndentWidth: 4 # 函数返回类型换行时，缩进函数声明或函数定义的函数名 IndentWrappedFunctionNames: false # 添加尾部注释 InsertTrailingCommas: None # Lambda块缩进 LambdaBodyIndentation: Signature # 开始一个块的宏的正则表达式 MacroBlockBegin: \\u0026quot;\\u0026quot; # 结束一个块的宏的正则表达式 MacroBlockEnd: \\u0026quot;\\u0026quot; # 连续空行的最大数量 MaxEmptyLinesToKeep: 1 # 命名空间的缩进: None, Inner(缩进嵌套的命名空间中的内容), All NamespaceIndentation: Inner # 使用的包构造函数初始化式样式 PackConstructorInitializers: NextLine # 在call(后对函数调用换行的penalty PenaltyBreakBeforeFirstCallParameter: 19 # 在一个注释中引入换行的penalty PenaltyBreakComment: 300 # 第一次在\\u0026lt;\\u0026lt;前换行的penalty PenaltyBreakFirstLessLess: 120 # 在一个字符串字面量中引入换行的penalty PenaltyBreakString: 1000 # 对于每个在行字符数限制之外的字符的penalty PenaltyExcessCharacter: 1000000 # 将函数的返回类型放到它自己的行的penalty PenaltyReturnTypeOnItsOwnLine: 200 # 指针和引用的对齐: Left, Right, Middle PointerAlignment: Left # 预处理的缩进 PPIndentWidth: -1 RawStringFormats: - Language: Cpp Delimiters: - cc - CC - cpp - Cpp - CPP - \\u0026quot;c++\\u0026quot; - \\u0026quot;C++\\u0026quot; CanonicalDelimiter: \\u0026quot;\\u0026quot; BasedOnStyle: google - Language: TextProto Delimiters: - pb - PB - proto - PROTO EnclosingFunctions: - EqualsProto - EquivToProto - PARSE_PARTIAL_TEXT_PROTO - PARSE_TEST_PROTO - PARSE_TEXT_PROTO - ParseTextOrDie - ParseTextProtoOrDie - ParseTestProto - ParsePartialTestProto CanonicalDelimiter: pb BasedOnStyle: google # 引用对齐 ReferenceAlignment: Pointer # 允许重新排版注释 ReflowComments: true # 允许排序#include SortIncludes: CaseSensitive # 允许排序声明 SortUsingDeclarations: true # 单独的定义块 SeparateDefinitionBlocks: Always # 在C风格类型转换后添加空格 SpaceAfterCStyleCast: false # 在赋值运算符之前添加空格 SpaceBeforeAssignmentOperators: true # 在逻辑非操作符之后插入一个空格 SpaceAfterLogicalNot: false # 在' template '关键字之后会插入一个空格 SpaceAfterTemplateKeyword: true # 在用于初始化对象的c++ 11带括号的列表之前(在前面的标识符或类型之后)将插入一个空格 SpaceBeforeCpp11BracedList: false # 构造函数初始化式冒号前的空格是否删除 SpaceBeforeCtorInitializerColon: true # 在继承冒号前添加空格 SpaceBeforeInheritanceColon: true # 控制括号前的单独空格。 SpaceBeforeParens: ControlStatements SpaceBeforeParensOptions: AfterControlStatements: true AfterForeachMacros: true AfterFunctionDefinitionName: false AfterFunctionDeclarationName: false AfterIfMacros: true AfterOverloadedOperator: false BeforeNonEmptyParentheses: false # 在基于冒号的范围循环之前 添加空格 SpaceBeforeRangeBasedForLoopColon: true # 在尾随的评论前添加的空格数(只适用于//) SpacesBeforeTrailingComments: 2 # 在尖括号的\\u0026lt;后和\\u0026gt;前添加空格 SpacesInAngles: Never # 在容器(ObjC和JavaScript的数组和字典等)字面量中添加空格 SpacesInContainerLiterals: true # 在C风格类型转换的括号中添加空格 SpacesInCStyleCastParentheses: false # 在方括号的[后和]前添加空格，lambda表达式和未指明大小的数组的声明不受影响 SpacesInSquareBrackets: false # tab宽度 TabWidth: 4 # 使用tab字符: Never, ForIndentation, ForContinuationAndIndentation, Always UseTab: Never WhitespaceSensitiveMacros: - STRINGIZE - PP_STRINGIZE - BOOST_PP_STRINGIZE - NS_SWIFT_NAME - CF_SWIFT_NAME 错误告警（Lint） 推荐 clang-tidy 简介与使用 看这个又是clang开头的应该就知道了，clang-tidy也是llvm项目的一部分，使用方法大同小异，都是在当前项目下放一个配置文件，这个叫.clang-tidy，然后就可以在里面指定你想要的检查项目。使用clangd时会自动对相关项进行检查与告警。\\n不过在前面clangd的部分中提到过，在clangd的配置文件中也可以指定你的默认检查项，具体的可以返回参考相关部分\\n配置 一开始我是恨不得开启所有的检查项，以求代码的干净。这样确实能快速学到很多更加规范的写法，所以也可以尝试一下。\\n但是如果指定的检查项太多了的话，打开一个项目全是波浪线，也有点难受。因此学一阵子之后，还是建议回归到开启最关键的和常用的即可。仍然是可以从认可的开源项目中抓一个下来用，也可以参考官方手册进行修改。\\n这里给出我的一个比较精简的配置：\\n# REFERENCE https://blog.csdn.net/stallion5632/article/details/139545885 Checks: \\u0026quot;-*, clang-analyzer-core.*, clang-analyzer-cplusplus.*, modernize-redundant-void-arg, modernize-use-bool-literals, modernize-use-equals-default, modernize-use-nullptr, modernize-use-override, google-explicit-constructor, ; google-readability-casting, readability-braces-around-statements, readability-identifier-naming.ClassCase, readability-identifier-naming.StructCase, readability-identifier-naming.TypedefCase, readability-identifier-naming.EnumCase, readability-non-const-parameter, cert-dcl21-cpp, bugprone-undelegated-constructor, bugprone-macro-parentheses, bugprone-macro-repeated-side-effects, bugprone-forward-declaration-namespace, bugprone-bool-pointer-implicit-conversion, bugprone-misplaced-widening-cast, cppcoreguidelines-narrowing-conversions, misc-unconventional-assign-operator, misc-unused-parameters\\u0026quot; WarningsAsErrors: \\u0026quot;\\u0026quot; HeaderFilterRegex: \\u0026quot;\\u0026quot; CheckOptions: # 现代化（Modernize） - key: modernize-redundant-void-arg value: \\u0026quot;true\\u0026quot; # 检查并移除函数声明中冗余的 void 参数。 - key: modernize-use-bool-literals value: \\u0026quot;true\\u0026quot; # 建议使用布尔字面量 true 和 false 代替整数值 0 和 1。 - key: modernize-use-equals-default value: \\u0026quot;true\\u0026quot; # 建议在默认构造函数、复制构造函数和赋值运算符中使用 = default，以简化代码。 - key: modernize-use-nullptr value: \\u0026quot;true\\u0026quot; # 建议使用 nullptr 代替 NULL 或 0 来表示空指针。 - key: modernize-use-override value: \\u0026quot;true\\u0026quot; # 建议在覆盖基类虚函数时使用 override 关键字，以增加代码的清晰性和安全性。 # Google 代码风格（Google） - key: google-explicit-constructor value: \\u0026quot;true\\u0026quot; # 检查并建议在单参数构造函数中使用 explicit 关键字，以防止隐式转换。 - key: google-readability-casting value: \\u0026quot;true\\u0026quot; # 检查并建议使用 C++ 风格的类型转换（如 static_cast、dynamic_cast、const_cast 和 reinterpret_cast）代替 C 风格的类型转换。 # 可读性（Readability） - key: readability-braces-around-statements value: \\u0026quot;true\\u0026quot; # 建议在单行语句周围添加大括号，以提高代码的可读性和一致性。 - key: readability-identifier-naming.ClassCase value: \\u0026quot;CamelCase\\u0026quot; # 类名应使用 CamelCase 风格，例如 MyClassName。 - key: readability-identifier-naming.StructCase value: \\u0026quot;CamelCase\\u0026quot; # 结构体名应使用 CamelCase 风格，例如 MyStructName。 - key: readability-identifier-naming.TypedefCase value: \\u0026quot;CamelCase\\u0026quot; # 类型定义应使用 CamelCase 风格，例如 MyTypeDef。 - key: readability-identifier-naming.EnumCase value: \\u0026quot;CamelCase\\u0026quot; # 枚举名应使用 CamelCase 风格，例如 MyEnumName。 - key: readability-non-const-parameter value: \\u0026quot;true\\u0026quot; # 检查并标识非 const 参数，以提高代码的可读性和安全性。 # CERT 安全编码标准（CERT） - key: cert-dcl21-cpp value: \\u0026quot;true\\u0026quot; # 检查并标识在头文件中不应包含无命名空间的 using 声明和指令，以防止命名空间污染。 # Bug 检测（Bugprone） - key: bugprone-undelegated-constructor value: \\u0026quot;true\\u0026quot; # 检查并标识未委托的构造函数，以确保构造函数的正确性。 - key: bugprone-macro-parentheses value: \\u0026quot;true\\u0026quot; # 检查并建议在宏定义中使用括号，以防止潜在的错误。 - key: bugprone-macro-repeated-side-effects value: \\u0026quot;true\\u0026quot; # 检查并标识宏中重复的副作用，以防止潜在的错误。 - key: bugprone-forward-declaration-namespace value: \\u0026quot;true\\u0026quot; # 检查并标识命名空间前向声明的潜在问题。 - key: bugprone-bool-pointer-implicit-conversion value: \\u0026quot;true\\u0026quot; # 检查并标识布尔指针的隐式转换，以防止潜在的错误。 - key: bugprone-misplaced-widening-cast value: \\u0026quot;true\\u0026quot; # 检查并标识错误的宽化转换，以防止潜在的错误。 # 杂项（Miscellaneous） - key: misc-unconventional-assign-operator value: \\u0026quot;true\\u0026quot; # 检查并标识不常见的赋值操作符重载，以确保代码的一致性和可维护性。 - key: misc-unused-parameters value: \\u0026quot;true\\u0026quot; # 检测未使用的参数。 # C++ 核心指南（CppCoreGuidelines） # - key: cppcoreguidelines-narrowing-conversions # value: \\u0026quot;true\\u0026quot; # 检查并标识可能导致数据丢失的窄化转换。 构建 单文件（编译选项） 构建，对于单个文件来说其实就是编译嘛，直接用 gcc/g++ 或者 clang/clang++ 加上一堆编译选项就可以了。但是编译选项比较多，很多比较偏的我也不甚精通，所以就列出几个常用的，能把代码跑起来就行，后面的还需进一步学习。比如菜鸟上有一个很直观的介绍编译选项的教程 GCC 参数详解 | 菜鸟教程 最简单的命令就是 g++ demo.cpp -o demo，得到的demo就是可执行文件（-o， output，用于指定输出文件的名字）。这背后有很多过程，如果想了解，或者编译出错了，那么就再进一步去了解相关的编译选项。\\n编译流程相关 编译的流程是: 源文件 -\\u0026gt; 预处理 -\\u0026gt; 汇编 -\\u0026gt; 编译 -\\u0026gt; 链接，这些流程都有对应的编译选项，也就是说你可以只编译到任意的中间步骤去查看整成什么样子了。\\ng++ -E demo.cpp -o demo.i：-E 是说只进行预处理（把你include的头文件展开、宏展开等） g++ -S demo.cpp -o demo.s: -S 是说只进行汇编，不编译链接，得到的是汇编码 g++ -c demo.cpp -o demo.o: -c 是说只编译得到目标文件，不进行链接 头文件库文件相关 当然有时候需要处理一些跟头文件库文件相关的内容\\ng++ demo.cpp -o demo -I../include -lmylib -L/home/usr/mylib：-I指定头文件查找位置，-L指定库文件查找位置，-l指定你想链接的库。-lmylib对应的库文件全名实际上是 libmylib.so 或者 libmylib.a，即-l跟的名字是掐头去尾得到的 g++ -static demo.cpp -o demo -lmylib: -static 指定了静态链接（简单来说就是把库文件打包进可执行文件里面，动态链接的库是在别的地方，程序运行的时候才加载），既然是静态链接，要注意你必须得有 libmylib.a这个文件，.so只没办法让你静态链接得。 g++ -fPIC -shared mylib.cpp -o libmylib.so: 这个用于生成动态库，-fPIC指定生成与位置无关的代码，-shared 说要生成动态库 ar rcs libmylib.a demo1.o demo2.o: 那么这个就是生成静态库的方法了，这里使用的不是g++，而是ar这个工具。静态库类似一种压缩包把，ar是个打包工具，你要先用g++生成目标文件，然后再将他们打包成静态库。rcs中，r表示添加文件到归档中，如果存在则替换；c表示归档不存在则创建；s表示创建索引 有时候不想每次都手动指定路径，可是头文件和库又不在默认位置，那么可以通过设置环境变量来解决。可以参考 详解Linux下环境变量C_INCLUDE_PATH、CPLUS_INCLUDE_PATH、CPATH以及常见错误_include path-CSDN博客 C_INCLUDE_PATH/CPLUS_INCLUDE_PATH/CPATH：它们分别是C、C++、C\\u0026amp;C++程序在编译时，默认的头文件搜索位置 LIBRARY_PATH：编译时默认的库文件搜索位置 LD_LIBRARY_PATH：运行时默认的库文件寻找位置 调试优化告警标准 然后是，调试、优化、告警、标准这些，还算常用，但不知道怎么归类了，就叫做风格化吧：\\ng++ demo.cpp -o demo -g: -g 是说要生成一个可以调试的文件，也就是说这个会在可执行文件中保留一些符号信息，用途就是调试，文件体积和性能相对不带的自然会弱一些。 g++ demo.cpp -o demo -O3：-O3 是一个优化选项，让编译器采用最激进的方式对你的源文件进行优化，以得到更好的性能（据说有可能有不稳定的情况，反正我没碰到过，相信编译器了），当然自然也有 -O2 -O1 -O0 优化越来越保守，-O0是不做任何优化，保留原汁原味的代码体验，一般调试的时候用 g++ demo.cpp -o demo -Wall -Werror: W就是warn，所以 -Wall 就是把所有的警告都报告出来，-Werror 就是把告警看作是一种错误，这俩放一块要求代码中不能有一处告警，否则就是编译出错直接中止，适合对代码有追求的人和项目。 g++ demo.cpp -o demo -g -fno-inline：-fno-inline不内联函数，能够使得调用链更清晰 g++ demo.cpp -o demo -std=c++20: -std 指定了你使用的c++标准 项目依赖查看 有时候需要看看项目的依赖，看看g++编译的时候到底都给你找了什么东西引用上了链接上了\\ng++ -MM demo.cpp \\u0026gt; demo.d: -MM 用于生成文件的所有依赖关系（除了标准库，-M则包括标准库头文件），一般用于Makefile中，可以做到头文件变动时也重新编译文件（否则只有源文件变动才重新编译，可能会出问题）。.d文件长这样demo.o: demo.cpp /usr/include/cstdio \\u0026hellip; g++ -H demo.cpp -o demo: -H 用于打印层次化的头文件引用情况，比如你直接引用了ABC，A有引用了DEF，B引用了GH，等等等等，都给你列出来 g++ -v demo.cpp -o demo: -v用于可视化整个编译过程，用了谁编译、编译选项如何、去哪里查找的头文件等等。如果编译过程出问题了，可以检查一下 g++ -v -E c++ -: 这个用于打印编译c++时的依赖搜索路径，可能个人比上面的用的多些。常见的场景：我已经安装了某个库了，或者我已经修改了某个头文件了，但是编译器里不符合预期，可以看看是不是压根没查找到它，查找的是别的同名的（比如在wsl中编译，链接的却是windows上msys2中的库） g++ -print-file-name=libmylib.a: -print-file-name 直接打印出，如果让g++去找这个库的话，它的查找路径 性能优化相关 性能优化的值得单开一部分\\ng++ -ftime-trace demo.cpp -o demo: -ftime-trace 用于显示分析编译耗时 Sanitizer: 是 LLVM/Clang 和 GCC 编译器提供的一套工具，用于在运行时检测程序中的各种错误。它的核心思想是通过在编译时插入额外的检查代码，来捕获内存错误、未定义行为、数据竞争等问题。编译完直接运行程序，然后会给你输出错误。后文 Sanitizer一节 还会再行介绍（列举一些参考文档罢了，用法就在这里） g++ -fsanitize=address -o demo demo.cpp: address 启用 AddressSanitizer，这是一个内存错误检测工具，能够检测内存泄漏、缓冲区溢出、使用未初始化的内存等问题 fsanitize=leak：仅检测内存泄漏 fsanitize=undefined：检测未定义行为 fsanitize=thread：检测多线程问题 项目构建 构建工具概要介绍 项目构建就要使用到构建工具了，常见的有 Make，Ninja，CMake，XMake，QMake, Bazel，VSProject \\u0026hellip;\\nMake: make是一个，怎么说呢，原始而强大的东西，可以很简单，比如你嫌弃用几个g++命令构建出目标文件，再手动链接比较麻烦，就把他们写进makefile中，然后make一下就可以了。这个时候的makefile就像一个shell脚本一样，你直接写shell脚本构建也是一样的。（所以有时候拿makefile当一个脚本启动器也是很不错的）但是它也可以像邪恶的古神一样很复杂，有很多高级配置，依赖查找balabala，复杂到维护这个项目Makefile的人奔溃到谁改一下下就吼谁（只是耳闻） Ninja：ninja和make类似，它是为了快速构建而生的。我见过手写makefile的，但是见识浅薄，身边没有手写ninja.build的，ninja更多是只负责快速编译，至于如何编译还是使用CMake直接生成的多一些。 CMake：c++的事实构建标准，这一句评价就够了。你可以会很多花里呼哨的构建方式构建器，你可以听很多人说它不好，xxx比它友好一万倍快十万倍，但是你最好还是要会使用它，因为它是事实标准。它的使用我知道一些，但是这里的空间太小了，写不下 XMake：这就是一个CMake的替代品，不过人家作者说了，无意取代CMake，只是在构建什么个人项目、小项目的时候提供一种更友好更快速的选择。它使用lua来写构建脚本，会lua的有福了。同时自带包管理（加分项）。然后就是，可能更新快一些吧，比如比CMake更支持c++20的Modules。 QMake：Qt的构建器，没用过，也没用过Qt。不过现在Qt已经拥抱CMake了，所以，没有必要也没有兴趣的话应该不用管。 Bazel：谷歌做的构建器，使用一种类似python的语法写构建脚本。优势是使用了分布式缓存，构建更快；然后是考虑到了构建环境，可以做到相同环境必定能复现构建；然后还有就是分析目标更精准吧，并行化好、重复构建最少。等等吧，反正就是又快又对。百度的Apollo项目使用的是这个，当然还有很多别的项目也都用了。 VSProject：使用Visual Studio开发的话默认这个，听说很方便，但是我用VS不多，对这个不甚了解 下面就简单介绍下Make、CMake、Bazel，是真的简单介绍，深入学习的话还是要进一步深入学习的。\\nMake Reference 跟我一起写makefile 这个是比较出名的教程了，想写就跟他一起写吧 之间随便搜罗的一个参考，没细看过 简单来说makefie就是指定目标，指定目标的依赖，然后指定怎么从依赖得到目标的一个脚本，比如:\\nrebuild: @rm -rf build \\u0026amp;\\u0026amp; cd build \\u0026amp;\\u0026amp; cmake .. -G\\u0026quot;Ninja\\u0026quot; 这里我指定了目标是rebuild，依赖是空，得到目标的办法是执行那一长串命令。这实际上不是编译，只是给那一长串命令起了个名字叫 make rebuild。makefile不只可以用来构建，也可以当作脚本启动器。\\nWarning 不过需要注意的是，makefile中的命令是新启动一个shell来做的，你可以指定使用shell还是使用bash，但你没法指定它不启动一个新的。所以想在makefile中设置当前的环境变量是不可以的\\n当然它的主业还是构建，简单介绍一些特性，然后直接给几个例子揣摩一下吧\\n特殊变量\\n$@ Target $^ 所有依赖，空格分隔 $\\u0026lt; 第一个依赖 模式替换\\n$(patsubst \\u0026lt;pattern\\u0026gt;,\\u0026lt;replacement\\u0026gt;,\\u0026lt;text\\u0026gt; )\\n查找中的单词（单词以“空格”、“Tab”或“回车”“换行”分隔）是否符合模式，如果匹配的话，则以替换。\\n这里，可以包括通配符“%”，表示任意长度的字串。如果中也包含“%”，那么，中的这个“%”将是中的那个“%”所代表的字串。（可以用“\\\\”来转义，以“%”来表示真实含义的“%”字符）\\n$(patsubst %.c,%.o, a.c b.c) # 把字串 “a.c b.c” 符合模式[%.c]的单词替换成[%.o]，返回结果是 “a.o b.o” 变量替换引用\\n对于一个已经定义的变量，可以使用“替换引用”将其值中的后缀字符（串）使用指定的字符（字符串）替换。格式为$(VAR:A=B)或者${VAR:A=B}\\n意思是，替换变量“VAR”中所有“A”字符结尾的字为“B”结尾的字。“结尾”的含义是空格之前（变量值多个字之间使用空格分开）。而对于变量其它部分的“A”字符不进行替换。\\nfoo := a.o b.o c.o bar := $(foo:.o=.c) # 注意变量不要带 $ SRCS_NODIR := $(notdir $(wildcard $(SRC_DIR)/*$(SRC_SUFFIX))) OBJS_NODIR := $(SRCS_NODIR:$(SRC_SUFFIX)=$(OBJ_SUFFIX)) 模板1\\n# 一个适合中小规模的makefile模版，基本上自己按照实际情况指定一下 源文件，目标文件，头文件目录，以及源文件后缀就行了。 # --------------------------------------------------------------------------- # commands # --------------------------------------------------------------------------- CC := gcc LINK := gcc RM := rm -rf MV := mv TAR := tar MKDIR := mkdir # --------------------------------------------------------------------------- # settings # --------------------------------------------------------------------------- SRC_SUFFIX := .c OBJ_SUFFIX := .o LIB_SUFFIX := .a BIN_SUFFIX := .exe DLL_SUFFIX := .so INC_PREFIX := -I LIB_PREFIX := -L OPT_C := -c OPT_OUT := -o OPT_LINKOUT := -o CFLAGS := $(OPT_C) LIBFLAGS := -Debug # --------------------------------------------------------------------------- # directories # --------------------------------------------------------------------------- SRC_DIR := ./src OBJ_DIR := ./obj INC_DIR := ./inc LIB_DIR := ./lib /usr/local/lib /lib /usr/lib # --------------------------------------------------------------------------- # common settings # --------------------------------------------------------------------------- SRCS := $(wildcard $(SRC_DIR)/*$(SRC_SUFFIX)) OBJS := $(patsubst $(SRC_DIR)/%$(SRC_SUFFIX),$(OBJ_DIR)/%$(OBJ_SUFFIX),$(SRCS)) INCS := $(addprefix $(INC_PREFIX), $(INC_DIR)) LIBS := $(addprefix $(LIB_PREFIX), $(LIB_DIR)) $(LIBFLAGS) TEMPFILES := core core.* *$(OBJ_SUFFIX) temp.* *.out typescript* # --------------------------------------------------------------------------- # make rule # --------------------------------------------------------------------------- TARGET := loader .PHONY: all clean all: $(TARGET) clean: $(RM) $(TARGET)$(BIN_SUFFIX) $(OBJS) $(TARGET):$(OBJS) $(LINK) $(OPT_LINKOUT)$(TARGET)$(BIN_SUFFIX) $(LIBS) $(OBJS) $(OBJS):$(OBJ_DIR)/%$(OBJ_SUFFIX):$(SRC_DIR)/%$(SRC_SUFFIX) $(CC) $(CFLAGS) $(INCS) $(OPT_OUT)$@ $\\u0026lt; 模板2\\nCXX := g++ SRC_DIR := ./src OBJ_DIR := ./build BIN_DIR := ./bin INC_DIR := ./include VPATH = $(INC_DIR) $(OBJ_DIR) $(SRC_DIR) vpath %.h $(INC_DIR) # 一种搜索源文件的方式 # SRC_DIRS = $(shell find $(SRC_DIR) -maxdepth 3 -type d) # SRCS = $(foreach dir, $(SRC_DIRS), $(wildcard $(dir)/*.cpp)) # TODO: 这样子出来的目标文件，在jing'tai时就找不到依赖了 # OBJS := $(OBJ_DIR)/$(notdir $(patsubst %.cpp, %.o, $(SRCS))) SRCS := $(wildcard $(SRC_DIR)/*.cpp) OBJS := $(patsubst $(SRC_DIR)/%.cpp, $(OBJ_DIR)/%.o, $(SRCS)) INCS := $(addprefix -I, $(INC_DIR)) BUILDING_DIRS := $(OBJ_DIR) $(BIN_DIR) TARGET := adb_lab2.exe RUN := run.sh $(TARGET) : $(BUILDING_DIRS) $(OBJS) $(CXX) -o $(BIN_DIR)/$(TARGET) $(OBJS) @touch $(RUN) @echo \\u0026quot;$(BIN_DIR)/$(TARGET)\\u0026quot; \\u0026gt; $(RUN) # 这里的前缀不能少。makefile不会自动去VPATH里面找这几个目标，而是直接当成新的目标来对待 $(OBJ_DIR)/BufferPoolManager.o : BufferPoolManager.h LRUReplacer.h $(OBJ_DIR)/DataStorageManager.o : DataStorageManager.h $(OBJ_DIR)/LRUReplacer.o : LRUReplacer.h $(OBJ_DIR)/main.o : BufferPoolManager.h # 一个创建运行时依赖文件夹的方法 $(BUILDING_DIRS) : @mkdir $@ # 这叫 静态模式 $(OBJS) : $(OBJ_DIR)/%.o : $(SRC_DIR)/%.cpp $(CXX) -o $@ -c $\\u0026lt; $(INCS) .PHONY: all clean output all : $(TARGET) clean: -rm -rf $(BUILDING_DIRS) test.dbf $(RUN) output: @echo $(SRCS) @echo -------------- @echo $(OBJS) 模板3\\nCC := gcc CC_INCLUDE_FLAGS := -I ./include/ CC_FLAGS := $(CC_INCLUDE_FLAGS) -g # 程序执行的参数 ARGS := ~/codes DIR_SRC := ./src DIR_OBJ := ./build DIR_EXE := ./bin SRCS := $(shell find $(DIR_SRC) -name \\u0026quot;*.c\\u0026quot;) OBJS := $(patsubst $(DIR_SRC)/%.c, $(DIR_OBJ)/%.o, $(SRCS)) DPTS := $(patsubst %.c, %.d, $(SRCS)) DIRS := $(DIR_OBJ) $(DIR_EXE) target := $(DIR_EXE)/my_ls_pro $(target): $(DIRS) $(OBJS) $(CC) $(OBJS) -o $@ $(DIRS): @mkdir $@ $(DIR_OBJ)/%.o: $(DIR_SRC)/%.c $(CC) $(CC_FLAGS) -c $\\u0026lt; -o $@ %.d: %.c @set -e; \\\\ rm -f $@; \\\\ $(CC) -MM $(CC_FLAGS) $\\u0026lt; $(CC_INCLUDE_FLAGS) \\u0026gt; $@.$$$$.dtmp; \\\\ sed 's,\\\\(.*\\\\)\\\\.o\\\\:,$*\\\\.o $*\\\\.d\\\\:,g' \\u0026lt; $@.$$$$.dtmp \\u0026gt; $@;\\\\ rm -f $@.$$$$.dtmp -include $(DPTS) clean: rm -f $(OBJS) rm -f $(DPTS) run: make $(target) $(ARGS) CMake 这里只说基本的，拷下来一个cmake项目怎么运行。具体的CMake项目怎么写怎么组织，可以参考项目 quick-cmake GitHub 一般来说分为三步：\\n项目根目录创建一个build文件夹，然后cd进去。在build文件夹中进行构建，cmake生成的文件就会都在build文件夹内，不会污染源项目，所以十分推荐这种方式。（当然不cd进去直接用 -B build 指定也可以） 运行cmake，获取到构建文件。是的，cmake只负责生成构建文件，具体的构建还是由make、ninja这些完成的。 常用的构建命令就是 cmake .. -G\\u0026quot;Ninja\\u0026quot; -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release -G 指定用谁来构建，有很多选项，比如 -G\\u0026quot;Unix Makefiles\\u0026quot;生成makefile， -G\\u0026quot;MinGW Makefiles\\u0026quot;在Windows上使用mingw的makefile，还可以指定使用你的Visual Studio 2017 2022啥的 -Dxxx=yyy，-D用于设置变量的值 运行构建命令，得到目标 make -j8 生成的 makefile，就用make，-j8 指定 8 个线程 ninja -j8 cmake \\u0026ndash;build . -j8： 如果不知道生成的啥，或者想通用性，就用这个 如果需要安装，就再加一步 make install or ninja install or cmake --build . --target=install。是的，install本身也只是一个target而已\\nBazel bazel我还在学，这里只说环境怎么配置就好了。想学习第一手资料还是去看 官网 首先需要安装的有：\\nbazelisk : 与 bazel 接口完全相同，区别在于这个能自动下载、切换到你需要的bazel版本，也是官方推荐安装的。详情看 使用 Bazelisk 安装 / 更新 Bazel buildtools : （scoop install bazel-buildtools）包括格式化工具 buildifier ，以及另外两个我没咋用到的 buildozer 和 unused_deps，项目 readme 中有说明 starpls : lsp 服务。目前 bazel 官方插件推荐 的有两个（另一个是 bazel-lsp ，但是恰好它的 6.3 版本在我这有 bug 用不了） bazel-vscode : vscode 插件，all in one。包括构建、高亮、补全。但是要依赖上述几个工具 vscode的配置如下：\\n{ \\u0026quot;bazel.executable\\u0026quot;: \\u0026quot;bazel\\u0026quot;, \\u0026quot;bazel.buildifierExecutable\\u0026quot;: \\u0026quot;buildifier\\u0026quot;, \\u0026quot;bazel.lsp.command\\u0026quot;: \\u0026quot;starpls\\u0026quot;, // alternatively: \\u0026quot;bazel-lsp\\u0026quot; \\u0026quot;bazel.enableCodeLens\\u0026quot;: true, } 代码补全\\n各语言源码补全参考 将 Bazel 与 IDE 集成 具体到 C/C++ 来说一般是生成 compile_commands.json 文件，官方推荐有两种方式：\\nkiron1/bazel-compile-commands ：在 Bazel 工作区中运行 bazel-compile-commands //... 以生成 compile_commands.json 文件。compile_commands.json 文件可让 clang-tidy、clangd (LSP) 和其他 IDE 等工具提供自动补全、智能导航、快速修复等功能。该工具使用 C++ 编写，并使用 Bazel 的 Protobuf 输出来提取编译命令。 hedronvision/bazel-compile-commands-extractor ：可在各种可扩展的编辑器（包括 VSCode、Vim、Emacs、Atom 和 Sublime）中启用自动补全、智能导航、快速修复等功能。它可让 clangd 和 ccls 等语言服务器以及其他类型的工具利用 Bazel 对 cc 和 objc 代码编译方式的理解，包括它如何为其他平台配置交叉编译。 交叉编译工具链\\n这里以常见的在windows上修改编译器为mingw（默认为MSVC）为例，说明工具链怎么修改。参考仓库 bazel-mingw-toolchain 使用blzmod的话，MODULE.bazel添加如下内容：\\nbazel_dep( name = \\u0026quot;mingw_toolchain\\u0026quot; ) git_override( module_name = \\u0026quot;mingw_toolchain\\u0026quot;, remote = \\u0026quot;https://github.com/vvviktor/bazel-mingw-toolchain.git\\u0026quot;, commit = \\u0026quot;0ea42a31c45f0ff146058cecd124053b6915205e\\u0026quot;, ) 修改.bazelrc文件\\nbuild --incompatible_enable_cc_toolchain_resolution # allow bazel to use custom toolchains build --define=MINGW_PATH=\\u0026quot;path/to/mingw\\u0026quot; # define path to yuor mingw location, for example: build --define=MINGW_PATH=\\u0026quot;C:/msys64/ucrt64\\u0026quot; build --define=GCC_VERSION=\\u0026quot;gcc version\\u0026quot; # define gcc version used, for example: build --define=GCC_VERSION=\\u0026quot;13.2.0\\u0026quot; 其余的参考原仓库即可\\n依赖管理 有些规模的C++程序，除了标准库外，一般都会依赖一些别的三方库，或者是自己造的轮子库，比如什么日志库、网络库等等。这些依赖大体上可以分为三种，一种是，静态库、动态库，还有一种 header-only 的库，顾名思义就是只有头文件，不用额外让你的程序链接上库文件（它的优劣可以参考这个 c++ - Benefits of header-only libraries - Stack Overflow ）。\\n如何正确防止三方库的位置、处理编译选项，使得程序能够跑起来，似乎是 编译 部分的事。确实是这样，因为很多程序跑不起来的重要的原因之一，就是第三方依赖找不到、找不对、编译不过，而C++在这一问题上尤为严重。主要是相比较其他主流语言如python(pip)、jvav(maven)、rust(cargo)等，C++没有一个主流的、让各方都信服的包管理工具。可能一方面是C++话事人委员会不care这个，另一方面或许是，我称之为Cppers的傲慢。都用c++了，轮子不是自己造的，那算什么用c++？（或许这也是一种乐趣吧）。\\n所以自己写的包，或者peer写的包，就只能通过一种比较原始的方式，集成到项目中来——把他们下载下来、放到指定的位置，然后手动在编译选项中指定它们。但其实也没有那么地原始。从某种程度上来说cmake、bazel这些构建工具也可以算是一种包管理器，比如cmake的find_package() find_library()，也可以相当自动地帮你完成依赖寻找的任务。只不过前提是你用的库按照cmake的方式组织了，写好了Findxxx.cmake这种。不过一般也都会有，毕竟cmake是事实标准。所以实际上，没有包管理器这件事，是有些不方便，但是其实也并没有一些CPP小黑子说得那么地，无药可救。\\n但是，事实上C++也是有好用的包管理器的，虽然不是官方的，但也并非什么小作坊的作品。如果你就是习惯有个包管理，那还是相当值得一用的。\\nAttention 由于C++的编译产物跟平台是强相关的，windows还是linux，x86还是arm，之间是完全不兼容的。因此这些个包管理呢实际上并不是给你下载个二进制文件就直接用了，而是把源码下载下来，然后用你机器上的工具，自动的给你编译好，再放到一个可以方便找到的地方。所以使用它和不使用的区别就是，它可能比你更会编译这个库。当然，都用它来做，更方便管理。\\nvcpkg Tldr 微软巨硬做的C++包管理，如果不知道用什么，就相信品牌的力量。支持自动下载、编译、管理三方库，与 CMake 深度集成。支持几千个C++库了，基本涵盖所有常用的。详细学习请参考 vcpkg 文档 | Microsoft Learn 使用起来很简单，跟着下面做就行了。\\n# 安装 git clone https://github.com/microsoft/vcpkg cd vcpkg ## 执行引导脚本（Windows 使用 .\\\\bootstrap-vcpkg.bat） ./bootstrap-vcpkg.sh # 添加环境变量（可选） export VCPKG_ROOT=\\u0026quot;/path/to/vcpkg\\u0026quot; export DEFAULET_TRIPLET=\\u0026quot;x64-linux\\u0026quot; export PATH=$VCPKG_ROOT:${PATH} # vcpkg还有一个一键和 visual studio集成的命令，但我不咋用vs，给搞忘了。有兴趣可以搜一下 然后你就可以使用vcpkg了。需要注意的是，vcpkg有两个比较重要的环境变量，VCPKG_ROOT和DEFAULT_TRIPLET，前者用于搜索vcpkg的位置，后者，triplet，三元组，就是描述你平台的三个关键词，比如x64-linux-static，就说明要安装x64版本linux上的静态库。具体的参考 Triplet | Microsoft Learn # 搜索 vcpkg search spdlog # 安装 vcpkg install spdlog # 在cmake中使用 ## 法 1，使用vcpkg的toolchain。 注意 toolchain的指定要在 project(xxx) 之前 set(CMAKE_TOOLCHAIN_FILE \\u0026quot;$ENV{VCPKG_ROOT}/scripts/buildsystems/vcpkg.cmake\\u0026quot;) find_package(spdlog REQUIRED) target_link_libraries(your_target PRIVATE spdlog::spdlog) ## 法2：设置CMAKE_PREFIX_PATH，这样相当于只是告诉cmake了查找库的位置，侵入性更小 list(APPEND CMAKE_PREFIX_PATH \\u0026quot;$ENV{VCPKG_ROOT}/installed/$ENV{VCPKG_DEFAULT_TRIPLET}\\u0026quot;) find_package(spdlog REQUIRED) target_link_libraries(your_target PRIVATE spdlog::spdlog) ## 更详细专业的用法参考 https://learn.microsoft.com/zh-cn/vcpkg/users/buildsystems/cmake-integration conan conan是一个去中心化的c++包管理，可以指定具体的库版本（这么说是因为vcpkg在哪个场景来着，只支持使用最新版的库），可以构建自己的库仓库。使用的人也很多，支持的库也有几千个。做这种包管理的，还做出名堂来的，你所了解的常用的库肯定都会支持，所以这方面不必担心。\\n不过我用的不多，详情还是搜一下。以下内容来自deepseek。\\n# 安装 pip install conan # 创建默认 profile（生成 ~/.conan2/profiles/default） conan profile detect # 创建配置文件 conanfile.txt [requires] fmt/10.1.0 [generators] CMakeDeps CMakeToolchain [layout] cmake_layout # 安装依赖并生成配置 mkdir build \\u0026amp;\\u0026amp; cd build conan install .. --build=missing # 集成到 CMake include(${CMAKE_BINARY_DIR}/generators/conan_toolchain.cmake) find_package(fmt REQUIRED) target_link_libraries(your_target PRIVATE fmt::fmt) apt / pacman 严格来说呢，这些个并不是C++的包管理！它们是系统的包管理，但是很多时候你缺少依赖，直接一个sudo apt install libxxx-dev也就解决了（在arc linux，或者在msys2中，可以是pacman -S libxxx，还可能是yum等等等等）。那么，这怎么不算管理呢？（这个下载的是真的二进制文件，没有编译的步骤，跟前面说的vcpkg和connan那种包管理不同）\\n不过需要注意的是，通过这样安装的库，是全局的。有可能你这个项目安装了这个版本的库，下个项目想用的是另一个版本的，这就会导致冲突。不过对于很多基础的库，像什么boost啦、opencv啦，直接安装是没问题的，也是最最方便的（甚至都可以不用加编译选项）。\\n调试 程序跑起来有错误是相当正常滴，用各种方法，找到错误在哪并修改，再找再改，直到把程序跑起来的过程就是调试。\\n当然这里说得更广义一些。有时候程序只是跑起来了，但可能并不那么健康。能跑不一定就对，只是暂时没执行到有错误的逻辑而已。如何查找预防这种隐藏起来的错误，也算调试了。还有就是，程序写好了，性能如何呢？跑得对，但是跑得慢，怎么让它快起来，优化性能，也是一种调试。下面逐个进行简单介绍。\\n程序调试 找错误一般来说有以下几种方法：\\n瞪眼法 这应该是最直观也是最常用的。不管你用的什么构建工具，编译出错，它都会告诉你错误是什么。有的报错信息很直观，你直接就能看懂。有的报错信息很冗长，像乱码一样，刚接触你可能看不懂，但是看多了，一看到某种乱码的模式，根据经验，或者捕捉关键词，就能立马明白错误是什么，应该怎么改。读报错信息，然后明白过来哪里错了，这就是瞪眼法。\\n关于冗长的报错信息如何看，可以参考《Effective STL》的 第49条：学会分析与STL相关的编译器诊断信，简单来说就是，C++有很多模板，即使你没用，你用的标准库、三方库中也会用。报错信息看着很长，其实很多都是模板展开后的结果。肉眼排除掉冗余信息（或者写个过滤的小工具 ErrorReducer.py ）能够使得错误更直观一些。不过这些可能都是老巴式了，直接复制粘贴到AI中，让ai帮你分析，也是不错的。不过最好分析完了理解一些，不然每次都只会复制粘贴问AI，长进不大。\\nprint 大法 当小脑袋瓜子栈溢出的时候，反应不过来到底是怎么个错误法了，一般就会选择在代码的某些位置上写上一串神秘字符：printf(\\u0026quot;【x=%d, y=%s】\\\\n\\u0026quot;, x, y);或者std::cout\\u0026lt;\\u0026lt;\\u0026quot;========\\\\n\\u0026quot;; 或者 LOG(\\u0026quot;XXXXXXX\\u0026quot;);这是很直观的，也基本是无师自通的。\\n不管是printf还是直接读日志，都可以算是print大法了吧，即，在程序的关键位置输出一些有特征的信息，从而判断程序运行情况。有人嘲笑这种太土太Low，不会开个gdb打个断点就不能算是程序员；有人对这种推崇备至，说是真正高级的程序员谁tm打断点，都是看日志。我的看法是，管它高级不高级，有效的最快最对的就是最好的。\\nWarning 刚学的时候小脑袋瓜子不要装一堆饭圈的东西，这个高级那个老土。有用就行，装杯那是以后的事。程序调完了，丝滑运行了，喝杯茶冲冲浪，看看网友吹B，瘾上来了也下场小装一下，那会才是需要分辨谁High谁Low的时候。\\nReference 简单的print太过简单了，可以参考这个 header-only 单头文件库 dgb-macro ，可以帮你更好的print。（灵感来源rust的dbg!宏）\\ngdb gdb是一个命令行运行的黑窗口工具，作用是可以让你在程序运行的时候，让它在指定的位置停下，然后还能让你读取停下来的位置的各种变量值是多少，的一个工具。非常强大，但是背后的原理也不算太复杂，通过什么系统调用实现的感兴趣也可以一学，甚至可以一做。\\n要想使用gdb，在编译程序的时候要添加上一个 编译选项 -g，保留程序的各种符号信息，作用是调试的时候能看到源代码，如果不加也能调试，但是看不到源码（可以硬看汇编）。\\n调试的工具有很多，但是基本的原理都一样，就是打断点，分析断点，分析变量取值，分析调用栈等等。这里简单罗列一下：\\ngdb：原汁原味，说开就开。缺点是命令行使用不够直观，程序是运行了是断点了，但是看不到对应的源代码是什么，很难受。不过gdb也有一个tui模式，可以呈现简单的界面。可以通过layout src/split/asm等切换布局，一定程度上解决了看不了源码的问题。 lldb：llvm项目的，和gdb的关系，大概就像是clang和gcc的关系吧 cgdb ：值得推荐的一个工具，完美解决了gdb没有界面不好看的问题，能够将界面分为两块，左边显示源代码，可以直接打断点，右边显示gdb，直接操作gdb。支持VIM快捷键。（如右图所示，就是在Vim的floatterm直接运行cgdb进行调试的样子，很轻量，推荐） IDE：ide的图形界面做的最完善，功能很多，如果不想折腾，直接用也很舒服。至于什么不能用IDE的情况，以后碰上了再学。（当然还是那句话，都用IDE了，可能配环境的问题就没那么大了，也就不会看到这了） links gdb快速上手 | SHUAIKAI\\u0026rsquo;s Blog cgdb官网 cgdb手册 单元测试 调试程序，一般你先得知道程序有错误。自己写的小程序，跑一边就知道又没错误了。但是如果是多人合作的大型项目，一来程序分支众多，跑一边不见得会跑到出错误的那种情况；另一方面，你好不容易设计出了一个好东西，或者修改好了一个bug，你当然不想被人再破坏它。保证这种情况的手段就是 单元测试。\\n或许你听说过一个词叫 面向测试开发，或者什么测试先行。简单来说就是，代码还没写呢，功能还没实现呢，先把测试功能的代码写出来。这个一般说的就是，你先写出单元测试。单测的粒度比较小，比较精细，能够验证某个函数甚至某一个分支逻辑行为是否符合预期。\\nC++有很多单测框架，著名而全面的有GoogleTest，它还带了一个可以模仿接口的GoogleMock，这个一般是绝对够用了的。你只会嫌弃它太重了而想换到更轻量的，比如catch2，doctest等这种单个头文件的。\\n（这一节其实是后面才想起来，随便写写填个坑了）具体的参考这篇总结 C++ 单测框架Catch2、doctest、CppTest、GTest、CppUnit 和 CppUTest 安全检查 c++程序的安全问题，最出名的当属内存泄，以及指针相关的空指针野指针悬挂指针，此外还有一些除零、越界、溢出等等吧。这一节究竟是按照工具分类，还是按照错误分类呢？纠结了一下，还是直接介绍工具吧。读者知道有这么些个工具，等环境配好了，真个碰到对应场景的时候，再搜相关的问题，见到这些名词有个印象即可。\\nValgrind 详情请参考 Valgrind快速上手 | SHUAIKAI\\u0026rsquo;s Blog 简单来说，valgrind提供了如下几个工具。使用方法就是 valgrind --tool=\\u0026lt;tool\\u0026gt; ./\\u0026lt;your_program\\u0026gt;。不同的工具可能还会输出一些文件，这些文件具体又怎么可视化，详情直接一搜即可。\\nmemcheck： （默认tool）探测程序中内存管理存在的问题。它检查所有对内存的读/写操作，并截取所有的malloc/new/free/delete调用。因此memcheck工具能够探测到以下问题：1）使用未初始化的内存 2）读/写已经被释放的内存 3）读/写内存越界 4）读/写不恰当的内存栈空间 5）内存泄漏 6）使用malloc/new/new[]和free/delete/delete[]不匹配。 7）src和dst的重叠 cachegrind：模拟执行CPU中的L1, D1和L2 cache，因此它能很精确的指出代码中的cache未命中，可以打印出cache未命中的次数，内存引用和发生cache未命中的每一行代码，每一个函数，每一个模块和整个程序的摘要。 massif：堆栈分析器，它能测量程序在堆栈中使用了多少内存，告诉我们堆块，堆管理块和栈的大小 helgrind：主要用来检查多线程程序中出现的竞争问题。Helgrind 寻找内存中被多个线程访问，而又没有一贯加锁的区域，这些区域往往是线程之间失去同步的地方，而且会导致难以发掘的错误 callgrind：收集程序运行时的一些数据，函数调用关系等信息。用callgrind_annotate可以对输出文件进行可视化 callgrind_annotate --auto=yes callgrind.out.[pid] \\u0026gt; log.log \\u0026amp;\\u0026amp; vim log.log Sanitizer Sanitizer最开始是google做的一个错误检查工具，通过在你的代码中插入一些东西，然后运行你的程序，这些东西就会把你的错误给你报出来。现在三大编译器都已经默认支持这个编译选项了。具体怎么用在上文 性能优化相关 的编译选项中已经介绍过了，直接加编译选项就好:\\ng++ -fsanitize=address/leak/undefined/thread -o demo demo.cpp\\nReference Clang 21.0.0git documentation 这里面有许多关于clang用法的介绍，自然包括Address/Thread/Memory\\u0026hellip; Sanitizer，就不一一列举链接了\\nAddressSanitizer — Clang 21.0.0git documentation google/sanitizers 项目文档 google sanitizer项目原汁原味的文档\\nAddressSanitizer \\u0026amp; LeakSanitizer · google/sanitizers Wiki ThreadSanitizer · google/sanitizers Wiki MemorySanitizer · google/sanitizers Wiki AddressSanitizer 的一些错误示例代码 | Microsoft Learn 静态分析 静态分析有很多工具，像 Cppcheck ， ClangStaticAnalyzer(CSA) ， cpplint ，前面说的 clang-tidy 也算是吧。\\n个人浅显的总结：cppcheck检查逻辑错误，csa能更深入的检查运行时错误，cpplint检查风格是否符合google style，clang-tidy写代码的时候给lint。有很多吧，感兴趣随便搜一下，比如这一篇 C++静态代码检查工具？ - 知乎 ，这一篇 开源C++静态代码检测工具clang-tidy、cppcheck和oclint的比较_clang-tidy cppcheck-CSDN博客 \\u0026hellip;\\u0026hellip;\\nCppCheck Cppcheck 是 C/C++ 代码的静态分析工具，它提供独特的代码分析来检测错误（大概就是说可以检查一些别的检查不出来的错误。只检查编译器检查不出来的bug，不检查语法错误），专注于检测未定义的行为和危险的编码结构。\\n使用\\ncppcheck [OPTIONS] [files or paths]\\ncppcheck . 2\\u0026gt; err.txt: 递归检查当前文件夹，并在屏幕上打印进度，将错误写入文件 cppcheck --quiet ../myproject/: 递归检查 ../myproject/，并且不打印进度 cppcheck --enable=all --inconclusive --library=posix test.cpp: 检查test.cpp，启用所有检查 cppcheck -I inc1/ -I inc2/ f.cpp: 检查f.cpp并搜索inc1/和inc2/中的include文件 –enable=all,warning,style,performance,portability,information,unusedFunction,missingInclude启用更多检查。默认情况下只显示错误消息 --platform=unix32,unix64 ,win32A,win32W,win64,avr8,elbrus-e1cp,pic8,pic8-enhanced,pic16,mips32,native,unspecified: 指定平台，精确检查 -i \\u0026lt;dir or file\\u0026gt; 忽略源文件或源文件目录 --suppress=syntaxError屏蔽该类错误 -j n 启动多线程同时进行检查。 ClangStaticAnalyzer Clang Static Analyzer 是一个工业级的静态源码检测工具，可以用来发现 C、C++ 和 Objective-C 程序中的 Bug。它既可以作为一个独立工具（scan-build）使用，也可以集成在 Xcode 中使用。Clang Static Analyzer 建立在 Clang 和 LLVM 之上。严格地讲，它是 Clang 的一部分，因此它是完全开源的。Clang Static Analyzer 使用的静态分析引擎被实现为一个 C++ 库，可以在不同的客户端中重用，因此拥有很高的可扩展性。\\nscan-build 是它自带的命令行工具，可以劫持你的构建工具来用（直接在工具如clang++、cmake前面加上scan-build即可）。找到问题后会给你生成一个一个可视化的报告，非常易读，用scan-view查看。\\n#(1) 单文件用scan-build scan-build clang++ demo.cc -o demo #(2) cmake项目用 scan-build mkdir build \\u0026amp;\\u0026amp; cd build ## 在你的cmake前面添加上scan-build scan-build cmake .. ## 然后构建 scan-build cmake --build . -j8 ## 可能的输出 # scan-build: Analysis run complete. # scan-build: 8 bugs found. # scan-build: Run 'scan-view /tmp/scan-build-2025-04-08-130150-171264-1' to examine bug reports. ## 根据提示命令，用scan-view就可以查看报告 scan-view /tmp/scan-build-2025-04-08-130150-171264-1 形式化验证 形式化验证能够从数学的角度对代码进行分析验证，查找问题。常见的工具有CBMC和ESBMC。可能更偏学术一些，可以了解下有这么种东西。\\nCBMC CBMC(C Bounded Model Checker) 是一个有界模型检查器，专门用于C和C++程序。它通过将程序转换为逻辑公式，并使用SAT求解器来验证这些公式，从而检测程序中的错误。CBMC特别适用于验证嵌入式系统和安全关键软件。\\n使用：cbmc [opt] file.cpp，可添加选项如--bounds-check。支持生成验证报告（--xml-ui）。\\nESBMC ESBMC(Efficient SMT-Based Context-Bounded Model Checker) 是一个基于SMT（可满足性模理论）的有界模型检查器，支持C、C++和Java程序。它使用SMT求解器来验证程序的属性，能够处理更复杂的逻辑和数据结构。ESBMC在验证并发程序和实时系统方面表现出色。\\n使用：esbmc [opt] file.cpp，输入C++代码并指定属性（如--memory-leak-check）。通过esbmc file.cpp执行验证，输出反例路径或确认安全性。\\n性能分析 perf 暂时写不动了，等着后续吧。如果你看到的时候还没有后续，直接STFW得了。\\n运行 程序编译好了，怎么跑起来，一般不是问题。但偶尔确实有问题，出去系统格式不对这种低级错误之外，最常见的问题应该是动态库找不到。\\n找不到的原因有很多，可能程序是你自己编译的，但是输出到bin目录，动态库却在build目录、在lib目录；可能程序不是你编译的，你只有可执行文件，没有动态库文件；可能你有动态库文件，但是没放在默认能找到的位置。说来说去，总结一句话：动态库放的位置不对。（没动态库也算位置不对，相当于是放在了人家电脑上，没放自己电脑上）\\n那么放哪里才算对呢？=\\u0026gt; 放系统默认位置，和当前目录下。最快的验证方法就是把动态库拷贝到当前文件夹再运行，一般就能跑起来了。\\n如何判断缺没缺动态库可以用 ldd 这个工具。ldd [your_excutable] 他会告诉你这个程序依赖哪些动态库，找到的在哪个位置，没找到的又是谁。\\n如果是安装的库，一般都会安装到默认位置，肯定能找到。如果是自己编译的库，那么不推荐放到系统默认位置，可以通过一个环境变量来指定：LD_LIBRARY_PATH，它是程序运行的时候默认的动态库搜索位置。\\n# 临时添加路径 export LD_LIBRARY_PATH=/path/to/libs:$LD_LIBRARY_PATH # 永久配置（写入 ~/.bashrc 或 /etc/ld.so.conf） sudo ldconfig # 刷新缓存 具体编辑器配置 vscode Reference .vscode几个配置文件说明 vim nvim sublime 学习资料推荐 手册类 zh.cppreference.com and cppreference.com ：最经典、最好用、最全面的c++在线手册，建议有问题直接去这上面查。怎么更方便的使用可以参考 手册速查方案（如cppreference） | SHUAIKAI\\u0026rsquo;s Blog Learn Contemporary C++ | Concise\\u0026amp;Visual Examples | hacking C++ ：图形化展示各种c++标准库组件，非常非常直观理解、记忆、回忆各种api\\nGoogle C++项目风格指南 ：谷歌的C++项目风格指导\\n工具类 Compiler Explorer - Goldbolt ：一个非常有名的C++在线编辑器/IDE。它可以（1）用各种版本的编译器，编译运行你的c++代码或者cmake项目。（2）也能让你实时查看你写的c++代码每一段每一行对应的汇编，方便理解底层。（3）还可以作为一个代码分享工具，向别人原汁原味的展示你的代码。\\nCppInsight ：让你查看c++代码预处理后的样子。比如头文件展开、lambda表达式实现等等\\n其他 ISO/IEC JTC1/SC22/WG21 - The C++ Standards Committee - ISOCPP ：C++话事人 \"",
      categories: "[\"环境配置\"]",
      tags: "[\"c++\"]",
      series: [],
      date: "\"2025-03-26\""
    });
  
    searchIndex.push({
      title: "\"带着目的学：CyberRT\"",
      permalink: "\"/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/cyberrt/%E5%B8%A6%E7%9D%80%E9%97%AE%E9%A2%98%E5%AD%A6cyberrt/\"",
      content: "\"带着目的学：CyberRT 故事背景 最近处在上学与退学，上班与无业的叠加态，想学点CyberRT、Ros2、DDS这些大型项目为工作做准备。虽说之前实习时也算接触过大型项目了，但是毕竟现在时间更充裕，也没有一个明确的任务催着、针对性的去解决，所以看了好几天代码，给环境配得极其顺手，但是实际上对项目的了解始终停留在0。这也值得小小反思以下：\\n为什么时间越多反而越看不好项目呢？ 比较一下，实习的时候看代码，是带着一个明确的目标看的。先有业务场景，比如是一个表达式解析错误的bug，当输入表达式是什么的时候，出现什么样的bug。然后我就专找表达式解析部分的代码，专找相应的case处理逻辑，理解起来就很快。表达式解析的case见多了（业务场景见多了），自然也能理解解析部分的代码，为什么 要那样写。\\n现在看代码呢，我的目的就只是，学习cyberrt。但是至于具体学习什么，其实没有一点概念，只知道要学这个项目，要学那个库。甚至我还没想清楚没了解清楚CyberRT到底是一个什么东西，就深入到代码逻辑中去了。去看它的协程，看协程调度，然后跳了几次调用几个文件，就去打游戏了，什么也没记住。\\n如果不明白为什么要调度，不清楚究竟是什么场景，才需要专门写一套协程去调度，那就很难真正理解调度的逻辑。\\nImportant 因为不管什么代码，生产项目还是个人项目，哪怕是虚空打靶，它们都对应着一个或者多个目的，搞清楚这个目的，才能更清楚这段代码为什么要这样写。\\n真正重要的是业务场景对应的解决方案，而不是某一处代码的实现细节，某一个代码片， Know Why 要比 Know How 要重要，也更高效。\\n已经浪费了很久很久的时间了，没有一个明确的目标而学习，耗时是巨大的，收获是甚微的，看再久代码，最终也不过是盲人摸象管窥蠡测，难以有深入的理解。\\n因此，我决定，以后要尽力做到：\\nThink more, code/read less. CyberRT学习目标 啰哩吧嗦了那么多，现在来分析一下所谓的学习CyberRT，到底是要学什么？现在我完全没有概念，那么先让AI替我深度思考一下切入点，带着AI的理解去学一阵子，再回过头来总结我认为的切入点\\nDeepseek\\u0026rsquo;s comprehension of CyberRT 我认为学习开源代码库或者技术的时候，最重要的不是代码本身怎么实现，而是先搞明白现实中有哪些需求，然后再是，这个技术具体是怎么解决这些问题的，为什么要这么做。然后才是具体的实现。从这个思路，我想学习百度的Apollo项目中的CyberRT框架，你帮我十分详尽地分析下，这个框架对应的需求是什么？要解决什么问题？对应的设计又是什么？（你可以参考Ros2，听说它们很多功能类似，我也有学习ros2的兴趣）\\n百度 Apollo CyberRT 框架分析：需求、问题与设计\\nCyberRT 的核心需求与背景 自动驾驶系统对实时性、可靠性和计算效率的要求极高，传统机器人中间件（如ROS1）在以下方面难以满足需求：\\n确定性调度：ROS1 的节点以独立进程运行，调度顺序无法保证，导致任务执行周期不可控。 通信效率：ROS1 基于 TCP/UDP 的通信模型存在高延迟和带宽瓶颈，难以处理自动驾驶多传感器的高频数据流。 资源管理：传统线程模型（OS Thread）的上下文切换开销大，大量异步任务会导致 CPU 缓存失效（Cache Miss）。 模块化部署：自动驾驶需要动态加载算法模块，ROS1 的静态节点管理缺乏灵活性。 CyberRT 的定位：专为自动驾驶设计的高性能运行时框架，核心目标是提供高吞吐、低延迟、确定性调度的计算环境，支持商业化量产需求。\\nCyberRT 解决的核心问题 实时性与确定性调度 问题：自动驾驶算法需在固定周期内完成数据处理（如感知-规划-控制链路），传统线程调度无法保证任务优先级和周期。\\n解决方案：\\n用户空间协程（CRoutine）：将任务从 OS 线程转为轻量级协程，由 CyberRT 调度器统一管理，减少内核态切换开销。\\n基于 DAG 的任务调度：通过有向无环图（DAG）定义任务依赖关系，结合优先级和周期配置，确保关键任务优先执行。\\n高效通信机制 问题：ROS1 的通信模型（Topic/Service）存在序列化开销和网络延迟。\\n解决方案：\\n共享内存与零拷贝：支持进程内、跨进程（共享内存）和网络（DDS）通信，减少数据复制。 Protobuf 序列化：采用高效的二进制协议，压缩率比 XML/JSON 更高，提升传输效率。 资源隔离与优化 问题：多任务竞争 CPU 资源导致计算延迟不可控。\\n解决方案：\\nCPU 亲和性绑定：将关键任务绑定到特定 CPU 核，减少缓存抖动（Cache Bouncing）。 进程级资源隔离：不同模块（如感知、规划）运行在独立进程，分配专属 CPU 核，避免资源抢占。 模块化与动态部署 问题：自动驾驶算法需灵活更新，传统二进制部署需重启系统。\\n解决方案：\\n组件（Component）模型：通过继承 Component 基类实现算法模块，动态加载共享库（.so），支持热更新。 DAG 配置文件：定义模块拓扑结构和通信通道，修改配置无需重新编译。 CyberRT 的核心设计 分层架构 通信层：基于 DDS/共享内存的发布-订阅模型，支持多种 QoS 策略（如低延迟、高可靠性）。 数据层：提供数据缓存与融合机制，例如 Blocker 用于多传感器数据同步。 计算层：协程调度器（Scheduler）负责任务调度，支持两种策略： Choreography：强调周期性和实时性，适用于自动驾驶任务。 Classic：传统优先级调度，适用于通用场景。 关键组件 Node：功能模块的载体，管理 Reader/Writer 和 Service/Client。\\nComponent：继承自 Component 或 TimerComponent，通过 Init() 和 Proc() 定义初始化和处理逻辑。\\nDAG 文件：描述模块依赖关系和通信通道，例如：\\nmodule_config { components { class_name: \\u0026quot;PerceptionComponent\\u0026quot; readers { channel: \\u0026quot;sensor_data\\u0026quot; } } } 通过 mainboard 工具动态加载。\\n性能优化技术 无锁队列：减少线程竞争，提升并发效率。 协程池：预分配协程资源，避免频繁创建销毁开销。 时间同步：基于硬件时钟的精准时间戳，支持数据融合与控制协同。 \"",
      categories: "[\"自动驾驶\"]",
      tags: "[\"CyberRT\"]",
      series: "[\"CyberRT专项总结\"]",
      date: "\"2025-03-25\""
    });
  
    searchIndex.push({
      title: "\"Linux环境变量加载顺序分析\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/linux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%8A%A0%E8%BD%BD%E9%A1%BA%E5%BA%8F%E5%88%86%E6%9E%90/\"",
      content: "\"Linux环境变量加载顺序分析 环境变量是shell运行时的运行参数，比如执行命令时，就会从PATH指定的路径查找可执行文件。有的程序也会使用环境变量作为参数。\\n当你发现配置了环境变量，但实际使用时环境变量未生效时，希望这篇文章能对你有所帮助。\\n我们登录linux有很多种，bash来交互式执行，或者直接非交互式执行命令。试验后，可以发现，原来这几个的环境变量加载都是不同的。\\n相关文件： 电脑上和初始化相关的是这几个文件。\\n/etc/profile /etc/environment /etc/bashrc ~/.bash_profile ~/.bashrc ~/.bash_logout bash登录方式和环境变量的关系： 环境加载和4种bash模式相关。 什么是交互式shell（interactive shell）和非交互式shell（non-interactive shell）： 交互式的shell会有一个输入提示符，并且它的标准输入、输出和错误输出都会显示在控制台上。所以一般来说只要是需要用户交互的。\\n非交互式shell是 bash script.sh 这类的shell，脚本或程序执行完就结束了，没有交互。\\n登录式shell（login shell）和非登陆式shell（no-login shell）： 需要输入用户名和密码的shell就是登陆式shell。因此通常不管以何种方式登陆机器后用户获得的第一个shell就是login shell。不输入密码的ssh是公钥打通的，某种意义上说也是输入密码的。\\n非登陆式的就是在登陆后启动bash等，即不是远程登陆到主机这种。\\n不同方式的加载情况： 以下是实验结果，可直接参考\\n文件 登陆 + 非交互 登陆 + 交互 非登陆 + 交互 非登陆 + 非交互 /etc/profile 加载 加载 /etc/environment /etc/bashrc 加载 加载 ~/.bash_profile 加载 加载 ~/.bashrc 加载 加载 加载 BASH_ENV 加载 场景分析 常见的几种场景 登陆机器后的第一个shell​：登录+交互(login + interactive) 新启动一个shell进程，如运行bash​：非登录+交互(non-login + interactive) 执行脚本，如bash script.sh​：非登录+非交互(non-login + non-interactive)) 运行头部有如#!/usr/bin/env bash的可执行文件，如./executable​：非登录+非交互(non-login + non-interactive)) 远程执行脚本，如 ssh user@remote script.sh​：非登录+非交互(non-login + non-interactive)) 远程执行脚本，同时-t强制分配伪终端，如ssh user@remote -t ‘echo $PWD’ ：非登录+交互(non-login + interactive) 在图形化界面中打开terminal，Linux上: 非登录+交互(non-login + interactive) 在图形化界面中打开terminal，Mac OS X上: 登录+交互(login + interactive) 实验: 准备 在每个文件的开头和结尾都加了行输出用于打印状态。\\necho 脚本名 begin xxxx脚本内容xxxx echo 脚本名 end 情况 下面显示输出的情况，用表格来隔开，以显示递归的情况。\\n登陆机器后的第一个shell： 交互式，登录式shell​。\\n/etc/profile begin /etc/profile end ~/.bash_profile begin ~/.bashrc begin /etc/bashrc begin /etc/bashrc end ~/.bashrc end ~/.bash_profile end 在已经登陆后的终端，执行bash命令： 交互式，非登录式shell​。\\n~/.bashrc begin /etc/bashrc begin /etc/bashrc end ~/.bashrc end 在已经登陆后的终端，执行bash -l命令： 交互式，登陆式shell​。\\n/etc/profile begin /etc/profile end ~/.bash_profile begin ~/.bashrc begin /etc/bashrc begin /etc/bashrc end ~/.bashrc end ~/.bash_profile end su命令到另一个用户： 交互式，非登录式shell​。\\n~/.bashrc begin /etc/bashrc begin /etc/bashrc end ~/.bashrc end 普通用户下sudo ls： 非交互式，非登陆shell​。\\n没有打印任何信息。\\nbash -l -c “ls”命令： 非交互式，登录式shell​。\\n/etc/profile begin /etc/profile end ~/.bash_profile begin ~/.bashrc begin /etc/bashrc begin /etc/bashrc end ~/.bashrc end ~/.bash_profile end 远程 ssh sean@test ls 命令： 非交互式，登陆式shell​。\\n~/.bashrc begin /etc/bashrc begin /etc/bashrc end ~/.bashrc end 一些结论： 其实从上面的显示中，我们可以看出，有几个文件有调用关系。\\n调用关系： ~/.bash_profile -\\u0026gt; ~/.bashrc -\\u0026gt; /etc/bashrc 其实去查看它们的代码就能发现，里面有执行的语句。\\n注意 bash -l ： 加了-l参数后，打开的是登陆式shell。这要注意。\\nBASH_ENV变量： 一个环境变量，用于指定非交互+非登陆式的环境变量文件\\n用法 因此想要一些设置在任何时候都能用，最方便的就是加入到 ~/.bashrc 中，对执行脚本时有要求的话，再设置个 BAHS_ENV\\n\"",
      categories: "[\"环境配置\"]",
      tags: "[\"linux\"]",
      series: [],
      date: "\"2025-03-14\""
    });
  
    searchIndex.push({
      title: "\"手册速查方案（如cppreference）\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/zeal-dataset%E4%B8%AD%E6%96%87cppreference%E9%85%8D%E7%BD%AE/\"",
      content: "\" zeal 直接下载 Zeal - Offline Documentation Browser ，然后搜索自己感兴趣的 docset 下载即可\\nutools-dataset 使用 utools 的 dataset 插件，能够更快更方便地唤起 zeal。按照插件指引配置 zeal 的 docset 文件夹位置即可。\\n这里需要说明的是，怎么将 cppreference 的语言变为中文，也即使用 zh.cppreference.com 配置 首先要下载 中文离线版手册 （不如英文版的新，但是无所谓了），解压后里面有两个关键的文件夹，所有需要做的就是用 zh-html-book\\\\reference\\\\zh 替换掉 docsets\\\\C++.docset\\\\Contents\\\\Resources\\\\Documents\\\\en.cppreference.com\\\\w 这个，将 zh-html-book\\\\reference\\\\common 文件夹放到 w 的相同位置。推荐使用软连接来做，可以参考下面的命令\\nmklink /d %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C++.docset\\\\Contents\\\\Resources\\\\Documents\\\\en.cppreference.com\\\\w %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C++.docset\\\\zh-html-book\\\\reference\\\\zh mklink /d %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C++.docset\\\\Contents\\\\Resources\\\\Documents\\\\en.cppreference.com\\\\common %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C++.docset\\\\zh-html-book\\\\reference\\\\common C 的 reference 其实是复用的 Cpp 的，完全可以删除 c.docset 中的 en.cppreference.com，直接用一个软连接指向 cpp 中的即可\\nrm -rf %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C.docset\\\\Contents\\\\Resources\\\\Documents\\\\en.cppreference.com mklink /d %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C.docset\\\\Contents\\\\Resources\\\\Documents\\\\en.cppreference.com %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh_C++.docset\\\\Contents\\\\Resources\\\\Documents\\\\en.cppreference.com 这里我想同时保留中英文，没有直接修改 %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\C++.docset ，而是创建了 %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh-C++.docset 和 %LOCALAPPDATA%\\\\Zeal\\\\Zeal\\\\docsets\\\\zh-C.docset 两个作为副本，然后同时保持cpp和cppzh两条命令作为区分。这样不影响 zeal 更新\\n样式 common/ext.css:\\nbody.min-width: 180px;可以缩小边距； body.width:70%; 放大后往左移； #bodyContent.font-size: 0.9em;，这里修改字体大小 utools-网页快开 换个思路，能够快速打开官网手册，进一步，快速打开官网手册的关键词搜索位置，也可以做到速查手册。这里列出几个链接作为配置参考\\ncppreference: https://www.google.com/search?q={query}+site%3Acppreference.com python: https://docs.python.org/zh-cn/3.13/search.html?q={query} java: https://www.google.com/search?q={query}+site%3Aapiref.com/java11-zh man: https://man.freebsd.org/cgi/man.cgi?query={query} tldr: https://tldr.inbrowser.app/pages/common/{query} \"",
      categories: "[\"环境配置\"]",
      tags: "[\"cppreference\"]",
      series: [],
      date: "\"2025-03-12\""
    });
  
    searchIndex.push({
      title: "\"CyberRT中的代码和工程技巧\"",
      permalink: "\"/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/cyberrt/cyberrt%E4%B8%AD%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%92%8C%E4%BB%A3%E7%A0%81%E6%8A%80%E5%B7%A7/\"",
      content: "\"CyberRT 中的代码和工程技巧 C++规范 Tip C++设计类时总有一些不确定的写法，这里列举出 CyberRT 中的一些设计，作为参考\\n成员命名后划线 private: int x_;\\n很多类成员也是直接就声明的时候就等号赋值了。比如std::atomic_flag lock_ = ATOMIC_FLAG_INIT;\\n头文件中实现函数加上inline\\n也大量用std::function，std::shared_ptr等，不至于提到这些就谈性能色变。比如协程中using RoutineFunc = std::function\\u0026lt;void()\\u0026gt;;\\nC++语法技巧 匿名 namespace 当 static 用，限定作用域在当前文文件中\\n// file1.cpp namesapce { int x = 10; } int foo(){return x;} // 当前文件内正常访问 // 等价于： static int x = 10; \"",
      categories: "[\"自动驾驶\"]",
      tags: "[\"CyberRT\",\"C++\"]",
      series: "[\"CyberRT专项总结\"]",
      date: "\"2025-03-01\""
    });
  
    searchIndex.push({
      title: "\"设计模式\"",
      permalink: "\"/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/\"",
      content: "\"设计模式 1 关系 关联 \\u0026amp; 依赖 依赖 表示一种使用关系，一个类的实现需要另一个类的协助，因此尽量使用单向的依赖。代码表现为参数依赖、局部变量、静态方法/变量依赖等 关联 偏向一种拥有关系，A 拥有 B，即 A 的某个成员，是 B 类的对象，也可以双向拥有，也可以仅仅是存在一种关联 @startuml scale 1 class Car { +run() void } class Driver { +Car car +drive() void } Driver \\u0026quot;1\\u0026quot;--\\u0026gt;\\u0026quot;n\\u0026quot; Car class Bus { +run() void } class BusDriver { +drive(bus:Bus) void } class Passenger { } BusDriver ..\\u0026gt; Bus Bus \\u0026quot;n\\u0026quot;--\\u0026quot;n\\u0026quot; Passenger @enduml Note 依赖强调一方要使用另一方、依赖另一方而存在\\n司机拥有了汽车，二者存在关联。\\n公交司机使用公交车进行开车工作，他依赖公交车，但是不拥有公交车。\\n乘客与公交车之间互不依赖互不拥有，但是他们之间确实存在多对多的关系\\nWarning 动物依赖氧气而活，这是依赖关系。动物活着也会与气候发生关系，但是动物不是直接依赖气候而活，因此是关联关系。公交司机之所以是公交司机，是因为有公交车存在，这是依赖关系。\\n组合 \\u0026amp; 聚合 聚合和组合都是强调整体与部分的关系，也都可以视为一种关联关系\\n组合 是一种强拥有关系，部分组装成整体，失去了整体，组装的零件也就没有了存在的意义 聚合 是一种弱拥有关系，部分聚集成整体，但是整体解散了部分存在依然有意义 @startuml scale 1 class Bird { - Wing[2] wings + fly():void } class Wing { - double size } Bird \\u0026quot;1\\u0026quot;*--\\u0026quot;2\\u0026quot; Wing : 组合关系 class Class { + Student** stus } class Student { - string name } Class \\u0026quot;1\\u0026quot; o-- \\u0026quot;n\\u0026quot; Student : 聚合关系 @enduml Note 聚合的部分可以脱离整体而存在，而组合的部分不能脱离整体而存在\\n翅膀是鸟的组成部分，脱离了鸟，翅膀便不是一个完整的功能部分 学生是班级的组成部分，班级解散了，不影响这批学生存在的意义 Note 二者与关联关系的区别就在于，聚合与组合，更强调整体与部分之间的关系。鸟与翅膀、班级与学生之间自然存在关联，但他们之间有更进一步的整体部分关系，而非仅仅是关联关系。\\n泛化 \\u0026amp; 实现 泛化/继承 是一种类之间的关系，子类继承父类属性和方法，各自有自己的新特性，父类是子类的泛化。 实现 是接口与实现类之间的关系。接口是一种抽象的规范，定义了一组方法的签名。一个类通过实现接口来表明它提供了接口中定义的所有方法。实现关系使得类之间的依赖基于接口而不是具体的实现。 @startuml scale 1 class Person { # string name + eat():void } class Student { - string sid + work():void } class Teacher { - string tid + work():void } Student --|\\u0026gt; Person Teacher --|\\u0026gt; Person class work { \\u0026lt;\\u0026lt;interface\\u0026gt;\\u0026gt; + work():void } Student ..|\\u0026gt; work Teacher ..|\\u0026gt; work @enduml 学生和老师都是人，都从 Person 那里继承了属性和方法 学生和老师都需要工作，工作的方式和内容五花八门，但是他们都实现了统一的接口 work Note 继承强调类的层次关系，上层是下层的泛化，下层是上层的派生。实现强调的是方法，即定义一组规范接口，让别的类去实现，并没有泛化派生的意味\\n下图是一张经典的 UML 图：\\n2 SOLID 原则 里氏替换原则 LSP 概念 开闭原则(OCP)背后的主要机制是抽象(abstraction)和多态(polymorphism)。在静态类型语言中，比如 C+和 Java,支持抽象和多态的关键机制之一是继承(inheritance)。正是使用了继承，我们才可以创建实现其基类(base class)中抽象方法的派生类。 是什么设计规则在支配着这种特殊的继承用法呢？最佳的继承层次的特征又是什么呢？怎样的情况会使我们创建的类层次结构掉进不符合 OCP 的陷阱中去呢？这些正是 Liskov 替换原则(LSP)要解答的问题。 ——《敏捷软件开发：原则、模式和设计》\\nLet q(x) be a property provable about objects x of type T . Then q(y) should be true for objects y of type S where S is a subtype of T .\\nWarning 这里需要如下替换性质：若对每个类型 S 的对象 O1，都存在一个 T 类型的对象 O2，使得在针对 T 类型编写的程序 P 中，用 O1 替换 O2 后，程序 p 的行为功能保持不变，则 S 是 T 的子类型\\n总之就是一句话：\\nNote 子类型必须能够替换掉它们的基类型。说得长一点：当你扩展一个类时， 记住你应该要能在不修改客户端代码的情况下将子类的对象作为父类对象进行传递。\\n核心理解 在 OOP 中，我们通常是把表现出相同行为的一类对象，抽象为一个类。这里要特别注意，也就是说，我们真正看重的，用以标志区分类的，是对象/类的行为。\\n继承是一种is-a关系，“派生类，是一种基类”。但是 IS-A 的含义太过宽泛了，在实际编程中可能会与真正的“行为”角度要求有抵触。看两个例子：\\naka 正方形是一种矩形，这个与我们的经验相符，因此矩形类派生出正方形类应该是顺理成章的。但实际上这里也有一些小细节：我们说正方形是矩形，是从内角角度说的，矩形是内角和为 360° 且内角都是 90° 的四边形，正方形也是，因此从内角的行为上来看，正方形是矩形无疑。 但是如果我考察的行为是边而不是内角呢？矩形的长宽是独立变化的，而正方形的长宽是相等的，变化是联动的。也就是说从边的行为上来说，正方形和长方形已经不同了，行为不同，还能说是一类么？这就是经典的“正方形不是长方形”\\n同样的，鸵鸟（不会飞）和鸟（会飞），如果我考察的就是飞行能力，比如我要做一个鸟类飞行模拟器，那鸵鸟能继承自鸟类么？显然不能，因为二者行为不一样。但是如果我不看飞行能力，比如做一个鸟类养殖模拟器，那鸵鸟和鸟，都有羽毛都有两个爪子\\u0026hellip;，鸵鸟又可以从鸟类派生出了，此时鸵鸟是鸟。\\n正方形是矩形，也不是矩形；鸵鸟是鸟，也不是鸟。这种悖论产生的原因有二1：\\n继承关系的定义没搞清楚：面向对象的设计关注的是对象的行为，它是使用“行为”来对对象进行分类的，只有行为一致的对象才能抽象出一个类来，而不是拍脑袋决定 is-a\\n设计要依赖于用户需求和具体环境：需求、关注点不同，关系自然也会不同\\nLSP 就是一种描述如何设计类继承结构最好，不会出现上述问题的原则。它告诉我们：\\nNote 子类型的正确定义是“可替换性的”，子类对象是可以替换父类对象而保持功能正常的。这里的可替换性可以通过显示或隐式的契约来定义\\n不满足可替换性，也能写出符合语法的继承结构，也可以工作，但是不总是能正确工作。也即，违背 LSP 的代码，可以正确实现继承、多态等语法功能，但是不见得能满足我们的预期。具体看后面的例子\\n代码示例 “正方形不是矩形”\\n这里多态是能满足的，继承体系从语法上讲是没问题的，但是从预期行为上看是有毛病的。在这里，在边的行为上，Square 不能替换掉 Rectangle，违背了 LSP。\\n事实上可以重新设计类层次：提取公共部分，创建一个四边形抽象类。关于提取公共部分：\\n如果一组类都支持一个公共的职责，那么它们应该从一个公共的超类(superclass)继承该职责。如果公共的超类还不存在，那么就剑建一个，并把公共的职责放入其中。毕竟，这样一个类的有用性是确定无疑的—你已经展示了一些类会继承这些职责。然而稍后对系统的扩展也许会加入一个新的子类，该子类很可能会以新的方式来支持同样的职责。此时，这个新创建的超类可能会是一个抽象类。\\n有公共部分，就应当考虑提取出来创建一个新的抽象类。不然就意味着代码面临重复的问题\\n除了提取公共部分，还有一个原则：\\n*继承体系中，应当总是从抽象类继承。也就是说，继承树应该是这么一棵树：所有有子节点的类都是抽象类，所有具体类都应当是叶子节点*\\n具体要求 基于契约设计（DBC Design By Contract）\\n类的编写者可以显示的规定针对该类（父类）的契约，客户端的编写者（写子类扩展的人）可以通过契约获悉值得信赖的行为方式。契约即：\\nNote 为每个方法声明前置条件和后置条件。要正确执行一个方法，前置条件必须为真，且执行完之后，要保证后置条件也为真。\\n前置条件和后置条件的规则是：重新声明的派生类中，只能使用相等或更弱(≤)的前置条件替换原始前置条件，只能使用相等或更强(≥)的后置条件来替换原始后置条件\\n换句话说，通过基类接口使用对象的时候，用户只知道前置条件和后置条件。因此你不能期望用户遵从比基类前置条件更强的前置条件，同时你的行为方式和输出也要跟基类确立的限制一样。\\n参数要广：子类方法的参数类型必须（≥）与其超类的参数类型相匹配或更加抽象 返回要细：子类方法的返回值类型必须（≤）与超类方法的返回值类型或是其子类别相匹配 子类中的方法不应抛出基础方法预期之外的异常类型 子类不应该加强其前置条件，不能削弱其后置条件 超类的不变量必须保留 子类不能修改超类中私有成员变量的值 比如接口定义输入为整数，那你写的子类就不能要求输入是正整数；接口规定输出是整数，你可以输出正整数，但不能输出浮点数。\\nWarning 父类中的虚函数你可以重写，注意要满足前置条件与后置条件的要求。父类中的别的内容你最好不要修改，因为那个可以理解为是一种规范、约定。\\n例子 所谓“子承父业”，我现在想为所有木工编写一个Father类，类中有一个接口叫earnMoney(Carpentry c1)，也就是说要挣钱，挣钱的参数是做木工。现在 Father 派生除了子类Son和女儿类Daughter。\\n儿子女儿都更新了父亲挣钱的方式，但是这个继承都是很脆弱的。儿子不仅会木工，还会搬砖，当然可以替代父亲（参数扩大 √）。但是当妈妈问父亲要钱的时候，她期待的是人民币，换成儿子之后给的可能是 Q 币（返回值扩大 ×），那肯定不行。女儿交的是人民币现金，没问题，但是她只会刨木头，仍然替换不了父亲。因此二者都违背了 LSP\\n后来儿子生了个孙子。孙子会干的活对，拿的钱也没问题，但是孙子有个讲究：工资低于 5000 的话不干（强化前置条件 ×），可他爹是不挑剔的。因此孙子替代他爹去干活的时候，也可能会出问题（找不到活儿）。孙女也有个讲究：干完活只收拾锤子，别的不管（弱化后置条件 ×)。可惜，工地上贼比较多，孙女不明白他爹这么做的血泪教训。因此代替他爹去干活的第二天，就只剩下个锤子能用了。【以后涨了记性，教育从外孙子干完活不仅收拾自己的家伙儿，连工友的也给收拾了。工地上再也没有丢过东西。(强化后置条件 √)】不过这是后话，反正孙子辈也全部违背了 LSP\\n面向对象基础设计原则：3.里氏替换原则 - 知乎 (zhihu.com) \\u0026#160;\\u0026#x21a9;\\u0026#xfe0e;\\n\"",
      categories: "[\"软件工程\"]",
      tags: "[\"SE\"]",
      series: "[\"设计模式专项总结\"]",
      date: "\"2025-02-28\""
    });
  
    searchIndex.push({
      title: "\"一站式环境配置\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/%E4%B8%80%E7%AB%99%E5%BC%8F%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/\"",
      content: "\"配置万千 \\u0026#x1f914; 配置新系统 1. 用户相关 # 1. 修改 root 密码 sudo passwd # 2. 创建新用户(adduser有交互；用useradd没有) su root ## 2.1 用useradd useradd [newuser] passwd [newuser] useradd -d /home/[newuser] [newuser] ## 2.2 用adduser adduser [newuser] # 3. 设置 sudo 权限 ## 3.1 更改文件 sudo vim /etc/sudoers/[newuser] [newuser] ALL=(ALL) NOPASSWD: ALL # 4. 更改名字 sudo vim /etc/hostname 2. 网络相关 2.1 ssh # 初始化rsa密钥 ssh-keygen -t rsa\\t# 三次回车（创建私钥，公钥） # hostname自然是你想去登录的，别的主机名 ssh-copy-id hostname # 取消哈希已知hosts，不然后面删除的时候认不出来了 sudo vim /etc/ssh/ssh_config - HashKnownHosts no # 如果出现 Permission denied (publickey) 记得检查这两项，取消其注释！ sudo vim /etc/ssh/sshd_config - PubkeyAuthentication yes - PasswordAuthentication yes # 重启sshd服务 sudo systemctl stop sshd sudo systemctl start sshd sudo systemctl status sshd 3. 安装 sudo sudo apt install build-essential gdb git cmake openjdk-11-jdk maven python -y \\u0026#x1f431; 系统配置 1 网络 1.1 防火墙与 iptables # 备份 iptables iptables-save \\u0026gt; /etc/iptables.rules # 恢复 iptables-restore \\u0026lt; /etc/iptables.rules \\u0026#x1f402; 其它备忘 1. wsl-gdb 修改 如果是【wsl，ubuntu22.04，gdb12.1】也可以直接下载我修改好的替换/usr/bin/gdb \\u0026#x1f517; gdb12.1 WSL 中的 gdb 不能用，对其进行一定的修改：参考 这里 ，以及 这里 首先定位到 wsl 中 gdb 的位置（我这时 gdb 版本是 12.1），然后 explorer.exe . ，将 gdb 复制出来\\n然后利用反汇编工具 IDA 打开 wsl 的 gdb，用 Search-for-text （左上角一个小望远镜带个 T) 搜索 linux_proc_xfer_memory_partial，看它的 function 地址（使用 text-view)\\n然后定位到 function 地址查看这函数的汇编码\\n前面一堆堆栈处理不用管，找一条指令叫 cmp esi 1，然后jz short loc_xxxxxx，即发现内存不存在就跳转到错误处理去了。记住 jz 指令的地址：0x335C7D\\n回到 WSL，运行：（注意用你上面的地址替换掉 XXX 部分）\\necho -ne '\\\\x90\\\\x90' | sudo dd of=/usr/bin/gdb seek=$((0xXXX)) bs=1 count=2 conv=notrunc 然后运行 gdb 打断点调试一个你的文件，跟着走即可正常运行。\\n让上面的设置永久生效只需：\\nvim .gdbinit # 写入：set debuginfod enabled on 2. 各种换源 2.1 ubuntu 换源 源就在 /etc/apt/sources.list 文件里面写着。备份一下，重写文件，然后 sudo apt update 就好了\\n不同 ubuntu 版本之间，区别就在一个小动物上（就是默认桌面的壁纸），改个名字就好了\\nUbuntu 22.04：jammy\\nUbuntu 20.04：focal\\nUbuntu 18.04：bionic\\nUbuntu 16.04：xenial\\n默认注释了代码源以提高速度，注释了预发布软件源（可能不稳定），如有需要可以取消注释。\\n建议将所有常用镜像源保存在/etc/apt/目录下，并命名为类似source.list.aliyun的形式，需要使用时直接复制替换source.list文件即可。( 国内镜像源 )\\n# 中科大源 deb https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse deb https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-updates main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-backports main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-security main restricted universe multiverse ## Pre-released source, not recommended. # deb https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse # deb-src https://mirrors.ustc.edu.cn/ubuntu/ focal-proposed main restricted universe multiverse 2.2 pip 换源 # USTC pip config set global.index-url https://pypi.mirrors.ustc.edu.cn/simple/ # 阿里云 https://mirrors.aliyun.com/pypi/simple/ # 科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ # 豆瓣(douban) https://pypi.douban.com/simple/ # 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ # 中国科学技术大学 https://pypi.mirrors.ustc.edu.cn/simple/ 2.3 npm 换源 npm config get registry # 查看当前源地址 # 临时使用 npm install [xxx] --registry https://registry.npm.taobao.org # 永久更换 npm config set registry https://registry.npm.taobao.org # 淘宝 npm config set registry https://mirrors.huaweicloud.com/repository/npm # 华为 3. 云服务器 3.1 安全组 放通端口的时候注意，看你更改的是 安全组 ，还是实例的防火墙( 轻量应用服务器 )。这俩是不一样的，别对着安全组一顿放通，结果发现实例没关联上安全组 3.2 对象存储 \\u0026#x1f436; 糊口家伙儿 1 vscode code-runner：在 settings.json 中，可以在当前工作目录下重写一部分，比如对 C++ 文件，单独指定编译命令 -lpthread -lhiredis -D _DEBUG 等等 。可以通过 ctrl p 打开设置然后搜索 code runner 找到 2 redis 使用 docker 操作 redis 2.1 安装 # 只有这一个版本，就是最新的，不用点进去看了 wget http://download.redis.io/redis-stable.tar.gz \\u0026amp;\\u0026amp; tar xzf redis-stable.tar.gz cd redis-stable make -j4 make test # 电脑可能会很吵，不知道它受不受得鸟。一般情况下是不用test的 sudo make install # 把可执行文件拷贝到 /usr/local/bin 目录下 2.2 运行 # 启动服务，可以选择加上你的配置文件 redis-server [{directory}/redis.conf] # 停止服务 redis-cli shutdown # 启动命令行 redis-cli -h [hostname] -p [port] -a [passwd] # 可以 --no-auth-warning，或者不加 -a，进去之后写密码 auth [passwd] # 修改设置 CONFIG SET/GET loglevel warning CONFIG SET requirepass '' 2.3 配置 （1）配置文件：\\n初始在redis-stable/redis.conf(rw-rw-r\\u0026ndash;664)，可以给它拷贝到~/.redis/，然后修改的有：\\ndaemonize yes\\t# 以守护进程形式启动 port 6379\\t# 端口号，默认是 6379 appendonly yes\\t# 打开 AOF 持久化（默认RDB也是打开的） dir {~/.redis/6379}\\t# 放置持久化文件的位置 rwxrwxr-x 775 logfile {.redis/redis.log}\\t# 日志文件\\trw-rw-rw- 666 # 允许远程lian'jie bind 0.0.0.0\\t# 任意主机连接 protected-mode no\\t# 关闭保护模式 （2）设置开机自启\\n初始有一个脚本：redis-stable/utils/redis_init_script，把它放到 /etc/init.d/ 目录下，而后\\n# 先备份一下，别等下删了 cp ./utils/redis_init_script ~/.redis/ sudo cp ./utils/redis_init_script /etc/init.d/ # chmod 774 /etc/init.d/redis_init_script sudo update-rc.d redis_init_script defaults （3）常见错误\\n(error) ERR Errors trying to SHUTDOWN. Check logs\\n主要检查：持久化文件路径和日志文件路径的权限，最起码当前用户要有读写权限。特别是设置在系统目录的时候。（如果设置在etc var等目录，除非把这些目录设为可写，不然好像一直退出不了，所以我建议在 home 路径下设置这两个） Could not connect to Redis at 127.0.0.1:6379: Connection refused\\n笨蛋，快看看是不是已经停止掉 redis 服务了，还想着 redis-cli shutdown 呢？\\u0026#x1f604; 不能远程连接\\n检查下 redis.conf，看看 bind 的是谁\\n试试 telnet，看是不是端口没放通\\nredis 通过 6379 端口无法连接服务器 2.4 使用 python 连接 pip install redis\\nimport redis r = redis.StrictRedis(host='127.0.0.1', port=6379, db=0) r.set('foo', 'bar') # True r.get('foo') # 'bar' # 哈希表 r.hmset('dict', {'name': 'Bob'}) people = r.hgetall('dict') print people # {'name': 'Bob'} # 事务与管道 pipe = r.pipeline() pipe.set('foo', 'bar') pipe.get('foo') result = pipe.execute() print result # [True, 'bar'] # 管道 pipe = r.pipeline(transaction=False) result = r.pipeline().set('foo', 'bar').get('foo').execute() # [True, 'bar'] C++ 连接 hredis\\ngit clone https://github.com/redis/hiredis cd hiredis make -j4 sudo make install #仍然是复制可执行文件 sudo ldconfig /usr/local/lib\\t# 更新链接库缓存 g++ redis.cc -lhiredis -o myredisclient # 记得指定库文件 /* 示例代码 #include \\u0026lt;hiredis/hiredis.h\\u0026gt; redisConnect(...); redisCommand(...); */ #include \\u0026lt;iostream\\u0026gt; #include \\u0026lt;hiredis/hiredis.h\\u0026gt; const char *AUTH_KEYS = \\u0026quot;shuaikaisredis\\u0026quot;; int main() { // 连接到 Redis 服务器 redisContext *c = redisConnect(\\u0026quot;43.139.137.123\\u0026quot;, 6379); if (c-\\u0026gt;err) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;连接失败: \\u0026quot; \\u0026lt;\\u0026lt; c-\\u0026gt;errstr \\u0026lt;\\u0026lt; std::endl; return -1; } std::cout \\u0026lt;\\u0026lt; \\u0026quot;连接成功\\u0026quot; \\u0026lt;\\u0026lt; std::endl; // 使用密码进行身份验证 redisReply *reply = (redisReply *)redisCommand(c, \\u0026quot;AUTH %s\\u0026quot;, AUTH_KEYS); if (reply-\\u0026gt;type == REDIS_REPLY_ERROR) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;身份验证失败: \\u0026quot; \\u0026lt;\\u0026lt; reply-\\u0026gt;str \\u0026lt;\\u0026lt; std::endl; freeReplyObject(reply); redisFree(c); return -1; } std::cout \\u0026lt;\\u0026lt; \\u0026quot;身份验证成功\\u0026quot; \\u0026lt;\\u0026lt; std::endl; freeReplyObject(reply); // 列出所有的键值 reply = (redisReply *)redisCommand(c, \\u0026quot;KEYS *\\u0026quot;); if (reply-\\u0026gt;type == REDIS_REPLY_ARRAY) { for (int i = 0; i \\u0026lt; reply-\\u0026gt;elements; i++) { std::cout \\u0026lt;\\u0026lt; \\u0026quot;key: \\u0026quot; \\u0026lt;\\u0026lt; reply-\\u0026gt;element[i]-\\u0026gt;str \\u0026lt;\\u0026lt; std::endl; } } freeReplyObject(reply); // 获取某一键的值 const char *key2get = \\u0026quot;name\\u0026quot;; reply = (redisReply *)redisCommand(c, \\u0026quot;GET %s\\u0026quot;, key2get); if (reply-\\u0026gt;type == REDIS_REPLY_STRING) { printf(\\u0026quot;%s: %s\\\\n\\u0026quot;, key2get, reply-\\u0026gt;str); } else { printf(\\u0026quot;There is NO %s EXITS!\\\\n\\u0026quot;, key2get); } freeReplyObject(reply); // 设置一个新的键值对 const char *key1 = \\u0026quot;editor\\u0026quot;; const char *value1 = \\u0026quot;vscode\\u0026quot;; reply = (redisReply *)redisCommand(c, \\u0026quot;SET %s %s\\u0026quot;, key1, value1); std::cout \\u0026lt;\\u0026lt; \\u0026quot;RESULT: \\u0026quot; \\u0026lt;\\u0026lt; reply-\\u0026gt;str \\u0026lt;\\u0026lt; std::endl; freeReplyObject(reply); // 断开连接 redisFree(c); return 0; } 3 docker Docker — 从入门到实践 Docker 容器使用 | 菜鸟教程 3.1 安装 官方脚本快速安装\\n# 安装 curl -fsSL get.docker.com -o get-docker.sh sudo sh get-docker.sh --mirror Aliyun # 启动 sudo systemctl enable docker sudo systemctl start docker # 创建用户组并添加当前用户，否则可能会 Permission Deny sudo groupadd docker sudo usermod -aG docker shuaikai # 配置镜像加速 sudo vim /etc/docker/daemon.json # 写入如下配置 { \\u0026quot;registry-mirrors\\u0026quot;: [ \\u0026quot;https://hub-mirror.c.163.com\\u0026quot;, \\u0026quot;https://mirror.baidubce.com\\u0026quot; ] } # 重启服务，并查看是否配置成功 sudo systemctl daemon-reload sudo systemctl restart docker docker info | tail -5 # 如果这里显示权限不够： ## 首先检查一下你的用户是否在docker用户组中 groups gropus [shuaikai] ## 如果两条命令显示不一致（后者显示你已经在docker组里面了），则需要退出重连一下 3.2 常用指令 # 列出所有镜像 docker images # 列出所有的容器 docker container ls -a docker ps -a # pull 下载镜像 ## docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] docker pull ubuntu:18.04 # 从镜像创建一个容器并运行 docker run -it --rm --hostname {hostname} ubuntu:18.04 bash ## -i 交互操作; -t 终端; --rm 容器退出之后将其删除; ubuntu:18.04 启动容器的基础镜像 ## bash 启动容器后运行的命令，因为是想要一个终端 # 启动一个停止的容器 docker start [id/name] docker attach [id/name] # 进入一个容器，且exit不会导致容器退出的方法 docker exec -it [kkdocker01] bash # 删除一个/所有已终止的容器 docker rm [id/name] docker container prune # 向容器传递内容 docker cp {local_path} \\u0026lt;dockerid\\u0026gt;:{docker_path} # 查看整个docker占用的磁盘空间详细信息 docker system df -v # 网络：映射本地端口到docker的端口，从而实现外部访问docker # 导入导出：将容器打包成tar文件导出，也可从别的方式导入容器 3.3 docker - redis docker run -p 6379:6379 --name redis1 -v /opt/docker_redis/redis.conf:/etc/redis/redis.conf -v /opt/docker_redis/data:/data -d redis redis-server /etc/redis/redis.conf --appendonly yes --requirepass 123456 # 命令说明 # -p 6379:6379 端口映射：前面表示主机的端口，后面表示容器的端口。 # --name redis01 指定该容器名称，查看和进行操作都比较方便。 # -v 挂载文件或目录 ：前表示主机部分，：后表示容器部分。 # -d redis 表示后台启动redis # redis-server /etc/redis/redis.conf 以配置文件启动redis，加载容器内的conf文件，最终找到的是挂载的目录/usr/local/docker/redis.conf # --appendonly yes 开启redis 持久化 # --requirepass 123456 设置密码为123456 # # 进入： docker exec -it redis /bin/bash # redis-cli -p 6379 # 获取密码：config get requirepass # 输入密码： auth 123456 \\u0026#x1f3c7; 消遣玩意儿 1 wox 插件：\\n[][Plugin Detail (wox.one)] directory ，查词翻译，!t, !d, !e 自带的一些，比如查文件夹，查书签，显示十六进制颜色，进制转换等 可以是 everything 的关键词查找，如果采用 glob 匹配，则注意匹配全名 2 typora \\u0026#x1fab2; Typora 1.4.8 (1) 设置自动上传阿里云图床\\n图片$\\\\Rarr$上传服务设定：选择 PicGo-Core(command line)，没下载的记得下载。使用方法参考 Upload Images - Typora Support 和 PicGo-Core 然后申请你的阿里\\u0026#x2601;\\u0026#xfe0f;腾讯云这云那云的，更新配置文件（在 C:\\\\Users\\\\[username]\\\\.picgo\\\\）：\\n{ \\u0026quot;picBed\\u0026quot;: { \\u0026quot;uploader\\u0026quot;: \\u0026quot;aliyun\\u0026quot;, // 指定当前默认的图床为 aliyun, \\u0026quot;aliyun\\u0026quot;: { \\u0026quot;accessKeyId\\u0026quot;: \\u0026quot;\\u0026quot;, //创建用户时生成的accessKeyId，替换为自己的 \\u0026quot;accessKeySecret\\u0026quot;: \\u0026quot;\\u0026quot;, //创建用户时生成的accessKeySecret，替换为自己的 \\u0026quot;bucket\\u0026quot;: \\u0026quot;shuaikai-bucket0001\\u0026quot;, // 存储空间名，也就是我们创建的Bucket的名字 \\u0026quot;area\\u0026quot;: \\u0026quot;oss-cn-shanghai\\u0026quot;, // 存储区域代号，课通过bucket概览查看，替换为自己的 \\u0026quot;path\\u0026quot;: \\u0026quot;blog_img/\\u0026quot;, // 自定义存储路径，一定要以\\u0026quot;/\\u0026quot;结尾！，根据自己需求修改 \\u0026quot;customUrl\\u0026quot;: \\u0026quot;\\u0026quot;, // 自定义域名，注意要加http://或者https:// ，根据自己实际情况修改 \\u0026quot;options\\u0026quot;: \\u0026quot;\\u0026quot; // 针对图片的一些后缀处理参数 PicGo 2.2.0+ PicGo-Core 1.4.0+ 不用修改 } }, \\u0026quot;picgoPlugins\\u0026quot;: {} } (2) CSS 已经备份，\\u0026#x1f914; 等待上传云上\\n3 sharpkeys 映射按键，下载解压版的就够了 4 snipaste Alt + S 截图， Alt + Z 贴图， Ctrl + T 固定到屏幕上（直接点击就好） ,和 . 能在历史记录中移动，历史记录保存着整个屏幕 1 2 3 4可以对贴图进行旋转以及镜像。如果想要看一部分镜像的样子，这或许很有用 双击左键关闭贴图，对贴图 shift+左键双击：得到缩略图， 鼠标中间单击：从缩略图恢复原样 shift+上下左右/WASD：以像素为单位缩小截图区域；ctrl + 上下左右/WASD：放大 5 nginx sudo apt install nginx\\nsudo systemctl status nginx\\n配置文件在 sudo vim /etc/nginx/nginx.conf 中 (\\u0026#x1f517; Nginx 配置文件详解 )\\n在http{}里面添加上server{...}\\nuser shuaikai; ... server { listen 80; server_name xxx.xxx.xxx.xxx; root /home/shuaikai/web/; index index.html; access_log /home/shuaikai/web/log/kkcloud.access.log; error_log /home/shuaikai/web/log/kkcloud.error.log; } nginx -t 测试配置文件有没有毛病\\n超详细图解：从 0 搭建一个个人网站 6 lazyvim # 1. 首先安装最新版neovim curl -LO https://github.com/neovim/neovim/releases/latest/download/nvim-linux64.tar.gz sudo rm -rf /opt/nvim sudo tar -C /opt -xzf nvim-linux64.tar.gz export PATH=\\u0026quot;$PATH:/opt/nvim-linux64/bin\\u0026quot; # 2. 安装 Lazyvim ## 可以选择备份一下 (这里用了bash的大括号扩展语法) mv ~/.config/nvim{,.bak} mv ~/.local/share/nvim{,.bak} mv ~/.local/state/nvim{,.bak} mv ~/.cache/nvim{,.bak} git clone https://github.com/LazyVim/starter ~/.config/nvim rm -rf ~/.config/nvim/.git # 3. 启动neovim，让lazyvim自动下载 nvim ## 这时候，Mason可能会有一些lsp下载不下来。主要原因是系统没有相关环境，安装上即可 ## 3.1 安装node，有些插件需要npm wget https://nodejs.org/dist/v22.3.0/node-v22.3.0-linux-x64.tar.xz sudo tar -C /opt -xJf node-v22.3.0-linux-x64.tar.xz export PATH=\\u0026quot;$PATH:/opt/node-v22.3.0-linux-x64/bin\\u0026quot; ## 3.2 安装go wget https://go.dev/dl/go1.22.4.linux-amd64.tar.gz sudo tar -C /opt -xzf go1.22.4.linux-amd64.tar.gz export PATH=\\u0026quot;$PATH:/opt/go/bin\\u0026quot; ### 注意 go 还要配置一下国内源 go env -w GO111MODULE=auto go env -w GOPROXY=https://goproxy.cn,direct ## 3.3 安装 rust curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh ## 3.5 安装 ruff(一个号称最快的python检查工具，类似pylint，但是更快) ### 有pip直接用pip，如果是debain12，可以使用pipx sudo apt install pipx pipx install ruff ## 3.6 一般情况下，我都会准备好C/C++/clangd等内容，所以不会缺 # 4. 其他可选项，如lazygit，tmux，剪切板支持等 ## LazyGit: https://github.com/jesseduffield/lazygit/releases ## Tmux: sudo apt install tmux -y 自定义配置可以参考 lazyvim 配置文件参考 \\u0026#x1f414; 奇技淫巧 1 windows 技巧 Systeminfo.exe 查看系统信息，包括基本信息、BIOS 版本、网卡、Hyper-V 等 \"",
      categories: "[\"环境配置\"]",
      tags: [],
      series: [],
      date: "\"2025-02-24\""
    });
  
    searchIndex.push({
      title: "\"leetcode调试指南\"",
      permalink: "\"/%E7%AE%97%E6%B3%95/leetcode%E8%B0%83%E8%AF%95%E6%8C%87%E5%8D%97/\"",
      content: "\"leetcode 调试 方法 2 代码拷贝到本地，用 ide/gdb 调试。 比如使用 vim + floaterm + cgdb，效果见后图\\n对于此法，提供一个 header-only 的头文件 📜 《lc.h》 ，只需要引用此头文件，然后将 Class Solution 复制到本地，加上 main 函数即可运行\\n功能简介 常用头文件（类似\\u0026lt;bits/stdc++.h\\u0026gt;，但是 win 上没有）以及 using namespace std; leetcode 的链表和二叉树的定义，以及快速构建函数 随机数库封装，可以直接获取随机 vector、字符串等 Logger，可以打印包括容器、嵌套容器、自定义类型在内的各种类型 Assert, 一些断言。是的，这跟 leetcode 无关，可以在你编写自己的小算法的时候提供一些测试套件。效果如图： benchmark，简单的性能测试（测试运行 n 次用时、平均每次用时） 其他的，大杂烩。（比如对 ppm 位图的封装，你可以由此实现一个对可视化的排序算法\\u0026hellip;） 效果图 另外，推荐使用 vim + floaterm + cgdb 的方式，配合此头文件对 leetcode 代码进行调试，喜欢的点是比较轻量，随时随地能调一下子。效果如下\\n方法 1 在 leetcode 代码头上定义测试宏，使用 print 大法来调试。\\n这里我把代码用 vscode 的 join line 合并成一行了，不然有些喧宾夺主。记得提交的时候把 DEBUG 宏关闭就好。格式化后的代码见后文\\n#define DEBUG 1 #if DEBUG #include \\u0026lt;iostream\\u0026gt; #include \\u0026lt;numeric\\u0026gt; #include \\u0026lt;string\\u0026gt; #include \\u0026lt;type_traits\\u0026gt; template \\u0026lt;typename T\\u0026gt; struct ListType { template \\u0026lt;typename Ptr\\u0026gt; static auto test(Ptr ptr) -\\u0026gt; decltype(ptr-\\u0026gt;val, ptr-\\u0026gt;next, std::true_type{}); template \\u0026lt;typename Ptr\\u0026gt; static std::false_type test(...); static constexpr bool value = decltype(test\\u0026lt;T\\u0026gt;(nullptr))::value; }; template \\u0026lt;typename T, typename = void\\u0026gt; struct Container : std::false_type {}; template \\u0026lt;typename T\\u0026gt; struct Container\\u0026lt;T, std::void_t\\u0026lt;typename T::value_type\\u0026gt;\\u0026gt; : std::true_type {}; const std::string sep = \\u0026quot;,\\u0026quot;; template \\u0026lt;typename T\\u0026gt; std::string skToString(T c) { if constexpr (ListType\\u0026lt;T\\u0026gt;::value) { std::string ret = \\u0026quot;[\\u0026quot;; auto p = c; while (p != nullptr \\u0026amp;\\u0026amp; p-\\u0026gt;next != nullptr) { ret = ret + skToString(p-\\u0026gt;val) + sep; p = p-\\u0026gt;next; } if (p != nullptr) { ret += skToString(p-\\u0026gt;val); } ret += \\u0026quot;]\\u0026quot;; return ret; } else if constexpr (Container\\u0026lt;T\\u0026gt;::value \\u0026amp;\\u0026amp; !std::is_convertible_v\\u0026lt;T, std::string\\u0026gt;) { if (c.empty()) { return \\u0026quot;[]\\u0026quot;; } return \\u0026quot;[\\u0026quot; + std::accumulate(std::next(c.begin()), c.end(), skToString(*(c.begin())), [](std::string a, auto b) { return a + sep + skToString(b); }) + \\u0026quot;]\\u0026quot;; } else if constexpr (std::is_arithmetic_v\\u0026lt;T\\u0026gt;) { return std::to_string(c); } else if constexpr (std::is_convertible_v\\u0026lt;T, std::string\\u0026gt;) { return c; } else { return \\u0026quot;{\\u0026quot; + skToString(c.first) + sep + skToString(c.second) + \\u0026quot;}\\u0026quot;; } } template \\u0026lt;typename... Args\\u0026gt; std::string skFmt(std::string_view format, Args... args) { std::string fmtStr(format); return ((fmtStr.replace(fmtStr.find(\\u0026quot;{}\\u0026quot;), 2, skToString(args))), ...); } template \\u0026lt;typename... PairTypes\\u0026gt; void dumpWithName(PairTypes... args) { ((std::cout \\u0026lt;\\u0026lt; \\u0026quot;【\\u0026quot; \\u0026lt;\\u0026lt; skToString(std::get\\u0026lt;0\\u0026gt;(args)) \\u0026lt;\\u0026lt; \\u0026quot;】:\\u0026quot; \\u0026lt;\\u0026lt; skToString(std::get\\u0026lt;1\\u0026gt;(args)) \\u0026lt;\\u0026lt; \\u0026quot; \\u0026quot;), ...); } #define TO_PAIR(x) std::make_pair(#x, x) #define DUMP1(x) dumpWithName(TO_PAIR(x)) #define DUMP2(x, ...) dumpWithName(TO_PAIR(x)), DUMP1(__VA_ARGS__) #define DUMP3(x, ...) dumpWithName(TO_PAIR(x)), DUMP2(__VA_ARGS__) #define DUMP4(x, ...) dumpWithName(TO_PAIR(x)), DUMP3(__VA_ARGS__) #define DUMP5(x, ...) dumpWithName(TO_PAIR(x)), DUMP4(__VA_ARGS__) #define DUMP6(x, ...) dumpWithName(TO_PAIR(x)), DUMP5(__VA_ARGS__) #define DUMP7(x, ...) dumpWithName(TO_PAIR(x)), DUMP6(__VA_ARGS__) #define DUMP8(x, ...) dumpWithName(TO_PAIR(x)), DUMP7(__VA_ARGS__) #define GET_MACRO(_1, _2, _3, _4, _5, _6, _7, _8, NAME, ...) NAME #define OUTV(...) std::cout \\u0026lt;\\u0026lt; skFmt(__VA_ARGS__) \\u0026lt;\\u0026lt; std::endl; #define DUMP(...) do{GET_MACRO(__VA_ARGS__, DUMP8, DUMP7, DUMP6, DUMP5, DUMP4, DUMP3,DUMP2, DUMP1)(__VA_ARGS__);std::cout \\u0026lt;\\u0026lt; \\u0026quot;\\\\n\\u0026quot;;}while(0) #else #define OUTV(...) #define DUMP(...) #endif 功能简介 LOG(X) 输出 [#x] X \\\\n 的效果 LOGF(\\u0026hellip;) 即 format，可以实现 LOGF(\\u0026quot;This's my var: list:{}, map:{}, vector:{}, string:{}, int:{} ...\\u0026quot;, l, mp, vc, str, i)等类型的输出 对 leetcode 涉及到类型（无非就是容器，链表，和基本类型）进行 toString()转换。（正因为有此假设，所以实现时重点在于简洁而不在鲁棒，不支持类型可能会 segment fault） 效果图 进行了一波小更新，DUMP 可以将传入的变量（最多 8 个）按照【name】: value 的格式打印出来，省去了写 format 字串的麻烦，更方便一些。\\n(LOGF就是现在的宏OUTV，下面的图是更新前的老名字。这里只是为了展示可以支持哪些类型)\\n附： 格式化后的代码，供诸君参考\\n#define DEBUG 1 #if DEBUG #include \\u0026lt;iostream\\u0026gt; #include \\u0026lt;numeric\\u0026gt; #include \\u0026lt;string\\u0026gt; #include \\u0026lt;type_traits\\u0026gt; template \\u0026lt;typename T\\u0026gt; struct ListType { template \\u0026lt;typename Ptr\\u0026gt; static auto test(Ptr ptr) -\\u0026gt; decltype(ptr-\\u0026gt;val, ptr-\\u0026gt;next, std::true_type{}); template \\u0026lt;typename Ptr\\u0026gt; static std::false_type test(...); static constexpr bool value = decltype(test\\u0026lt;T\\u0026gt;(nullptr))::value; }; template \\u0026lt;typename T, typename = void\\u0026gt; struct Container : std::false_type {}; template \\u0026lt;typename T\\u0026gt; struct Container\\u0026lt;T, std::void_t\\u0026lt;typename T::value_type\\u0026gt;\\u0026gt; : std::true_type {}; const std::string sep = \\u0026quot;,\\u0026quot;; template \\u0026lt;typename T\\u0026gt; std::string skToString(T c) { if constexpr (ListType\\u0026lt;T\\u0026gt;::value) { std::string ret = \\u0026quot;[\\u0026quot;; auto p = c; while (p != nullptr \\u0026amp;\\u0026amp; p-\\u0026gt;next != nullptr) { ret = ret + skToString(p-\\u0026gt;val) + sep; p = p-\\u0026gt;next; } if (p != nullptr) { ret += skToString(p-\\u0026gt;val); } ret += \\u0026quot;]\\u0026quot;; return ret; } else if constexpr (Container\\u0026lt;T\\u0026gt;::value \\u0026amp;\\u0026amp; !std::is_convertible_v\\u0026lt;T, std::string\\u0026gt;) { if (c.empty()) { return \\u0026quot;[]\\u0026quot;; } return \\u0026quot;[\\u0026quot; + std::accumulate(std::next(c.begin()), c.end(), skToString(*(c.begin())), [](std::string a, auto b) { return a + sep + skToString(b); }) + \\u0026quot;]\\u0026quot;; } else if constexpr (std::is_arithmetic_v\\u0026lt;T\\u0026gt;) { return std::to_string(c); } else if constexpr (std::is_convertible_v\\u0026lt;T, std::string\\u0026gt;) { return c; } else { return \\u0026quot;{\\u0026quot; + skToString(c.first) + sep + skToString(c.second) + \\u0026quot;}\\u0026quot;; } } template \\u0026lt;typename... Args\\u0026gt; std::string skFmt(std::string_view format, Args... args) { std::string fmtStr(format); return ((fmtStr.replace(fmtStr.find(\\u0026quot;{}\\u0026quot;), 2, skToString(args))), ...); } template \\u0026lt;typename... PairTypes\\u0026gt; void dumpWithName(PairTypes... args) { ((std::cout \\u0026lt;\\u0026lt; \\u0026quot;【\\u0026quot; \\u0026lt;\\u0026lt; skToString(std::get\\u0026lt;0\\u0026gt;(args)) \\u0026lt;\\u0026lt; \\u0026quot;】:\\u0026quot; \\u0026lt;\\u0026lt; skToString(std::get\\u0026lt;1\\u0026gt;(args)) \\u0026lt;\\u0026lt; \\u0026quot; \\u0026quot;), ...); } #define TO_PAIR(x) std::make_pair(#x, x) #define DUMP1(x) dumpWithName(TO_PAIR(x)) #define DUMP2(x, ...) dumpWithName(TO_PAIR(x)), DUMP1(__VA_ARGS__) #define DUMP3(x, ...) dumpWithName(TO_PAIR(x)), DUMP2(__VA_ARGS__) #define DUMP4(x, ...) dumpWithName(TO_PAIR(x)), DUMP3(__VA_ARGS__) #define DUMP5(x, ...) dumpWithName(TO_PAIR(x)), DUMP4(__VA_ARGS__) #define DUMP6(x, ...) dumpWithName(TO_PAIR(x)), DUMP5(__VA_ARGS__) #define DUMP7(x, ...) dumpWithName(TO_PAIR(x)), DUMP6(__VA_ARGS__) #define DUMP8(x, ...) dumpWithName(TO_PAIR(x)), DUMP7(__VA_ARGS__) #define GET_MACRO(_1, _2, _3, _4, _5, _6, _7, _8, NAME, ...) NAME #define OUTV(...) std::cout \\u0026lt;\\u0026lt; skFmt(__VA_ARGS__) \\u0026lt;\\u0026lt; std::endl; #define DUMP(...) \\\\ do { \\\\ GET_MACRO(__VA_ARGS__, DUMP8, DUMP7, DUMP6, DUMP5, DUMP4, DUMP3, \\\\ DUMP2, DUMP1) \\\\ (__VA_ARGS__); \\\\ std::cout \\u0026lt;\\u0026lt; \\u0026quot;\\\\n\\u0026quot;; \\\\ } while (0) #else #define OUTV(...) #define DUMP(...) #endif \"",
      categories: [],
      tags: "[\"leetcode\"]",
      series: [],
      date: "\"2024-03-14\""
    });
  
    searchIndex.push({
      title: "\"linux命令行大记忆恢复术\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E7%94%A8%E6%B3%95/\"",
      content: "\"常用 Linux 命令 find \\u0026amp; fd fd 默认是正则表达式状态，以及会忽略一些文件\\n-g 使用 glob 通配符 -e 查找拓展名 -x 为每一条结果分别执行命令 -X 为所有结果执行同一个命令 -h 不跳过隐藏文件 -uu 不忽略任何东西,包括.gitnore 中的 -i 忽略大小写(fd 默认是只能匹配,即输入小写是大小写不敏感,输入大写时敏感) 权限 find . -perm /111 -type f -delete：linux 下删除可执行文件（加个 type 可以略掉文件夹）（ find 命令参考 ） -perm mode：必须与 mode 指示的一样 -perm /mode：mode 中表示的，满足一个就好了，比如111，则只要有一个1满足就好了 -perm -mode：mode 中表示的，必须全部具有，111就是 ugo 都得可执行，缺一不可。别的属性不管 find -iname readme -o -name *.c -not -size +100k -exec ls -i {} + -fprintf0 file.txt ： find 查找是完全匹配；逻辑与或非；size 的单位注意默认不是 byte；exec 结尾是{} +大括号表示结果 diff diff file1 file2：比较文件的异同：怎么样改变第一个文件，可以把它变成第二个文件 \\u0026lt; 表示左边 file1 独有的文件/行，\\u0026gt;表示右边 file2 独有的文件/行，| 表示两边都有，但不一样 2,4a2,4：数字是闭区间，[2-4]行，需要add 才能跟 file2 一样，【add、 change、 delete】 diff file1 file2 -y -W 100 | grep \\u0026quot;\\u0026gt;\\u0026quot;：并排显示不同之处，每排宽度 100 -y并排显示： --suppress-common-lines仅显示不同的；--left-column相同的仅在左边显示 -w忽略所有空格，-i忽略大小写，-I \\u0026lt;str\\u0026gt;忽略字符串，-b 忽略行尾空格，字符串中若干空格视为相等 -C \\u0026lt;num\\u0026gt; 不同之处上下显示 num 行上下文 -q仅显示是否相同 -p可用于比较 C 程序 -r递归比较子目录，-N独有的文件会显示\\u0026quot;only in xxx\\u0026quot; diff {dir1} {dir2} -Nrqy只显示文件夹中哪些文件不一样，不输出具体的文件 grep -i：忽略大小写进行匹配 -v：反向查找，只打印不匹配的行 -E: 使用正经的正则表达式 -n：显示匹配行的行号 -r：递归查找子目录中的文件 -l：只打印匹配的文件名（小写 L） -c只打印匹配的行数 sed sed 命令的基本格式是sed [-ni][-e\\u0026lt;script\\u0026gt;][-f\\u0026lt;script文件\\u0026gt;][文本文件]\\n-n：安静模式，只显示被 sed 处理过的行（否则会输出所有来自 stdin 的输入） -e：允许后面直接跟命令，换句话说，不使用 -e 的话命令需要用单引号括起来。可以使用多个 -e -f：允许使用指定 sed 脚本文件 -i：直接处理文件本身（会生成 temp 文件） sed 命令中有一些动作：（sed 从 1 开始计算行）\\ni \\\\：插入， 后面接字串，插入在当前行的上一行*（注意 i a c 这三个动作后面要加上反斜杠）*\\na\\\\：新增， 后面接字串，插入在当前行的下一行\\nc\\\\ ：取代， 后面接字串，取代 n1, n2 之间的行\\nd ：删除，因为是删除，所以 d 后面通常不接任何东西\\np ：打印，亦即将某个选择的数据印出。通常 p 会与参数 sed -n 一起运行\\ns ：取代，通常搭配正则表达式，例如 1,20s/old/new/g\\nsed 以行为单位处理，加g是替换全部 pattern，不加是只替换每一行的第一个\\n# 在第二行上面插入一行 rowxxxyyyy sed -i -e 2i\\\\ rowxxxyyyy test.txt sed '2,5c\\\\ shuaikai' # 在满足 pattern 模式的行下面插入一行 sed -i '/.*123.*/a 456' test.txt # 可以用圆括号来进行正则表达式捕获，并用\\\\+数字来进行引用。圆括号要进行转义 echo \\u0026quot;Hello, World\\u0026quot; | sed -n 's#.*,\\\\s\\\\(\\\\w*\\\\)#\\\\1#p' awk awk 命令的基本格式是awk -F \\u0026quot; \\u0026quot; ' pattern { action } ' filename，即指定分隔符，然后单引号括起来的所有内容作为参数传递给 awk，其中前半部分是一个正则表达式/条件，后面具体执行的操作用大括号括起来\\nawk 处理文件是以行为单位，对每一行执行操作；每一行通过分隔符划分为NF个部分\\nNR：当前处理的行号；NF：当前行的块数。NF==0即表示空行 $0：整行内容；$1...：第 1、2\\u0026hellip;NR 部分 使用变量不需要声明，第一次用到的时候自动赋空值 循环、分支等与 C 语言相同 action 部分可执行内置函数：print、length、sqrt、match等，也可以通过system()来执行任意函数 BEGIN块，指定在执行动作之前做什么；EDN块，指定在执行完动作之后做什么 # 输出csv文件每行中长度超过5的字符串，不超过的用xxx代替 awk -F ',' 'NF%3==0 {for(i=1;i\\u0026lt;=NF;i++) if(length($i)\\u0026gt;5) print$i; else if print\\u0026quot;xxx\\u0026quot;}' # 删除文件中行号是4的倍数的行 awk 'NR%4==0 {print NR}' file | xargs -I{} sed -i \\u0026quot;{}d\\u0026quot; file # BAEGIN 和 END 的示意，中间的action才是真正要执行的命令 ## 比如如果需要什么累加的东西，则可以在 END 块中输出出来 awk '[pattern] BAEGIN{print\\u0026quot;我要开始了\\u0026quot;} {action...} END{print\\u0026quot;我结束了\\u0026quot;}' 例子 例 1 用 awk 和 sed 迁移阿里云上的图片：\\n找到阿里云 oss 仓库，选择批量导出 url，导出后是一个.csv 文件，格式为 obj，url\\n找一个文件夹下载所有 url\\ncat export_urls.csv | awk -F, '{print $2}' | xargs wget 把下载的这些文件上传到新的 oss 上，得到新的链接。这会导致原来的笔记里面的图片链接全部失效，因此要更改链接。链接的区别只在前面的 bucket 地址，后面的图片名是完全一样的。因此只需要找到所有的笔记文件，把其中图片 url 中前面的 bucket 链接改成新的连接前缀即可\\n此处用到的 fd 命令要先下载，即 fd-find。可以对文件夹进行递归正则查询。至此，就完成了对所有图片的迁移、更改链接操作。\\nfd \\u0026quot;.*\\\\.md$\\u0026quot; | xargs sed -i 's#https:\\\\/\\\\/xxx.xxx#https:\\\\/\\\\/yyy.yyy#g' \"",
      categories: "[\"工具使用\"]",
      tags: "[\"linux\",\"cmdline\"]",
      series: "[\"快速上手\"]",
      date: "\"2023-11-25\""
    });
  
    searchIndex.push({
      title: "\"番茄鸡蛋面\"",
      permalink: "\"/%E8%A1%A3%E9%A3%9F%E4%BD%8F%E8%A1%8C/%E8%8F%9C%E8%B0%B1/%E7%95%AA%E8%8C%84%E9%B8%A1%E8%9B%8B%E9%9D%A2/\"",
      content: "\"番茄鸡蛋面 食材 番茄 x2 面条若干 鸡蛋 x2 风味 白胡椒 小葱 香油、花椒油 香菜、洋葱、豆腐、一切你觉得合适的东西 做法 1 煎两个荷包蛋 先煎鸡蛋，煎完盛出放一边，等会做好番茄汤再下锅煮。可以不信教程，但是一定要相信 热锅凉油 ，不然它是真粘锅。\\n也可以先煮番茄汤，再直接磕鸡蛋。这种情况下要注意：\\n小心鸡蛋沉入锅底粘锅，可以用铲子轻轻铲动 选好位置，买定离手。定型前不要搅动，除非你想做的是蛋花汤 2 炖一锅番茄汤 番茄切丁，可以直接下锅小火慢炒，炒成糊。也可以少加点水，边炒边炖，没什么区别。中间可以用勺子压一压，加快成糊速度\\n不论哪种方法，都要小心糊锅。炒番茄也是可能糊的\\n配菜也是这里下入，什么豆腐洋葱腊肉，手边有什么就可以放什么，当然不要放太多喧宾夺主\\n图省事这里就可以调味了，胡椒粉、盐、鸡精。\\n3 炖，狠狠地煮 炖，总是有一种时间越久味道越醇厚的魔力，虽然可能这里并没有什么用。总之，别干锅了\\n4 下面条 量力而行，下入面条，接着煮。面条过多会有点稠，过少，会吃不饱。上一步可以煮很久，但是这一步久了，面条就坏了。\\n5 出锅 葱花香油麻油之类的这时候放正好。准备一个大面碗，直接倒进去。谁能拒绝初秋清冷的夜晚，来一碗暖暖的汤面呢？\\n\"",
      categories: "[\"衣食住行\"]",
      tags: [],
      series: "[\"快速做饭\"]",
      date: "\"2023-10-22\""
    });
  
    searchIndex.push({
      title: "\"PlantUML快速上手\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/plantuml%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/\"",
      content: "\"PlantUML 快速上手 通用 命令 title header footer：标题、页首、页脚 skin rose ： rational rose 的皮肤 skinparam monochrome true ： 黑白皮肤 scale 2 ： 生成图片放大两倍，嫌图片分辨率不够的时候可以用 participant 可以预定义参与者 actor 小人儿 注释 时序图 boundary 边界\\n箭头 -\\u0026gt;， \\u0026ndash;\\u0026gt;， -\\u0026raquo;， -\\\\， -/, o-\\u0026gt;， -x， [-\\u0026gt;， ?-\\u0026gt; 实线同步消息，虚线返回消息（直接用 return），细箭头异步消息 [ 方括号表示虚空来历（不关心从哪来、往哪去） 标记 ==xx==分割线 ||| 增大间隔 \\u0026hellip; 延迟 (30) 圆括号指定角度 {start}\\u0026lt;-\\u0026gt;{end} 纵向连接线，要开启一个命令， ++ 激活 activate \\u0026ndash; 取消 deactivate !! 删除对象 ** 创建对象 块 xxx \\u0026hellip; end xxx。标签颜色井号紧跟名字，空格跟背景颜色 box-end 括住整个参与者 mainframe-end 一般包，可定义别名 opt （switch） alt-else-end （if-else） loop-end par-end （并行） 活动图 start开始，stop/end结束\\n:xxx;表示一个实体\\n活动图语法和功能 (plantuml.com) 用例图 usecase或(xxx)定义用例\\nactor或:xxx:定义参与者\\nas定义别名。如 usecase U1 ad (U1\\\\alias)\\npackage xxx{}或rectangle xxx {}定义包\\n箭头：--\\u0026gt; -\\u0026gt; -- .\\u0026gt; ..\\nTip 有时候你可能只需要一个“框图”，而非严格的带有什么 start 和 stop 的活动图。那么“用例图”实际上可以完成一二。用例图自带小人和椭圆，以及一些箭头，通过rectangle \\u0026quot;xxx\\u0026quot; as A可以创建一个方框。\\n@startuml rectangle \\u0026quot;AAA\\u0026quot; as A rectangle T1 rectangle T2 rectangle T3 rectangle \\u0026quot;...\\u0026quot; as B A -\\u0026gt; T1 : sth T1 -\\u0026gt; T2 T2 -\\u0026gt; T3 T3 -\\u0026gt; B note left of A #fff: Comment @enduml 类图 EBNF 开始 @startebnf @endebnf\\n例子：LISP 语法\\n\"",
      categories: "[\"工具使用\"]",
      tags: "[\"uml\",\"plantuml\"]",
      series: "[\"快速上手\"]",
      date: "\"2023-10-11\""
    });
  
    searchIndex.push({
      title: "\"WSL安装与配置\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/wsl%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/\"",
      content: "\"安装 wsl 本文简要介绍 WSL2 的自定义位置安装。比较简略，适合有一定经验的选手回忆用。\\n基本流程为，从链接下载一个程序包，然后解压缩到指定位置，运行ubuntu.exe即可\\n\\u0026#x1f517; WSL 的手动安装步骤 | Microsoft Learn \\u0026#x1f517; 最新版 ubuntu 的 AppxBundle 包 WSL2 手动安装流程 首先对 WSL2 是什么有个基本了解。然后如果不想从应用商店或者直接命令 install（默认 C 盘）的话，按照上述链接去下载一个包。\\n与此同时，参考下面的 1、2、3、4 命令，检查计算机环境是否准备好了，并设置你想安装的 wsl 版本号。\\n如果不是第一次安装，或者是想卸载之前的，可以参考 5、6、15、16 命令\\n配置完成后，打开下载好的 appx 文件，后缀名改为 zip，然后解压缩到你想要的文件夹，比如E:\\\\wsl。注意，官方教程说双击也能运行，确实，双击还是安装默认位置 ，那此举属实是有点脱裤子放\\u0026#x1f4a8;\\n所以要解压，有可能你下载的是一个版本包，里面有多个 appx，有 arm64 的、x64 的，还有一些缩放的。解压你对应的那个版本，然后运行.\\\\ubuntu.exe，就会自动安装了，安装完后 wsl2 可以看到一个vhdx文件，那就是它的虚拟磁盘。\\n如果这之间发生了什么异常，首先检查是不是虚拟化什么的没准备好，如果好了，那 STFW\\nWSL1 手动安装流程 鉴于 WSL2 丢失 wifi 的情况，如果想安装 wsl1，那么只需要wsl --set-default-version 1，然后仍然按照上述流程走就好了。运行完.\\\\ubuntu.exe后得到的就是 wsl1\\nWSL 常用命令 Get-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux检查是否开启了 wsl 功能。还有什么系统版本、HyperV 之类的都检查一下 dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart上一步发现Enable的用这条命令开启 wsl 功能 dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart开启虚拟化。这里官方教程说WSL2 需要，而且需要重启。WSL1 的俺忘了 注意 win11 开这个有可能会痛失 wifi 使用权，如果碰到了这个问题，我的建议是用 VM。下个 debain 的无 gui 版本，用 windows terminal 连，一个样。你不说谁知道是 wsl2 还是 vm 如果已经发生了上述问题，执行： dism.exe /online /disable-feature /featurename:VirtualMachinePlatform /norestart 手动重启（必须手动，实践出真知，不指定/norestart，从命令行执行 y 重启不行） 有一说一，win11 丢 wifi 很早之前就有了，刚出来的时候，开内核隔离还是内存完整性来着，就会丢 wifi 模块，大概都是虚拟化相关。两三年了还没修，又让我重蹈覆辙一次，fucking ridiculous wsl --set-default-version 2 设置默认版本号 wsl --list --verbose列出本机的 wsl wsl --unregister \\u0026lt;DistributionName\\u0026gt;卸载 wsl --set-version \\u0026lt;distribution name\\u0026gt; \\u0026lt;versionNumber\\u0026gt; wsl --distribution \\u0026lt;Distribution Name\\u0026gt; --user \\u0026lt;User Name\\u0026gt;运行特定版本 wsl --status wsl --shutdown立即终止所有正在运行的发行版和 WSL 2 轻量级实用工具虚拟机。 在需要重启 WSL 2 虚拟机环境的情形下，例如 更改内存使用限制 或更改 .wslconfig 文件 ，可能必须使用此命令。 wsl --terminate \\u0026lt;Distribution Name\\u0026gt;终止指定的发行版或阻止其运行 wsl --export \\u0026lt;Distribution Name\\u0026gt; \\u0026lt;FileName\\u0026gt;：导入导出，可以进行迁移，也是一种指定安装位置的手法 wsl --import \\u0026lt;Distribution Name\\u0026gt; \\u0026lt;InstallLocation\\u0026gt; \\u0026lt;FileName\\u0026gt;.tar 将指定 tar 文件导入和导出为新的发行版。 在标准输入中，文件名可以是 -。 选项包括： --vhd：指定导入/导出分发应为 .vhdx 文件而不是 tar 文件（这仅在使用 WSL 2 的情况下受支持） --version：（仅导入）指定将发行版导入为 WSL 1 还是 WSL 2 发行版 Get-AppxPackage -allusers | grep -i ubuntu搜索安装的 ubuntu 包 Remove-AppxPackage -Package \\u0026lt;PackageFullName\\u0026gt;移除包。可能手动安装新的包时需要这两条命令（比如出现什么更高版本已安装的问题） WSL2经典问题 coredump文件生成 Reference ubuntu配置coredump文件生成位置 | SHUAIKAI\\u0026rsquo;s Blog 网络问题 现在已经是5202了，应该都是相对来说比较新的Win11，WSL2支持了Mirror镜像模式网络，还是比较方便联网的。如果没有这个模式，建议更新一下。不说多么追新了，基本的大版本还是要跟得上的\\n第一步，设置里直接拉满\\n第二步，在windows下编辑~/.wslconfig文件（其实编辑这个的话，上面的拉不拉无所吊慰了，只是展示一下其实是有图形界面的）\\n可以参考这个人的 https://github.com/microsoft/WSL/issues/10753#issuecomment-2041372912 [wsl2] networkingMode=mirrored dnsTunneling=true firewall=true autoProxy=true [experimental] # requires dnsTunneling but are also OPTIONAL bestEffortDnsParsing=true useWindowsDnsCache=true 第三步，注意其实一般是这里的问题多一些，也即是，联不通网络，很多情况下是因为WSL的DNS解析不了\\n# 首先检查一下下面这个文件是不是软连接 ll /etc/resolv.conf # (case 1) 如果是软连接，那么说明这个是自动生成的，你首先要关掉它 sudo vim /etc/wsl.conf # (case 1) 然后添加下面的东西 [network] generateResolvConf=false # (case 1) 然后 wsl --shutdown 重启 # (case 2) 如果不是软连接，那么直接编辑就好了。换成一个顺眼的nameserver，比如： nameserver 8.8.8.8 nameserver 8.8.4.4 # (case 2) 具体是用哪个DNS，有以下几个原则： # - 如果你的本机DNS没啥问题，就打开控制面板，找到你的本机的DNS天上就好 # - 如果你想要折腾更快的，那么可以使用 DnsJumper 天天测 https://dnsjumper.net/ # - !如果你在公司里面用之类的，那么注意最好找到公司网的DNS，8.8.8.8这种不一定能行 想要systemd sudo vim /etc/wsl.conf # add below [boot] systemd=true \"",
      categories: "[\"环境配置\"]",
      tags: [],
      series: [],
      date: "\"2023-09-12\""
    });
  
    searchIndex.push({
      title: "\"C++网络编程入门概念及api总结\"",
      permalink: "\"/%E7%AC%94%E8%AE%B0/linux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B/\"",
      content: "\"Linux 系统编程 Chapter 1 系统编程入门 GCC 区别 GCC 与 G++\\ngcc 既能编译 c，也能编译 c++。只不过 gcc 在链接的时候，不能自动链接 C++的库。在编译阶段，g++会调用 gcc，二者是等价的。 __cplusplus宏：g++编译 .c 文件时会定义，按照严谨的 cpp 语法去执行；gcc 编译 .cpp 文件时也会定义。 gcc -lstdc++即可解决 gcc 链接不了 c++库的问题 -D选项，可以指定一个编译时后的宏，可以方便调试。比如调试版本和 release 版本，就不用删除 log 了\\n静态库与动态库 静态库 # 编译,得到目标文件 gcc -c tes1.c tes2.c # 打包成静态库: -r插入 -c -s起名 ar -rcs libxxx.a tes1.o tes2.o # 使用：指定库名、库位置、头文件 gcc -o demo tes1.o tes2.o -l xxx -L ./lib -I ./include 优点：\\n加载速度快，因为打包到程序里面了 发布无需额外提供库，方便移植 缺点：\\n消耗资源，每个程序使用库，都要加载到内存。如果多个程序使用同一个库，那就太浪费了\\n更新发布麻烦，你把库发给别人，别人还要再编译一遍\\n动态库 # 编译得 与位置无关 的目标文件 gcc -fpic -c tes1.c tes2.c # 编译成共享库 gcc -shared -o libxxx.so tes1.o tes2.o # 使用共享库，指定：指定库名、库位置、头文件 # ！！还要确保能找到库的绝对路径 可以使用ldd命令来查看可执行文件所依赖的动态库，找不到的会提示\\u0026quot;not found\\u0026quot;。\\n程序执行时，加载动态库的过程是由动态加载器ld-linux.so来完成的。他会依次寻找 elf 文件的 DT-RPATH 段（进程内存空间，改不了不用管）\\u0026mdash;\\u0026gt;环境变量 LD_DIRECTORY_PATH\\u0026mdash;\\u0026gt;/etc/ld.so.cache\\u0026mdash;\\u0026gt;/lib /usr/lib，找不到就报错。因此可以有以下方式指定路径：\\n#(1)更改环境变量 export LD_DIRECTORY_PATH=$LD_DIRECTORY_PATH:{your_lib_directory} # 当然也可以修改 ~/.bashrc 或 /etc/profile #(2)更改 /etc/ld.so.cache，但这是一个二进制文件，要更改它的config文件 sudo echo {your_lib_directory} \\u0026gt; /etc/ld.so.conf #(3)添加到 /lib /usr/lib 【不推荐】 优点 可以实现进程间资源共享（共享库） 更新部署发布简单，用户不需要重新编译 可以控制何时加载动态库，使用到的时候才进入内存 缺点 加载速度比静态库稍慢 发布程序时需要提供依赖的动态库 makefile make 默认执行的是第一条规则，其他的都是为第一条服务的 模式匹配中，多个百分号表示的是同一串字符 .PHONY，伪目标，那么就不会与外面的同名文件，如 clean 比较 GDB GDB 的功能，一般来说有：\\n启动程序，随心所欲的运行程序 让被调试程序在指定断点处停止，断点可以是表达式 当程序被停住，可以检查此时程序中发生的所有事 可以改变程序，修正一个BUG，从而去测试其他BUG core-file core：查看core文件【通过ulimit -a查看，再设置 core 文件大小，编译时-g即可生成 core 文件】\\n-g只是把源文件的信息加入可执行程序中，并不是嵌入了源程序。因此调试时还需要能找到源程序\\n命令：\\nset args arg_1 arg_2：给程序设置参数\\nshow args：显示参数\\nlist 文件名 : 行号/函数名：显示某文件，改函数或行号，附近的代码l\\nbreak 文件名 ： 行号/函数名：在该处设置断点b\\ninfo break：查看断点i\\ndelete/disable/enable 断点编号：查看/删除/无效/生效断点d/del/dis/ena\\nbreak [pos] if [condition] ：条件断点\\nstart/run：开始，到第一行停下/开始，到断点停下start/r\\ncontinue：执行到下一个断点c\\nnext：执行到下一行代码（不进入函数体）n\\nstep：向下单步调式（有函数就进入函数）s\\nfinish：跳出函数体（函数里面不能有断点）\\nutil ：跳出循环(循环内不能有可用的断点，且要停在循环的第一行/最后一行)\\nprint/ptype 变量名：打印变量值/打印变量类型\\ndisplay + 变量名：自动打印指定变量的值\\nundisplay + 编号 ：取消打印对应变量\\ninfo display：查看显示信息i\\nset var 变量名 = 变量值：更改变量的值\\nset disassemble-nextline on：设置自动输出下一行代码的汇编\\n文件 IO 标准 C 库与系统 IO C 库的 IO 函数是可以跨平台的。跨平台，要么是像 java 那样不同平台开发不同的虚拟机，要么是调用不同平台的系统 API，从而统一接口。\\n标准 C 库带有缓冲区，因此效率是更高的\\nC 库函数的 man 手册等级是 3，可以man 3 fwrite\\nUNIX 系统 IO\\nC 库有缓冲区，可以提高读写效率，但注意，是效率，而不是速度。在网络通信情境中，我们希望能迅速收到对方发来的消息，那么此时应该使用系统 IO，即时读写。总不能我发来的信息，等半天了你还在缓冲区里呢\\n虚存与文件描述符 一个应用程序可以打开很多文件，因此需要一个数组，来存储其打开的文件描述符\\n所谓一切皆文件，0 1 2 是默认打开的，对应的就是当前终端，终端也是一个“文件”。\\n同一文件可以被打开多次，相互之间的文件描述符是不相同的，比如不同用途，一个只读，一个只写。文件释放掉时文件描述符才会释放。分配文件描述符时，就从尚未分配的数子中选择一个最小的。\\nLinux 系统 IO 函数 系统 IO 在 man(2)，标准 C 库在 man(3)。因此这里就不具体列举了，直接man 2\\nopen int open(const char *pathname, int flags, mode_t mode);\\n注意，这里不是重载（C++才重载），这里用到的是 可变参数 open 函数失败返回 -1，然后，系统会恰当地设置一个“错误号”来标识此次错误的类型即errno flags的几个可选项之间，采用的是 按位或 | ，其实就是给 flags（32 位）不同位上加个 1 mode_t参数指定文件的权限，最终的权限 = mode \\u0026amp; ~umask umask作用就是抹去一些权限，保证你不会给错。 在当前终端直接 umask 即即可输出，也可用函数 mode_t umask(mode_t mode) errno：错误号，属于 Linux 系统函数库（而非属于函数），是全局变量，记录最近的错误号。\\nvoid perror(const char *s)：打印 errno 对应的错误描述，其中参数 s 是用户描述，输出的样子是 用户描述（s） ： errno 对应的错误\\nreadv \\u0026amp; writev \\u0026#x1f517; readv()和 writev()函数 #include \\u0026lt;sys/uio.h\\u0026gt; ssize_t readv(int fd, const struct iovec *iov, int iovcnt); ssize_t writev(int fd, const struct iovec *iov, int iovcnt); struct iovec { void *iov_base; /* Starting address */ size_t iov_len; /* Number of bytes to transfer */ }; 分散读与聚集写，可以用一次系统调用写多块\\nread \\u0026amp; write 返回值为 0，是判断读到文件读完的标志 while((len = read(fd_read, buffer, sizeof(buffer))) \\u0026gt; 0) 对同一文件连续读写操作的时候，一定要注意，文件指针的位置 $\\\\downarrow$ lseek off_t lseek(int fd, off_t offset, int whence);\\n作用：把文件指针移动到whence + offset的位置\\n返回值：成功返回文件指针相对于文件开始的偏移量，失败返回 -1\\n对于参数 whence，有三个取值： SEEK_SET：设置文件指针的偏移量为 offset SEEK_CUT：设置文件指针的偏移量为 当前位置 + offset SEEK_END：设置文件指针的偏移量为 文件大小 + offset lseek 一般有下面几个 移动文件指针到文件头，反复的读。不然就要关闭，再重新打开 lseek(fd, 0, SEEK_SET) 获取当前文件指针的位置 lseek(fd, 0, SEEK_CUR) 获取文件的大小 lseek(fd, 0, SEEK_END) 拓展文件长度（比如在下载文件时，下载器是先占用这么大，再慢慢往里写数据） lseek(fd, enlarge_size, SEEK_END)，要写入一定内容才会真正拓展 stat \\u0026amp; lstat 命令行：stat [filename]，用以查看文件的信息 int stat(const char *pathname, struct stat *statbuf); int lstat(const char *pathname, struct stat *statbuf);（当文件是软链接时，获取链接本身的信息） struct stat { dev_t st_dev; /* ID of device containing file */ ino_t st_ino; /* Inode number */ mode_t st_mode; /* File type and mode */ nlink_t st_nlink; /* Number of hard links */ uid_t st_uid; /* User ID of owner */ gid_t st_gid; /* Group ID of owner */ dev_t st_rdev; /* Device ID (if special file) */ off_t st_size; /* Total size, in bytes */ blksize_t st_blksize; /* Block size for filesystem I/O */ blkcnt_t st_blocks; /* Number of 512B blocks allocated */ }; 判断各区段的值，只需要按位与，即st.st_mode \\u0026amp; S_FLAGS，得到的结果与各种宏进行比较即可。也正因如此，这些 FLAGS 的值看起来才这么“长”，因为它们都是 16 位的，直接与整个 st_mode 相与的，其余无关的位都置 0，起到一个过滤的作用。\\n文件属性 access\\u0026hellip; access \\u0026amp; chmod \\u0026amp; truncate\\nint access(\\u0026quot;const char *pathname\\u0026quot;, int mode)\\nmode：F_OK判断文件是否存在，R_OK, W_OK, X_OK判断文件的读/写/执行/权限 int chmod(const char *pathname, mode_t mode);\\n系统中的用户和组，分别在文件/etc/passwd和/etc/group。也可以是用id + username命令 int truncate(const char *pathname, off_t length)\\n缩减/扩张文件到指定大小 目录操作 mkdir\\u0026hellip; mkdir \\u0026amp; rmdir \\u0026amp; rename \\u0026amp; chdir \\u0026amp; getcwd\\nint mkdir(const char *pathname, mode_t mode); int rmdir(const char *pathname); int rename(const char *oldpath, const char *newpath); int chdir(const char *path); char *getcwd(char *buf, size_t size); 对应 shell 的命令：mkdir、rmdir、mv、cd、pwd。查手册时要注意使用 man 2 makdir，否则默认打开的是第一章的 mkdir 命令\\nchdir：修改进程的工作目录（默认是在当前工作路径，即，在哪个目录启动程序，进程默认路径就在哪，而不是程序所在的文件夹！）\\ngetcwd：返回值其实就是传递进去的 buffer 的地址\\n目录遍历 readdir\\u0026hellip; man （3）\\nDIR *opendir(const char *dirname); struct dirent *readdir(DIR *dirp); int closedir(DIR *dirp); DIR *opendir(const char *dirname);：\\nDIR : 目录流结构体（不对用户开放，也用不到，只有指定参数类型时用） 错误返回 NULL struct dirent *readdir(DIR *dirp);\\n会自动指向流中，下一个目录的位置【这里疑惑：man 中说返回值是，下一个目录的结构体指针？】 返回读取到的目录信息（即 dirent 结构体指针）。错误或到结尾返回 NULL。可以通过errno来区分究竟是文件尾还是错误 int closedir(DIR *dirp);\\ndup \\u0026amp; dup2 int dup(int oldfd);\\n选择一个最小的未被使用的文件描述符，来指向 oldfd 指向的文件，即复制出来了一个文件描述符 int dup2(int oldfd, int newfd);\\n用指定的 newfd 来指向 oldfd 指向的文件。如果 newfd 指向的有文件，则先执行 close 操作。这里 oldfd 必须是一个有效值，否则 newfd 没有意义。如果二者相同，则等于什么都没做。返回值就是 newfd\\n可以用dup2来进行输入输出重定向，比如默认的输出是标准输出(fd1=STDOUT_FILENO)，现在想让它输出到文件中(fd2=12)，那么，就可以dup2(fd2, STDOUT_FILENO); 注意！重定向，是被更改的那一方作为 newfd，比如想重定向标准输出，则标准输出因该作为 newfd。因为 dup2 的作用是，关闭newfd指向的文件，并让其指向oldfd\\nfcntl int fcntl(int fd, int cmd, ... /*args*/);\\n参数cmd：命令，其实就是函数定义的一些宏，作用有五个：（列出了常用的两个）\\n复制文件描述符：F_DUPFD，返回一个新的文件描述符\\n设置/获取文件状态： F_GETFL，获取文件描述符对应的状态，即open函数中的flag F_SETFL，设置文件的状态 flag\\n注意，3 个必选项不可以修改（只读、只写、读写，以及一些创建文件的选项等） 可以修改的 flags 有O_APPEND、O_NONBLOCK(设置成非阻塞) . . . 阻塞/非阻塞：描述的函数调用的行为，函数对当前进程的影响。如，可籍此将管道文件设置为非阻塞\\nint fd = open(\\u0026quot;xxx\\u0026quot;); // 首先要获取当前文件的FLAG int flag = fcntl(fd, F_GETFL);\\t// 失败返回-1，成功返回flag // 然后，修改的时候，注意不是直接替换 flag |= O_APPEND; // 添加 flag \\u0026amp;= ~O_APPEND; // 删除 int ret = fcntl(fd, F_SETFL, flag);\\t// 失败返回-1，成功返回0 Chapter 2 Linux 多进程开发 进程概述 区别程序 \\u0026amp; 进程 多道程序、时间片、并发\\u0026amp;并行 进程控制块(PCB) 进程状态 其实内核实现是不区分就绪态和运行态的。你占有 cpu 就是运行态，不占有就是就绪态\\n新建态：新建后进入就绪列表\\n终止态：可能是运行结束，也可能是被高权限者终结。终结后，进程不再继续执行，但仍然会留在操作系统中等待善后。等其他进程完成了对终止进程信息抽取后，操作系统才会将其从系统中删除。\\n进程相关命令 {cmd} \\u0026amp;：在命令后面加上一个\\u0026amp;可以让其在后台运行（会定时将结果输出到前台来，但不影响输入输出）\\n进程号和相关函数 进程操作 进程创建 fork() pid_t fork(void)：复制当前进程，但是运行在不同内存空间（仔细查看 fork(2)手册中的 DESCRIPTION）\\n创建成功，函数会返回两次：父进程中返回子进程 pid，子进程中返回 0\\n创建失败：父进程中返回-1，并设置 errno：\\nEAGAIN：当前系统进程数达到上限\\nENOMEM：当前系统内存不足\\n如何区分父子进程？：利用 fork()函数的返回值。返回值为 0 说明是子进程，否则说明是父进程。由于父子进程是共享代码段的，因此通过添加一个 if-else 判断，来实现，两个进程执行相同代码，在某些地方又执行不同代码的效果。\\n理解子进程创建：\\n我们说，子进程“拷贝”一份父进程的虚拟地址空间（内核区也会拷贝）。但其实这么想会好些：子进程复制父进程的数据空间(数据段)、栈、堆；共享父进程的正文段，也即二者执行相同的代码，只是开始位置有些不同，但并非是，你有一段代码，我有另一段。原因往下看。 子进程共享父进程的代码，是从 fork()后开始执行的 注意，是直接复制了一份内存空间，因此里面的什么变量啊的都是两份，改动互不影响 实际上，复制的实现，是通过“写时拷贝”（copy-on-write）来实现的，即，fork 后并不会真的直接复制一段内存，而是通过“只读共享”的方式，让父、子进程共用一段内存。只有在需要写入数据的时候，才真正进行拷贝，使得二者拥有独自的空间。\\n父子进程共享文件，共用相同的文件描述符、相同的文件偏移指针，引用计数增加\\n父子进程区别：\\nfork()函数返回值不同 PCB 中一些数据不一样，比如当前进程 pid、父进程 ppid(就是说,内核区也不是完全相同的) 信号集不同 父子进程共同点\\n子进程刚被 fork 出来时，和父进程的：用户区数据、文件描述符表都是一样的 GDB 多进程调试 GDB 默认只能跟踪一个进程，可以在 fork 函数调用之前，设置其跟踪的是子进程还是父进程(默认父进程) set follow-fork-mode [ parent | child ] 跟踪一个进程了，那另一个呢？另一个可以选择脱离 GDB 调试（直接运行到结束），也可以选择被 GDB 挂起。（detach:脱离） set detach-on-fork [ on | off ] 查看调试的进程：info inferiors 切换当前调试的进程：inferior id 使进程脱离 GDB 的调试：detach inferiors id exec 函数族 函数族：一系列具有相同/相似功能的函数（C 语言中没有重载）\\nexec 函数族功能: 能够在当前进程中，调用一个别的可执行程序。调用成功后，本进程的代码段、数据段、堆栈等所有信息都会被替换掉，相当于完全变成了另一个进程。此时调用函数也就不存在了，自然也就不会有返回值。只有失败了才会返回-1，从源程序调用点接着往下执行。 但一般情况下，调用程序都是有别的任务的，你这么直接替换了怎么能行。因此，常用的做法是，先fork()一个子进程，然后再子进程中调用 exec 函数族，来，一下子，把子进程变成一个实现别的功能的新进程，而不只是原进程的拷贝了 具体实现过程为：用指定程序，去把调用程序虚拟地址空间中的用户区替换掉，内核区保持不变。即，什么进程 id、父进程 id、当前工作目录这些内核区的框架不变，但是实际执行的内容却改变了。金蝉脱壳 exec 函数族介绍 总览 其中只有最后一个execve()函数是 UNIX 的，别的都属于标准 C 库函数，是对 execve()的封装\\n函数名其实就指明了函数的参数的传递方式\\nexecl() int execl(const char *path, const char *args1, ...); path：要调用的文件路径。推荐使用绝对路径\\nargs：参数列表，直接传入多个，其中第一个参数约定为文件名，并且最后以NULL结尾(哨兵)\\n例如：int ret_flag = execl(\\u0026quot;/usr/bin/ls\\u0026quot;, \\u0026quot;ls\\u0026quot;, \\u0026quot;-h\\u0026quot;, \\u0026quot;-al\\u0026quot;, \\u0026quot;/home/usr\\u0026quot;, NULL)。即 ls -alh ~\\n注意到，shell 命令也是可以执行的，它也不过是个可执行程序嘛。这个-，在命令既有参数又有文件名等时，不加是不行的。\\n注意有可能会产生孤儿进程\\n被 execl 族函数替换后，整个进程都变了，包括代码段等等。因此，原进程中 execl 函数后的代码将不会被执行！\\nexeclp() int execlp(const char *file, const char *args1, ...)\\nfile：调用文件的文件名 args：仍然是参数列表 进程控制 进程退出 void exit(int status)：标准 C 库的退出，在 stdlib.h 中\\nvoid _exit(int status)：系统调用，在 unisd.h 中\\nstatus是退出时状态，父进程在回收子进程资源时能够获取到\\n区别在于，调用exit()时，会先调用退出处理函数、刷新 IO 缓冲、关闭文件描述符等工作，然后再调用系统调用_exit()退出进程。\\n举个例子，printf(\\u0026quot;hello\\\\nworld\\u0026quot;);然后调用exit(0)，这是是能输出 hello\\\\nworld 的。但是如果调用的是_exit()，那就只会输出一个 hello。因为 C 库的 IO 是带有缓冲区的，\\\\n 会刷新缓冲，因此 hello 一定能输出。但是调用_exit()，此时 world 尚在缓冲区里，但进程直接就退出了，没有输出\\nexit()会把 status 返回给父进程，就跟 main 的 return 一样，main 是被系统调用的，return 也是把状态返回给上一级。但只是对 main 而言，这两个一样的。\\n区分 exit 与 return，只需要品味他们的名字即可。exit 是进程退出，而 return 是返回，在 main 函数中调用别的函数，func，func 和 main 都是在同一个进程中。这时 return 是返回，也即堆栈弹栈，是返回到调用者 main，main 还在；而 exit 是终结进程，main 也没了。\\n孤儿进程 孤儿进程：父进程运行结束，但是子进程还在运行，那么它就是孤儿进程\\n每当出现孤儿进程，操作系统就会把它的父进程设置为init(pid = 1)，init 会循环 wait()它已经退出的子进程，并最终回收其资源，做善后工作。因此孤儿进程并不会有什么危害\\n显然，对孤儿进程，其 ppid = 1\\n僵尸进程 僵尸进程：每个进程结束后，内核都会释放掉该进程的所有资源、打开的文件、占用的内存等。但是仍为其保留一定的资源，主要是保留 PCB 信息（包括进程号、退出状态、运行时间等），需要父进程去释放。因此，子进程终止，且父进程还没来得及回收时，这时子进程残留资源（PCB）存放于内核中，即变成僵尸进程。\\n僵尸进程是不能被kill -9杀死的 系统进程号数量是有上限的。如果产生大量僵尸进程，一直占用着 pid，那么就有可能导致操作系统无法产生新的进程，因此需要去避免。 僵尸进程是有父进程的。如果 kill 父进程，那么僵尸进程就会被 init 函数托管，并释放 但是一般是不会直接 kill 父进程的，而是在其中调用 wait()或 waitpid()来处理僵尸进程 父进程可以通过调用wait()或waitpid()，来获取其退出状态的同时，杀死该进程 wait \\u0026amp; waitpid wait 类函数，用于等待一个进程，直至其状态发生改变（终止、挂起、kill），然后获取它的信息。\\n对于进程终止（terminiate）的情况，调用 wait 可以让系统能够回收其资源，而不是让其变成僵尸进程。\\n如果状态已经改变，则函数立即返回，否则调用 wait 的进程会被挂起，直到其等待的进程收到了一个不可被忽视的信号。\\n区别在于，wait 会被阻塞，waitpid 可以设置不被阻塞，还可以指定等待哪个子进程结束。阻塞即，父进程 wait 不到时，就会停下手头的工作，去一直 wait 子进程，直至其结束。\\n一次 wait 函数只能清理一个子进程，清理多个应使用循环。\\npid_t wait(int *wstatus); wstatus：一个 int 类型地址，是传出参数，用于获取返回值。返回值还要传入一些宏中，即可获得一些有用的状态：Wait-IF-EXIT-EnD，Wait-EXITSTATUS，Wait-IF-SIGNAL-EnD，Wait-TERM-SIGnal\\u0026hellip;\\u0026hellip;\\npid_t waitpid(pid_t pid, int *wstatus, int options); pid pid \\u0026gt; 0：即表示等待 pid 对应的子进程 pid =0：回收当前进程组的所有子进程，即当前调用者的进程组 pid = -1：回收所有的子进程，即使你跑到了别的组（最常用） pid \\u0026lt; -1：等待任意一个，gpid 等于参数绝对值的，组内的，任一子进程 options：设定阻塞/非阻塞 0：阻塞 WNOHANG：非阻塞，立即返回 返回值 \\u0026gt; 0：返回子进程 pid = 0：（只有非阻塞情况下才会返回 0，即options = WNOHANG）表示还有子进程活着 = -1：错误或者没有子进程了 进程间通信 基本概念 子进程“复制”了父进程的东西，但是那叫“读时共享、写时拷贝”，写的时候，是两个相互独立的区域。在逻辑上，二者是隔离的。只不过是实现上，有一段共享的时候。\\n进程是独立的，但不是孤立的\\n进程间通信方式 匿名管道（管道） 匿名管道概述 管道的特点 亲缘关系的进程能够共享管道的原因：\\n父子进程共享文件描述符表，管道具有文件的性质，因此可以操作同一个管道\\n管道的数据结构 环形队列。因为使用普通队列的话，写过的地方就不好再用了，采用环形队列可以节省内存空间。\\n匿名管道创建 int pipe(int pipefd[2]); 参数：一个 int 数组，是传出参数。pipefd[0]对应管道的读端（输出），pipefd[1]对应管道的写端（输入）\\n返回值：成功返回 0，失败返回-1\\n注意，要在 fork 之前创建 pipe！ 管道默认是阻塞的，如果空了，则 read 阻塞，如果满了，则 write 阻塞 管道是有大小的，如果传递的数据超过管道大小会被忽略。（可以循环写） 循环读取管道后，可以把读出的值清空（memset）。否则，最后一次读出的值可能并不能填满 buff，那么输出的结果后面就会有一些不该出现的值 如果用匿名管道进行交互通信，则有可能产生一些问题：期待是父进程写，子进程读。但完全有可能产生进程读出自己写的内容的情况！因此，使用匿名管道时，一般只做，一方就是读的并且 close 写端，另一方就是写的并且关闭读端。 插播一些有用的函数 long fpathconf(int fd, int name);：用于获取文件的一些信息，比如最大链接数、最长名字、最大管道尺寸等等，通过 name 传递一个宏值来指定功能。如_PC_LINNK_MAX, _PC_PAYH_MAX, _PC_PIPE_BUF等等等 void bzero(void *s, size_t n);：将 s 指针指向位置开头的 n 字节用\\\\0填充（可能会受，头文件是 string.h 还是 strings.h 的影响） void *memset(void *s, int c, size_t n);：将 s 指针指向位置开头的 n 字节用常字符(int)c填充，并返回一个指向 s 区域的指针 void *memcpy(void *dest, const void *src, size_t n);：内存拷贝（利用内存映射来拷贝文件时可以用） 管道读写特点总结 都是在阻塞 IO 的情况下讨论：\\n写端全部关闭（fd[1]的引用计数 = 0），如果管道中的数据被读取完了，那么再次读取，read()会返回0，相当于读到了文件末尾 写端没有全部关闭（fd[1]的引用计数 \\u0026gt; 0），如果管道中的数据读完了，且没有再往里写，那么再次读取，read()会被阻塞。（如果设置了非阻塞，那么 read 将会返回-1) 同理，读端都关闭了，此时再往里面写，则该进程会收到一个信号SIGPIPE，通常会导致管道异常终止 读端没有全部关闭，此时往里写，写满的时候，write()会被阻塞 那么，管道也是一个文件，因此自然也可以设置管道文件的文件描述符的属性 ==\\u0026gt; fcntl()，将其设为非阻塞\\n有名管道 命令行：mkfifo [fifoname]\\nint mkfifo(const char *pathname, mode_t mode); 参数\\npathname：带路径的文件名\\nmode：与open()的 mode 相同\\n成功返回 0，失败返回-1 并设置 errno\\n打开最好是，你是写的，就O_WRONLY，你要是读的，就O_RDONLY\\n有名管道读写特点 （其实同匿名管道）\\n对于只读/只写的进程来说，只有只读的进程打开管道，或者只有只写的进程打开管道，都会导致该进程阻塞。换言之，必须要同时有读写进程，才不会在打开这一步就被阻塞。 读： 管道中有数据，则返回读取到的字节数 管道中无数据时， 若写端没有全部关闭，则read()阻塞； 若写端全部关闭，则read()返回0 写： 若读端全部关闭，则收到SIGPIPE信号（管道破裂），导致写端异常终止。 若读端未全部关闭： 管道未满，则返回实际写入的字节数 管道满了，则write()阻塞 总结：不管是有名还是匿名管道（在不设置非阻塞情况下）： 读的重点在管道中有没有数据。有就读，没有就阻塞。如果既没有数据，又没有人写了，那就说明读完了，返回 0；而写更在乎有没有人在读，如果没有读的人了，那直接终止。如果有，那就继续写，写满了就阻塞。 内存映射 参考读物： mmap 内存映射原理 内存映射 (Memory-mapped I/O) 是将磁盘文件的数据映射到内存，用户通过修改内存就能修改磁盘文件。\\n内存映射函数 #include\\u0026lt;sys/mman.h\\u0026gt; // 映射到内存 void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); // 解除映射 void munmap(void *addr, size_t length); 内存映射函数 m-map()：\\naddr：指定映射的内存起始地址。（最好传递NULL，由内核选择地址进行映射）\\nlength：要映射的数据长度，要求大于 0 ；如果 length 未达到一页，则映射一页的大小【分页】。建议直接映射文件的大小（stat、lseek）\\nprot：对申请内存映射区的操作权限，不能和打开的文件的权限冲突。最起码要有读的权限。通常是读，或者读写即可。PROT_READ，PROT_WRITE，PROT_EXEC，PROT_NONE，相或\\nflags：内存的权限\\nMAP_SHARED ：共享，即映射区的数据回自动与磁盘文件进行同步。如果要完成进程间通信则必须选择此 flags\\nMAP_PRIVATE：不会与文件同步，如果发生数据改变，则会创建一个 copy，而不会改写源文件\\nMAP_ANONYMOUS：实现匿名映射，即不需要文件实体了。那么\\n① 只能实现父子进程之间的映射\\n② 参数也要改变， fd = -1 ，offset = 0，flags = MAP_SHARED | MAP_ANONYMOUS\\nfd：open 一个磁盘文件。注意，不能为空文件！且 open 指定的权限不能与 prot 权限冲突\\noffset：必须指定 4K 整数倍。一般不用管，即置 0\\n返回值：\\n成功返回映射内存区的起始地址 失败返回MAP_FAILED，即(void *) -1 接触内存映射函数 m-un-map()\\naddr：要接触映射的内存始址 length：要和 mmap 的参数一样 实现进程间通信 （指的是文件映射。匿名映射前面提过，设置参数MAP_ANONYMOUS，只能实现父子进程之间的通信）\\n有关系的进程（父子进程）：在fork()之前，先选择一个非空文件，并创建内存映射区。然后子进程复制父进程地址空间，即可实现父子进程共享内存映射区（注意，这与写时拷贝也不冲突） 无关系的进程：准备一个非空磁盘文件，两个进程分别对该文件进程内存映射得到各自内存指针，然后开始共享内存。 内存映射为非阻塞通信。因此，比如父子进程通信时，要确保别写的还没写完，就读了，那肯定读不到 问题总结 如果对 mmap()的返回值(ptr)做++操作(ptr++)，munmap()是否能够成功?\\n可以。但是要注意备份，即传递给 munmap 的地址应当是分配内存的首地址 如果 open()O_RDONLY，mmap()时 prot 参数指定PROT_READ | PROT_WRITE会怎样?\\n会映射失败，返回MAP_FAILED。prot 的权限 \\u0026lt;= open 的权限 如果文件偏移量为 1000 会怎样?\\n会映射失败，返回MAP_FAILED。必须为 4K(4096)的整数倍 mmap()什么情况下会调用失败?\\n空文件、权限错误（没有读权限或与 open 不一致）、偏移量不对 可以 open()的时候O_CREAT一个新文件来创建映射区吗?\\n可以，但是创建文件的大小为 0 会失败。可以对新的文件进行拓展（lseek、truncate） mmap()后关闭文件描述符，对 mmap()映射有没有影响\\n不会。映射区仍然存在，尚未释放。mmap 对传进来的 fd 进行了拷贝，你的关闭了，它同步的还在 对ptr越界操作令怎样?\\n系统实际分配的，是 length 对应的分页大小。越界会段错误 内存映射不只可以进行进程通信，还可以实现比如文件复制等功能。牢记其原理：把文件映射到内存中，并且建立内存与文件之间的同步，把文件操作变成内存操作即可。\\n信号 信号概述 查看信号详细信息：man 7 signal\\n信号默认的五种处理动作：\\nTerm：终止进程 Ign：当前进程忽略掉这个信号 Core：终止进程，并生成一个 core 文件 Stop：暂停当前进程 Cont：继续执行当前被暂停的进程 信号的几种状态：产生、未决、递达\\nSIGKILL和SIGSTOP不能被捕捉、阻塞或者忽略，只能执行默认动作\\n信号一览 信号相关函数 int kill(pid_t pid, int sig); int raise(int sig); void abord(void); kill \\u0026amp; raise \\u0026amp; abord kill：给指定进程发信号。注意，不一定是发送信号 9\\npid：取\\u0026gt; 0，表示发送给该进程，0，发给当前进程组的所有进程，-1，发给所有有资格发送信号去的进程（除了 init），\\u0026lt;-1给绝对值对应的进程组\\nsig：取0表示不发送信号\\n成功返回 0，失败返回-1\\nraise：只给当前进程/线程发送信号。成功返回 0，失败返回-1\\nabord：默认终止当前进程\\nunsigned int alarm(unsigned int seconds); int setitimer(int which, const struct itimerval *new_val, struct itimerval *old_value); alarm \\u0026amp; setitimer alarm()：设置定时器，当时间到了的时候，给当前进程发送SIGALRM信号，默认终止当前进程。每个进程都有且只有一个计时器\\nseconds：倒计时时间（秒），设置为 0 无效，即可通过alarm(0)取消定时器 返回值：之前没有设置定时器则返回 0，之前有定时器则返回其剩余的时间 setitimer()：也是设置定时器，可以替代 alarm 函数，可以周期性定时，精度更高（微秒）\\nwhich：指定定时器以什么时间计时 ITIMER_REAL：真实时间，时间到达发送 SIGALRM信号 ITIMER_VIRTUAL：用户时间，时间到发发送SIGVTALRM ITIMER_PROF：进程在用户态和内核态的时间，时间到达发送SIGPROF new_val：一个结构体，设置定时器的属性（ 这有一份示例代码 ） struct itimerval {\\t/*定时器的结构*/ struct timeval it_interval; /* Interval for periodic timer，后面每次间隔时间 */ struct timeval it_value; /* Time until next expiration，延迟多久开始执行定时器 */ }; /* 就是说，只有第一次闹钟是等待it_value值后“响”，后面每隔it_interval值“响”一下 */ struct timeval {\\t/*时间的结构*/ time_t tv_sec; /* seconds */ suseconds_t tv_usec; /* microseconds ，两个都要设置，否则可能是随机值*/ }; old_val：记录上一次定时的时间参数（传出参数），不用可以设置为NULL 成功返回 0，失败返回-1 信号捕捉 signal #include \\u0026lt;signal.h\\u0026gt; typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); signum：要捕捉的信号，就是那一堆宏。SIGKILL和SIGSTOP不可被捕捉、忽略 handler：捕捉后要如何处理，是一个指向参数为 int（即信号编号），返回值为 void 的函数的函数指针 SIG_IGN：忽略信号 SIG_DFL：采用信号默认的处理方式 回调函数：让内核调用你写的某一个函数来进行处理（ 回调函数介绍 ） 返回值：成功返回上一次设置的回调函数的指针（第一次为 NULL），失败返回SIG_ERR 注册信号捕捉，要提前注册好，等信号来了再注册就来不及了，程序就直接结束了 信号捕捉 sigaction 建议使用 sigaction 而不是 signal，因此 sigaction 能满足更多的标准，更通用。\\n// 检查或者改变信号的处理方式（新版信号捕捉） int sigaction(int signum, const struct sigaction *act, struct sigaction *oldact); struct sigaction { void (*sa_handler)(int); // 信号处理函数① void (*sa_sigaction)(int, siginfo_t *, void *); //信号处理函数②，不常用，由flags指定 sigset_t sa_mask; // 在信号捕捉函数执行过程中，临时阻塞一些信号，不用记得清空 int sa_flags; // 指定信号的处理方式，一堆宏值，其中0表示用①，SA_SIGINFO表示用② void (*sa_restorer)(void); // 废弃掉了，指定NULL即可 }; sigaction：\\nsignum：要捕捉的信号，除了 sigkill 和 sigstop act：捕捉到信号后的处理动作 oldact：上一次的处理动作，不用传入NULL 信号集 信号集在 PCB 中其实就是一个 01 数组（位图），信号尚未被处理，那就在未决信号集里面，值 1；阻塞了，那就在阻塞信号集里面值 1。\\n未决信号集中的信号不能马上被处理，还需要先跟阻塞信号集中对应的值比较，如果非阻塞，就发给进程去处理，发之后，就是送达状态，未决位就置 0 了\\n不能直接设置这些位，而是要借用对信号集的一些操作函数来实现改变。比如阻塞信号集默认都非阻塞，但可以通过函数来设置阻塞。\\n信号集相关函数 注意：下面这些函数操作的都是你自己创建的信号集，就是一个类似的数组，然后要通过一个系统调用sigpromask才能映射到系统中的阻塞信号集中。一般操作的都是阻塞非阻塞属性(sigprocmask)，未决信号集只有获取这个动作（sigpending)。\\n注意：在多线程环境中，应当使用 pthread_sigmask()，其参数含义与作用完全相同\\n// sigset就是一个你自己创建的无符号长整型数组，函数什么清空添加删除，都是操作的这个数组 typedef __sigset_t sigset_t; #define _SIGSET_NWORDS (1024 / (8 * sizeof (unsigned long int))) typedef struct{ unsigned long int __val[_SIGSET_NWORDS]; } __sigset_t; // 将信号集中的参数全部置为0/1，set是传出参数，即操作的信号集，成功返回0失败返回-1 int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); // 将信号集中的某个信号置为1/0，表示阻塞/不阻塞这个信号，成功返回0失败返回-1 int sigaddset(sigset_t *set, int signum); int sigdelset(sigset_t *set, int signum); // 判断信号是否阻塞。返回1表述信号阻塞，0表示不阻塞，-1表示错误 int sigismember(const sigset_t *set, int signum); /* 将自定义信号集中的数据设置到内核 阻塞 信号集中：设置阻塞、解除阻塞、替换 */ int sigprocmask(int how, const sigset_t *set, sigset_ *oldset); /* 获取内核中的 未决 信号集*/ int sigpending(sigset_t *set); sigprocmask：将自定义信号集中的数据设置到内核中：设置阻塞、解除阻塞、替换\\nhow：设置函数工作的方式。不妨设内核中的阻塞集为 mask，用户自定义的为 set SIG_BLOCK：将用户设置阻塞信号添加到内核中，mask = mask | set，set 中为 1 的内核中置为 1 SIG_UNBLOCK：根据用户设置的数据，解除内核中的阻塞，mask \\u0026amp;= ~set，set 中为 1 的内核中置为 0 SIG_SETMASK：根据用户的信号集覆盖内核中的阻塞集，mask == set，set 是啥就是啥 set：用户自定义的信号集 oldset：传出内核中原来的数据集，即做一个备份，不用设置为NULL 返回值，成功返回 0，失败返回-1，设置错误号EFAULT出错，EINVAL传入的 how 非法 信号捕捉过程 信号从开始执行回调函数，其未决状态会置为 0。此时再来一个相同的信号，未决变为 1，但是此时回调函数在执行过程中，新来的信号是执行不了的，会被阻塞在那里。 回调函数处理过程中使用的是临时阻塞信号集，你要是没设置那就还是原来的 前 32 个常规信号是不支持排队的，因为它只能记录 0 或者 1。后 32 个信号可以存储有多少个信号在排队 SIGCHILD 信号 在以下三种情况下，会给父进程发送SIGCHILD信号，而父进程默认会忽略此信号\\n子进程终止 子进程收到SIGSTOP信号而暂停 子进程处在停止态，然后收到SIGCONT信号被唤醒时 问题 0，之前解决僵尸进程的办法是，不断循环 wait，这显然是不合理的，怎么优雅回收子进程资源呢？ 解决 0思路很简单，可以在父进程中捕捉 SIGCHILD 信号，等子进程结束时再调用 wait 回收它就好了 这里会有一个问题 1，假如子进程很多，它们都在同一时间结束，前面提到过，常规信号是不支持排队的，因此，收到第一个 SIGCHILD 信号去执行 handler 的过程中，会到达很多别的 SIGCHILD 信号，他们最终都只是未决队列里的同一个 1，等 handler 结束再回来的时候，再把这个“一个”未决的信号送达。等于是，一堆子进程就执行了两次 handler。 解决 1方法也很简单，在 handler 中循环调用非阻塞的waitpid函数，当前有终止的子进程就回收，如果没有（返回值为 0 或-1）就 break 结束 handler，返回主控函数，不影响父进程的正常工作。这样就可以实现，收到一次信号，就可以回收当前所有已经终止的子进程。 然后又有一个问题 2：如果子进程很快就结束了，快到父进程注册信号捕捉这个系统调用还没结束，那岂不是就不能回收掉这个子进程了？因为这个子进程发送的 SIGCHILD 信号是被父进程默认忽略掉的 是的，解决 2办法是，在父进程中，先设置一个信号集，阻塞掉 SIGCHILD 信号，然后注册信号捕捉，等注册成功，在对 SIGCHILD 信号接触阻塞，即可。 共享内存 共享内存是效率最高的进程间通信方式，注意与内存映射区分，内存映射还是基于文件的，只不过少了一次从内核缓冲拷贝到用户缓冲的时间，直接实现磁盘和用户缓冲区之间的同步\\n比较的时候要记住，凡是通过文件的 IO，不论读写，用户都是与内核的缓冲区进行交互的，内核缓冲区才负责读写文件，是用户—内核—文件的模式\\n共享内存操作函数 key_t ftok(const char *pathname, int proj_id); // 获取一个创建共享内存的key，也可以自己指定 int shmget(key_t key, size_t size, int shmflg);\\t// 创建物理共享 void *shmat(int shmid, const void *shmaddr, int shmflg); // 映射到自己的虚地址空间 int shmdt(const void *shmaddr); // 解除共享，从自己的虚地址空间中移除 int shmctl(int shmid, int cmd, struct shmid_ds *buf); // 读取或设置共享内存的一些属性 key_t ftok(const char *pathname, int proj_id); ftok()： 根据文件名和给定的 int 值，生成一个共享内存的 key。如果文件和 int 值不变，那 key 值在哪生成都是一样的。所以可以由此实现不同进程用同一个 key 来创建/获取共享内存。\\npathname： 必须是一个已经存在的可以访问的文件 proj_id： 只会使用低八位，因此可以传入一个字符 \\u0026lsquo;a\\u0026rsquo;, \\u0026lsquo;b\\u0026rsquo; int shmget(key_t key, size_t size, int shmflg); shmget()： 创建或获取共享内存标识，默认内存全部清 0\\nkey： key_t 类型（整形），共享内存的标识符，一般用 16 进制表示，非 0。A 进程开辟了一段共享内存，获取这段内存的 ID。但是 B 怎么找到这块内存呢？所以 key，就是“暗号”，让 AB 可以定位到同一段物理共享内存，当然，他们返回的 shmid 也是一样的。\\nsize： 共享内存的大小，向上取整到分页大小，即按页对齐。如果是获取，那置为 0 就行了\\nshmflg： 指定属性，如内存权限（八进制），和附加属性（创建|存在与否）\\n用法：IPC_CREAT | IPC_EXCL | 0664。存在判断必须要与创建连用才行\\n返回值： 成功返回共享内存引用的 ID（不是 key），失败返回 -1\\nvoid *shmat(int shmid, const void *shmaddr, int shmflg); shmat()： 将一个物理的共享内存和当前进程关联（放进自己的虚拟地址空间中，在共享区）\\nshmid： 共享内存的标识 ID，由shmget返回值获取\\nshmaddr： 共享内存在虚拟地址空间的起始地址，指定NULL，让内核去指定。自己指定有可能出错\\nshmflg： 对共享内存的操作，无非是读写等权限，注意，必须要有读权限\\nSHM_RDONLY指定只读，0默认是读写都有\\n返回值： 成功返回共享内存虚拟地址空间的起始地址，失败返回((void*)-1)\\n写入 的时候可以用memcpy()，来把你想写的东西拷贝进去\\n读出 的时候，也可以用memcpy()，还可以把void *类型指针转换成char *读取\\nint shmdt(const void *shmaddr); shmdt()： 解除共享内存和当前进程的关联，参数即虚拟共享内存的起始地址，成功返回 0，失败返回-1\\nint shmctl(int shmid, int cmd, struct shmid_ds *buf); shmctl()： 操作共享内存，常用来删除。内存只有主动删除才消失，与创建进程存在与否无关。\\nshmid： 共享内存的 ID\\ncmd： 要进行的操作\\nIPC_STAT：获取共享内存当前状态，此时参数 buf 是传出参数 IPC_SET：设置共享内存状态，此时参数 buf 是传入参数 IPC_RMID：标记共享内存为待删除，此时参数 buf 没有用，设置NULL buf： 一个shmid_ds结构体指针，存放需要设置或读出的参数，作用与cmd的选择有关\\nstruct shmid_ds { struct ipc_perm shm_perm; /* Ownership and permissions */ size_t shm_segsz; /* Size of segment (bytes) */ time_t shm_atime; /* Last attach time */ time_t shm_dtime; /* Last detach time */ time_t shm_ctime; /* Creation time/time of last modification via shmctl() */ pid_t shm_cpid; /* PID of creator */ pid_t shm_lpid; /* PID of last shmat(2)/shmdt(2) */ shmatt_t shm_nattch; /* No. of current attaches */ ... }; 所谓删除是，先标记删除，将共享内存段的key置 0，表示要删除这一段共享内存。只有等到共享内存的链接数为 0 的时候，才会真正删除这段内存。因此可以对一段内存进行多次删除，反正只有最后一个进程的删除动作才有效。\\n链接数等信息，就是保存在一个shmid_ds结构体中\\n共享内存操作命令 # (1) ipcs 显示进程间通信的一些信息 ipcs -a\\t# 打印当前系统中 所有的 进程间通信方式 的信息 ipcs -m\\t# 打印出使用 共享内存 进行进程间通信的信息 ipcs -q\\t# 打印出使用 消息队列 进行进程间通信的信息 ipcs -s\\t# 打印出便用 信 号 进行进程间通信的信息 # (2) ipcrm 进程间通信媒介的 删除手段 ipcrm -M {shmkey}\\t# 移除用 shkey 创建的 共享内存段 ipcrm -m {shmid}\\t# 移除用 shmid 标识的 共享内存段 ipcrm -Q {msgkey}\\t# 移除用 msqkey 创建的 消息队列 ipcrm -q {msqid}\\t# 移除用 msqid 标识的 消息队列 ipcrm -S {semkey}\\t# 移除用 semkey 创建的 信号 ipcrm -s {semid}\\t# 移除用 serid 标识的 信号 共享内存和内存映射的区别 共享内存可以直接创建，内存映射需要依赖文件（匿名映射除外） 共享内存效率更高，内存映射需要与磁盘同步 共享内存操作的是同一块内存，内存映射是，每一个进程在自己的虚拟内存中都有一块独立的内存，只不过这块内存通过一个共同的文件关联了起来 数据安全： 进程退出，共享内存还在（需要主动调用删除才行）只不过进程不再与之关联，但内存映射区不在了 电脑断电，没电了内存自然是消失了，但是由于磁盘文件还在，因此内存映射区的数据还在 生命周期，共享内存需要手动删除，且进程关联数为 0 时，才会真正被删除。而内存映射区，进程退出后就自动销毁了 守护进程 控制终端 终端是一个设备（命令tty可以查看），用户通过终端登录后，获得一个 shell 进程（命令echo $$显示当前 shell 的 pid），这个进程的**控制终端（Controlling Terminal）**即是此终端。\\n进程中，控制终端的信息是写在 PCB 中的，因此，从此 shell 启动的所有进程，其控制终端都是本终端（因为 fork()会复制 PCB），标准输入输出错误默认指向控制终端，因此也就都是指向本终端。\\n可以在控制终端输入一些命令来控制进程，但这只对前台进程有效。因为后台进程（在启动命令后面加一个$或者用Ctrl + Z即可得到后台进程）是没有控制终端的。\\n进程组 \\u0026amp; 会话 相关进程放在同一个组里，方便管理，比如修改进程优先级，直接把组的改了就行了\\n创建会话的两步，第一步会话首进程创建一个进程组，组号等于自己的进程号；第二步，会话首进程创建一个会话，会话号等于自己的进程号。因为会话是进程组的集合嘛，得先创建一个组\\n控制终端的第一个程序，会创建一个会话。一个终端只有一个会话；任意时刻，一个终端都有且只有一个前台进程组。下面是一个示例\\nfind / 2 \\u0026gt; /dev/null | wc -l \\u0026amp; sort \\u0026lt; longlist | uniq -c 守护进程概念 守护进程创建步骤 执行 fork()，之后父进程退出，子进程继续执行。 因为下面要创建一个会话，创建会话的进程，不能是进程组的首进程（步骤 2 解释原因），而你执行父进程的时候，它默认就会创建一个进程组。因此，让它生成一个子进程来创建会话，子进程的 pid 和它的 pgid 是不一样的。 父进程退出之后，会被 shell 得知，并输出一个 shell 提示符。显然我们不希望要这个提示符 子进程调用 setsid() 开启一个新的会话 创建一个新的会话，不会连接控制终端，因此这个新的会话就不会有控制终端。注意，是没有控制终端了，但不是说这个进程没有终端。这点在步骤 5 中有解释。 **为什么要用子进程创建会话呢？**因为，如果使用父进程，父进程本身会有一个进程组（它是首进程），进程组的 pgid 就是父进程的 pid，父进程也是在一个会话 A 里面的。如果选择父进程来创建一个新的会话 B，那么首先，他会创建一个进程组，这个组的 pgid 和它的 pid 是一样的。好的，现在问题就出现了：在会话 A 和会话 B 这两个会话里面，有两个组号相同的进程组。这是不行的。因此，创建会话的进程，不能是进程组的首进程。（换言之：因为什么进程创建新会话，都要先以自身为组长创建进程组，而一个进程不能当两个组的组长，组长走了，原来的组还在呢） 清除进程的 umask，以确保当守护进程创建文件和目录时拥有所需的权限 修改进程的当前工作目录，通常会改为根目录/ 关闭守护进程从其父进程继承而来的所有打开者的文件描述符 守护进程是一直运行着的，如果不关闭文件描述符，那这些个文件就会被一直占用，删不掉 关闭文件描述符 0、1、2，然后打开/dev/null，并使用 dup2()重定向到这个设备 创建一个新会话脱离控制终端，但是终端还是有的，会继承父进程的文件描述符。因此要把这些都关闭，以防止误操作 而有些操作会用到这些描述符。因此就重定向到 null，写到里面的东西都会被丢弃掉 执行核心业务逻辑 Chapter 3 Linux 多线程开发 线程概述 线程 \\u0026amp; 进程 插播一段别的知识：\\n未初始化数据段 ，即.bss里面存放的是，未初始化，或初始化为 0 的，全局变量或静态变量。而.data数据段，里面存放的是初始化为 非 0 的全局变量或静态变量。在程序运行起来之后，这俩是合在一块的，统称为数据区。之所以弄这个区别，是因为，bss 段里面的变量只有个符号，其实并没有实际分配内存，只有在运行起来后，连接器才会把后面跟着的这一块 bss 区，全部清零。而 data 段里面的，你初始化了 1000 个 int 的数组，它就真真切切的占用了 1000*4B 的空间，可执行程序就会大一些。\\n共享与非共享 线程之间共享同一个虚拟地址空间，只有一些地方有区别，比如不同线程间，有各自的.text段和栈空间\\n信号掩码即阻塞信号集，每个线程都有自己的阻塞信号集。每个线程都有自己的 error\\n线程操作 创建线程 // 创建线程：传出线程号，指定线程属性（NULL）、线程业务（函数指针）和线程执行需要的参数（void*） int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); // 获取线程自己的 tid，类似getpid() pthread_t pthread_self(); // 用于比较两个线程的线程号是否相等。因为不同平台线程号的实现不同，有的用的是结构体，就没法 == 了 int pthread_equal(pthread_t t1, pthread_t t2); 进程是一个比较大的概念，是用来分配资源的单位，线程是用来调度的单位。main 函数中执行的是主线程，其余的是子线程。\\n参数\\nthread：传出参数，创建成功后，会把子线程的 id 存放在其指向的那一块缓存中，再返回 attr：设置线程的属性，一般使用`NULL`` start_routine：即线程要执行的代码。是一个指向 参数为 void* 返回值也为 void* 的函数 的函数指针 arg：给线程要执行的函数 传递其需要的参数 返回值：成功返回 0， 失败返回 一个错误号（不是 -1 了，也不同于 errno，不能 perror 了）。现在的错误处理函数定义在 string.h 头文件中：char *strerror(int errnum); pthread不是标准库，因此有时编译不成功时，记得加上-pthread选项（或者加-lpthread指定也一样）\\n终止线程 void pthread_exit(void *retval); 在哪个线程中调用，即表示终止哪个线程。参数是你自己的 返回值 retval：传出自己的返回值，可以在pthread_join()中获取到 其实对子线程（返回值为 void*）来说，用这个退出，跟它调用 return 退出是一样的，即 return retval; 谁调用，谁退出，但在主线程中执行退出，不会影响其他线程的运行。而主线程如果正常运行到 return 0 结束，相当于进程退出了，整个虚拟地址空间都不存在了，那自然所有的线程也就都没了。 线程（包括主线程）调用了 pthread_exit 后就结束了，后面的代码就不再执行了。主线程 pthread_exit 后，不会像 return 和 exit 那样释放所有资源，但并不意味着这之间的代码还能执行。 （对指针熟练了可以跳过下面这两段话）\\n线程返回值，不能返回局部变量。每个线程有自己的栈，线程退出了，这块栈也就销毁了。那么你返回的值，再去读取，可能就不是原来的值了。因此要返回全局或者静态变量，而这个，也正是下面 pthread_join 第二个参数是个二级指针的原因。因为返回值是个“全局”（指针类型）变量，你获取到之后，如果传递的是一级指针，是不就等于 C 语言函数传参里面的，传值方法？也就是说，你不能去修改它，因此要想能回这个值进行修改，就要返回一个指向它的指针，指向指针的指针，那就是二级指针。\\n换言之，join 的工作过程其实就是，如果 retval 非空，则把目标线程的返回值（一个 void* 类型的数据），拷贝到 retval 指向的地址。（这里不要钻牛角尖，指向指针的指针，还是个指针，也还是指向一块存放数据的内存。只不过对这块内存的解读是，又是一个指针。类型不就是标记怎么解读比特数据的么）看出区别了没，其实跟之前传出参数一样，之前是用指针传出（而不是传值），现在也是用指针传出。区别就在，这次要传的参数，是一个指针。\\n回收线程 // 连接终止的线程，连接的目的，就是回收其资源，并获取其返回值 int pthread_join(pthread_t thread, void **retval); 子进程有一部分不能自己释放的资源，需要父进程回收。子线程也有，也需要回收，不同的是，任何线程都可以去回收另一个结束的线程。（一般也都是主线程调用）\\n回收不了会阻塞；一次只能回收一个，回收多个需要用循环\\n参数\\nthread：需要回收的子线程的 tid retval：回收子线程的返回值（不管是 return 返回的，还是调用 pthread_exit() 返回的，一样） 返回值：成功返回 0， 失败返回错误号 线程分离 // 分离指定的线程 int pthread_detach(pthread_t thread); 被分离标记的线程，其结束的时候，会自动把资源归还给操作系统，不需要回收 不能 detach 一个已经被 detach 的线程（unspecified behavior） 也不能 join 一个已经被 detach 的线程（ivalid argument） 线程取消 // 取消指定线程（让线程终止） int pthread_cancel(pthread_t thread); 线程可以被取消与否，取决于被取消线程的一些属性，（即创建线程时的第二个参数pthread_attr_t）\\n被取消的线程，不是立马终止的，而是要运行到一些被定义好的取消点（cancellation point，可以man 7 pthreads查看）时，才会被终止。大致上可以理解为，要运行到某些系统调用处，发生内核与用户态切换时，才会被终止。\\n线程属性 // 设置/获取线程的分离属性 int pthread_attr_setdetachstate(pthread_attr_t *attr, int detachstate); int pthread_attr_getdetachstate(const pthread_attr_t *attr, int *detachstate); // PTHREAD_CREATE_DETACHED PTHREAD_CREATE_JOINABLE 首先要创建线程属性变量，然后对其进行初始化pthread_attr_init，然后设置其属性。设置了分离状态PTHREAD_CREATE_DETACHED就说明，不需要别的进程来 join 我，我结束了自己会释放。然后pthread_create创建线程，把 attr 传进去就好了。\\n设置了 detach 属性，就不能再去 pthread_detach 或者 pthread_join 了，跟执行一次pthread_detach()一样\\n线程同步 概述 互斥锁 mutex restrict：C 语言修饰符，被修饰的指针，不能被别的指针操作\\n锁的使用步骤：创建锁(全局) $\\\\Rarr$ 初始化锁(使用前) $\\\\Rarr$ 加锁(阻塞)或尝试加锁(非阻塞) $\\\\Rarr$ 操作 $\\\\Rarr$ 解锁\\n初始化一个已经被初始化的锁，和销毁正在被用着的锁，都是未定义行为。但是一个锁被销毁后，是可以再被重新初始化的。合理的去 destory 锁，反正在主线程退出之后 destory，和退出之前，但是别的线程还在用着呢的时候 destory，都是不合适的。个人认为，本身他也就是一个栈上的变量而已，全局的联合体变量。你 destroy 它，它也不会释放空间，只是变得可以再被 init 了而已。没有需要就不 destroy 了\\n死锁 读写锁 rwlock 读可以共享，写的时候不许读 写是独占的 写的优先级更高 条件变量 条件变量不是锁，是配合锁来更好实现线程同步的。可以实现，满足某个条件时通知线程来做，不满足时就阻塞。至于互斥的访问临界区，那还是得锁来做。 wait是一直等待，直到被通知，timedwait是等待指定时间，如果没收到通知就不等了 注意，当pthread_cond_wait(\\u0026amp;cond, \\u0026amp;mutex)等待 cond 被阻塞的时候，系统会自动解锁，等到信号，准备就绪的时候，mutex 这个锁又会被加上 signal是至少通知一个正在等待的，broadcast是通知阻塞队列里的全部 信号量 同样的，信号量也是用来阻塞线程的，可以实现同步互斥前驱关系等，并不能保证线程安全，也即，想要保证多线程数据安全，仍然需要配合锁来实现（当然，单个信号量，值取 01，那跟锁一样了）\\n信号量是有值的，条件变量是没有值的，是看满不满足条件\\nsem_init：初始化信号量\\nsem：定义的 sem_t 类型的信号量的地址 pshared：指定是用于线程间同步还是进程间同步。0表示线程间同步，非0表示进程间同步 value：信号量的值 sem_wait：V 对信号量加锁，使信号量值减一，如果 value 大于零则直接返回；如果 value 小于 0 则阻塞\\nsem_post：P 对信号量解锁，使信号量值加一，如果让信号量的值大于 0，则唤醒一个被 wait 阻塞的线程\\n同步模型 生产者消费者模型：光有信号量是不够的，还要加互斥锁 哲学家进餐模型： \\u0026hellip; Chapter 4 Linux 网络编程 网络的结构模式 Client/Server 模型 Browser/Server MAC IP 每个网卡的 mac 地址是全球唯一的，由制造商烧录在网卡中\\nIP，Internet Protocal Address，分配一个逻辑地址，屏蔽物理地址的差异\\n子网掩码\\n端口（port），0-65535（2^16-1)\\n网络协议模型 OSI 七层模型 TCP/IP 四层协议 协议一览 协议，即网络协议的简称，是通信计算机双方必须遵从的一组约定，比如怎样建立连接，怎样互相识别等。只有遵守这个约定，之间才能互相通信交流。 协议的三要素是，语法、语义、时序。为了使数据在网上从源到达目的，网络通信的参与方必须遵守相同的规则，这套规则称为协议(protocal)，他最终体现为，在网络上传输的数据包格式。 协议往往分成几个层次，分层的定义是为了使某一层协议的改变，不影响其他层次。\\n网络通信的过程 封装与分用 上层协议是如何便用下层协议提供的服务的呢？其实这是通过封装 (encapsulation) 实现的。应用程序数据在发送到物理网络上之前，将沿着协议栈从上往下依次传递。每层协议都将在上层数据的基础上加上自己的头部信息（有时还包括尾部信息）以实现该层的功能，这个过程就称为封装。\\n当帧到达目的主机时，将沿着协议栈自底向上依次传递。各层协议依次处理帧中本层负责的头部数据，以获取所需的信息，并是终将处理后的帧交给目标应用程序。这个过程称为分用 (demultiplexing)。分用是依靠头部信息中的类型字段实现的。\\nARP 协议 地址解析协议：通过 IP 找 MAC 地址。把 ip 封装成 ARP 包，加上以太网帧头尾，进行广播，与目标地址相同的进行应答。\\n命令：arp -a\\n字节序 字节序理解 即大端小端。大端指：整数的高位在低地址，输出是“顺”的；小端指：低位在高地址，输出是“反”的。\\n举个例子，0x112233，最高字节是 11，最低字节是 33，则大端时输出其字节（访存是从低地址开始，往高地址读取），最高位在低地址，所以是 0x11，0x22，0x33；即与人读的顺序（从左往右）一致，人先看先读的就是高位。小端则相反，先拿到的是低位数据，因为低位放在低地址。\\n可以通过强制转为unsigned char *输出每一 byte，也可以创建一个 union，里面定义一个数据类型 x，一个char 数组，这样输出 char 数组就可以得知 x 的字节序\\n字节序转换函数 TCP/IP 中将网络字节序规定为：大端序。发送端如果是小端机则要先转换为大端序，接收端按大端序解释，后面随便（转换成你的主机字节序）。\\n网络中端口、IP 都没有负数，都采用 unsigned 格式。【注意是整数类型之间的转换，与inet_pton()等函数区别】\\n#include \\u0026lt;arpa/inet.h\\u0026gt; /* h-\\u0026gt;host; n-\\u0026gt;net; s-\\u0026gt;short(unsigned short: 2B); l-\\u0026gt;long(unsigned int: 4B) */ uint16_t htons(uint16_t hostshort);\\t// short 一般用来转换 端口 地址（2B） uint16_t ntohs(uint16_t netshort); uint32_t htonl(uint32_t hostlong);\\t// long 一般用来转换 IP 地址（4B） uint32_t ntohl(uint32_t netlong); 这里有一个定义 ip 的操作：先定义到字节数组里面，然后对其进行指针类型转换即可。\\nchar buff[4] = {192, 168, 5, 11}; unsigned long x = *((unsigned long *)buff); unsigned long y = htonl(x); unsigned char *p = (unsigned char *)\\u0026amp;x; unsigned char *q = (unsigned char *)\\u0026amp;y; printf(\\u0026quot;x: %d.%d.%d.%d\\\\n\\u0026quot;, *p, *(p + 1), *(p + 2), *(p + 3)); printf(\\u0026quot;y: %d.%d.%d.%d\\\\n\\u0026quot;, *q, *(q + 1), *(q + 2), *(q + 3)); IP 地址转换函数 作用：格式转换\\n点分十进制 IP 地址/16 进制 IPv6 地址（即字符串） $\\\\Leftrightarrow$ 网络字节序整数（二进制数） 主机字节序 $\\\\Leftrightarrow$ 网络字节序 /*a-\\u0026gt;address; n-\\u0026gt;network,即网络字节序的整数; p-\\u0026gt;point,即点分十进制字符串*/ #include\\u0026lt;arpa/inet.h\\u0026gt; // 【不推荐使用】 in_addr_t inet_addr(const char *cp); // 字符串IP 转换为 大端 整数 IP int inet_aton(const char *cp, struct in_addr *inp); char *inet_ntoa(struct in_addr in); // 下面俩同时适用IPv4和IPv6【推荐使用】 int inet_pton(int af, const char *src, void *dst); const char *inet_ntop(int af, const void *src, char *dst, socklen_t size); af：地址族，AF_INET，AF_INET6 二选一 src：点分十进制 IP 字符串 or 网络字节序的二进制整数 dst：【传出参数】网络字节序的二进制整数 or 点分十进制 IP 字符串 size：指定 dst 的大小（dst 字符数组的大小） 返回值：转换后的地址，与 dst 中内容一样（整数 to 字符串的情况） TCP 介绍 三握\\u0026amp;四挥 为什么要三次握手而不是两次？\\n因为如果 A 第一次请求连接时，发生了超时重传，重传的与 B 建立并完成了连接。但是第一次超时的连接请求，兜兜转转又传到了 B，如果采用的两次握手，则 B 又一次与 A 建立了连接，在 A 不知情的情况下，这显然是不合适的。如果采用三次握手，则 B 收到这个迟到的请求后，会向 A 进行确认，而 A 直到这是一个过期的请求，因此不予理会，那么建立连接失败。（被动方重传的是它的 FIN，直到收到主动方的 ACK 为止） 为什么主动断开的一方，要等待 2MSL（Maximum Segment Lifetime：两倍的最长报文段寿命）才能关闭\\n保证 A 发的最后一个确认报文段（即第四次挥手）能准确到达 B，如果 A 不等待 2MSL 就关闭，且此时第四次回收的报文丢了，A 无法再重传，那么 B 就无法正常关闭。\\n同采用三次握手的原因类似，等待 2MSL 可以保证本次连接中产生的所有报文段都从网络中消失。以免产生“已失效的连接请求报文段”等问题。\\n滑动窗口 拥塞控制 TCP 通信流程 TCP 状态转换 半关闭状态 第一次挥手后，被动方给主动方发送 ACK，但尚未发送 FIN，此时主动方进入 FIN_WAIT_2 状态，这时的主动方，可以接受被动方发来的消息，但是无法发出消息，即半关闭（半连接）状态。可以通过 API 来控制这一状态。\\nint shutdown(int sockfd, int how); how：允许 shutdown 操作选择以下几种方式\\nSHUT_RD(0)：关闭 sockfd 上的读功能，该套接字不再接收数据，其接收缓冲区中的数据将被直接丢弃 SHUT_WR(1)：关闭 sockfd 上的写功能，进程无法再对此 socket 进行写操作 SHUT_RWDR(2)：关闭 sockfd 读写功能，相当于调用 shutdown 两次 注意区别：使用close() 中止连接，即发送 FIN，但这只是减少 socket 描述符的引用计数，不会直接关闭。只有等引用计数减为 0 时才真正关闭。而 shutdown() 是立刻关闭连接，或者关闭一个方向，不考虑引用计数。即多进程通信时，一个进程调用 close 并不会影响别的进程通信，但有人调用的 shutdown 则都不能通信了。\\nsocket 通信 socket 地址 socket（套接字（插座）），就是对网络中不同主机上的应用进程之间进行双向通信的端点的抽象，一个套接字就是网络上进程通信的一端。上联应用进程，下联网络协议栈。socket 是一个伪文件。\\n（1）通用 socket 地址\\n表示 socket 地址的是一个结构体，有两个：sockaddr 和 sockaddr_storage，定义如下：\\n#include \\u0026lt;bits/socket.h\\u0026gt; typedef unsigned short int sa_family_t;\\t// 2B struct sockaddr { sa_family_t sa_family;\\t// 表示地址族类型，与协议族对应，通常可以混用 char sa_data[14]; // 存放socket地址值。不同协议族的地址具有不同的长度和含义 }; struct sockaddr_storege { sa_family_t sa_family; unsigned long int __ss_align; char __ss_padding[ 128 - sizeof(__ss_align) ]; }; 上图可见，sockaddr 中的 14B 的 data 是不够容纳所有协议的地址的，因此又新定义了一个 sockaddr_storage，以便容纳更长的地址，并且它是内存对齐的。\\n（2）专用 socket 地址\\n很多网络编程的函数诞生是早于 IPv4 协议的，当时用的都是 sockaddr 结构体，为了向前兼容，现在 sockaddr 退化成了，类似 void* 的作用，就是说，不管你是什么地址，统统转为 sockaddr 类型传给函数。至于这个地址到底怎么解释，是sockaddr_in还是sockaddr_in6，由协议族字段确定，然后函数内部再强制类型转换为相应的地址。\\n所有的专用 socket 地址（包括 socket_storage）都要强制转换为通用 socket 地址类型（即 sockaddr），因为所有 socket 编程接口的地址参数类型都是sockaddr\\n/* sockaddr_in: TCP/IP协议族中IPv4的sock地址，sockaddr_in6 则是IPv6的地址 */ #include \\u0026lt;netinet/in.h\\u0026gt; struct sockaddr_in { sa_family_t sin_family;\\t// 协议族(AF_INET \\u0026lt;=\\u0026gt; PF_INET) in_port_t sin_port;\\t// 端口号(16位无符号,2B) struct in_addr sin_addr;\\t// IP地址(32位五符号,4B) /*填充的部分*/ unsigned char sin_zero[sizeof(struct sockaddr) - __SOCKADDR_COMMON_SIZE - sizeof(in_port_t) - sizeof(struct in_addr)]; }; // 类型参考 struct in_addr { in_addr_t s_addr; }; typedef uint16_t in_port_t; typedef uint32_t in_addr_t; #define __SOCKADDR_COMMAN_SIZE ( sizeof(unsigned short int) ) sockaddr_in 地址指定方法为：\\nstruct sockaddr_in addr;\\t// 开始赋值： addr.sin_family = AF_INET;\\t// IPv4 addr.sin_port = hton(9999);\\t// 字节序转换 // 使用 IP 转换函数给需要的整形 sin_addr 赋值 inet_pton(AF_INET,\\u0026quot;192.168.5.11\\u0026quot;, (void*)\\u0026amp;addr.sin_addr.s_addr); // 也可以采用下面偷懒的写法。客户端不行，客户端一定要指定你想连接哪个服务器 addr.sin_addr = INADDR_ANY;\\t// 其实就是0.0.0.0，表示客户端进来任意地址都可以绑定 socket 函数 \\u0026#x2b50; Socket 缓冲区 #include \\u0026lt;sys/types.h\\u0026gt; #include \\u0026lt;sys/socket.h\\u0026gt; #include \\u0026lt;arpa/inet.h\\u0026gt;\\t// 包含了这个，上面的两个可以省略 /* 1. 服务端建立 */ int socket (int domain, int type, int protocal); int bind (int sockfd, const struct sockaddr *addr, socklen_t addrlen); int listen (int sockfd, int backlog); /* /proc/sys/net/core/somaxconn */ int accept (int sockfd, struct sockaddr *addr, socklen_t *addrlen);//长度是指针！！ int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); /* 2.1 读写函数 */ ssize_t write (int sockfd, const void *buf, size_t len); ssize_t read (int sockfd, void *buf, size_t len); /* 2.2 socket 专有的读写函数(就多了个 flags 选项) */ ssize_t recv (int sockfd, void *buf, size_t len, int flags); ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *src_addr_len); ssize_t send (int sockfd, const void *msg, size_t len, int flags); ssize_t sendto (int sockfd, const void *msg, size_t len, int flags, const struct sockaddr *to_addr, socklen_t to_addr_len); /* 3. 关闭socket连接，参见 4.7.6 半关闭 */ int close (int sockfd); int shutdown (int sockfd, int how); /* 4. 设置 socket 属性，参见 4.9.3 端口复用 */ int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t*optlen); int setsockopt(int sockfd, int level, int optname,const void *optval, socklen_t optlen); socket()： 获取一个套接字（cman 2 socket） domain：协议族，AF_INET ， AF_INET6， AF_UNIX/AF_LOCAL... type：通信过程中使用的协议类型（流 报\\u0026hellip;)，SOCK_STREAM，SOCK_DGRAM，SOCK_SEQPACKET... protocal：具体的协议，一般传 0。流式协议默认TCP，报式默认UDP 返回值：成功返回 socket 文件描述符，失败返回 -1 bind()： 将 套接字 和 本地的 IP + 端口 绑定。 sockfd：上一步创建的 socket addr：本地（服务器的） IP 和 端口 结构体 addrlen：addr 的大小 返回值：成功 0， 失败 -1 listen()： 监听指定 socket 上的链接。listen 时有两个队列：已连接的和未连接的 sockfd：要监听的 socket，即刚通过 socket() 获得的那个 backlog：两个套接字队列的总最大长度（似乎与 man 手册不一样，查）（在 somaxconn 中定义） accept()： 从用于 listen 的那个 socket 获取进来的客户端信息，然后返回一个用于通信的新 socket【阻塞】 sockfd：用于监听的那个 socket（即listen()用的那个），因为要从里面的缓冲区读取客户端的数据 addr：传出参数，记录连接成功后，链进来的 客户端的 IP 和 端口 addrlen：是指针！！！，不能直接 sizeof 了，先定义一个变量。 返回值：成功返回用于通信的 socket 描述符，失败返回 -1 connect()： 客户端调用，用于连接服务器 sockfd：客户端自己创建的，用于通信的文件描述符 addr：要连接的服务器的 IP 和 端口 addrlen：addr 的 size 返回值：成功 0，失败 -1 recv()： 从指定 sockfd 中接收消息到 buf 中，其 flags 取值如下： recv(2) MSG_WAITALL：阻塞，直到所有的 request 都满足才返回，除非中间出现错误或异常（信号、断连） MSG_DONTWAIT：不阻塞，不能读就直接返回 MSG_CMSG_CLOEXEC：一执行，就把接受的 fd 关闭（只接收一次呗） 0：啥也不干，跟 read 一样 send()： 给指定 sockfd 发送 buf 中的内容，其 flags 取值如下： send(2) MSG_DONTWAIT：不阻塞，不给发就返回 MSG_NOSIGNAL：不产生 SIGPIPE 信号 MSG_EOF：shutdown 发送方向的连接，并发送一个数据尾标识（仅对 IPv4 的 TCP 有效） 0：啥也不干，跟 write 一样 并发服务器开发 多进程并发 基本模型：\\n父进程循环 accept()，阻塞等待。有客户端链接进来，则创建一个子进程去与之通信，父进程继续回去阻塞等待 accept。 父进程中应注册信号捕捉函数捕捉SIGCHILD信号，以便在子进程完成通信后回收它。回收的处理函数应当是一个非阻塞的循环 waitpid，有子进程在工作就返回父进程，使其得以继续监听。 注意，执行回调函数回收子进程，相当于一次软中断。而accept() 是会被系统中断打断的，也就是说，等回调函数返回时，accpet 会被打断，返回 -1，并设置errno 为 EINTR。要解决这个问题，便要在 accept 的返回值为 -1 时进行一次判断，如果errno == EINTR，则 continue 即可。 多线程并发 多线程的思想同多进程类似，也是主线程负责监听，接收到一个就创建一个子线程去处理。这里有一些关于传参的问题：\\n创建线程，我有多个参数：客户端信息、线程号、通信文件描述符\\u0026hellip;\\u0026hellip;，如何把这些参数传递给线程的回调函数呢？ $\\\\Rightarrow$ 很简单，只需要创建一个结构体，然后传递结构体指针即可。\\n创建的结构体，如果放在主线程的 while 循环中，即一个局部变量，那肯定是不行滴，传参不能传局部变量的指针，因为下一个循环它就没有了。\\n$\\\\Rightarrow$ 法一：给结构体在堆上分配内存（用 malloc 或 new），缺点是需要自己管理内存 $\\\\Rightarrow$ 法二：把结构体创建成一个全局变量。但是既然是多线程环境，如果要同时提供多个服务，都要传参，那肯定是需要一个结构体数组了。\\n既然要预先创建数组，那你得指定大小呀。指定了大小，就会有不够用的问题。也即，首先要确定，怎么从数组中找出当前可以用的结构体呢？如果找不到（用完了）又该怎么办呢？ $\\\\Rightarrow$ 首先是怎么找：当然是循环遍历了。如果是遍历结构体数组，那么开始时要对结构体数组进行初始化，将其中的客户端文件描述符置为-1，线程使用完后同样置为-1。这样，遍历找 client_fd 不是 -1 的结构体就好了 $\\\\Rightarrow$ 也可以设置一个可用数组，甚至可以采用位图的方法，专门描述哪些结构体数组可用。 $\\\\Rightarrow$ 比如结构体数组大小设置为 128，那意思就是，我这个服务器，最多只能并发 128 个线程。那多的请求呢？比如遍历到最后没找着，那就让其先睡一会儿，然后再去从头或者别的地儿遍历一下。找不着接着睡\\n另外，对子线程采用pthread_join来回收显然也是不可取的，因为它会阻塞主线程。设置分离属性即可。\\n端口复用 防止服务器重启时，之前绑定的端口还没释放 程序突然退出系统而没有释放端口 比如正在运行的 server 和 client，突然 server 被关掉了，此时使用 netstat -anp 命令会发现，client处于 close_wait 状态，服务器不存在了，监听端口状态也没了，但是这条连接的，服务器端口还在，并处于 fin_wait_2 状态，此时再结束客户端，服务器端口则处于 time_wait 状态（过一会就结束了）\\n就是说，服务器关闭了，但是 TCP 协议的任务还没完成，端口还被占用着。如果在这个 2MSL 的时间内，我想重启服务器，那么会发现，端口被占用了启动不了。为了避免这种情况，我们可以在绑定端口之前，指定端口复用属性。\\nnetstat -anp # -a 所有 socket # -n 显示正在使用 socket 的程序的名称 # -p 直接使用 IP 地址，而不通过域名服务器 int getsockopt(int sockfd, int level, int optname, void *optval, socklen_t *optlen); int setsockopt(int sockfd, int level, int optname,const void *optval, socklen_t optlen); 以上两个是设置/获取 socket 属性的函数，不只可以用来设置端口复用（ UNP7.2(P150) ）\\n端口复用要在服务器绑定之前设置（socket 之后，bind 之前 setsockopt）\\nsockfd：打开的 socket 描述符 level：级别，选 SOL_SOCKET（把选项解释为 通用套接字代码） optname：选项的名称，选 SO_REUSEADDR 或 SO_REUSEPORT optval：端口复用的值，0表示不可以复用，1表示可以复用【int 型】 optlen：optval 的长度，注意是否是指针。（因为 optval 不只是 int，还可以是 struct，参见 UNP） IO 模型 \\u0026#x1f31f; 从内核角度看 IO 模型 BIO(阻塞) 好处是不占用 CPU 资源，但是效率不高。accept 会阻塞，read 也会阻塞，服务器就干不了别的事了，一次一个 解决方法是，创建多个线程，让别的线程去进行交互，这样主线程一直监听，就可以实现并发。\\n这样仍有缺点：可能会瞬间产生大量的线程，大量的线程并发会消耗很多资源，而其中大部分都是在阻塞中，并没有干活 但根本的问题没解决：即这是一个阻塞的模型，阻塞，就导致程序不能走下去，才会有后面的一系列问题\\nNIO(非阻塞) 要遍历去询问准备好了没（O(n))。这种模型已经可以做到：用很少的线程去处理多个连接了。\\n但是仍有弊端：每一次遍历寻找就绪的 socket，都是一次系统调用，不断调用非常浪费 CPU 资源。那不系统调用了，这轮询的工作直接让内核去做不就行了？ =\\u0026gt; IO 多路转接/复用技术， 委托内核去帮我们做轮询 =\\u0026gt; select ，但是 select 只告诉你到了几个，不会说具体哪一个 内核直接帮你把谁到了都检测出来 =\\u0026gt; epoll\\n根本区别 对网络数据包接收流程可以分为两个阶段：\\n数据准备阶段： 在这个阶段，网络数据包到达网卡，通过DMA的方式将数据包拷贝到内存中，然后经过硬中断，软中断，接着通过内核线程ksoftirqd经过内核协议栈的处理，最终将数据发送到内核Socket的接收缓冲区中。 数据拷贝阶段： 当数据到达内核Socket的接收缓冲区中时，此时数据存在于内核空间中，需要将数据拷贝到用户空间中，才能够被应用程序读取。 阻塞 IO ，就是会在第一阶段，数据准备阶段 阻塞，非阻塞 IO 就是在第一阶段不阻塞，如果读不到，就直接返回。而无论阻塞非阻塞，在第二阶段都是阻塞的。在第二阶段阻塞的叫同步 IO，在第二阶段不阻塞的叫异步 IO\\n同步与异步 IO 同步模式在数据准备好后，是由用户线程的内核态来执行第二阶段。所以应用程序会在第二阶段发生阻塞，直到数据从内核空间拷贝到用户空间，系统调用才会返回。\\n异步模式下是由内核来执行第二阶段的数据拷贝操作，当内核执行完第二阶段，会通知用户线程 IO 操作已经完成，并将数据回调给用户线程。所以在异步模式下 数据准备阶段和数据拷贝阶段均是由内核来完成，不会对应用程序造成任何阻塞。\\n基于以上特征，我们可以看到异步模式需要内核的支持，比较依赖操作系统底层的支持。\\nIO 多路复用 I/O 多路复用使得程序能够同时监听多个文件描述，能够提高程序的性能。Linux 下实现 I/O 多路复用的系统调用主要有：select、poll、epoll\\nselect 主旨思想：\\n首先要构建一个文件描述的列表，将要监听的文件描述符添加到其中 调用一个系统函数（select），监听该列表中的文件描述符，（阻塞）直到其中有人进行了 IO 操作才返回 返回时会告诉有多少文件描述符到达了数据 #include \\u0026lt;sys/select.h\\u0026gt; /* 让内核监听列表中的文件描述符 */ /* sizeof(fd_set) = 128B = 1024 位，用位来表示对应的文件描述符 */ int select (int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); void FD_CLR (int fd, fd_set *set);\\t// 将 fd 对应的标志位置 0 void FD_SET (int fd, fd_set *set);\\t// 将 fd 对应的标志为置 1 int FD_ISSET(int fd, fd_set *set);\\t// 判断 fd 对应的标志位是否为 1,并返回该标志位值 void FD_ZERO (fd_set *set);\\t// 将 set 中标志位全置为 0 nfds：委托内核进行检测的文件描述符 最大数量 + 1（加 1 才能遍历到 max，因为从 0 开始嘛） readfds：【传入传出参数】设置位，让内核检查读缓冲，看对应文件描述符上是否有谁发来数据可读，有的话不变，没有的话，就会把对应的位置为 0，再从内核拷贝回用户态 writefds：让内核检查写缓冲，看是否有空余位置可写 exceptfds：检查异常 timeout：设置等待多久；如果为 0 表示不阻塞，为 NULL 表示永久阻塞 返回值：大于 0 表示有 n 个文件描述符发生了变化，0 表示超时了且没有检测到，-1 表示失败 工作原理 select 会修改用户传进去的 fdset，因此如果你下次还想要监听相同的文件描述符，那就要重新填充 fdset select 只是把活跃的 fd 置 1，返回给用户。用户仍需要再遍历一次，才能找到活跃的 fd 你要做的就是，每接收到一个新的客户端，就把它的 sockfd 添加到 fdset 中，交给 select 去监听 编写代码 在 accept 之前，先定义一个 fdset，把监听的文件描述符加进去，然后传给 select，让内核去遍历这个 set 这里有一个细节：传给 select 的，应当是一个中间值（即新建一个 temp_set）因为内核会修改传入的 set，这显然是我们不希望的。定义一个中间值，每次循环都把我们定义的 set 赋值给它 select 返回，如果返回的 tempset 里面，listen_fd 是 1，这个文件描述符上有数据，就说明有新的客户端进来了，需要去进行链接，即 accept，得到客户端的文件描述符，之后，将它添加到 set 中，更新 maxfd，然后传给内核继续 select 遍历 循环遍历 select 返回的 set，找到所有返回的文件描述符，然后处理上面的数据 如果处理数据时发现客户端断开连接，那么也应该清除其 set 位 【问题来了】，select 怎么多线程呢？新客户端进来之后，如果要创建新线程，那么新线程不还是要 BIO\\nselect 的缺点： 需要在内核态和用户态来回拷贝 fdset（两次拷贝）（当然还有两次切换） 每次对内核返回的 set 都要进行遍历，O(n) select 支持的文件描述符太少了，就 1024 fset 集合不能重用，每次都需要重置（内核会修改传入的 fdset，虽然有别的办法，但总归是机制不方便） poll poll 和 select 没有本质上的区别，只不过是，select 用的是 fdset 这么个位数组来传给内核，而 poll 用的是一个 pollfd 结构体数组来和内核传递消息。这就没有了 fd 最多 1024 的限制（但仍受限于系统的 fd 上限，这是显然的）。结构体数组中同时包括了文件描述符 和读写事件的区分，因此不需要分成三个 fdset 来传参\\n至于工作的过程，仍然需要拷贝，仍然需要轮询，仍不是能解决 C10k 问题 （处理 10k 个并发连接）的好调度\\n#include \\u0026lt;poll.h\\u0026gt; struct pollfd { int fd; /* 委托内核进行检测的文件描述符 */ short events; /* 委托内核检测什么事 */ short revents; /* 内核反馈实际上发生了什么事 */ }; int poll(struct pollfd *fds, nfds_t nfds, int timeout); fds：同文件描述符表，只不过换成了结构体数组，没有 1024 的限制了 nfds：fds 数组的有效下标 + 1 timeout：0 不阻塞，-1 阻塞，\\u0026gt;1 表示要阻塞的 毫秒 数 返回值：-1 失败，n：fds 中有 n 个文件描述符有变化 宏取值：使用多个用 | ，判断是否相等用 \\u0026amp;【注意，不能用 == 判断与某个宏值相等】 代码编写 创建一个 fds 结构体数组，初始化第一个元素为监听文件描述符，nfds 先置为 0，调用 poll 检查 poll 返回的数组，如果 fds[0].revents \\u0026amp; PILLIN，说明有新客户端，则进行 accept；然后将新的客户端文件描述符加入到 fds 数组中，要用 for 循环遍历找空位，以免浪费，更新 nfds 然后遍历 fds 数组，查找revents \\u0026amp; POLLIN的 fd，进行通信 poll 缺点 poll 改进了 select 的 3 4 缺点，即使用了一个结构数组，数组项可以重用了，也没有上限了。但仍有缺点：\\n仍然需要在内核态和用户态拷贝 仍然需要遍历。虽然告诉了你那几个发生了改变，但是并没有指出到底是谁，还是需要遍历 epoll select 的性能瓶颈 无论是 select 还是 poll，它们都存在着下列问题：\\n内核不会保存我们要监听的 sockfd 列表，因此每次调用，都需要来回拷贝一整份的数组**$\\\\rarr$红黑树** 内核不会通知具体是哪些 fd 就绪，只是在他们的数组位上打上标记，用户需要遍历才能找到$\\\\rarr$双链表 内核也是通过遍历来寻找就绪的 socket fd 的$\\\\rarr$回调函数 epoll 对这三个问题都进行了解决。它会在内核中创建一个 epoll 对象，这里面包括一个红黑树rbr：用来存放用户需要监听的文件描述符，和一个双向链表rdlist：用来保存内核找到的就绪描述符，并返回给用户。当然还有别的数据，比如一个阻塞队列wq：存放的是阻塞在 epoll 上的用户进程，在 IO 就绪的时候 epoll 可以通过这个队列找到这些阻塞的进程并唤醒它们，从而执行 IO 调用读写 Socket 的数据。\\n下面先看 epoll 的 API\\nepoll API #include\\u0026lt;sys/epoll.h\\u0026gt; /**epoll_create * @brief : 创建一个新的 epoll 实例（即内核中创建了一块数据结构） * - 需要检测的文件描述符信息（红黑树） * - 和就绪列表，存放内核检测到发生变化的文件描述符（双链表） * @parameter: * A size: 没有意义，随便指定。（历史遗留问题，因为之前是用hash实现的） * @return: -1失败，\\u0026gt;0 指向内核实例的文件描述符*/ int epoll_create(int size); struct epoll_event { unint32_t events;\\t// 发生了什么事件 epoll_data_t data;\\t// 用户数据(Union)，一般只用到 fd }; typedef union epoll_data { void *ptr; int fd;\\t// 用这个传递 fd（注意这是个 Union） unint32_t u32; unint64_t u64; }epoll_data_t; /**epoll_ctl * @brief: 对 epoll 实例进行管理，比如添加个文件描述符 * @parameter: * 1. epfd : create 返回的文件描述符，操作内核实例 * 2. op : 要进行什么操作（互相之间用 | ） * # EPOLL_CTL_ADD: 往红黑树中添加文件描述符 * # EPOLL_CTL_MOD: 修改 * # EPOLL_CTL_DEL: 删除 * # EPOLLET: 边缘触发 * # EPOLLONESHOT: LT模式下的，ET类似【待考究】 * 3. fd : 要操作/添加的文件描述符 * 4. event: 检测文件描述符什么事件(结构体，包括事件和文件描述符(跟fd一样)) * # EPOLLIN\\t: 写入 * # EPOLLOUT * # EPOLLERR */ int epoll_ctl (int epfd, int op, int fd, struct epoll_event *event); /**epoll_wait * @brief : 真正的调用函数 * @parameter: 1. epfd : 2. event : 结构体数组，【传出参数】保存发生变化的文件描述符，以及发生了肾莫事 同样是一个指针，ctl函数中传入的是单个，wait函数传出的是数组 3. maxevent : 前一个结构体数组的大小 4. timeout : 0不阻塞，-1阻塞直到检测到数据发生变化，\\u0026gt;0阻塞时常，单位毫秒 @return : 成功返回发生变化的文件描述符的个数 \\u0026gt;0，失败返回-1 */ int epoll_wait (int epfd, struct epoll_event *events, int maxevents, int timeout); 工作原理 可见 epoll 解决了如下问题：\\n内核态和用户态来回拷贝的问题：直接在内核态创建一个数据结构 内核态增删：创建一个红黑树，高效增删 内核态查找就绪：注册回调函数，就绪了直接定位 返回后用户不只谁变化，还需要遍历：创建一个就绪链表，返回的直接就是所有变化的 \\u0026#x2753; epoll 的回调函数ep_poll_callback正是epoll同步 IO 事件通知机制的核心所在，也是区别于select，poll采用内核轮询方式的根本性能差异所在。（\\u0026#x26d3;\\u0026#xfe0f; 内核角度看 IO 模型 ，源码实现，以后再看）\\nepoll 优势总结 内核中通过红黑树管理海量的连接，所以在调用epoll_wait获取IO就绪的 socket 时，不需要传入监听的 socket 文件描述符。从而避免了海量的文件描述符集合在用户空间和内核空间中来回复制。 epoll 仅会通知IO就绪的 socket。避免了在用户空间遍历的开销 epoll 通过在 socket 的 等待队列 上注册回调函数ep_poll_callback通知用户程序IO就绪的 socket。避免了在内核中轮询的开销。 代码编写 调用epoll_create，直接在内核创建一个数据结构（红黑树），返回文件描述符。通过文件描述符可以去操作这个内核区的实例 调用epoll_ctl把监听文件描述符添加EPOLL_CTL_ADD进内核的红黑树中 调用epoll_wait来让内核干活，返回一个发生变化的文件描述符列表epoll_event结构体数组 遍历结构体数组的每一个，如果是监听的变了，就 accept，同时把新客户 ADD 进去；如果是别的，就进行数据传输，如果传输完了就把该客户 DEL 掉 两种工作模式 （1）LT 模式（水平触发）\\nEPOLLLT，缺省即为此模式，可以同时支持阻塞和非阻塞 socket。这种模式下，内核会告诉你一个文件描述符是否就绪了，然后你可以对此就绪的 fd 进行 IO 操作。如果你不操作，或者没操作完（没读完），内核下一次还是会继续通知你这个 fd 可操作。\\n即：只要 fd 缓冲区中有数据，epoll 就会一直通知（每一轮），直到读完\\n（2）ET 模式（边缘触发）\\nEPOLLET，一种高速的工作方式，只支持 non-block socket，描述符变为就绪状态的时候，内核会通知你一次，后面就不会再为这个 fd 发送更多的信息了，直到某些操作导致其变为非就绪状态\\n即：只在第一次 fd 就绪的时候通知一下，后面不管是读完没读完，还是一直没读导致 fd 又变为非就绪，都不会再通知了。直到你进行了某些操作使其变为非就绪，才会再新的轮次中发送有关该 fd 的可用通知\\n两种模式比较\\nET 很大程度上减少了 epoll 时间被重复出发的次数，因此效率比 LT 高。必须使用非阻塞接口，以免由于一个 fd 阻塞而把多个 fd 饿死\\n本质区别就在于：\\nLT 模式下，线程调用 epoll_wait 操作一通 sockfd 之后，再次调用 epoll_wait 的时候，epoll_wait 会检查 socket 缓冲区中是否还有数据，是否读干净了。如果没读干净，那么就会把这个 sockfd 再次放进 rdlist 中，然后下次调用的时候还会返回这个 sockfd，还能接着读 而 ET 模式下，这一次调用了 epoll_wait 之后，直接就把就绪队列 rdlist 清空了，因此，不管你读没读，完没完，你下次都读不到这个 sockfd 了。除非，这个 socket 上有新的 IO 数据到达，根据 epoll 的工作过程，该 socket 会被再次放入 rdllist 中。 IO 线程模型 5 种 IO 模型是从内核空间的视角，来剖析网络数据的收发模型。而站在用户空间的视角，即可得到两种 IO 线程模型。即 Reactor 模型和 Proactor 模型\\n这些用户空间的IO线程模型都是在讨论当多线程一起配合工作时谁负责接收连接，谁负责响应 IO 读写、谁负责计算、谁负责发送和接收，仅仅是用户 IO 线程的不同分工模式罢了。\\nReactor Reactor是利用NIO（非阻塞）对IO线程进行不同的分工\\n使用 IO 多路复用模型比如select, poll, epoll, kqueue，进行 IO 事件的注册和监听。 将监听到就绪的 IO 事件分发dispatch到各个具体的处理Handler中进行相应的 IO 事件处理。 Reactor 模型依赖 IO 多路复用技术(epoll)，来实现监听 IO 事件，不断的分发dispatch，就像一个反应堆一样，看起来像不断的产生 IO 事件，因此我们称这种模式为Reactor模型。\\n具体分为三类：\\n单Reactor单线程 单Reactor多线程 主从Reactor 单 Reactor 单线程 单 Reactor 意味着只有一个 epoll 对象，用来监听所有的事件，比如连接事件，读写事件。 单线程 意味着只有一个线程来调用 epoll_wait，获取 IO 就绪的 Socket，然后对这些就绪的 Socket 执行读写，以及后边的业务处理也依然是这个线程。 相当于一个线程（小老板）要完成 accept 事件（迎客） 、接受 IO 请求（顾客点菜）、业务处理（做菜）、IO 响应（上菜）、断开连接（送客）\\n单 Reactor 多线程 仍然是一个 epoll 对象监听所有 IO 事件， 一个线程来调用 epoll_wait 来获取所有就绪 socket 但是处理 IO 事件的对应的业务 Handler 时，使用的是线程池，因此提高了执行效率 主从 Reactor 主 Reactor 专门用来迎接客人（接受新连接），对应的 Handler 就是 acceptor 从 Reactor 则负责招待客人（后续业务），在 acceptor 中将要监听的read 事件注册到从 Reactor中，由从 Reactor 来监听 socket 上的读写事件 注意：这里向从Reactor注册的只是read事件，并没有注册write事件，因为read事件是由epoll内核触发的，而write事件则是由用户业务线程触发的（什么时候发送数据是由具体业务线程决定的），所以write事件理应是由用户业务线程去注册。\\n用户线程注册write事件的时机是只有当用户发送的数据无法一次性全部写入buffer时，才会去注册write事件，等待buffer重新可写时，继续写入剩下的发送数据、如果用户线程可以一股脑的将发送数据全部写入buffer，那么也就无需注册write事件到从Reactor中。\\nProactor Proactor是基于AIO对IO线程进行分工的一种模型。前边我们介绍了异步IO模型，它是操作系统内核支持的一种全异步编程模型，在数据准备阶段和数据拷贝阶段全程无阻塞。\\nProactorIO 线程模型将 IO事件的监听，IO操作的执行，IO结果的dispatch统统交给内核来做。\\n模型组件介绍 completion handler 为用户程序定义的异步 IO 操作回调函数，在异步 IO 操作完成时会被内核回调并通知 IO 结果。 Completion Event Queue 异步 IO 操作完成后，会产生对应的IO完成事件，将IO完成事件放入该队列中。 Asynchronous Operation Processor 负责异步IO的执行。执行完成后产生IO完成事件放入Completion Event Queue 队列中。 Proactor 是一个事件循环派发器，负责从Completion Event Queue中获取IO完成事件，并回调与IO完成事件关联的completion handler。 Initiator 初始化异步操作（asynchronous operation）并通过Asynchronous Operation Processor将completion handler和proactor注册到内核。 执行过程 用户线程发起aio_read，并告诉内核用户空间中的读缓冲区地址，以便内核完成IO操作将结果放入用户空间的读缓冲区，用户线程直接可以读取结果（无任何阻塞）。 Initiator 初始化aio_read异步读取操作（asynchronous operation）,并将completion handler注册到内核。 在Proactor中我们关心的IO完成事件：内核已经帮我们读好数据并放入我们指定的读缓冲区，用户线程可以直接读取。在Reactor中我们关心的是IO就绪事件：数据已经到来，但是需要用户线程自己去读取。\\n此时用户线程就可以做其他事情了，无需等待 IO 结果。而内核与此同时开始异步执行 IO 操作。当IO操作完成时会产生一个completion event事件，将这个IO完成事件放入completion event queue中。 Proactor从completion event queue中取出completion event，并回调与IO完成事件关联的completion handler。 在completion handler中完成业务逻辑处理。 两线程模型比较 Reactor是基于NIO实现的一种 IO 线程模型，Proactor是基于AIO实现的 IO 线程模型。 Reactor关心的是IO 就绪事件，Proactor关心的是IO 完成事件。 Proactor中，用户程序需要向内核传递用户空间的读缓冲区地址。Reactor则不需要。这也就导致了在Proactor中每个并发操作都要求有独立的缓存区，在内存上有一定的开销。 Proactor 的实现逻辑复杂，编码成本较 Reactor要高很多。 Proactor 在处理高耗时 IO时的性能要高于 Reactor，但对于低耗时 IO的执行效率提升并不明显。 线程池 池是一组资源的集合，在服务器启动之初就被完全创建好并初始化，是静态资源。线程池是由服务器预先创建的一组子线程，线程池中的线程数量，应该和 CPU 核心数量差不多。线程池中的所有子线程运行着相同的代码，当有新任务到来时，主线程通过某种方式选择一个子线程来位置服务。空间换时间。\\n相比动态创建子线程，选择一个已经存在的子线程代价小得多。至于如何选择：\\n主线程使用某种算法来选择。 主线程和子线程共享一个工作队列，子线程在上面睡眠，有新任务来就唤醒 \"",
      categories: [],
      tags: "[\"linux\",\"网络编程\"]",
      series: "[\"面筋\",\"快速上手\"]",
      date: "\"2023-04-02\""
    });
  
    searchIndex.push({
      title: "\"苏州旅行计划\"",
      permalink: "\"/%E8%A1%A3%E9%A3%9F%E4%BD%8F%E8%A1%8C/%E6%97%85%E8%A1%8C%E6%94%BB%E7%95%A5/%E8%8B%8F%E5%B7%9E/\"",
      content: "\" ☂️ 吃喝 店铺 鲍师傅马蹄爆爆珠泡芙（外卖） 纸皮烧卖（外卖） 科软夜市红黑榜 山城三姐火锅（有人推荐） 破店小酒馆（观前店） 玩乐 1. 平江路 图1 遇见平江路 图2 平江路熙熙攘攘 图3 遇见平江路 图4 平江路熙熙攘攘 2. 狮子园 山塘街\\n\"",
      categories: "[\"衣食住行\"]",
      tags: "[\"旅行\"]",
      series: [],
      date: "\"2023-04-01\""
    });
  
    searchIndex.push({
      title: "\"gdb快速上手\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/gdb%E6%95%99%E7%A8%8B/\"",
      content: "\"gdb 命令 通用命令 \\u0026#x1f4d6; GDB Reference \\u0026#x1f517; 调试器 GDB 常用功能 x / [Length] [Format: t o d x f a c s] [Address expression b-8 h-16 w-32 g-64 ] \\u0026#x1f4ce; GDB Command Reference : x p / t-2 o-8 d-10 x-16 f-loat a-ddress c-har s-tring [var]\\n\\u0026#x26a0;\\u0026#xfe0f; 要注意区分，x 是扫描内存，因此后面跟的直接是内存地址， 而 p 是输出变量的值，因此后面想跟地址的话，需要取其内容，即加上* 关于 *，很多命令地址前面都要加星号，因为不加星号的一个地址，是被当成函数来看待的 s n ：C 语言级别的单步执行； si ni汇编级别的单步执行\\ni [line] / [locals] / [vtbl] / [args] / [checkpoints] / [breakpoints] info line [line] / [function] / [*addr]：显示源码对应的内存中的起始结束地址\\ninfo vtbl [objs]：直接查看对象的虚函数表（也可以类型转换的形式打印出来，参考 C++类的内存分配 ，基本思想就是：对象的第一块内存放的就是虚表，虚表是一个函数指针数组，因此可以先将对象地址转换为指向指针的指针，然后对其取内容，就得到了虚表指针。把这个值转换为指向指针的指针，即得虚表）\\nset print array-indexes on：打印数组的时候显示 index\\nset disassemble next-line on，disassemble\\nset [args] / [register] / [*address] = [val]：设置参数、寄存器值、内存处值\\njump [*address]：跳转到指定地址处执行，return [val]：直接返回。都可以改变程序走向。\\nshell [cmd]：运行 shell 命令\\nrbreak [regex]：在所有满足正则表达式的函数处打断点\\n多进程/线程调试 gdb [pid]：调试正在运行的进程，或者进去后 attch [pip] 例子 打印栈内容（你打数组肯定也行）：不妨设 $rsp 中存放的是 0x1234 p $rsp =\\u0026gt; (void*)0x1234 x/10dw $rsp 或 x/10dw 0x1234，即用 x 命令直接把栈那一块内存扫描出来 p *(int (*)[10])0x1234 把栈顶地址类型转换为一个指向数组的指针，然后 print 这个数组 val 的值（所以要加*），即栈的内容 p (int [10])*0x1234 把栈顶的内容直接变成一个数组，然后输出 p *0x1234@6 注意@的用法，其左边必须是你想查看内存处的值，可以直接输出后面的六个变量 类似的 p *argv@argc，也是先取内容转换为变量，再输出 总结一下，用 x 就是直接扫描内存了，简单粗暴；用 p 则是要把你想看的内存区域转化成一个变量，一个 val，不管是 int 还是 int 数组，不管是怎么类型转换，反正基本思想是把内存当成一个变量进行输出。最好还是用 x ，因为效果一样，用 p 你还需要先得到 rsp 里面的值 查看虚表 略 运用 core 文件：gdb debug core进入之后，disassemble，可以看到 =\\u0026gt; 指向的就是运行出错的地方 \"",
      categories: "[\"工具使用\"]",
      tags: "[\"gdb\",\"cmdline\"]",
      series: "[\"快速上手\"]",
      date: "\"2022-11-25\""
    });
  
    searchIndex.push({
      title: "\"Ubuntu22.04安装Hadoop完全分布式集群\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/ubuntu%E9%85%8D%E7%BD%AEhadoop%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F/\"",
      content: "\"Ubuntu22.04 安装 Hadoop 完全分布式集群 1. 网络配置 需要修改四处，windows（宿主机），vmware，和虚拟机 ubuntu （NAT模式）\\nwindows，设置 vmware8 的 ipv4 选项即可\\nvmware 的 ip 设置和 windows 是一样的，网关都是192.168.5.2，还有 NAT 网络设置\\nubuntu 的主要任务就是\\n把 DHCP 换成静态IP（这部分要看具体集群配置，比如设置 master 和 slave1，slave2，则可以分别分配 ip 为192.168.5.11,192.168.5.12,192.168.5.13） 再改改网关 gateway 和 DNS（这部分和上面是一样的） 然后为 ip 地址起个别名，即修改hosts，添加映射 cd /etc/netplan/ \\u0026amp;\\u0026amp; ll vim 01-network-manager-all.yaml # 把以下内容粘贴上 # Let NetworkManager manage all devices on this system network: ethernets: ens33: ## 网卡名，要改对 dhcp4: false addresses: - 192.168.5.11/24 ## set static IP routes: - to: default via: 192.168.5.2 ## gateway nameservers: addresses: [8.8.8.8,8.8.4.4,192.168.3.1] version: 2 # 开启systemd-networkd服务 sudo systemctl start systemd-networkd # 查看状态 sudo systemctl status systemd-networkd # 重启网络服务 sudo netplan apply #查看设定的ip是否生效 ifconfig | head -n 3 # 测试网络 ping -c 3 www.baidu.com # 修改hostname sudo vim /etc/hostname # 设置ip映射 sudo vim /etc/hosts # 把对应的ip添加到文件中 192.168.5.11 master 192.168.5.12 slave1 在 windows 中也添加 ip 映射 /C:\\\\windows\\\\system32\\\\drivers\\\\etc\\\\hosts\\n## 2. 安装JDK与Hadoop ### 2.1 安装 ```bash # 将下载的安装包解压到 /opt下新建的文件夹module中 tar -zxvf jdk-XXXX-x64.tar.gz -C /opt/module tar -zxvf hadoop-XXXX-x64.tar.gz -C /opt/module 2.2 配置环境变量 # 新建.sh文件；因为\\\\etc\\\\profile会遍历\\\\etc\\\\profile.d文件夹下的所有.sh文件 sudo vim /etc/profile.d/my_env.sh # 在文中添加如下内容： # set JAVA_HOME export JAVA_HOME=/opt/module/jdk1.8.0_212 export PATH=$PATH:$JAVA_HOME/bin # set HADOOP_HOME export HADOOP_HOME=/opt/module/hadoop-3.1.3 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin # source一下profie即可，因为他会自动遍历profile.d文件夹 source /etc/profile # 测试一下是否配置成功 java -version hadoop version # 不行就reboot 2.3 克隆虚拟机 注意选则完全克隆，然后修改静态ip地址和hostname\\n3. 配置完全分布式 3.1 配置 SSH 无密登录 # ssh-server是缺省的，注意安装一下 sudo apt install openssh-server # 生成公钥和私钥，以rsa算法 ssh-keygen -t rsa # 将公钥拷贝给别的机器 ssh-copyid [maser][slave1][slave2] 3.2 常用命令 3.2.1 scp（secure copy) scp -r $pdir/$filename $user@$host:$pdir/$filename\\n拷贝 递归 要拷贝的文件 目标服务器:目的路径/名称\\n3.2.2 rsync（远程同步工具） rsync -av $pdir/$filename $user@$host:$pdir/$filename\\n远程同步 参数 要拷贝的文件 目标服务器:目的路径/名称\\n-a 表示归档拷贝，-v 表示显示过程\\nrsync可以避免复制重复内容，所以比scp效率要高；同时支持符号链接\\n3.2.3 xsync（自己编写的脚本） xsync:将当前文件自动分发到集群中所有机器的相同位置\\n# 在~/bin目录下创建脚本文件，因为这个目录已经被添加到环境变量中，可以全局使用。当然也可以自己添加环境变量 sudo vim /home/usr/bin/xsync # 编写以下内容： #!/bin/bash #1. 判断参数个数 if [ $# -lt 1 ] then echo Not Enough Arguement! exit; fi #2. 遍历集群所有机器 for host in master slave1 slave2 do echo ==================== $host ==================== #3. 遍历所有目录，挨个发送 for file in $@ do #4. 判断文件是否存在 if [ -e $file ] then #5. 获取父目录 pdir=$(cd -P $(dirname $file); pwd) #6. 获取当前文件的名称 fname=$(basename $file) ssh $host \\u0026quot;mkdir -p $pdir\\u0026quot; rsync -av $pdir/$fname $host:$pdir else echo $file does not exists! fi done done # 设置可执行权限 sudo chmod 777 xsync source /etc/profile 3.3 集群配置 3.3.1 集群规划 master slave1 slave2 HDFS NameNode\\nDataNode DataNode SecondaryNamenodeDataNode YARN NodeManager ResourceManager\\nNodemanager NodeManager 历史服务器 HistoryServer\\n日志聚集 3.3.2 配置集群 共有四个用户自定义配置文件core-site.xml,hdfs-site.xml,yarn-site.xml,mapred-site.xml，都在路径$HADOOP_HOME/etc/hadoop下\\n3.3.2.1 core-site.xml \\u0026lt;configuration\\u0026gt; \\u0026lt;!-- 指定NameNode的地址 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;fs.defaultFS\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;hdfs://master:8020\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 指定hadoop数据的存储目录 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;hadoop.tmp.dir\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;/opt/module/hadoop-3.1.3/data\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 配置HDFS网页登录使用的静态用户为shuaikai --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;hadoop.http.staticuser.user\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;shuaikai\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;/configuration\\u0026gt; 3.3.2.2 hdfs-site.xml \\u0026lt;configuration\\u0026gt; \\u0026lt;!-- nn web端访问地址--\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;dfs.namenode.http-address\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;master:9870\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 2nn web端访问地址--\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;dfs.namenode.secondary.http-address\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;slave2:9868\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;/configuration\\u0026gt; 3.3.2.3 yarn-site.xml \\u0026lt;configuration\\u0026gt; \\u0026lt;!-- 指定MR走shuffle --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;yarn.nodemanager.aux-services\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;mapreduce_shuffle\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 指定ResourceManager的地址--\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;yarn.resourcemanager.hostname\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;slave1\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 环境变量的继承 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;yarn.nodemanager.env-whitelist\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 开启日志聚集功能 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;yarn.log-aggregation-enable\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;true\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 设置日志聚集服务器地址 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;yarn.log.server.url\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;http://master:19888/jobhistory/logs\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 设置日志保留时间为7天 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;yarn.log-aggregation.retain-seconds\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;604800\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;/configuration\\u0026gt; 3.3.2.4 mapred-site.xml \\u0026lt;configuration\\u0026gt; \\u0026lt;!-- 指定MapReduce程序运行在Yarn上 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;mapreduce.framework.name\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;yarn\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 历史服务器端地址 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;mapreduce.jobhistory.address\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;master:10020\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;!-- 历史服务器web端地址 --\\u0026gt; \\u0026lt;property\\u0026gt; \\u0026lt;name\\u0026gt;mapreduce.jobhistory.webapp.address\\u0026lt;/name\\u0026gt; \\u0026lt;value\\u0026gt;master:19888\\u0026lt;/value\\u0026gt; \\u0026lt;/property\\u0026gt; \\u0026lt;/configuration\\u0026gt; 3.3.2.5 在集群上分发配置文件 xsync $HADOOP_HOME/etc/hadoop/ 4. 群起集群 4.1 配置 worker vim $HADOOP_NOME/etc/hadoop/workers # 把所有主机名添加进去，不要有多余的空格、换行 master slave1 slave2 # 分发 xsync $HADOOP_NOME/etc/hadoop/workers 4.2 启动集群 如果集群是第一次启动，需要在 master 节点格式化 NameNode\\n\\u0026#x1f47a;注意：格式化 NameNode 后，会产生新的集群 id，导致 NameNode 和原来 DataNode 对应的集群 id 不一致，这样集群就找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。\\n\\u0026#x1f479;要严格按照集群规划，启动对应的部分，hdfs，yarn，历史服务器等\\n# (1) 格式化NameNode hdfs namenode -format # (2) 启动Hdsf 【在master上】 $HADOOP_HOME/sbin/start-dfs.sh # (3) 启动该Yarn 【在slave1上】 $HADOOP_HOME/sbin/start-yarn.sh # (4) 启动历史服务器\\t【在master上】 mapred --daemon start historyserver # (5) 查看启动情况\\t【在各个机器上】 jps # (6) 在web端口查看 # HDFS http://master:9870 # YARN http://slave1:8088 # HistoryJob http://hadoop102:19888/jobhistory # (7) 关闭集群 4.3 集群启动和关闭方法 4.3.1 各个模块分别启动/停止 HDFS:start-dfs.sh,stop-dfs.sh YARN:start-yarn.sh,stop-yarn.sh\\n4.3.2 各个服务器组件逐一停止 HDFS:hdfs --daemon start/stop namenode/datanode/secondnamenode\\nYARN:yarn --daemon start/stop resourcemanager/nodemanager\\n4.3.3 编写脚本 集群整体启动/停止 vim ~/bin/myhadoop.sh #!/bin/bash if [ $# -lt 1 ] then echo \\u0026quot;No Args Input...\\u0026quot; exit ; fi case $1 in \\u0026quot;start\\u0026quot;) echo \\u0026quot; =================== 启动 hadoop集群 ===================\\u0026quot; echo \\u0026quot; --------------- 启动 hdfs ---------------\\u0026quot; ssh master \\u0026quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh\\u0026quot; echo \\u0026quot; --------------- 启动 yarn ---------------\\u0026quot; ssh slave1 \\u0026quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh\\u0026quot; echo \\u0026quot; --------------- 启动 historyserver ---------------\\u0026quot; ssh master \\u0026quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver\\u0026quot; ;; \\u0026quot;stop\\u0026quot;) echo \\u0026quot; =================== 关闭 hadoop集群 ===================\\u0026quot; echo \\u0026quot; --------------- 关闭 historyserver ---------------\\u0026quot; ssh master \\u0026quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver\\u0026quot; echo \\u0026quot; --------------- 关闭 yarn ---------------\\u0026quot; ssh slave1 \\u0026quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh\\u0026quot; echo \\u0026quot; --------------- 关闭 hdfs ---------------\\u0026quot; ssh master \\u0026quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh\\u0026quot; ;; *) echo \\u0026quot;Input Args Error...\\u0026quot; ;; esac chmod 777 myhadoop.sh 4.3.4 编写脚本 查看所有服务器运行的服务 vim ~/bin/jpsall #!/bin/bash for host in master slave1 slave2 do echo =============== $host =============== ssh $host jps done chmod 777 jpsall 4.4 常用端口号 端口名称 Hadoop3.x NameNode 内部通信 8020/9000/9820 NameNode HTTP UI 9870 MapReduce 8088 HistoryServer 19888 5. 集群基本测试 官方案例 wordcount（本地模式运行）\\n上传下载，web 浏览\\n\\u0026hellip;\\u0026hellip;\\n\"",
      categories: "[\"环境配置\"]",
      tags: "[\"hadoop\"]",
      series: [],
      date: "\"2022-11-21\""
    });
  
    searchIndex.push({
      title: "\"C++连接mysql\"",
      permalink: "\"/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/c++%E8%BF%9E%E6%8E%A5mysql/\"",
      content: "\"C++连接 mysql Info MySQL 是 社区版 ，8.0.31；clion 2022.2.3；ubuntu22.04\\n1）Windows 下，clion 连接 mysql 是用的直接解压版，主要图一个方便。假定已经成功 配置好 mysql 把%MySQL_HOME%/lib下的libmysql.dll和libmysqllib两个文件拷贝到 clion 工程的cmake-build-debug文件夹下\\n然后在 Cmakelist.txt 中添加：\\n# 自动生成 cmake_minimum_required(VERSION 3.23) project(connect_mysql) set(CMAKE_CXX_STANDARD 11) # 声明mysql头文件路径 set(INC_DIR D:\\\\\\\\mysql\\\\\\\\include) # 声明mysql链接库路径 set(LINK_DIR D:\\\\\\\\mysql\\\\\\\\lib) # 引入头文件 include_directories(${INC_DIR}) # 注意这里如果直接用路径的话，不要加引号 # 引入库文件 link_directories(${LINK_DIR}) link_libraries(libmysql) add_executable(connect_mysql main.cpp) target_link_libraries(connect_mysql libmysql) 然后直接#include\\u0026lt;mysql.h\\u0026gt;就好了\\n2）ubuntu 下 # 三步走 sudo apt install mysql-server sudo apt install mysql-client sudo apt install libmysqlclient-dev 默认链接库安装在/usr/lib/x86_64-linux-gnu/下\\n补充知识点：\\ngcc 编译选项 -I: (大写的 I）指定引用头文件路径，如-I/usr/include/mysql\\n-l:（小写的 l） 手动添加链接库，这里 gcc 是到默认链接库下搜索的，如/usr/lib。\\n库文件标准文件名为libxxx.a，在使用时前缀lib和后缀.a是省略的，即直接-lxxx，l 是自己添加的\\n举个例子，数学库\\u0026lt;math.h\\u0026gt;默认是不链接的，因此即使你包含了这个头文件，编译时仍然会报错 undefined reference。正确的编译命令是gcc test.c -o test.out -lm【数学库的名称为 libm.a】\\n-L:（大写的 L） 指定一个搜索链接库的目录，如-L/usr/lib/x86_64-linux-gnu -lmysqlclient，后面再跟你指定的库文件\\nmysql_config whatis mysql_config #OUT: mysql_config (1) - display options for compiling clients whereis mysql_config #OUT: /usr/bin/mysql_config mysql_config --cflags # 同 --cxxflags --include #OUT: -I/usr/include/mysql mysql_conig --libs #OUT: -L/usr/lib/x86_64-linux-gnu -lmysqlclient -lzstd -lssl -lcrypto -lresolv -lm 可以看出，这是一个专门为编译 mysql 文件提供编译选项的脚本。因此，可以通过这个脚本方便的对写的文件进行编译\\ngcc connect_mysql -o demo.out `mysql_config --include --libs` -Wall 这样头文件和链接库都指定好了，只需要#include\\u0026lt;mysql.h\\u0026gt;就好了\\nmysql 接口 mysql_init() 获取或初始化 MYSQL 结构 mysql_real_connect() 连接到 MySQL 服务器。 mysql_query() 执行指定为“以 Null 终结的字符串”的 SQL 查询。 mysql_use_result() 初始化逐行的结果集检索。 mysql_field_count() 返回上次执行语句的结果集的列数。 mysql_fetch_row() 从结果集中获取下一行 mysql_num_fields() 返回结果集中的字段数 测试用例 下面列两个验证的例子\\n#include \\u0026lt;iostream\\u0026gt; #include \\u0026lt;mysql.h\\u0026gt; //mysql提供的函数接口头文件 using namespace std; int main() { const char* host = \\u0026quot;localhost\\u0026quot;; //主机名 const char* user = \\u0026quot;your_name\\u0026quot;; //用户名 const char* pwd = \\u0026quot;your_passwd\\u0026quot;; //密码 const char* dbName = \\u0026quot;demo\\u0026quot;; //数据库名称 int port = 3306; //端口号 // 创建mysql对象 MYSQL *sql = nullptr; sql = mysql_init(sql); if (!sql) { cout \\u0026lt;\\u0026lt; \\u0026quot;MySql init error!\\u0026quot; \\u0026lt;\\u0026lt; endl; } // 连接mysql sql = mysql_real_connect(sql, host, user, pwd, dbName, port, nullptr, 0); if (!sql) { cout \\u0026lt;\\u0026lt; \\u0026quot;MySql Connect error!\\u0026quot; \\u0026lt;\\u0026lt; endl; } // 执行命令 int ret = mysql_query(sql, \\u0026quot;select * from student\\u0026quot;); if (ret) { cout \\u0026lt;\\u0026lt; \\u0026quot;error!\\u0026quot; \\u0026lt;\\u0026lt; endl; } else { cout \\u0026lt;\\u0026lt; \\u0026quot;success!\\u0026quot; \\u0026lt;\\u0026lt; endl; } cout \\u0026lt;\\u0026lt; ret \\u0026lt;\\u0026lt; endl; // 关闭mysql mysql_close(sql); return 0; } #include\\u0026lt;iostream\\u0026gt; #include\\u0026lt;mysql/mysql.h\\u0026gt; /* mysql_init() 获取或初始化MYSQL结构 mysql_real_connect() 连接到MySQL服务器。 mysql_query() 执行指定为“以Null终结的字符串”的SQL查询。 mysql_use_result() 初始化逐行的结果集检索。 mysql_field_count() 返回上次执行语句的结果集的列数。 mysql_fetch_row() 从结果集中获取下一行 mysql_num_fields() 返回结果集中的字段数 */ class MyDB { public: MyDB(); ~MyDB(); bool initDB(std::string host,std::string user,std::string pwd,std::string db_name); bool exeSQL(std::string sql); private: MYSQL *connection;//连接mysql句柄指针 MYSQL_RES *result; //指向查询结果的指针 MYSQL_ROW row; //按行返回的查询信息 }; MyDB::MyDB() { connection = mysql_init(nullptr); //初始化数据库连接变量 if(connection == nullptr) { std::cout\\u0026lt;\\u0026lt;\\u0026quot;mysql_init error!\\u0026quot;\\u0026lt;\\u0026lt;std::endl; exit(1); } } MyDB::~MyDB() { if(connection != nullptr) { mysql_close(connection); } } bool MyDB::initDB(std::string host,std::string user,std::string pwd,std::string db_name) { // 函数mysql_real_connect建立一个数据库连接 // 成功返回MYSQL*连接句柄，失败返回NULL connection = mysql_real_connect(connection,host.c_str(),user.c_str(),pwd.c_str(),db_name.c_str(),0,nullptr,0); if(connection == nullptr) { std::cout\\u0026lt;\\u0026lt;\\u0026quot;mysql_real_connect error!\\u0026quot;\\u0026lt;\\u0026lt;std::endl; return false; } return true; } bool MyDB::exeSQL(std::string sql) { // mysql_query()执行成功返回0，失败返回非0值. if(mysql_query(connection,sql.c_str()) != 0) { std::cout\\u0026lt;\\u0026lt;\\u0026quot;mysql_query error!\\u0026quot;\\u0026lt;\\u0026lt;std::endl; return false; } else { result = mysql_store_result(connection); //获取结果集 // mysql_field_count()返回connection查询的列数 while ((row = mysql_fetch_row(result)) != nullptr) { // mysql_num_fields()返回结果集中的字段数 for(int j = 0;j \\u0026lt; mysql_num_fields(result);++j) { std::cout\\u0026lt;\\u0026lt;row[j]\\u0026lt;\\u0026lt;\\u0026quot; \\u0026quot;; } std::cout\\u0026lt;\\u0026lt;std::endl; } // 释放结果集的内存 mysql_free_result(result); } return true; } int main() { MyDB db; db.initDB(\\u0026quot;localhost\\u0026quot;,\\u0026quot;your_name\\u0026quot;,\\u0026quot;your_passwd\\u0026quot;,\\u0026quot;demo\\u0026quot;); db.exeSQL(\\u0026quot;show databases;\\u0026quot;); return 0; } \"",
      categories: "[\"环境配置\"]",
      tags: [],
      series: [],
      date: "\"2022-11-20\""
    });
  
    searchIndex.push({
      title: "\"征服C指针笔记\"",
      permalink: "\"/%E7%AC%94%E8%AE%B0/%E5%BE%81%E6%9C%8Dc%E6%8C%87%E9%92%88/\"",
      content: "\"征服 C 指针 关于指针 初步 指针类型定义 指针类型 可由函数类型、对象类型或不完全的类型派生。派生指针类型的类，称为引用类型。指针类型描述这样一个对象：该类对象的值，提供对该引用类型实体的引用。由引用类型 T 派生的指针类型，有时称为*“（指向）T 的指针*。从引用类型构造指针类型的过程，称为*\\u0026ldquo;指针类型的派生”*。这些构造派生类型的方法可以递归地应用。\\n和基本类型一样，指针也有：指针类型，指针类型的变量，指针类型的值\\n指针与地址关系 指针就是地址。对么？\\n无论是用%d, %p, %x,都能输出指针，指针就是unsigned int。似乎这样理解也不无道理。但是需要指出的是，这是与环境有关的。指针的长度是固定的，无论其是指向什么类型，可以参见下面的例子：\\nint *p1; double *p1; char *p3; printf(\\u0026quot;%d %d %d\\\\n\\u0026quot;, sizeof(p1), sizeof(p2), sizeof(p3)); // 输出： 8 8 8 既然指针是地址，那指向 int 指向 double 有必要区分么？有的。仅仅告知内存地址，不告知在那个地址上的数据类型，是无法正确取出值来的。 题外话，指针的强制类型转换，也只是改变对内容的解释方法，指针的长度是固定不变的\\nint x = 0x00000041; char *p; p = (char*)\\u0026amp;x; pintf(\\u0026quot;%c\\\\n\\u0026quot;, p); // 输出： A 指针就是地址，对指针 +1，指针不应该就前进一个字节么？ 当然不是，对指针 +n，指针前进“当前指针指向的数据类型长度 $\\\\times$n\\n空指针 空指针\\n确保它和任何非空指针进行比较都不会相等\\n只有NULL，无论对方指向什么类型，都可以进行赋值和比较\\nNULL， 0 和 \\u0026lsquo;\\\\0\\u0026rsquo; 在\\u0026lt;stdio.h\\u0026gt;中，NULL 定义如下：#define NULL 0，那么空指针不就是为 0 的地址么？大部分环境中确实是这样，但这么说是不准确的。（原作中说的我也没听懂要说什么，但为了便于阅读，还是写 NULL 吧，又不费劲？）不过有一点：在 C 语言中，当常量 0 处于应该作为指针的上下文中时，他就作为空指针使用，所以：\\nint *p = 3; // error! 不能将 int 型赋值给 int* 型 int *q = 0; // 可以，此时等价于， p == NULL \\u0026rsquo;\\\\0\\u0026rsquo;即所有位均为 0 的空字符，也即其 ASCII 码为 00000000，空字符\\u0026rsquo;\\\\0\\u0026rsquo;是常量，实际上它等同于 0，但同样的，仍建议不要这样写（C 语言中，‘\\\\0\\u0026rsquo;呀\\u0026rsquo;a\\u0026rsquo;呀，其类型实际上是 int 而不是 char）\\nchar alp = 'a'; printf(\\u0026quot;%d %d\\u0026quot;, sizeof(alp), sizeof('a')); // 输出： 1 4 指针和数组 这是本书最重要的“一”句话：\\n在表达式中，数组可以解读成\\u0026quot;指向它的初始元素的指针\\u0026rdquo;，除了\\n数组为 sizeof 运算符的操作数时，求出的时全体数组元素的大小（在函数中又例外，函数中形参传递的就是指向数组的指针） 数组为 \\u0026amp; 运算符的操作数时，（ANSI C 中)返回 指向数组的指针 初始化数组时的字符串常量 字符串常量是char 的数组，在表达式中通常被解读成指向 char 的指针。但在初始化 char 数组时候的字符串常量会作为被花括号括起来的单个字符的省略形式，被编译器特别解释 p[i] 只是 *(p + i) 的语法糖，下标运算符[]原本只有这种用法，它和数组无关，不是依赖数组才存在的 （所以哪怕你写成i[p]也是一样可以的。当然，请不要这样写）\\n一些实验：\\n// 对于点 1 int nums[N]; int len = sizeof(nums) / sizof(int); //数组元素个数 void(int nums[]); void(int *nums); // 两种写法是等价的，所以此时nums就是个指针，sizeof(nums) == 8; // 对于点 3 char str[4] = \\u0026quot;abc\\u0026quot;; str[0] = 'b'; // 可以, 花括号形式赋值 char *str = \\u0026quot;abc\\u0026quot;; str[0] = 'b'; // 不可以，指针赋值，指向的是字符串常量（在只读区），常量能改么？ char *str[] = {\\u0026quot;abc\\u0026quot;, \\u0026quot;ab\\u0026quot;}; str[0][0] = 'b'; // 不可以，str是一个数组，里面存放的是指针，所以对应的”abc“是赋值给指针了 char str[][4] = {\\u0026quot;abc\\u0026quot;, \\u0026quot;ab\\u0026quot;}; str[0][0] = 'b'; // 可以， str是数组的数组，所以”abc“是赋值给数组，也即花括号形式赋值 为什么 C 语言不做数组下标越界检查？ 简单来说，C 中访问数组元素，（即使你用的是下标访问法，）都是用指针来进行的。这样的指针可以有很多种，存在于多处、多个源文件中，他们还可以自由的进行加减运算。对编译器来说是很难追踪每一个指针的\\n函数指针 正如数组在表达式中被解读成指针一样，函数，也同时是指向函数的指针，这个指针指向函数的初始地址\\nANSI C 标准 表达式中的函数，自动转换成指向函数的指针，但是除了作为sizeof和\\u0026amp;的操作符时 函数调用运算符()的操作数不是函数，而是函数的指针 因此对于指向函数的指针，使用*对其解引用，变为函数，但是由于是在表达式中，因此立马又被解释成指向函数的指针，因此，下面这个也是能工作的\\nvoid func(int a); void (*func_p)(int); func_p = func; // 此时 func 直接可以解释成指向函数的指针 func_p = \\u0026amp;func; // 此时 func 不能再解释称函数指针了，因为是 \\u0026amp; 的操作数 (****printf)(\\u0026quot;hello\\\\n\\u0026quot;); // 一样正常工作 函数指针的用途 GUI 中的按钮控件记忆“当自身被按下的时候需要调用的函数” “指向函数的指针，的数组”，可以避免用 switch C 是如何使用内存的 C 的变量种类 作用域 全局变量：在函数之外声明，在任何地方可见。即使源文件被分割成多个文件编译，别的文件仍然可见 文件内部的静态变量：只限定在当前源代码文件中，用static修饰 局部变量：只在语句块内被引用 存储期 静态存储期：全局变量、文件内 static 变量、指定 static 的局部变量。从程序开始，到程序结束 自动存储期：只在代码块{}内存活 malloc()动态分配的内存：直到用free()释放 各变量在内存中的位置 函数和字符串常量 函数自身，和字符串常量，汇总配置在一个只读的内存区域\\n静态变量 静态变量：包括全局变量，文件内 static 变量，static 指定的局部变量。它们总在虚拟地址空间中占有固定区域，从程序启动到结束持续存在。\\n函数和全局变量，如果他们的名称相同，即使跨越了多个源代码文件，也被当作相同的对象来对待。这是由链接器负责的\\n为了在链接器中将名称结合起来，各个目标代码(.o)都具备一个符号表（可以用nm命令查看）\\n自动变量不会出现在符号表中，因为他们是在运行时被决定的，属于链接器管辖范围之外的\\n自动变量 自动变量重复使用内存区域（栈），创建、释放，他们的内存地址是不一定的\\n函数调用过程 在调用方，参数从后往前堆积在栈中【注：先进栈的是参数列表，从右往左！而且，此时由调用函数负责！】 和调用有关的返回信息（返回地址等）进栈【注：返回地址在参数之上，因此先返回，参数释放由调用方操作】 跳转到作为被调用对象的函数地址 被调函数使用的自动变量进栈【注：1-4 增长的栈区域，为被调函数的可引用区域】 被调函数执行过程中，为了进行复杂的表达式运算，有时会向栈中放入结果 被调函数结束，释放自动变量内存，使用返回信息返回【注：此时参数还在栈中】 从栈中去掉调用方的参数【注：所谓传值，即这里的参数是 copy 的，还要被释放】 函数栈内存溢出 一旦破坏了自动变量的内存区域，一直往下，就是函数的返回信息。如果数组越界越到了这里，破坏了返回信息，那么函数将不能再正确返回。甚至可以通过越界在返回信息处填上别的内容，此即安全漏洞。\\n可变长参数 在 2.2.3.1 中提到，C 语言函数的参数进栈，是从后往前的，因此无论堆积多少参数，总是能知道第一个参数的地址。利用这点可以实现参数个数不固定的函数\\nvoid func(char *format,...); 函数原型中出现...，那么对这一部分是不会进行类型检查的。根据format中指出的参数格式，逐个对后面的参数进行处理即可。因为 format 是能找到的，然后只需往栈中向后读取参数就好了。\\nmalloc()分配的内存 返回值为void*，即通用型指针，所以不需要进行强制类型转换；分配失败则返回NULL\\n不是系统调用\\n在\\u0026quot;利用malloc()分配的内存区域\\u0026quot;下面，是一大块空的内存空间。多次调用malloc()会调用一次系统调用 brc()，内存区域向地址较大的方向身长（栈是向小地址增长）\\nmalloc()分配过程 malloc()遍历链表寻找空的内存块，如果发现尺寸大小合适的块，就将其分割出来，把管理区域中的标记变成“使用中的块”，并向应用程序返回紧邻管理区域的后面的区域的地址；free()则将管理区域中的标记改为“空块”，并顺便将上下空块合并成一个块，防止碎片化。 一旦发生越界，越过malloc()分配的内存区域向后写入数据，就会破坏后一个块的管理区域，此后使用 malloc 和 free 就容易出现崩溃了！ free()之后可能出现的错误 调用free()后，对应的内存块内容不会马上被破坏掉，要等到下次 malloc\\u0026ndash;\\u0026gt;但有可能别的地儿还在使用这块内存（free 早了），所以发现错误较晚\\u0026ndash;\\u0026gt;改写 free，一旦 free 就破坏其中的内容\\u0026ndash;\\u0026gt;可是不知道内存的大小，怎么填充新东西呢？\\u0026ndash;\\u0026gt;再改写 malloc，使得每次分配都预留一小块来设定区域大小信息\\u0026ndash;\\u0026gt;当然，只用于调试版本\\n解读 C 的声明 of-to-returning 读法 首先着眼于标识符（变量名或函数名）【先定性，xx 是 xx】\\n从距离标识符最近的地方开始，依照优先顺序解释派生类型（指针、数组、函数），优先顺序为：\\n① 用于整理声明的括弧()② 表示数组的[]，表示函数的();③ 表示指针的*\\n解释完成派生类型，使用 of to returning 将他们连接起来\\n最后，追加数据修饰类型修饰符（在左边，int double 等）\\nvoid (*sinnal(int sig, void (*func)(int)))(int); 读法：singal is function[sig is int, func is pointer to function(int) returning void] returning pointer to function(int) returning void\\nsignal 是一个函数（参数是 int, 和指向返回值为 void 函数的指针），返回值为：指向一个返回值为 void 函数（参数为 int）的指针；\\n简写：\\ntypedef void(*sig_t)(int); // 给指向:参数为 int,返回值为 void,的函数 的指针类型,起个别名：sig_t\\nsig_t signal(int sig, sig_t func); const const int *p: p is a pointer to read-only int 指针常量\\nint * const p: p is a read-only pointer to int 常量指针\\ntypedef C 的数据类型的模型 基本类型和派生类型 基本类型：整形（char，int)、浮点型(float,double) 枚举类型：【定义的一些离散变量】【枚举类型 + 基本类型 = 算数类型】 void 类型：【void 表示没有可用的值】 派生类型：指针类型，数组类型（元素个数为属性），函数类型（指返回值类型，参数是属性），结构类型，共用体类型\\n例如，有如下声明：\\nint (*func_table[10])(int a); 用链结构图表示类型，链的最前面的元素是基本类型：\\n@startuml left to right direction rectangle \\u0026quot;数组\\u0026quot; as A rectangle \\u0026quot;指针\\u0026quot; as B rectangle \\u0026quot;函数\\u0026quot; as C rectangle \\u0026quot;int\\u0026quot; as D note right of A #FFFFFF: 元素个数为10 note right of C #FFFFFF: 参数为int A --\\u0026gt; B : 的元素为 B --\\u0026gt; C : 指向 C --\\u0026gt; D : 返回 @enduml 最开始类型“数组（元素 10）”整和了全体类型的意义，所以将其称为类型分类【即“定性”，你到底是个什么东西】\\n从基本类型开始，递归地粘附上派生类型，就可以生成无限类型\\n类型的派生 指针类型的派生 后面的 T1 T2\\u0026hellip;统称为被引用类型 T\\n@startuml scale 1 rectangle \\u0026quot;指针\\u0026quot; as A rectangle T1 rectangle T2 rectangle T3 rectangle \\u0026quot;...\\u0026quot; as B A -left-\\u0026gt; T1 : 指向 T1 -left-\\u0026gt; T2 T2 -left-\\u0026gt; T3 T3 -left-\\u0026gt; B @enduml 数组类型的派生 @startuml scale 1 rectangle \\u0026quot;指针\\u0026quot; as A rectangle T1 rectangle T2 rectangle T3 rectangle \\u0026quot;...\\u0026quot; as B A -left-\\u0026gt; T1 : 包含 T1 -left-\\u0026gt; T2 T2 -left-\\u0026gt; T3 T3 -left-\\u0026gt; B note right of A #fff: 元素个数 @enduml 函数类型的派生 @startuml scale 1 left to right direction rectangle T1 as E rectangle T2 as F rectangle T1 as G rectangle T2 as H rectangle T1 as I rectangle T2 as J rectangle \\u0026quot;函数\\u0026quot; as C rectangle \\u0026quot;参数\\u0026quot; as D rectangle \\u0026quot;...\\u0026quot; as B rectangle \\u0026quot;...\\u0026quot; as K rectangle \\u0026quot;...\\u0026quot; as L B --\\u0026gt; F F --\\u0026gt; E E --\\u0026gt; C: 被返回 C .. D D --\\u0026gt; G G --\\u0026gt; H H --\\u0026gt; K D --\\u0026gt; I I --\\u0026gt; J J --\\u0026gt; L @enduml 有特定长度的类型，称为对象类型 函数类型不是对象类型，因为其没有特定长度 数组类型就是将几个派生类型排列而成的类型，其全体长度为sizeof(T) * len;, 因此无法从函数类型派生数组类型（以及其他任何类型），即没有函数的数组（但可以有指向函数的指针的数组） 也无法从数组类型派生函数类型，因为数组不是标量，不能返回 基本类型 推荐 同义表现 备注 char 与下面俩同义，默认是什么需要看具体处理环境 %c $\\\\pm127$ signed char %c unsigned char %c 0~255 short signed short, short int, singed short int unsigned short unsigned short int int signed, signed int, 无指定类型 %d unsigned int unsigned %u long signed long, long int, signed long int %ld unsigned long unsigned long int float %f double long double 零碎 assert() scanf()：返回读取到的字符数，对于未读取的字符，仍保留在流中，可被别的读取！ realloc() 标量 \\u0026amp; 聚合类型：P15、P83 C++中可以将任意指针赋值给 void*，但是反过来不行，所以 malloc 必须强制类型转换。不过人 C++都用new了 内存布局对齐：结构体中，一些数据类型可能会被配置到比如 4/8 的倍数的地址上，即使它没有这么长。例如： typedef struct{ int a; double b; char c; // 会被自动对齐到 4 的倍数的内存地址上 }hoge; printf(\\u0026quot;%d\\\\n\\u0026quot;, sizeof(hoge)); //输出： 16 大端、小端存储 int hoge = 0x12345678; unsigned char *hoge_p = (unsigned char*)\\u0026amp;hoge; printf(\\u0026quot;%x %x %x %x\\\\n\\u0026quot;, hoge_p[0], hoge_p[1], hoge_p[2], hoge_p[3]); // 输出： 78 56 34 12 // 小端存储 \"",
      categories: [],
      tags: [],
      series: [],
      date: "\"2022-10-04\""
    });
  
    searchIndex.push({
      title: "\"Leetcode刷题指南\"",
      permalink: "\"/%E7%AE%97%E6%B3%95/leetcode%E5%88%B7%E9%A2%98%E6%8C%87%E5%8D%97/\"",
      content: "\"1. 数据结构 1.1 数组 循环数组问题：把数组扩大为两倍即可，但不是真的扩大两倍，而是通过索引取模的方式 1.2 链表 链表可以通过引入虚拟头节点 ListNode *dummy = new ListNode{-1, nullptr} 来极大简化\\n**递归：**要区分基础情况和跳出情况，即可以有两种 return，比如：如果链表为空，那么返回。这时候的 return 并非是用来跳出递归的，而是一个 base 情况的判断，只有最基本的（最后一层递归）会用到。一系列操作，比如反转链表之后，再 return，则时候是退出递归的 return，即后面每一层递归想出栈都是走的这一条 return。\\n反转链表【递归】：反转从 head-\\u0026gt;next 开始的链表，然后拼接上第一个节点。base：单节点链表\\n反转前 n 个元素：反转从 head-\\u0026gt;next 开始的 n-1 个元素，然后拼接。base：n = 1\\n反转 [m, n] 的元素：反转从 head-\\u0026gt;next 开始的 [m-1, n - 1] 的元素，然后拼接。base：m = 1，同上\\n倒序输出链表：对链表进行后序遍历，（递归的 base 是，head==nil）\\n1.3 栈与队列 单调队列 有这样一类问题：如何得到一个队列中的最值？遍历，然后维护一个最值就好了。但这会有一个问题：当最值出队之后，次最值无从得知，需要再次遍历。可以参考例题：\\n【 剑指 Offer：队列最大值 】，【 leetcode-1438. 绝对差不超过限制的最长连续子数组（解法二） 】\\n如何快速得到一个队列中，当前所有元素的最值呢？维护一个单调队列 queueMax，对入队元素 Value，如果 queueMax.back() \\u0026gt; value，则直接入队，否则一直 queueMax.pop_back()，直至满足该条件。这样便可以保证：对原队列中所有元素，单调队列的队首，总是其最大值。如果原队列出队，使得最值出队，则单调队列中的下一个，仍是原队列中剩余元素的最值。\\n单调栈 类似的还有单调栈的问题 503. 下一个更大元素 II - 力扣（LeetCode） ：给你一个数组，有什么办法返回一个数组 res，使得 res 中存放原数组元素，其后面第一个比自己大的元素。也即利用单调栈寻找第一个大于自己的元素：\\n（1）数组从后往前入栈（出栈时即是顺序），如果栈顶元素小于自己，则一直出栈，直至栈顶大于自己，此时即有 $res[i] = stack.top()$ ，再把当前元素入栈。\\n（2）从前入栈也可以（看题解写法）。从栈里的元素的角度看：元素先入栈，如果后面碰到比它大的元素，那它就会出栈；从要入栈的元素角度看，如果我比栈顶大，那就出栈，直到栈顶比我大我再入栈。这样一来，出栈就意味着，碰到了后面第一个比自己大的元素，而留在栈里的说明目前还没有比它大的。\\n下面是示意图：\\n而我们仍需一个数组来记忆元素的下一个大哥，所以如果直接是元素入栈的话，你只是知道了 2 的下一个大哥是 5，但是找不到 2 的索引，就没办法设置结果 stack2.pop();数组。因此可以采取：索引入栈、pair 入栈、哈希数组\\n索引入栈的话，即 $if( nums[i] \\u0026gt; nums[s.top()])\\\\rarr ret[s.top()]=nums[i], s.pop()$，如果大于栈顶，那就一直出栈（出的是索引），并且把出栈元素的邻近大哥（即 ret）标记为待入栈元素\\n2. 双指针 双指针一般用于数组字串和链表，尤其是二者还有序的情况。有三种双指针：\\n两指针：字面意义上的双指针，就是说有两个表需要遍历，你整俩指针出来 左右指针：左右分为，从两端往中间同时跑，和从中间往两边（最长回文子串） 快慢指针：又分为，同时出发一快一满，和速度相同，但其中一个先走（维持 k 间距） 滑动窗口：[left, right) 这么个区间，不断扩大 right，直至这是一个满足要求的窗口，然后缩小 left，使得此窗口为一个紧确的窗口，然后再扩大 right 搜索新的窗口，满足了再紧确，直至抵达边界。 注意滑动窗口，要分清何为\\u0026quot;valid window\\u0026quot;，有时候这是一个大小不固定的，有时候又是固定大小的。 下面是一些应用：\\n（1）链表\\n**求链表中点：**二倍速指针走到末尾，一倍速走到中点 求链表倒数第 k 个节点：先走 k 步的离开末尾时，后面那个距离它为 k，即倒数第 k 个 判断链表有无环：地球是圆的的话，快慢指针终有相遇的一天 求出环的入口：快慢指针相遇之时，让一个重回起点再走，再次相遇即是在入口（列一下式子就出来了） 求两链表的交点： ① 两个指针各自遍历链表。在走到链表结尾的时候（p==nullptr），进入另一个链表。这样它们会走过相同的路程，即$a + b + c$，该处即为交点。如果不相交，则走过 $m+n$ 后会有： p==q==nullptr，也是相等 ② 把其中一个链表的尾巴和另一个的头相连，就成了判断有无环，有就找到环入口的问题 ③ 先求出两表的长度，让长的指针先走（long - short）步，这样链表就对齐了，对齐了就好办了 （2）数组\\n数组原地删除相同元素：（有序数组）快指针在前面探路，遇到不同的赋值给 slow++，这样前面的都不同 数组原地删除某一值：快指针在前面探路，只要不碰到 target，就赋值给 slow++ 数组二分查找：（有序）最常见的双指针 low 和 high，或者叫 left 和 right 两数之和：（有序）两端开始，和大了就把大的缩点，和小了就把小的加点 原地反转数组：从两头开始互相交换【原地反转链表呢？\\u0026raquo; 递归】 回文串判断：两头开始比较是否相等 求最大回文子串：从某一点或两点开始，往两边扩散求最长回文串；如此对全部元素都扩一遍，求最大值 盛水最多容器 11 题目：\\n如下图，给你一个数组 height，找出能“盛水”的最大值\\n分析：\\n从两端扫一遍数组，则盛水量为：\\n$$ max\\\\_contain = (right - left)\\\\times \\\\min\\\\{height[left],\\\\ height[right]\\\\} $$现在考虑怎么个扫描法。反正只要移动，容器的“底”必然会变小，如果移动长板，那么容器的边最多不会超过原来的短板，因为边去的是最小值，移动后小于原来的短板，则变小，移动后大于，边也不会变大，因此移动长板，必然会使容量减小。那么就移动短边。\\n题解：\\nint maxArea(vector\\u0026lt;int\\u0026gt;\\u0026amp; height) { int l = 0, r = height.size() - 1; int max_contain = 0; while (l \\u0026lt; r) { int area = min(height[l], height[r]) * (r - l); ans = max(max_contain, area); if (height[l] \\u0026lt;= height[r]) ++l; else --r; } return max_contain; } 3 二分法 对有序数组进行二分查找，有三种情况：只查找目标、查找目标元素序列左边界、右边界。\\n二分查找思想很简单，关键在一些细节：比如 right 是等于 size 还是 size-1， while 循环 $\\\\le$ 还是 $\\u0026lt;$，找着目标之后 right 是等于 mid 还是 mid-1。其实很好理解，只需要分清你的搜索区间是什么：\\n如果 $left=0, right = len-1$，那搜索区间就是闭区间 $[left,right]$，while 循环如果写$l\\u0026lt;r$，则退出条件就是$left==right$，此时闭区间 $[left,left]$ 里面还有一个元素，有元素还退出，那肯定是要漏了，所以应该选$left\\\\le right$，如果搜索区间为左闭右开则同理。\\n搜索目标的左右边界，与直接搜索目标区别在于：找到目标后不是直接返回，而是继续缩小区间。搜元素是命中时退出，搜边界一定是 left \\u0026gt; right 退出。那么：\\n如果存在目标元素，则到最后一定是 $left \\\\rarr target,\\\\ right\\\\rarr target-1$，只需 return nums[left]; 如果目标不存在，则 $left\\\\rarr nums.size()\\\\ \\\\or\\\\ right\\\\rarr -1$ 模板如下\\nint left_bound(int nums[], int target) { int left = 0, right = nums.length - 1;\\t//（0） while (left \\u0026lt;= right) { //（1） // 防止加法溢出 int mid = left + (right - left) / 2; if (nums[mid] \\u0026lt; target) { left = mid + 1; } else if (nums[mid] \\u0026gt; target) { right = mid - 1; } else if (nums[mid] == target) { // 别返回，锁定左侧边界 right = mid - 1;\\t//（2） } } // 判断 target 是否存在于 nums 中 // 此时 target ⽐所有数都大/小，返回 -1 if (left \\u0026lt;mark\\u0026gt; nums.length || right \\u0026lt;/mark\\u0026gt; -1)\\t//（3） return -1; return left; } 下面是一些应用：\\n查找峰值：【无序】也可以二分，即先比较 mid 和两边的元素大小，如果 mid 在上坡，则说明峰值在前方，left = mid + 1，如果在下坡，说明在后方，right = mid - 1，如果直接命中，则返回 4 贪心 \\u0026amp; 动态规划 4.1 线性 DP 1 斐波那契数列 $$ dp[i] = dp[i-1]+dp[i-2]\\\\ \\\\xRightarrow{\\\\text{优化}} \\\\ r = p + q $$矩阵快速幂 其实斐波那契数列还有一个O(log n) 复杂度的做法：用矩阵快速幂，转换成求这么个矩阵的 n 次幂\\n$$ \\\\begin{pmatrix} F_{n+1} \\u0026amp; F_n \\\\end{pmatrix} \\\\begin{pmatrix} F_{n} \\u0026amp; F_{n-1} \\\\end{pmatrix} \\\\begin{pmatrix} 1 \\u0026amp; 1 \\\\ 1 \\u0026amp; 0 \\\\end{pmatrix} \\\\begin{pmatrix} F_{1} \\u0026amp; F_{0} \\\\end{pmatrix} {\\\\begin{pmatrix} 1 \\u0026amp; 1 \\\\ 1 \\u0026amp; 0 \\\\end{pmatrix}}^n $$\\n而矩阵快速幂，跟一般的快速幂都是类似的，都是将幂分解为二进制表示，$a^n = a^{2^i}a^{2^{i-1}}\\\\cdots a^0$，然后运用累乘的思想。\\ntypedef vector\\u0026lt;vector\\u0026lt;double\\u0026gt;\\u0026gt; Matrix; Matrix MatrixMultiply(const Matrix\\u0026amp; A, const Matrix\\u0026amp; B); // 自行实现矩阵相乘 Matrix MatrixPower(const Matrix\\u0026amp; A, const int n){ // A^13 = A^8 * A^4 * A^1 int size = A.size(); // 创建一个结果矩阵，先初始化为 单位矩阵 Matrix result(size, vector\\u0026lt;int\\u0026gt;(size, 0)); for (int i = 0; i \\u0026lt; size; i++) { result[i][i] = 1; } Matrix base = A; while (n \\u0026gt; 0) { // 如果该位上为 1，说明有 2^i 这一项，则乘上 if (n \\u0026amp; 1) { result = multiply(result, base); } // 将base自乘，用于下一位的计算 base = MatrixMultiply(base, base); // 右移一位 n \\u0026gt;\\u0026gt;= 1; } return result; } O(log n) 的时间复杂度就是在base = MatrixMultiply(base, base); 这一步来的。因为将矩阵的幂换成了如干个 $2^i$ 个幂相乘，最高不会超过 $2^{log(n)}$ 次，而且每个更高级的幂都是用低级的平方上去的，不会有额外复杂度\\n2 BST 种类 求由 n 个节点构成的 二叉搜索树 有多少种？\\n\\u0026#x1f914;两种方向： 动态规划应当有两种思考方向：\\n（1）从 1 到 n（自下而上）：\\n一个节点：有一种；\\n两个节点：有两种，以小的为根，和以大的为根\\n三个节点：有三种情况：最小的作为根，中间的作为根，最大的作为根。$dp[2] + dp[1]*dp[1]+dp[2]$\\n更多节点：同上了，俺顺序，依次选取不同的根，元素就会被分成两部分。\\n可得递推式：\\n$$ dp[n] = dp[0]\\\\times dp[n-1] + dp[1]\\\\times dp[n-2] + \\\\cdots + dp[n-1]\\\\times dp[0] $$这里用到了乘法原理。这里的 0，要说空树也是树嘛，为了公式的整齐性，也应将其置为 1\\n（2）从 n 到 1（自上而下）：\\nn 个节点的树，肯定是要分为左右子树的，则自然有：$dp[n] = dp[left] \\\\times dp[right]$。而左右子树具体有多少个节点，那肯定也不一样嘛，因此：\\n$$ dp[n] = \\\\sum_{i = 0}^{n-1}(dp[i]\\\\times dp[n-1-i]) $$殊途同归。具体问题的时候，可以往下想想，往上想想，就能把问题拆解清楚了。线性 DP，还是比较简单的\\n3 最大子数组和 连续最大 和 给你一个数组有正有负，求连续的子数组，使得其和最大\\n**把握核心：**核心是什么？求最大子数组，核心当然是子数组。你只有分析子数组，才能找到最大的子数组\\n子数组怎么分呢？要动态规划，你肯定得从 0 做起，而且还要朝着一个方向坚定不移前进（往前推进），不能一会前一会后（前后可以考虑滑动窗口）。所以，要找一个朝着某一方向的，变化的子数组。所以：\\n以当前元素结尾的子数组的最大值，是 dp[i]\\n$$ dp[i] = max(dp[i - 1] + arr[i], arr[i]) $$线性的，能不能优化为原地的呢？可以看到，只用到了 dp[i-1]，完全可以用一个变量保存起来就好了\\n连续最大 积 思考一下，积，跟和的区别，在哪里呢？\\n积，会存在负负得正的情况。因此，当前结尾的最大子数组积，\\n要么是前面的最大的正数，乘了一个大于 1 的正数，变大了；要么是前面最大的乘了一个正真分数，变小了；要么，是前面的负的最小值，乘了一个负数，变大了。\\n因此最大值有三种来历：正正，负负，当前元素\\n$$ dp\\\\_max[i] = \\\\max(dp\\\\_max[i-1]\\\\times arr[i],dp\\\\_min[i-1]\\\\times arr[i],arr[i]) \\\\\\\\ dp\\\\_min[i] = \\\\min(dp\\\\_min[i-1]\\\\times arr[i],dp\\\\_max[i-1]\\\\times arr[i],arr[i]) $$显然，也是可以优化为原地 dp 的\\n连续最大 乘积为正 乘积为正的子数组：要么负负得正，负数加一；要么正正，正的加一；要么归 0\\n$$ \\\\begin{align*} dp\\\\_pos[i] = \\\\begin{cases} dp\\\\_pos[i-1] + 1 \\u0026 arr[i]\\u003e0 \\\\\\\\ 0 \\u0026 arr[i]=0 \\\\\\\\ dp\\\\_neg[i-1] + 1 \\u0026 arr[i] \\u003c 0 \\\\end{cases} \\\\\\\\\\\\\\\\ dp\\\\_neg[i] = \\\\begin{cases} dp\\\\_neg[i-1] + 1 \\u0026 arr[i]\\u003e0 \\\\\\\\ 0 \\u0026 arr[i]=0 \\\\\\\\ dp\\\\_pos[i-1] + 1 \\u0026 arr[i] \\u003c 0 \\\\end{cases} \\\\end{align*} $$环形数组 最大和 环形数组，都可以转换成数组二倍。$arr[]$是环形数组，则遍历一遍 ${0,1,2\\\\dots n, 0,1\\\\dots n}$ 就相当于遍历了环\\n因此照着这个遍历一遍就好了（不用真的扩充数组，到末尾的时候再回到开始就好了）。相当于得到了 dp 数组之后，又回过头来更新一遍\\n4 字符串 最长编辑距离 将一个字符串变成（增加、删除字符）另一个字符串，最少需要多少次操作？\\n用 $dp[i][j]$ 表示字符串 $x_{1\\\\dots i}$ 和 $y_{1\\\\dots j}$ 的编辑的最少次数。则 $dp[i][j-1],\\\\ dp[i-1][j],\\\\ dp[i-1][j-1]$ 都是可“预知”的。 然后，添加一个或两个元素\\n如图，共有一下三种对齐方式：最后一位补上，和最后一位不一样\\n$$ dp[i][j] = \\\\max\\\\{dp[i-1][j]+1,\\\\ dp[i][j-1]+1,\\\\ dp[i-1][j-1]+diff(i,j)\\\\} $$股票最佳时机 股票最佳时机 Ⅰ 121 题目：\\n给一个 prices 数组表示每天股票的价格，只能某天买入，后面一天卖出，求能赚的最大利润。\\n分析：\\n今天的最大利润，等于昨天的最大利润，与之前最低时买入并在今天卖出所得利润，的最大值。即\\n$$ profit[i] = max \\\\{\\\\ profit[i - 1],\\\\ prices[i] - min\\\\_prices\\\\ \\\\} $$类比后面几种，也可以写成，\\n$$ \\\\left \\\\{ \\\\begin{aligned} buy_0 \\u0026= 0,\\\\ sell_0 = 0 \\\\\\\\ buy_1 \\u0026= max\\\\{\\\\ buy_1^`,\\\\ sell_0-prices[i]\\\\ \\\\} \\\\\\\\ sell_1 \\u0026= max \\\\{\\\\ sell_1^`,\\\\ buy_1+prices[i]\\\\ \\\\} \\\\end{aligned} \\\\right . $$题解：\\nint maxProfit(vector\\u0026lt;int\\u0026gt;\\u0026amp; prices) { int inf = 1e9; int minprice = inf, maxprofit = 0; for (int price: prices) { maxprofit = max(maxprofit, price - minprice); minprice = min(price, minprice); } return maxprofit; } 股票最佳时机 Ⅱ 122 题目：\\n仍然是 prices 数组表示每日价格，区别是，可以进行多次买卖，但是每一天手里最多只能有一只股票。即买了就得卖，不卖不能再买。求最大利润。\\n与 Ⅰ 的区别在于，能多次买卖，只不过必须是一买一卖，不能同时持有多支。\\n分析：\\n由于最多持有一只股票，因此第 i 天只有两种情况：持有一支和 0 支，分别用$dp[i][0]$和$dp[i][1]$表示。每天的最大利润等于，要么卖了更赚，要么前一天就最赚。则有状态转移方程如下：\\n$$ \\\\left \\\\{ \\\\begin{aligned} dp[i][0] \\u0026= max\\\\{dp[i - 1][0],dp[i-1][1]+prices[i]\\\\} \\\\\\\\ dp[i][1] \\u0026= max\\\\{dp[i - 1][1],dp[i-1][0]-prices[i]\\\\} \\\\end{aligned} \\\\right . $$初值，也即第一天时，$dp[0][0] = 0,\\\\ dp[0][1] = -prices[0]$，最后卖了肯定比不卖赚，因此最大值即为$dp[n][0]$。\\n同样的，类比一下，这里也可以不用二维数组。\\n题解：\\nint maxProfit(vector\\u0026lt;int\\u0026gt;\\u0026amp; prices) { int dp0 = 0, dp1 = -prices[0]; int len = prices.size(); for(int i = 1; i \\u0026lt; len; i++) { // 这里可以直接操作dp0即可 dp0 = max(dp0, dp1 + prices[i]); dp1 = max(dp1, dp0 - prices[i]); // int new_dp0 = max(dp0, dp1 + prices[i]); // int new_dp1 = max(dp1, dp0 - prices[i]); // dp0 = new_dp0; // dp1 = new_dp1; } return dp0; } 股票最佳时机 Ⅲ 123 题目：\\n还是 prices 数组，但是最多只能进行两次买卖，且最多同时持有一支股票。\\n与 Ⅱ 的区别在于，限制了交易次数，最多两次。\\n分析：\\n某一天，最多有五种操作：不买，买了一支，卖了一支，买了第二支，卖了第二支。对应的状态转移方程为：\\n$$ \\\\left\\\\{ \\\\begin{aligned} buy_0 \\u0026= 0 ,\\\\ sell_0=0\\\\\\\\ buy_1 \\u0026= max\\\\{\\\\ buy_1^`,\\\\ - price[i] \\\\ \\\\} \\\\\\\\ sell_1 \\u0026= max\\\\{\\\\ sell_1^`,\\\\ buy_1^`+prices[i]\\\\ \\\\} \\\\\\\\ buy_2 \\u0026= max\\\\{\\\\ buy_2^`,\\\\ sell_1^`-prices[i]\\\\ \\\\} \\\\\\\\ sell_2 \\u0026= max\\\\{\\\\ sell_2^`,\\\\ buy_2^`+prices[i]\\\\ \\\\} \\\\\\\\ \\\\end{aligned} \\\\right . $$加上'表示前一天的值。buy0，不买肯定是 0，不用考虑。最后最赚的，如果卖了两支那就两支最赚，返回 sell2，如果买了一支，那么$sell_2 = sell_1$，买了没卖一定比卖了赚的少。因此最后返回值为 sell2\\n另外，这里直接对\\n题解：\\nint maxProfit(vector\\u0026lt;int\\u0026gt;\\u0026amp; prices) { int buy1 = -prices[0], sell1 = 0; int buy2 = -prices[0], sell2 = 0; for(int i = 1; i \\u0026lt; prices.size(); i++) { buy1 = max(buy1, 0 - prices[i]); sell1 = max(sell1, buy1 + prices[i]); buy2 = max(buy2, sell1 - prices[i]); sell2 = max(sell2, buy2 + prices[i]); } return sell2; } 股票最佳时机 Ⅳ 188 题目：\\n还还还是那个 prices 数组，你可以进行k次交易，仍然是最多同时持有一支股票。\\n与 Ⅲ 的区别在于，从 2 次改成了 k 次\\n分析：\\n解法同上，区别在于，限制买两次，每天是 5 种状态，限制买 k 次，每天还是那么分析状态，用一个 for 循环表示出来即可。要注意初始化时，buy 要全部初始化为-p0，因为一天可以连续买卖。\\n题解：\\nint maxProfit(int k, vector\\u0026lt;int\\u0026gt;\\u0026amp; prices) { vector\\u0026lt;int\\u0026gt; buy(k+1, -prices[0]); vector\\u0026lt;int\\u0026gt; sell(k+1, 0); buy[0] = 0; for(int i = 1; i \\u0026lt; prices.size(); ++i) { for(int j = 1; j \\u0026lt;= k; ++j) { buy[j] = max(buy[j], sell[j - 1] - prices[i]); sell[j] = max(sell[j], buy[j] + prices[i]); } } return sell[k]; } 停下思考 1 上面这几个股票问题，采用了动态规划方法解决。那么他们的最优子结构是什么呢？\\n可以举几个最优子结构的例子进行类比学习：\\n最佳游艇租赁，假设最优路径有中间停靠站 k，那左右两边的租赁价格都得是最小\\n矩阵链乘，假设要从中间 k 处分割，那么左右的链乘代价都得是最小的 最长公共子序列，假设Z 是 X 和 Y 的最长公共子序列，那么，如果三者末位元素相等，那么去掉一个，Zk-1还的是 Xm-1、Yn-1的最长子序列。如果末尾元素不同，那么去掉那个不同的（假设是 X 的末位），Zk还得是 Xm-1与 Yn的最长子序列 基因编辑（字符串变为另一字符串所需的最小代价），假设X 和 Y 的最短编辑距离是d[i][j]，那么对于 X 和 Y 的右侧，要么放得对齐：相同了不编辑，不同则编辑；要么不对齐：去掉长的，或给短的插入一个。反正均可以用 d 表示出来： 0-1 背包，\\n**20230303：**都是先假设最优解存在，将最优解设出来，然后去表示子问题的最优解（即递推）。我认为股票的最优子结构是，每一天买卖股票所能获得的最大利润。知道了前面每一天的，就能知道最后一天的答案。分析 dp 解题步骤：找状态转移方程$\\\\rightarrow$分析初值，然后就可以写循环了\\n\"",
      categories: "[\"算法\"]",
      tags: "[\"leetcode\"]",
      series: "[\"leetcode刷题指南\"]",
      date: "\"2022-09-11\""
    });
  
    searchIndex.push({
      title: "\"word 页眉页脚设置\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/word%E9%A1%B5%E7%9C%89%E9%A1%B5%E8%84%9A%E9%85%8D%E7%BD%AE/\"",
      content: "\"word 页眉页脚设置 页眉设置（略） 页脚设置 第 n 页 共 n 页 格式 （暂略）\\n页脚页码忽略前几页 首先要插入分节符（在‘布局’选项卡里面），分节之后操作页脚才不会“牵一发而动全身” 插入后页脚左上方会显示‘第 2 节’,右上方会显示‘与上节相同’这种 点击选项卡上的不于上一节保持一致\\n然后对前三页（标题、title、目录）不设页脚，而选择‘页码’选项卡，编辑为罗马数字格式。后面的页设置页码不与前一节相同，即可出现‘Ⅰ Ⅱ Ⅲ 1 2 3……”这样的编码方式\\n到这一步，前三页不显示第几页共几页的页脚了，但后面算页码时还是会将这几页计算进去 此时要先进入页脚的编辑界面，然后按 Alt+F9,此时此时页脚显示为“第 { PAGE } 页 共 { NUMPAGES } 页”，光标选中‘第’和‘共’之间的全部内容，然后按下 Ctrl+F9，页码会转为域代码，其实就是在外面加了一对大括号，即“共 { NUMPAGES } 页”变为“共 { { NUMPAGES } }页” 将其修改为共 { ={ NUMPAGES }-3 }页即可，注意空格的位置！\\n同理对第几页的 PAGE 同样操作即可\\n\"",
      categories: "[\"工具使用\"]",
      tags: [],
      series: [],
      date: "\"2021-04-03\""
    });
  
    searchIndex.push({
      title: "\"Markdown Demo\"",
      permalink: "\"/%E6%B5%8B%E8%AF%95/markdown-demo/\"",
      content: "\" KSimple Ksimple 是在 hugo-xmin 基础上修改而来一个 hugo 主题，加入了目录、xmind、mermaid/plantuml等代码渲染图片、代码块高亮复制折叠、模糊查找、评论系统以及其他各类元素样式定制，整体风格力求简约而实用。\\n样式一览 基本元素 Bold， Italic， Highlight，highlight，H2O2，X^2^，++insert++，Delete，\\u0026#x26fa;，😘， Inline Code\\nReference1, Reference22\\nthis is a blockquote\\n标题引用 ， 标题引用2 ：标题名去掉特殊字符(除了-和空格之外的所有，包括但不限于逗号、括号、冒号等)，英文全小写，空格用-替代，然后加上#就是对应的链接了\\n公式与内联公式 Tip 内联公式支持 \\\\(...\\\\) 和 $...$ 两种写法； 单行公式支持 $$...$$、\\\\[...\\\\]、\\\\begin{equation}...\\\\end{equation} 等等多种写法 具体定制参见 https://cdn.jsdelivr.net/gh/captainwc/cdn-release/website/js/auto-render.min.js \\\\(x^2 + y^2 = 1\\\\)，$ \\\\frac{x^2}{5} + \\\\frac{y^2}{3} = 1$\\n$${\\\\sqrt {n}}\\\\left(\\\\left({\\\\frac {1}{n}}\\\\sum _{i=1}^{n}X_{i}\\\\right)-\\\\mu \\\\right)\\\\ {\\\\xrightarrow {d}}\\\\ N\\\\left(0,\\\\sigma ^{2}\\\\right)$$代码块 #include\\u0026lt;iostream\\u0026gt; using namespace std; int main(){ cout\\u0026lt;\\u0026lt;\\u0026quot;hello hugo\\\\n\\u0026quot;; return 0; } - hallo + hello 列表 list item Todo List todo1\\ntodo2\\ntodo3\\n更推荐下面的用法：\\nHow to use this theme？ git clone modify the hugo.yaml create notes push and public 未来三天计划： 玩一天 玩两天 玩三天 PlantUML 类图 @startuml interface Scriptable{ toSmtLib():String } class SmtScript{ -functions:List\\u0026lt;Function\\u0026gt; -addFunction(Function):void } abstract class Expr{ -node:ASTRootNode -children:List\\u0026lt;Expr\\u0026gt; } enum ConstExpr class CompoundExpr{ +getOp():String } struct ComplexExpr{ -format:String } class Function{ - funcName:string - args:List\\u0026lt;Pair\\u0026lt;String,String\\u0026gt;\\u0026gt; - returnType:String - funcBody:Expr } Scriptable \\u0026lt;|.. SmtScript Scriptable \\u0026lt;|.. Function Scriptable \\u0026lt;|.. Expr Expr \\u0026lt;|-- ConstExpr Expr \\u0026lt;|-- CompoundExpr Expr \\u0026lt;|-- ComplexExpr Expr \\u0026lt;-- Function SmtScript \\u0026quot;1\\u0026quot;--\\u0026gt;\\u0026quot;1..*\\u0026quot; Function @enduml 时序图 @startuml actor 用户 as user participant PtolemyII as ptii participant 验证选项配置器 as config participant 模型解与预校验器 as parser participant 形式化验证器 as verifier user -\\u0026gt; ptii++: 打开PtolemyII建模工具 ptii-\\u0026gt;ptii: 打开/创建模型 return 模型持久化XML文件 user -\\u0026gt; config++: 配置验证选项，启动验证过程 config -\\u0026gt; parser--++: 解析与校验模型 alt 校验失败 parser --\\u0026gt; user: 返回校验错误信息 else 校验通过 parser -\\u0026gt; verifier--++: 启动形式化验证 verifier --\\u0026gt;user--: 返回验证结果 end @enduml ebnf @startebnf Type = PrimitiveType | ReferenceType; PrimitiveType = [Annotation], (NumericType | boolean ); @endebnf 思维导图 @startmindmap title 需求分解 * \\u0026lt;\\u0026amp;star\\u0026gt;add_argument **:\\u0026lt;code\\u0026gt; add_argument(\\u0026quot;\\u0026quot;, \\u0026quot;\\u0026quot;, .type=, .help=,) \\u0026lt;/code\\u0026gt;; *** 优点：跟python很像 *** 缺点 ****_ 靠结构体的这个提示，没有约束 ****_ 结构体赋值没法跳过，也就是说必须全部指定 **:\\u0026lt;code\\u0026gt; add_argument(name) .help() .type() .default_value() \\u0026lt;/code\\u0026gt;; *** 优点：方便定制，类似java里面的\\u0026lt;b\\u0026gt;builder\\u0026lt;/b\\u0026gt;模式 *** 缺点：\\u0026lt;s\\u0026gt;好像其实也没啥明显缺点 * add_parser ** action *** 首先需要像位置参数那样添加 ** 返回 sub_parser *** 多个sub_parser添加/获取参数 ****_:学python的话，可以认为同时只有一个sub_parser， 进而参数存一块也是可以的; *** help信息 * help ** 格式化打印 *** 找最长的argument *** argument按照加入顺序排序 @endmindmap \\u0026hellip;\\u0026hellip;\\nMermaid Mermaid图表使用 mermaid.js 进行渲染\\nReference 语法参考 MermaidIntro-ZH 流程图 (graph/flowchart) --- title: 流程图示例 --- graph TB subgraph subgraph1 direction LR A[A] e1@--\\u0026gt;|comment| B(B) \\u0026amp; C((C)) -.-\\u0026gt; D{{D}} \\u0026amp; E[(E)] ==\\u0026gt; F{F} end subgraph subgraph2 direction LR O[/O\\\\] -- comment2 --o G[\\\\G/] -. comment3 .-x H[\\\\H\\\\] G \\u0026lt;---\\u0026gt; I\\u0026gt;I] end subgraph1 edge002@==\\u0026gt; subgraph2 e1@{ animate: true } edge002@{ animate: true } 时序图 (sequenceDiagram) sequenceDiagram Alice-\\u0026gt;\\u0026gt;+Bob: Hello Bob, how are you ? Bob--\\u0026gt;\\u0026gt;-Alice: Fine, thank you. And you? create participant Carl Alice-\\u0026gt;\\u0026gt;Carl: Hi Carl! create actor D as Donald Carl-)D: Hi! destroy Carl Alice-xCarl: We are too many destroy Bob Bob--)Alice: I agree 状态图 (stateDiagram-v2) --- config: theme: forest --- stateDiagram direction LR [*] --\\u0026gt; Still Still --\\u0026gt; [*] Still --\\u0026gt; Moving Moving --\\u0026gt; Still Moving --\\u0026gt; Crash Crash --\\u0026gt; [*] Moving: Moving Moving: Move to A Moving: Move to B 框图 (block-beta) --- config: theme: default --- block-beta %% 总列数 columns 3 %% 指定某一元素占据多少列 a b(\\u0026quot;b\\u0026quot;):2 %% 可以将多个元素组合成一个块，指定块占据的列数，块内再次细分列数 block:group1:2 columns 3 h i j down\\u0026lt;[\\u0026quot; \\u0026quot;]\\u0026gt;(down) space:2 k end %% 框图里面的lable必须加上双引号 g(((\\u0026quot;This is a circle\\u0026quot;))) block:group2:3 %% columns auto (default) l left\\u0026lt;[\\u0026quot; \\u0026quot;]\\u0026gt;(left) m n space o p blockArrowId6\\u0026lt;[\\u0026quot; \\u0026quot;]\\u0026gt;(right) q r end m --\\u0026gt; o 思维导图 (mindmap) --- config: theme: default --- mindmap A((root)) B{{B}} C D E F G 雷达图 (radar-beta) --- title: \\u0026quot;Grades\\u0026quot; config: theme: default --- radar-beta axis m[\\u0026quot;C++\\u0026quot;], s[\\u0026quot;Python\\u0026quot;], e[\\u0026quot;Java\\u0026quot;] axis h[\\u0026quot;C#\\u0026quot;], g[\\u0026quot;Shell\\u0026quot;], a[\\u0026quot;JavaScript\\u0026quot;] curve a[\\u0026quot;Alice\\u0026quot;]{99, 90, 50, 10, 80, 30} curve b[\\u0026quot;Bob\\u0026quot;]{20, 70, 20, 60, 20, 99} curve b[\\u0026quot;Mike\\u0026quot;]{0, 90, 10, 30, 70, 90} max 100 min 0 饼图 (pie) --- config: theme: default --- pie title 示例饼图 \\u0026quot;类别A\\u0026quot; : 40 \\u0026quot;类别B\\u0026quot; : 30 \\u0026quot;类别C\\u0026quot; : 20 \\u0026quot;类别D\\u0026quot; : 10 看板图 (kanban) --- config: theme: default --- kanban todo A[task A]@{ticket: 2025-04-11, priority: 'Very Low', assigned: 'zhangsan'} B[task B is a task named B, which is a quiet normal name]@{ticket: 2025-04-12, priority: 'Very High', assigned: 'lisi'} progress C[task C]@{ticket: 2025-04-07, assigned: 'wangermazi'} done D[task D]@{ticket: 2025-04-01, priority: 'Low', assigned: 'wangermazi'} D[task D]@{ticket: 2025-04-03, priority: 'High'} 甘特图 (gantt) --- config: theme: forest --- gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid excludes weekends %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\\u0026quot;sunday\\u0026quot;) or \\u0026quot;weekends\\u0026quot;, but not the word \\u0026quot;weekdays\\u0026quot;.) section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :until isadded Functionality added :milestone, isadded, 2014-01-25, 0d section Documentation Describe gantt syntax :active, a1, after des1, 3d Add gantt diagram to demo page :after a1 , 20h Add another diagram to demo page :doc1, after a1 , 48h section Last section Describe gantt syntax :after doc1, 3d Add gantt diagram to demo page :20h Add another diagram to demo page :48h Xmind嵌入 使用 xmind-embed-viewer 项目来渲染你的xmind文件，支持本地文件和远程文件。\\n使用方法如下，就是用xmind代码块里面填上xmind文件链接就好，比如\\n```xmind /xmind/demo.xmdin ``` 效果如下\\n/xmind/demo.xmind Warning 或许是xmind-embed-viewer的限制，当前支支持思维导图，对于其他图形如逻辑图、括号图、鱼骨图等，当前并不支持（布局会混乱）\\nMarkMap渲染 使用 Markmap.js 渲染思维导图，效果如下：\\n--- title: markmap markmap: colorFreezeLevel: 2 --- ## Links - [Website](https://markmap.js.org/) - [GitHub](https://github.com/gera2ld/markmap) ## Related Projects - [coc-markmap](https://github.com/gera2ld/coc-markmap) for Neovim - [markmap-vscode](https://marketplace.visualstudio.com/items?itemName=gera2ld.markmap-vscode) for VSCode - [eaf-markmap](https://github.com/emacs-eaf/eaf-markmap) for Emacs ## Features Note that if blocks and lists appear at the same level, the lists will be ignored. ### Lists - **strong** ~~del~~ *italic* ==highlight== - `inline code` - [x] checkbox-selected - [ ] checkbox-nonselected - Katex: $x = {-b \\\\pm \\\\sqrt{b^2-4ac} \\\\over 2a}$ \\u0026lt;!-- markmap: fold --\\u0026gt; - [More Katex Examples](#?d=gist:af76a4c245b302206b16aec503dbe07b:katex.md) - Now we can wrap very very very very long text based on `maxWidth` option - Ordered list 1. item 1 2. item 2 ### Blocks `console.log('hello, JavaScript')` | Products | Price | |-|-| | Apple | 4 | | Banana | 2 | ![](https://markmap.js.org/favicon.png) 至此，已有四种方式实现思维导图：\\n使用Plantuml (效果太简单，但是语法也很简单直观) 使用Mermaid (效果太花哨，像脑图云图之类的) 使用Markmind (简单且相对效果较好) 使用Xmind，本地编辑好后上传上来进行渲染 (效果最好，但是缺点也很明显，是二进制文件，不好用git管理，需要额外打开xmind进行编辑, 同时网页加载也比较慢)。可以根据场景自行取舍，选择最适合的使用) Kroki渲染 Kroki 支持mermaid, plantuml, graphviz, dbml \\u0026hellip; 等很多图表，具体的例子参考 kroki-examples 。\\n（不过本站 mermaid 由 mermaid.js 进行渲染，支持更多类型、更多定制、更快；plantuml 使用 plantuml-encoder.js 获取直链，更原汁原味。）\\ngraphviz digraph D { subgraph cluster_p { label = \\u0026quot;Kroki\\u0026quot;; subgraph cluster_c1 { label = \\u0026quot;Server\\u0026quot;; Filebeat; subgraph cluster_gc_1 { label = \\u0026quot;Docker/Server\\u0026quot;; Java; } subgraph cluster_gc_2 { label = \\u0026quot;Docker/Mermaid\\u0026quot;; \\u0026quot;Node.js\\u0026quot;; \\u0026quot;Puppeteer\\u0026quot;; \\u0026quot;Chrome\\u0026quot;; } } subgraph cluster_c2 { label = \\u0026quot;CLI\\u0026quot;; Golang; } } } 流程图 blockdiag { Kroki -\\u0026gt; generates -\\u0026gt; \\u0026quot;Block diagrams\\u0026quot;; Kroki -\\u0026gt; is -\\u0026gt; \\u0026quot;very easy!\\u0026quot;; } 时序图 seqdiag { browser -\\u0026gt; webserver [label = \\u0026quot;GET /seqdiag/svg/base64\\u0026quot;]; webserver -\\u0026gt; processor [label = \\u0026quot;Convert text to image\\u0026quot;]; webserver \\u0026lt;-- processor; browser \\u0026lt;-- webserver; } 泳道图 actdiag { write -\\u0026gt; convert -\\u0026gt; image lane user { label = \\u0026quot;User\\u0026quot; write [label = \\u0026quot;Writing text\\u0026quot;]; image [label = \\u0026quot;Get diagram image\\u0026quot;]; } lane Kroki { convert [label = \\u0026quot;Convert text to image\\u0026quot;]; } } 词云图(vega实现) 图片排版 借用超链接实现浮动 [\\u0026lt;\\u0026lt;img src=\\u0026quot;xxx\\u0026quot; alt=\\u0026quot;\\u0026quot; style=\\u0026quot;max-width: 50%; float:right;\\u0026quot;\\u0026gt;\\u0026gt;]() 效果看上面那个 github 头像即可\\ndiv flex 直接指定样式 \\u0026lt;div style=\\u0026quot;display: flex; gap: 2px; justify-content: center\\u0026quot;\\u0026gt; \\u0026lt;img src=\\u0026quot;aaa\\u0026quot; alt=\\u0026quot;\\u0026quot; style=\\u0026quot;max-width: 50%;\\u0026quot;\\u0026gt; \\u0026lt;img src=\\u0026quot;bbb\\u0026quot; alt=\\u0026quot;\\u0026quot; style=\\u0026quot;max-width: 50%;\\u0026quot;\\u0026gt; \\u0026lt;/div\\u0026gt; 使用预定义样式 img-align 只需指定div的class为img-align，它会自动将元素均分为n份填充，横向排版。\\n僵硬的地方在于，固定是均分的，所以更适合几张图片大小差不多的情况，否则可能不太协调。\\n\\u0026lt;div class='img-align'\\u0026gt; \\u0026lt;img src=\\u0026quot;aaa\\u0026quot;\\u0026gt; \\u0026lt;img src=\\u0026quot;bbb\\u0026quot;\\u0026gt; \\u0026lt;/div\\u0026gt; TODO: 定制 Shotcode ShortCodes 内嵌多媒体 内嵌网页 emb-web 用法及效果如下。第二个参数是iframe的宽度，默认值是 50vh\\n\\u0026lt;!--实际上应该用{，但是在代码块里的也会被解析，所以用[示意--\\u0026gt; [[\\u0026lt; emb-web \\u0026quot;https://kaikaixixi.xyz\\u0026quot; 36 \\u0026gt;]] 内嵌图片 emb-img 可以嵌入一些长图。原理是先用图片填充满一个临时html，然后将这个html嵌入到iframe中\\n目录 暂时不打算给博客添加目录 还是做目录了，鼠标悬浮右上角目录按钮，自动弹出目录框并将当前标题滚动到中间位置\\nTip 可以考虑推荐使用浏览器插件 OneToc ，有快捷键 Toggle 的功能，效果已经非常不错了也还可以。\\n版权声明 以下 callout 块相关的内容（包括本博客的实现）全部来自具有MIT开源协议的 hugo-admonitions 主题，详情请参考原主题！\\nCallout 块展示 Nosupport Helpful advice for doing things better or more easily.\\nGitHub Test Note Useful information that users should know, even when skimming content.\\nTip Helpful advice for doing things better or more easily.\\nImportant Key information users need to know to achieve their goal.\\nWarning Urgent info that needs immediate user attention to avoid problems.\\nCaution Advises about risks or negative outcomes of certain actions.\\nCallout Overview Abstract Abstract: This paper discusses the advantages and challenges of microservice architecture.\\nCaution Advises about risks or negative outcomes of certain actions.\\nCode Code snippet:\\nfunction fetchData() { return axios.get(\\u0026quot;/api/data\\u0026quot;); } Conclusion Conclusion: Based on the analysis above, we\\u0026rsquo;ve decided to implement Docker containerization.\\nDanger Danger! Critical security vulnerability detected in the system. Immediate action required.\\nError Error: Unable to connect to database. Please check your connection settings.\\nExample Example:\\ndef hello_world(): print(\\u0026quot;Hello, World!\\u0026quot;) Experiment Experiment: Testing the impact of new caching strategies on system performance.\\nGoal Goal: Reduce service response time by 30% by the end of this quarter.\\nIdea Idea: Implement a machine learning-based code quality detection system.\\nImportant Key information users need to know to achieve their goal.\\nInfo System status: All services are operating normally. Current uptime: 99.99%.\\nMemo Memo: Technical review meeting scheduled for next Tuesday at 2:00 PM.\\nNote Useful information that users should know, even when skimming content.\\nNotification System notification: Your password will expire in 30 days.\\nQuestion Question: How can we optimize database query performance?\\nQuote \\u0026ldquo;Code is like humor. When you have to explain it, it\\u0026rsquo;s bad.\\u0026rdquo; - Cory House\\nSuccess Congratulations! Your code has been successfully deployed to production.\\nTask To-do list:\\nUpdate documentation Deploy new version Tip Helpful advice for doing things better or more easily.\\nWarning Urgent info that needs immediate user attention to avoid problems.\\nTODO This is a todo list\\nFLAG This is a flag\\nBUG This is a bug\\nReference Here are all the references\\nMessage Please read these message\\nAI Generated by qwen deepseek chatgpt etc\\nTL;DR Too long dont read\\nCustomization Choose a callout you prefer and add a title\\nSummary This is a summary using the TIP callout!\\nSummary This is a summary using the IDEA callout!\\nHeader Only Mode You can choose to only to show the header!\\nThis paper discusses the advantages of microservice architecture Ensure all tests pass before merging to main branch Execute npm install to install all dependencies We\\u0026rsquo;ve decided to implement Docker containerization Critical security vulnerability detected in the system Error: Unable to connect to database. Please check your connection settings Git commit message format: \\u0026ldquo;feat: add user authentication\\u0026rdquo; Testing new caching strategy with Redis Reduce service response time by 30% by the end of this quarter Implement a machine learning-based code quality detection system Please review and update your security settings Current system status: All services are operating normally with 99.9% uptime Technical review meeting scheduled for next Tuesday at 2:00 PM Always backup your data before performing system updates System notification: Your password will expire in 30 days How can we optimize database query performance? \\u0026ldquo;Code is like humor. When you have to explain it, it\\u0026rsquo;s bad.\\u0026rdquo; - Cory House Congratulations! Your code has been successfully deployed to production Review and update API documentation by Friday Use Ctrl + C to quickly terminate a running program Warning: This operation will delete all data This is a todo list This is a flag You found a bug Refer to wikipieda A message for my readers Generate by deepseek Too long dont read This is the first reference。Alought it placed at the middle of markdown source, it will be move to the end of the html.\\u0026#160;\\u0026#x21a9;\\u0026#xfe0e;\\nAnd this is the second one\\u0026#160;\\u0026#x21a9;\\u0026#xfe0e;\\n\"",
      categories: [],
      tags: "[\"markdown\"]",
      series: [],
      date: "\"2021-02-15\""
    });
  
    searchIndex.push({
      title: "\"常用数学符号的latex表示\"",
      permalink: "\"/%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/%E5%B8%B8%E7%94%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E7%9A%84latex%E8%A1%A8%E7%A4%BA/\"",
      content: "\"常用数学符号 符号 语法 符号 语法 \\\\(\\\\infty\\\\) \\\\infty \\\\(\\\\vec{s}\\\\) \\\\vec{s} \\\\(\\\\dot{a}\\\\) \\\\dot{a} \\\\(\\\\ddot{a}\\\\) \\\\ddot{a} \\\\(\\\\rightarrow\\\\) \\\\righrarrow \\\\(\\\\Rightarrow\\\\) \\\\Rightarrow \\\\(\\\\ldots\\\\) \\\\ldots \\\\(\\\\cdots\\\\) \\\\cdots \\\\(\\\\vdots\\\\) \\\\vdots \\\\(\\\\ddots\\\\) \\\\ddots \\\\(\\\\geq\\\\) \\\\geq \\\\(\\\\leq\\\\) \\\\leq \\\\(\\\\neq\\\\) \\\\neq \\\\(\\\\approx\\\\) \\\\approx \\\\(\\\\equiv\\\\) \\\\equiv \\\\(\\\\in\\\\) \\\\in \\\\(\\\\notin\\\\) \\\\notin \\\\(\\\\subset\\\\) \\\\subset \\\\(\\\\supset\\\\) \\\\supset \\\\(\\\\subseteq\\\\) \\\\subseteq \\\\(\\\\subsetneq\\\\) \\\\subsetneq \\\\(\\\\cup\\\\) \\\\cup \\\\(\\\\cap\\\\) \\\\cap \\\\(\\\\bigodot\\\\) \\\\bigodot \\\\(\\\\bigotimes\\\\) \\\\bigotimes \\\\(\\\\emptyset\\\\) \\\\emptyset \\\\(\\\\R\\\\) \\\\R \\\\(\\\\Z\\\\) \\\\Z \\\\(\\\\times\\\\) \\\\times \\\\(\\\\div\\\\) \\\\div \\\\(\\\\pm\\\\) \\\\pm \\\\(\\\\mp\\\\) \\\\mp \\\\(\\\\cdot\\\\) \\\\cdot \\\\(\\\\ast\\\\) \\\\ast \\\\(\\\\underline{apple}\\\\) \\\\underline{apple} \\\\(\\\\overline{x+y}\\\\) \\\\overline{x+y} \\\\(\\\\overbrace{a+b+c}^{3.0}\\\\) \\\\overbrace{a+b+c}^{3.0} \\\\(\\\\underbrace{a+b}\\\\_{2}\\\\) \\\\underbrace{a+b}_2 \\\\(\\\\mbox{汉字}\\\\) \\\\mbox{汉字} \\\\(\\\\prime\\\\) \\\\prime \\\\(\\\\iint\\\\) \\\\iint \\\\(\\\\iiint\\\\) \\\\iiint \\\\(\\\\oint\\\\) \\\\oint \\\\(\\\\partial\\\\) \\\\partial \\\\(\\\\lceil{a}\\\\rceil\\\\) \\\\lceil {a} \\\\rceil \\\\(\\\\lfloor{b}\\\\rfloor\\\\) \\\\lfloor {b} \\\\rfloor \\\\(a\\\\quad b\\\\) a\\\\quad b \\\\(a\\\\qquad b\\\\) a\\\\qquad b \\\\(a\\\\;b\\\\) a;b \\\\(\\\\bigg(\\\\quad \\\\Bigg]\\\\) \\\\bigg( \\\\quad \\\\Bigg] \\\\(\\\\langle{a,b}\\\\rangle\\\\) \\\\langle{a,b}\\\\rangle 常用运算 极限：\\\\displaystyle \\\\lim_{x_\\\\to \\\\infty}{\\\\frac{3x^2+2}{4x^2+3x+1}}\\\\tag{1} \\\\lim\\n$$\\\\displaystyle\\\\lim_{x_\\\\to \\\\infty}{\\\\frac{3x^2+2}{4x^2+3x+1}}\\\\tag{1}$$积分：\\\\displaystyle \\\\int_{0}^{\\\\pi}{(sinx+cosx)dx}\\\\tag{2} \\\\int\\n$$\\\\displaystyle\\\\int_{0}^{\\\\pi}{(sinx+cosx)dx}\\\\tag{2}$$求和：\\\\displaystyle\\\\sum_{i=0}^n{i^2+i}\\\\tag{3} \\\\sum\\n$$\\\\displaystyle\\\\sum_{i=0}^n{i^2+i}\\\\tag{3}$$开方：\\\\sqrt[3]{x^2+3x}\\\\tag{4} \\\\sqrt\\n$$\\\\sqrt[3]{x^2+3x}\\\\tag{4}$$组合：{n+1\\\\choose k}={n\\\\choose k}+{n\\\\choose k-1}\\\\tag{5} \\\\choose\\n$${n+1\\\\choose k}={n \\\\choose k}+{n\\\\choose k-1}\\\\tag{5}$$矩阵： \\\\left(\\\\begin{matrix} \\u0026amp;1 \\u0026amp;2 \\u0026amp;\\\\cdots \\u0026amp;5\\\\\\\\ \\u0026amp;6 \\u0026amp;7 \\u0026amp;\\\\cdots \\u0026amp;10\\\\\\\\ \\u0026amp;\\\\vdots \\u0026amp;\\\\vdots \\u0026amp;\\\\ddots \\u0026amp;\\\\vdots\\\\\\\\ \\u0026amp;16 \\u0026amp;17 \\u0026amp;\\\\cdots \\u0026amp;20 \\\\end{matrix}\\\\right) ( \\\\begin{matrix}\\u0026amp; \\u0026amp; \\u0026amp;\\\\\\\\\\u0026amp; \\u0026amp; \\u0026amp; \\\\end{martix} )\\n$$\\\\left(\\\\begin{matrix}\\u00261\\u00262\\u0026\\\\cdots\\u00265\\\\\\\\\\u00266\\u00267\\u0026\\\\cdots\\u002610\\\\\\\\\\u0026\\\\vdots\\u0026\\\\vdots\\u0026\\\\ddots\\u0026\\\\vdots\\\\\\\\\\u002616\\u002617\\u0026\\\\cdots\\u002620\\\\end{matrix}\\\\right)$$希腊字母 大写只需将首字母换为大写即可\\n\\\\alpha \\\\beta \\\\gamma \\\\delta \\\\zeta \\\\eta \\\\theta \\\\epsilon\\n\\\\kappa \\\\lambda \\\\mu \\\\nu \\\\xi \\\\pi \\\\rho \\\\sigma\\n\\\\phi \\\\varphi \\\\psi \\\\omega \\\\varepsilon\\n$$ \\\\alpha\\\\quad\\\\beta\\\\quad\\\\gamma\\\\quad\\\\delta\\\\quad\\\\zeta\\\\quad\\\\eta\\\\quad\\\\theta\\\\quad\\\\epsilon\\\\\\\\\\\\kappa\\\\quad\\\\lambda\\\\quad\\\\mu\\\\quad\\\\nu\\\\quad\\\\xi\\\\quad\\\\pi\\\\quad\\\\rho\\\\quad\\\\sigma\\\\\\\\ \\\\phi\\\\quad\\\\varphi\\\\quad\\\\psi\\\\quad\\\\omega\\\\quad\\\\varepsilon $$$$ \\\\Alpha\\\\quad\\\\Beta\\\\quad\\\\Gamma\\\\quad\\\\Delta\\\\quad\\\\Zeta\\\\quad\\\\Eta\\\\quad\\\\Theta\\\\quad\\\\Epsilon\\\\\\\\\\\\Kappa\\\\quad\\\\Lambda\\\\quad\\\\Mu\\\\quad\\\\Nu\\\\quad\\\\Xi\\\\quad\\\\Pi\\\\quad\\\\Rho\\\\quad\\\\Sigma\\\\\\\\ \\\\Phi\\\\quad\\\\varphi\\\\quad\\\\Psi\\\\quad\\\\Omega\\\\quad\\\\varepsilon $$\"",
      categories: "[\"工具使用\"]",
      tags: "[\"latex\",\"markdown\"]",
      series: [],
      date: "\"2021-02-15\""
    });
  

  debug("当前本站共有 " + searchIndex.length + " 篇文章");
  console.log("搜索索引:", searchIndex);

  
  const options = {
    includeScore: true,
    threshold: 0.6, 
    keys: [
      { name: 'title', weight: 0.7 },
      { name: 'content', weight: 0.3 },
      { name: 'tags', weight: 0.5 },
      { name: 'categories', weight: 0.5 },
      { name: 'series', weight: 0.5 }
    ]
  };

  
  const fuse = new Fuse(searchIndex, options);

  document.addEventListener('keydown', function(event) {
    if (event.key === 'Escape') {
      document.getElementById('search-input').value = "";
      var res = document.getElementById('search-results');
      while (res.firstChild) {
        res.removeChild(res.firstChild);
      }
      debug("当前本站共有 " + searchIndex.length + " 篇文章");
      document.getElementById('search-input').focus();
    }
  });

  
  document.getElementById('search-input').addEventListener('input', function(e) {
    const searchTerm = e.target.value.trim();
    const resultsContainer = document.getElementById('search-results');

    
    resultsContainer.innerHTML = '';

    if (searchTerm === '') {
        debug("当前本站共有 " + searchIndex.length + " 篇文章");
      return;
    }

    debug("搜索词: '" + searchTerm + "'");

    
    const results = fuse.search(searchTerm);
    debug("找到 " + results.length + " 条结果");
    console.log("搜索结果:", results);

    if (results.length === 0) {
      resultsContainer.innerHTML = '<p>没有找到相关文章</p>';
      return;
    }

    results.forEach(result => {
      const item = result.item;
      const resultItem = document.createElement('div');
      resultItem.className = 'search-result-item';

      const date = document.createElement('span');
      date.textContent = item.date.replace(/^"|"$/g, '') + '   ';
      date.className = 'search-result-date';

      const link = document.createElement('a');
      link.href = item.permalink.replace(/^"|"$/g, '');
      link.textContent = item.title.replace(/^"|"$/g, '');
      link.className = 'search-result-title';

      resultItem.appendChild(date);
      resultItem.appendChild(link);
      resultsContainer.appendChild(resultItem);
    });
  });
</script>

<style>
 
.search-container {
    margin: 2rem 0;
    text-align: left;
}

#search-input {
    width: 100%;
    padding: 0.8rem;
    font-size: 1rem;
    border: 1px solid #ddd;
    border-radius: 4px;
    margin-bottom: 1rem;
}

.search-results-list {
    list-style: none;
    padding: 0;
    margin: 1rem 0;
}

.search-result-item {
    padding: 0.7rem;
    margin-bottom: 0.5rem;
    border-bottom: 1px solid #eee;
    display: flex;
    align-items: center;
}

.search-result-date {
    color: #666;
    font-size: 1.1rem;
    margin-right: 0.5rem;
    text-wrap: nowrap;
}

.search-result-title {
    font-weight: bold;
    color: #1a73e8;
    text-decoration: none;
}

.search-result-title:hover {
    text-decoration: underline;
}
</style>

<footer>
  
  <hr />
  © 
<a href="https://kaikaixixi.xyz"  target="_blank" rel="noopener noreferrer" >SHUAIKAI</a>
 2021 &ndash; 2025 | 🎨
<a href="https://github.com/captainwc/ksimple"  target="_blank" rel="noopener noreferrer" >KSimple</a>
  

</footer>
</body>

</html>
